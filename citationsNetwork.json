{
    "links": [
        {
            "source": 0,
            "target": 1
        },
        {
            "source": 2,
            "target": 3
        },
        {
            "source": 3,
            "target": 4
        },
        {
            "source": 3,
            "target": 5
        },
        {
            "source": 3,
            "target": 6
        },
        {
            "source": 3,
            "target": 7
        },
        {
            "source": 3,
            "target": 8
        },
        {
            "source": 8,
            "target": 3
        },
        {
            "source": 3,
            "target": 9
        },
        {
            "source": 3,
            "target": 10
        },
        {
            "source": 3,
            "target": 11
        },
        {
            "source": 3,
            "target": 12
        },
        {
            "source": 3,
            "target": 13
        },
        {
            "source": 3,
            "target": 1
        },
        {
            "source": 14,
            "target": 10
        },
        {
            "source": 14,
            "target": 15
        },
        {
            "source": 14,
            "target": 1
        },
        {
            "source": 16,
            "target": 17
        },
        {
            "source": 16,
            "target": 1
        },
        {
            "source": 18,
            "target": 10
        },
        {
            "source": 19,
            "target": 20
        },
        {
            "source": 19,
            "target": 1
        },
        {
            "source": 21,
            "target": 1
        },
        {
            "source": 22,
            "target": 23
        },
        {
            "source": 24,
            "target": 23
        },
        {
            "source": 25,
            "target": 12
        },
        {
            "source": 25,
            "target": 10
        },
        {
            "source": 24,
            "target": 10
        },
        {
            "source": 25,
            "target": 26
        },
        {
            "source": 25,
            "target": 27
        },
        {
            "source": 28,
            "target": 29
        },
        {
            "source": 28,
            "target": 30
        },
        {
            "source": 28,
            "target": 31
        },
        {
            "source": 28,
            "target": 32
        },
        {
            "source": 28,
            "target": 33
        },
        {
            "source": 28,
            "target": 34
        },
        {
            "source": 28,
            "target": 35
        },
        {
            "source": 28,
            "target": 36
        },
        {
            "source": 28,
            "target": 37
        },
        {
            "source": 28,
            "target": 38
        },
        {
            "source": 39,
            "target": 28
        },
        {
            "source": 39,
            "target": 37
        },
        {
            "source": 40,
            "target": 28
        },
        {
            "source": 40,
            "target": 37
        },
        {
            "source": 41,
            "target": 28
        },
        {
            "source": 41,
            "target": 37
        },
        {
            "source": 42,
            "target": 28
        },
        {
            "source": 42,
            "target": 37
        },
        {
            "source": 28,
            "target": 43
        },
        {
            "source": 28,
            "target": 44
        },
        {
            "source": 28,
            "target": 45
        },
        {
            "source": 28,
            "target": 46
        },
        {
            "source": 28,
            "target": 47
        },
        {
            "source": 28,
            "target": 14
        },
        {
            "source": 39,
            "target": 47
        },
        {
            "source": 40,
            "target": 47
        },
        {
            "source": 41,
            "target": 47
        },
        {
            "source": 42,
            "target": 47
        },
        {
            "source": 28,
            "target": 48
        },
        {
            "source": 28,
            "target": 49
        },
        {
            "source": 28,
            "target": 50
        },
        {
            "source": 28,
            "target": 51
        },
        {
            "source": 28,
            "target": 52
        },
        {
            "source": 28,
            "target": 53
        },
        {
            "source": 28,
            "target": 54
        },
        {
            "source": 28,
            "target": 55
        },
        {
            "source": 28,
            "target": 56
        },
        {
            "source": 28,
            "target": 57
        },
        {
            "source": 28,
            "target": 58
        },
        {
            "source": 28,
            "target": 59
        },
        {
            "source": 28,
            "target": 1
        },
        {
            "source": 60,
            "target": 1
        },
        {
            "source": 61,
            "target": 62
        },
        {
            "source": 61,
            "target": 63
        },
        {
            "source": 63,
            "target": 62
        },
        {
            "source": 63,
            "target": 64
        },
        {
            "source": 65,
            "target": 22
        },
        {
            "source": 65,
            "target": 64
        },
        {
            "source": 65,
            "target": 20
        },
        {
            "source": 63,
            "target": 66
        },
        {
            "source": 61,
            "target": 29
        },
        {
            "source": 61,
            "target": 30
        },
        {
            "source": 61,
            "target": 31
        },
        {
            "source": 63,
            "target": 29
        },
        {
            "source": 63,
            "target": 30
        },
        {
            "source": 63,
            "target": 31
        },
        {
            "source": 65,
            "target": 67
        },
        {
            "source": 61,
            "target": 10
        },
        {
            "source": 63,
            "target": 10
        },
        {
            "source": 65,
            "target": 10
        },
        {
            "source": 61,
            "target": 1
        },
        {
            "source": 63,
            "target": 1
        },
        {
            "source": 65,
            "target": 1
        },
        {
            "source": 68,
            "target": 69
        },
        {
            "source": 68,
            "target": 1
        },
        {
            "source": 70,
            "target": 69
        },
        {
            "source": 70,
            "target": 71
        },
        {
            "source": 72,
            "target": 70
        },
        {
            "source": 70,
            "target": 73
        },
        {
            "source": 70,
            "target": 24
        },
        {
            "source": 70,
            "target": 1
        },
        {
            "source": 74,
            "target": 37
        },
        {
            "source": 75,
            "target": 37
        },
        {
            "source": 76,
            "target": 77
        },
        {
            "source": 74,
            "target": 1
        },
        {
            "source": 78,
            "target": 79
        },
        {
            "source": 80,
            "target": 79
        },
        {
            "source": 37,
            "target": 32
        },
        {
            "source": 37,
            "target": 28
        },
        {
            "source": 37,
            "target": 33
        },
        {
            "source": 37,
            "target": 34
        },
        {
            "source": 37,
            "target": 35
        },
        {
            "source": 37,
            "target": 36
        },
        {
            "source": 37,
            "target": 38
        },
        {
            "source": 37,
            "target": 81
        },
        {
            "source": 37,
            "target": 82
        },
        {
            "source": 70,
            "target": 83
        },
        {
            "source": 37,
            "target": 70
        },
        {
            "source": 37,
            "target": 73
        },
        {
            "source": 37,
            "target": 84
        },
        {
            "source": 37,
            "target": 85
        },
        {
            "source": 37,
            "target": 86
        },
        {
            "source": 37,
            "target": 87
        },
        {
            "source": 37,
            "target": 88
        },
        {
            "source": 37,
            "target": 89
        },
        {
            "source": 37,
            "target": 90
        },
        {
            "source": 37,
            "target": 91
        },
        {
            "source": 37,
            "target": 10
        },
        {
            "source": 74,
            "target": 10
        },
        {
            "source": 37,
            "target": 1
        },
        {
            "source": 92,
            "target": 10
        },
        {
            "source": 93,
            "target": 28
        },
        {
            "source": 93,
            "target": 37
        },
        {
            "source": 94,
            "target": 28
        },
        {
            "source": 23,
            "target": 26
        },
        {
            "source": 95,
            "target": 12
        },
        {
            "source": 95,
            "target": 10
        },
        {
            "source": 87,
            "target": 10
        },
        {
            "source": 23,
            "target": 10
        },
        {
            "source": 95,
            "target": 11
        },
        {
            "source": 23,
            "target": 1
        },
        {
            "source": 96,
            "target": 97
        },
        {
            "source": 96,
            "target": 98
        },
        {
            "source": 96,
            "target": 99
        },
        {
            "source": 96,
            "target": 23
        },
        {
            "source": 96,
            "target": 1
        },
        {
            "source": 100,
            "target": 101
        },
        {
            "source": 100,
            "target": 102
        },
        {
            "source": 100,
            "target": 10
        },
        {
            "source": 100,
            "target": 46
        },
        {
            "source": 100,
            "target": 20
        },
        {
            "source": 100,
            "target": 103
        },
        {
            "source": 100,
            "target": 97
        },
        {
            "source": 104,
            "target": 10
        },
        {
            "source": 105,
            "target": 10
        },
        {
            "source": 106,
            "target": 107
        },
        {
            "source": 108,
            "target": 104
        },
        {
            "source": 104,
            "target": 109
        },
        {
            "source": 105,
            "target": 104
        },
        {
            "source": 105,
            "target": 109
        },
        {
            "source": 104,
            "target": 43
        },
        {
            "source": 105,
            "target": 43
        },
        {
            "source": 106,
            "target": 43
        },
        {
            "source": 104,
            "target": 26
        },
        {
            "source": 105,
            "target": 26
        },
        {
            "source": 105,
            "target": 110
        },
        {
            "source": 105,
            "target": 23
        },
        {
            "source": 104,
            "target": 1
        },
        {
            "source": 111,
            "target": 79
        },
        {
            "source": 112,
            "target": 79
        },
        {
            "source": 46,
            "target": 79
        },
        {
            "source": 112,
            "target": 17
        },
        {
            "source": 112,
            "target": 113
        },
        {
            "source": 46,
            "target": 23
        },
        {
            "source": 46,
            "target": 78
        },
        {
            "source": 46,
            "target": 114
        },
        {
            "source": 46,
            "target": 115
        },
        {
            "source": 46,
            "target": 9
        },
        {
            "source": 66,
            "target": 116
        },
        {
            "source": 66,
            "target": 1
        },
        {
            "source": 117,
            "target": 1
        },
        {
            "source": 74,
            "target": 23
        },
        {
            "source": 14,
            "target": 118
        },
        {
            "source": 74,
            "target": 15
        },
        {
            "source": 74,
            "target": 14
        },
        {
            "source": 14,
            "target": 119
        },
        {
            "source": 14,
            "target": 37
        },
        {
            "source": 120,
            "target": 70
        },
        {
            "source": 120,
            "target": 73
        },
        {
            "source": 121,
            "target": 69
        },
        {
            "source": 69,
            "target": 83
        },
        {
            "source": 69,
            "target": 63
        },
        {
            "source": 122,
            "target": 123
        },
        {
            "source": 122,
            "target": 124
        },
        {
            "source": 122,
            "target": 69
        },
        {
            "source": 69,
            "target": 124
        },
        {
            "source": 124,
            "target": 122
        },
        {
            "source": 124,
            "target": 123
        },
        {
            "source": 124,
            "target": 69
        },
        {
            "source": 69,
            "target": 70
        },
        {
            "source": 69,
            "target": 26
        },
        {
            "source": 3,
            "target": 17
        },
        {
            "source": 61,
            "target": 11
        },
        {
            "source": 61,
            "target": 12
        },
        {
            "source": 61,
            "target": 13
        },
        {
            "source": 63,
            "target": 11
        },
        {
            "source": 63,
            "target": 12
        },
        {
            "source": 63,
            "target": 13
        },
        {
            "source": 34,
            "target": 28
        },
        {
            "source": 34,
            "target": 33
        },
        {
            "source": 47,
            "target": 54
        },
        {
            "source": 47,
            "target": 28
        },
        {
            "source": 47,
            "target": 33
        },
        {
            "source": 28,
            "target": 125
        },
        {
            "source": 28,
            "target": 126
        },
        {
            "source": 28,
            "target": 94
        },
        {
            "source": 37,
            "target": 125
        },
        {
            "source": 37,
            "target": 54
        },
        {
            "source": 37,
            "target": 126
        },
        {
            "source": 37,
            "target": 94
        },
        {
            "source": 34,
            "target": 82
        },
        {
            "source": 47,
            "target": 82
        },
        {
            "source": 28,
            "target": 127
        },
        {
            "source": 28,
            "target": 82
        },
        {
            "source": 28,
            "target": 128
        },
        {
            "source": 37,
            "target": 127
        },
        {
            "source": 37,
            "target": 128
        },
        {
            "source": 47,
            "target": 34
        },
        {
            "source": 47,
            "target": 32
        },
        {
            "source": 47,
            "target": 48
        },
        {
            "source": 47,
            "target": 74
        },
        {
            "source": 47,
            "target": 37
        },
        {
            "source": 28,
            "target": 74
        },
        {
            "source": 47,
            "target": 14
        },
        {
            "source": 28,
            "target": 129
        },
        {
            "source": 37,
            "target": 14
        },
        {
            "source": 34,
            "target": 56
        },
        {
            "source": 47,
            "target": 56
        },
        {
            "source": 130,
            "target": 56
        },
        {
            "source": 37,
            "target": 57
        },
        {
            "source": 37,
            "target": 58
        },
        {
            "source": 37,
            "target": 59
        },
        {
            "source": 37,
            "target": 56
        },
        {
            "source": 28,
            "target": 78
        },
        {
            "source": 47,
            "target": 35
        },
        {
            "source": 47,
            "target": 36
        },
        {
            "source": 47,
            "target": 38
        },
        {
            "source": 28,
            "target": 81
        },
        {
            "source": 97,
            "target": 14
        },
        {
            "source": 97,
            "target": 31
        },
        {
            "source": 131,
            "target": 10
        },
        {
            "source": 97,
            "target": 10
        },
        {
            "source": 132,
            "target": 28
        },
        {
            "source": 50,
            "target": 28
        },
        {
            "source": 50,
            "target": 33
        },
        {
            "source": 51,
            "target": 28
        },
        {
            "source": 51,
            "target": 33
        },
        {
            "source": 75,
            "target": 28
        },
        {
            "source": 132,
            "target": 37
        },
        {
            "source": 50,
            "target": 37
        },
        {
            "source": 51,
            "target": 37
        },
        {
            "source": 50,
            "target": 32
        },
        {
            "source": 50,
            "target": 34
        },
        {
            "source": 51,
            "target": 32
        },
        {
            "source": 51,
            "target": 34
        },
        {
            "source": 47,
            "target": 133
        },
        {
            "source": 28,
            "target": 133
        },
        {
            "source": 50,
            "target": 47
        },
        {
            "source": 51,
            "target": 47
        },
        {
            "source": 47,
            "target": 49
        },
        {
            "source": 47,
            "target": 50
        },
        {
            "source": 47,
            "target": 51
        },
        {
            "source": 28,
            "target": 134
        },
        {
            "source": 135,
            "target": 28
        },
        {
            "source": 135,
            "target": 37
        },
        {
            "source": 133,
            "target": 32
        },
        {
            "source": 133,
            "target": 28
        },
        {
            "source": 133,
            "target": 37
        },
        {
            "source": 136,
            "target": 28
        },
        {
            "source": 136,
            "target": 37
        },
        {
            "source": 135,
            "target": 47
        },
        {
            "source": 133,
            "target": 47
        },
        {
            "source": 136,
            "target": 47
        },
        {
            "source": 28,
            "target": 23
        },
        {
            "source": 44,
            "target": 37
        },
        {
            "source": 45,
            "target": 37
        },
        {
            "source": 55,
            "target": 28
        },
        {
            "source": 55,
            "target": 37
        },
        {
            "source": 44,
            "target": 23
        },
        {
            "source": 55,
            "target": 57
        },
        {
            "source": 55,
            "target": 56
        },
        {
            "source": 68,
            "target": 70
        },
        {
            "source": 68,
            "target": 137
        },
        {
            "source": 69,
            "target": 137
        },
        {
            "source": 69,
            "target": 138
        },
        {
            "source": 68,
            "target": 139
        },
        {
            "source": 68,
            "target": 140
        },
        {
            "source": 139,
            "target": 68
        },
        {
            "source": 139,
            "target": 140
        },
        {
            "source": 139,
            "target": 69
        },
        {
            "source": 140,
            "target": 68
        },
        {
            "source": 140,
            "target": 139
        },
        {
            "source": 140,
            "target": 69
        },
        {
            "source": 69,
            "target": 68
        },
        {
            "source": 69,
            "target": 139
        },
        {
            "source": 69,
            "target": 140
        },
        {
            "source": 141,
            "target": 85
        },
        {
            "source": 141,
            "target": 86
        },
        {
            "source": 142,
            "target": 85
        },
        {
            "source": 142,
            "target": 86
        },
        {
            "source": 143,
            "target": 85
        },
        {
            "source": 143,
            "target": 86
        },
        {
            "source": 144,
            "target": 85
        },
        {
            "source": 144,
            "target": 86
        },
        {
            "source": 145,
            "target": 85
        },
        {
            "source": 145,
            "target": 86
        },
        {
            "source": 146,
            "target": 85
        },
        {
            "source": 146,
            "target": 86
        },
        {
            "source": 144,
            "target": 147
        },
        {
            "source": 144,
            "target": 16
        },
        {
            "source": 37,
            "target": 148
        },
        {
            "source": 37,
            "target": 149
        },
        {
            "source": 37,
            "target": 16
        },
        {
            "source": 144,
            "target": 37
        },
        {
            "source": 144,
            "target": 23
        },
        {
            "source": 37,
            "target": 23
        },
        {
            "source": 144,
            "target": 1
        },
        {
            "source": 150,
            "target": 10
        },
        {
            "source": 150,
            "target": 151
        },
        {
            "source": 150,
            "target": 12
        },
        {
            "source": 150,
            "target": 43
        },
        {
            "source": 150,
            "target": 79
        },
        {
            "source": 150,
            "target": 82
        },
        {
            "source": 144,
            "target": 56
        },
        {
            "source": 31,
            "target": 152
        },
        {
            "source": 31,
            "target": 153
        },
        {
            "source": 31,
            "target": 154
        },
        {
            "source": 64,
            "target": 70
        },
        {
            "source": 30,
            "target": 10
        },
        {
            "source": 31,
            "target": 10
        },
        {
            "source": 64,
            "target": 10
        },
        {
            "source": 64,
            "target": 69
        },
        {
            "source": 64,
            "target": 65
        },
        {
            "source": 155,
            "target": 1
        },
        {
            "source": 31,
            "target": 1
        },
        {
            "source": 64,
            "target": 1
        },
        {
            "source": 64,
            "target": 22
        },
        {
            "source": 156,
            "target": 68
        },
        {
            "source": 156,
            "target": 69
        },
        {
            "source": 156,
            "target": 70
        },
        {
            "source": 157,
            "target": 70
        },
        {
            "source": 156,
            "target": 158
        },
        {
            "source": 156,
            "target": 159
        },
        {
            "source": 156,
            "target": 160
        },
        {
            "source": 156,
            "target": 161
        },
        {
            "source": 157,
            "target": 156
        },
        {
            "source": 157,
            "target": 158
        },
        {
            "source": 157,
            "target": 159
        },
        {
            "source": 157,
            "target": 160
        },
        {
            "source": 157,
            "target": 161
        },
        {
            "source": 162,
            "target": 55
        },
        {
            "source": 106,
            "target": 55
        },
        {
            "source": 163,
            "target": 55
        },
        {
            "source": 164,
            "target": 55
        },
        {
            "source": 163,
            "target": 165
        },
        {
            "source": 163,
            "target": 43
        },
        {
            "source": 162,
            "target": 79
        },
        {
            "source": 162,
            "target": 166
        },
        {
            "source": 106,
            "target": 79
        },
        {
            "source": 106,
            "target": 166
        },
        {
            "source": 167,
            "target": 1
        },
        {
            "source": 163,
            "target": 1
        },
        {
            "source": 168,
            "target": 69
        },
        {
            "source": 16,
            "target": 43
        },
        {
            "source": 70,
            "target": 68
        },
        {
            "source": 70,
            "target": 98
        },
        {
            "source": 20,
            "target": 103
        },
        {
            "source": 20,
            "target": 169
        },
        {
            "source": 20,
            "target": 170
        },
        {
            "source": 20,
            "target": 171
        },
        {
            "source": 20,
            "target": 89
        },
        {
            "source": 20,
            "target": 10
        },
        {
            "source": 172,
            "target": 1
        },
        {
            "source": 17,
            "target": 173
        },
        {
            "source": 17,
            "target": 174
        },
        {
            "source": 17,
            "target": 1
        },
        {
            "source": 162,
            "target": 56
        },
        {
            "source": 175,
            "target": 20
        },
        {
            "source": 163,
            "target": 20
        },
        {
            "source": 162,
            "target": 106
        },
        {
            "source": 162,
            "target": 164
        },
        {
            "source": 176,
            "target": 106
        },
        {
            "source": 176,
            "target": 162
        },
        {
            "source": 176,
            "target": 164
        },
        {
            "source": 163,
            "target": 106
        },
        {
            "source": 163,
            "target": 162
        },
        {
            "source": 163,
            "target": 164
        },
        {
            "source": 10,
            "target": 177
        },
        {
            "source": 10,
            "target": 20
        },
        {
            "source": 10,
            "target": 69
        },
        {
            "source": 10,
            "target": 1
        },
        {
            "source": 55,
            "target": 10
        },
        {
            "source": 55,
            "target": 20
        },
        {
            "source": 178,
            "target": 162
        },
        {
            "source": 178,
            "target": 106
        },
        {
            "source": 178,
            "target": 164
        },
        {
            "source": 162,
            "target": 179
        },
        {
            "source": 163,
            "target": 179
        },
        {
            "source": 106,
            "target": 162
        },
        {
            "source": 106,
            "target": 179
        },
        {
            "source": 106,
            "target": 164
        },
        {
            "source": 106,
            "target": 56
        },
        {
            "source": 180,
            "target": 69
        },
        {
            "source": 181,
            "target": 151
        },
        {
            "source": 181,
            "target": 182
        },
        {
            "source": 182,
            "target": 181
        },
        {
            "source": 182,
            "target": 151
        },
        {
            "source": 151,
            "target": 181
        },
        {
            "source": 151,
            "target": 182
        },
        {
            "source": 182,
            "target": 31
        },
        {
            "source": 182,
            "target": 66
        },
        {
            "source": 181,
            "target": 183
        },
        {
            "source": 182,
            "target": 183
        },
        {
            "source": 151,
            "target": 183
        },
        {
            "source": 181,
            "target": 89
        },
        {
            "source": 181,
            "target": 10
        },
        {
            "source": 182,
            "target": 89
        },
        {
            "source": 182,
            "target": 10
        },
        {
            "source": 151,
            "target": 89
        },
        {
            "source": 151,
            "target": 10
        },
        {
            "source": 182,
            "target": 1
        },
        {
            "source": 151,
            "target": 1
        },
        {
            "source": 184,
            "target": 17
        },
        {
            "source": 17,
            "target": 185
        },
        {
            "source": 184,
            "target": 56
        },
        {
            "source": 17,
            "target": 56
        },
        {
            "source": 184,
            "target": 173
        },
        {
            "source": 144,
            "target": 91
        },
        {
            "source": 56,
            "target": 20
        },
        {
            "source": 56,
            "target": 17
        },
        {
            "source": 56,
            "target": 127
        },
        {
            "source": 56,
            "target": 82
        },
        {
            "source": 186,
            "target": 56
        },
        {
            "source": 56,
            "target": 182
        },
        {
            "source": 56,
            "target": 187
        },
        {
            "source": 56,
            "target": 100
        },
        {
            "source": 56,
            "target": 188
        },
        {
            "source": 186,
            "target": 10
        },
        {
            "source": 56,
            "target": 10
        },
        {
            "source": 56,
            "target": 1
        },
        {
            "source": 189,
            "target": 171
        },
        {
            "source": 189,
            "target": 170
        },
        {
            "source": 190,
            "target": 56
        },
        {
            "source": 191,
            "target": 56
        },
        {
            "source": 189,
            "target": 56
        },
        {
            "source": 189,
            "target": 20
        },
        {
            "source": 189,
            "target": 169
        },
        {
            "source": 12,
            "target": 10
        },
        {
            "source": 12,
            "target": 1
        },
        {
            "source": 82,
            "target": 127
        },
        {
            "source": 82,
            "target": 192
        },
        {
            "source": 82,
            "target": 193
        },
        {
            "source": 82,
            "target": 194
        },
        {
            "source": 73,
            "target": 10
        },
        {
            "source": 109,
            "target": 10
        },
        {
            "source": 104,
            "target": 68
        },
        {
            "source": 104,
            "target": 69
        },
        {
            "source": 105,
            "target": 70
        },
        {
            "source": 195,
            "target": 70
        },
        {
            "source": 73,
            "target": 70
        },
        {
            "source": 109,
            "target": 70
        },
        {
            "source": 105,
            "target": 165
        },
        {
            "source": 195,
            "target": 43
        },
        {
            "source": 73,
            "target": 43
        },
        {
            "source": 109,
            "target": 43
        },
        {
            "source": 195,
            "target": 109
        },
        {
            "source": 73,
            "target": 109
        },
        {
            "source": 109,
            "target": 26
        },
        {
            "source": 104,
            "target": 196
        },
        {
            "source": 104,
            "target": 98
        },
        {
            "source": 104,
            "target": 99
        },
        {
            "source": 105,
            "target": 163
        },
        {
            "source": 109,
            "target": 163
        },
        {
            "source": 105,
            "target": 100
        },
        {
            "source": 109,
            "target": 197
        },
        {
            "source": 73,
            "target": 198
        },
        {
            "source": 73,
            "target": 16
        },
        {
            "source": 109,
            "target": 16
        },
        {
            "source": 73,
            "target": 64
        },
        {
            "source": 199,
            "target": 151
        },
        {
            "source": 182,
            "target": 43
        },
        {
            "source": 151,
            "target": 43
        },
        {
            "source": 182,
            "target": 20
        },
        {
            "source": 151,
            "target": 20
        },
        {
            "source": 182,
            "target": 200
        },
        {
            "source": 151,
            "target": 200
        },
        {
            "source": 201,
            "target": 26
        },
        {
            "source": 201,
            "target": 19
        },
        {
            "source": 198,
            "target": 170
        },
        {
            "source": 201,
            "target": 109
        },
        {
            "source": 165,
            "target": 43
        },
        {
            "source": 165,
            "target": 151
        },
        {
            "source": 202,
            "target": 147
        },
        {
            "source": 147,
            "target": 202
        },
        {
            "source": 147,
            "target": 203
        },
        {
            "source": 184,
            "target": 20
        },
        {
            "source": 173,
            "target": 174
        },
        {
            "source": 173,
            "target": 17
        },
        {
            "source": 174,
            "target": 17
        },
        {
            "source": 43,
            "target": 100
        },
        {
            "source": 204,
            "target": 10
        },
        {
            "source": 43,
            "target": 102
        },
        {
            "source": 43,
            "target": 10
        },
        {
            "source": 204,
            "target": 43
        },
        {
            "source": 43,
            "target": 105
        },
        {
            "source": 43,
            "target": 165
        },
        {
            "source": 43,
            "target": 151
        },
        {
            "source": 43,
            "target": 1
        },
        {
            "source": 32,
            "target": 28
        },
        {
            "source": 205,
            "target": 28
        },
        {
            "source": 206,
            "target": 28
        },
        {
            "source": 32,
            "target": 33
        },
        {
            "source": 28,
            "target": 79
        },
        {
            "source": 17,
            "target": 20
        },
        {
            "source": 17,
            "target": 103
        },
        {
            "source": 173,
            "target": 20
        },
        {
            "source": 173,
            "target": 103
        },
        {
            "source": 17,
            "target": 177
        },
        {
            "source": 173,
            "target": 56
        },
        {
            "source": 26,
            "target": 1
        },
        {
            "source": 26,
            "target": 79
        },
        {
            "source": 26,
            "target": 150
        },
        {
            "source": 26,
            "target": 17
        },
        {
            "source": 26,
            "target": 192
        },
        {
            "source": 111,
            "target": 20
        },
        {
            "source": 207,
            "target": 20
        },
        {
            "source": 208,
            "target": 20
        },
        {
            "source": 209,
            "target": 20
        },
        {
            "source": 210,
            "target": 20
        },
        {
            "source": 10,
            "target": 171
        },
        {
            "source": 211,
            "target": 20
        },
        {
            "source": 10,
            "target": 112
        },
        {
            "source": 10,
            "target": 17
        },
        {
            "source": 10,
            "target": 12
        },
        {
            "source": 10,
            "target": 212
        },
        {
            "source": 10,
            "target": 79
        },
        {
            "source": 10,
            "target": 192
        },
        {
            "source": 213,
            "target": 214
        },
        {
            "source": 215,
            "target": 214
        },
        {
            "source": 215,
            "target": 1
        },
        {
            "source": 216,
            "target": 217
        },
        {
            "source": 216,
            "target": 163
        },
        {
            "source": 216,
            "target": 218
        },
        {
            "source": 217,
            "target": 163
        },
        {
            "source": 217,
            "target": 218
        },
        {
            "source": 167,
            "target": 163
        },
        {
            "source": 219,
            "target": 217
        },
        {
            "source": 219,
            "target": 163
        },
        {
            "source": 219,
            "target": 218
        },
        {
            "source": 220,
            "target": 217
        },
        {
            "source": 220,
            "target": 163
        },
        {
            "source": 220,
            "target": 218
        },
        {
            "source": 163,
            "target": 217
        },
        {
            "source": 163,
            "target": 218
        },
        {
            "source": 218,
            "target": 217
        },
        {
            "source": 218,
            "target": 163
        },
        {
            "source": 218,
            "target": 221
        },
        {
            "source": 217,
            "target": 222
        },
        {
            "source": 163,
            "target": 70
        },
        {
            "source": 218,
            "target": 70
        },
        {
            "source": 218,
            "target": 222
        },
        {
            "source": 73,
            "target": 223
        },
        {
            "source": 218,
            "target": 223
        },
        {
            "source": 218,
            "target": 224
        },
        {
            "source": 218,
            "target": 16
        },
        {
            "source": 14,
            "target": 77
        },
        {
            "source": 63,
            "target": 77
        },
        {
            "source": 63,
            "target": 225
        },
        {
            "source": 14,
            "target": 226
        },
        {
            "source": 14,
            "target": 227
        },
        {
            "source": 163,
            "target": 223
        },
        {
            "source": 218,
            "target": 228
        },
        {
            "source": 218,
            "target": 215
        },
        {
            "source": 218,
            "target": 229
        },
        {
            "source": 230,
            "target": 231
        },
        {
            "source": 231,
            "target": 232
        },
        {
            "source": 233,
            "target": 14
        },
        {
            "source": 147,
            "target": 14
        },
        {
            "source": 234,
            "target": 147
        },
        {
            "source": 234,
            "target": 235
        },
        {
            "source": 234,
            "target": 236
        },
        {
            "source": 233,
            "target": 235
        },
        {
            "source": 233,
            "target": 236
        },
        {
            "source": 147,
            "target": 235
        },
        {
            "source": 147,
            "target": 236
        },
        {
            "source": 234,
            "target": 223
        },
        {
            "source": 147,
            "target": 237
        },
        {
            "source": 147,
            "target": 223
        },
        {
            "source": 147,
            "target": 64
        },
        {
            "source": 223,
            "target": 237
        },
        {
            "source": 235,
            "target": 237
        },
        {
            "source": 235,
            "target": 223
        },
        {
            "source": 223,
            "target": 1
        },
        {
            "source": 238,
            "target": 239
        },
        {
            "source": 238,
            "target": 214
        },
        {
            "source": 240,
            "target": 239
        },
        {
            "source": 240,
            "target": 214
        },
        {
            "source": 238,
            "target": 213
        },
        {
            "source": 238,
            "target": 215
        },
        {
            "source": 240,
            "target": 213
        },
        {
            "source": 240,
            "target": 215
        },
        {
            "source": 241,
            "target": 63
        },
        {
            "source": 242,
            "target": 70
        },
        {
            "source": 243,
            "target": 70
        },
        {
            "source": 244,
            "target": 70
        },
        {
            "source": 245,
            "target": 70
        },
        {
            "source": 117,
            "target": 246
        },
        {
            "source": 117,
            "target": 70
        },
        {
            "source": 247,
            "target": 70
        },
        {
            "source": 117,
            "target": 248
        },
        {
            "source": 117,
            "target": 249
        },
        {
            "source": 117,
            "target": 250
        },
        {
            "source": 117,
            "target": 118
        },
        {
            "source": 251,
            "target": 14
        },
        {
            "source": 252,
            "target": 14
        },
        {
            "source": 253,
            "target": 14
        },
        {
            "source": 254,
            "target": 14
        },
        {
            "source": 254,
            "target": 201
        },
        {
            "source": 254,
            "target": 1
        },
        {
            "source": 255,
            "target": 256
        },
        {
            "source": 255,
            "target": 257
        },
        {
            "source": 255,
            "target": 241
        },
        {
            "source": 255,
            "target": 258
        },
        {
            "source": 255,
            "target": 259
        },
        {
            "source": 255,
            "target": 260
        },
        {
            "source": 261,
            "target": 77
        },
        {
            "source": 144,
            "target": 77
        },
        {
            "source": 261,
            "target": 73
        },
        {
            "source": 144,
            "target": 73
        },
        {
            "source": 14,
            "target": 262
        },
        {
            "source": 263,
            "target": 77
        },
        {
            "source": 264,
            "target": 265
        },
        {
            "source": 265,
            "target": 266
        },
        {
            "source": 264,
            "target": 266
        },
        {
            "source": 267,
            "target": 214
        },
        {
            "source": 258,
            "target": 268
        },
        {
            "source": 258,
            "target": 269
        },
        {
            "source": 258,
            "target": 138
        },
        {
            "source": 257,
            "target": 268
        },
        {
            "source": 257,
            "target": 269
        },
        {
            "source": 257,
            "target": 138
        },
        {
            "source": 214,
            "target": 241
        },
        {
            "source": 239,
            "target": 213
        },
        {
            "source": 239,
            "target": 215
        },
        {
            "source": 239,
            "target": 214
        },
        {
            "source": 270,
            "target": 239
        },
        {
            "source": 270,
            "target": 214
        },
        {
            "source": 214,
            "target": 239
        },
        {
            "source": 214,
            "target": 213
        },
        {
            "source": 214,
            "target": 215
        },
        {
            "source": 239,
            "target": 271
        },
        {
            "source": 214,
            "target": 272
        },
        {
            "source": 214,
            "target": 271
        },
        {
            "source": 214,
            "target": 273
        },
        {
            "source": 214,
            "target": 274
        },
        {
            "source": 214,
            "target": 275
        },
        {
            "source": 214,
            "target": 276
        },
        {
            "source": 214,
            "target": 277
        },
        {
            "source": 103,
            "target": 1
        },
        {
            "source": 278,
            "target": 85
        },
        {
            "source": 278,
            "target": 86
        },
        {
            "source": 149,
            "target": 85
        },
        {
            "source": 149,
            "target": 86
        },
        {
            "source": 16,
            "target": 85
        },
        {
            "source": 16,
            "target": 86
        },
        {
            "source": 149,
            "target": 198
        },
        {
            "source": 16,
            "target": 198
        },
        {
            "source": 16,
            "target": 64
        },
        {
            "source": 149,
            "target": 148
        },
        {
            "source": 149,
            "target": 16
        },
        {
            "source": 16,
            "target": 148
        },
        {
            "source": 16,
            "target": 149
        },
        {
            "source": 16,
            "target": 63
        },
        {
            "source": 279,
            "target": 280
        },
        {
            "source": 280,
            "target": 83
        },
        {
            "source": 280,
            "target": 1
        },
        {
            "source": 281,
            "target": 282
        },
        {
            "source": 281,
            "target": 283
        },
        {
            "source": 282,
            "target": 284
        },
        {
            "source": 282,
            "target": 285
        },
        {
            "source": 282,
            "target": 283
        },
        {
            "source": 286,
            "target": 287
        },
        {
            "source": 286,
            "target": 213
        },
        {
            "source": 286,
            "target": 214
        },
        {
            "source": 286,
            "target": 239
        },
        {
            "source": 137,
            "target": 214
        },
        {
            "source": 137,
            "target": 268
        },
        {
            "source": 137,
            "target": 269
        },
        {
            "source": 137,
            "target": 138
        },
        {
            "source": 137,
            "target": 215
        },
        {
            "source": 118,
            "target": 77
        },
        {
            "source": 288,
            "target": 127
        },
        {
            "source": 288,
            "target": 82
        },
        {
            "source": 288,
            "target": 192
        },
        {
            "source": 91,
            "target": 127
        },
        {
            "source": 91,
            "target": 82
        },
        {
            "source": 90,
            "target": 82
        },
        {
            "source": 90,
            "target": 192
        },
        {
            "source": 90,
            "target": 194
        },
        {
            "source": 91,
            "target": 171
        },
        {
            "source": 90,
            "target": 171
        },
        {
            "source": 289,
            "target": 20
        },
        {
            "source": 288,
            "target": 20
        },
        {
            "source": 91,
            "target": 20
        },
        {
            "source": 90,
            "target": 20
        },
        {
            "source": 290,
            "target": 20
        },
        {
            "source": 14,
            "target": 70
        },
        {
            "source": 14,
            "target": 291
        },
        {
            "source": 14,
            "target": 292
        },
        {
            "source": 43,
            "target": 20
        },
        {
            "source": 43,
            "target": 293
        },
        {
            "source": 43,
            "target": 294
        },
        {
            "source": 43,
            "target": 89
        },
        {
            "source": 43,
            "target": 113
        },
        {
            "source": 43,
            "target": 295
        },
        {
            "source": 43,
            "target": 103
        },
        {
            "source": 296,
            "target": 70
        },
        {
            "source": 109,
            "target": 201
        },
        {
            "source": 173,
            "target": 43
        },
        {
            "source": 297,
            "target": 43
        },
        {
            "source": 105,
            "target": 151
        },
        {
            "source": 109,
            "target": 116
        },
        {
            "source": 296,
            "target": 298
        },
        {
            "source": 299,
            "target": 229
        },
        {
            "source": 268,
            "target": 137
        },
        {
            "source": 268,
            "target": 229
        },
        {
            "source": 299,
            "target": 268
        },
        {
            "source": 268,
            "target": 259
        },
        {
            "source": 268,
            "target": 138
        },
        {
            "source": 233,
            "target": 70
        },
        {
            "source": 234,
            "target": 300
        },
        {
            "source": 147,
            "target": 300
        },
        {
            "source": 147,
            "target": 63
        },
        {
            "source": 147,
            "target": 232
        },
        {
            "source": 147,
            "target": 301
        },
        {
            "source": 231,
            "target": 213
        },
        {
            "source": 231,
            "target": 214
        },
        {
            "source": 77,
            "target": 98
        },
        {
            "source": 77,
            "target": 302
        },
        {
            "source": 77,
            "target": 14
        },
        {
            "source": 77,
            "target": 26
        },
        {
            "source": 77,
            "target": 303
        },
        {
            "source": 184,
            "target": 10
        },
        {
            "source": 229,
            "target": 304
        },
        {
            "source": 283,
            "target": 70
        },
        {
            "source": 305,
            "target": 306
        },
        {
            "source": 305,
            "target": 246
        },
        {
            "source": 305,
            "target": 307
        },
        {
            "source": 305,
            "target": 70
        },
        {
            "source": 308,
            "target": 305
        },
        {
            "source": 283,
            "target": 305
        },
        {
            "source": 305,
            "target": 309
        },
        {
            "source": 310,
            "target": 137
        },
        {
            "source": 310,
            "target": 268
        },
        {
            "source": 310,
            "target": 138
        },
        {
            "source": 229,
            "target": 137
        },
        {
            "source": 229,
            "target": 268
        },
        {
            "source": 229,
            "target": 138
        },
        {
            "source": 163,
            "target": 280
        },
        {
            "source": 280,
            "target": 237
        },
        {
            "source": 280,
            "target": 311
        },
        {
            "source": 280,
            "target": 223
        },
        {
            "source": 181,
            "target": 20
        },
        {
            "source": 312,
            "target": 20
        },
        {
            "source": 230,
            "target": 214
        },
        {
            "source": 107,
            "target": 17
        },
        {
            "source": 107,
            "target": 113
        },
        {
            "source": 107,
            "target": 313
        },
        {
            "source": 107,
            "target": 314
        },
        {
            "source": 144,
            "target": 97
        },
        {
            "source": 144,
            "target": 98
        },
        {
            "source": 144,
            "target": 99
        },
        {
            "source": 315,
            "target": 98
        },
        {
            "source": 315,
            "target": 99
        },
        {
            "source": 141,
            "target": 98
        },
        {
            "source": 141,
            "target": 99
        },
        {
            "source": 316,
            "target": 98
        },
        {
            "source": 316,
            "target": 99
        },
        {
            "source": 144,
            "target": 212
        },
        {
            "source": 144,
            "target": 317
        },
        {
            "source": 144,
            "target": 114
        },
        {
            "source": 144,
            "target": 318
        },
        {
            "source": 319,
            "target": 192
        },
        {
            "source": 320,
            "target": 192
        },
        {
            "source": 321,
            "target": 77
        },
        {
            "source": 321,
            "target": 302
        },
        {
            "source": 100,
            "target": 43
        },
        {
            "source": 164,
            "target": 162
        },
        {
            "source": 164,
            "target": 106
        },
        {
            "source": 107,
            "target": 37
        },
        {
            "source": 107,
            "target": 322
        },
        {
            "source": 29,
            "target": 28
        },
        {
            "source": 29,
            "target": 33
        },
        {
            "source": 29,
            "target": 94
        },
        {
            "source": 30,
            "target": 28
        },
        {
            "source": 30,
            "target": 33
        },
        {
            "source": 30,
            "target": 94
        },
        {
            "source": 31,
            "target": 28
        },
        {
            "source": 31,
            "target": 33
        },
        {
            "source": 31,
            "target": 94
        },
        {
            "source": 29,
            "target": 66
        },
        {
            "source": 29,
            "target": 31
        },
        {
            "source": 30,
            "target": 29
        },
        {
            "source": 30,
            "target": 66
        },
        {
            "source": 30,
            "target": 31
        },
        {
            "source": 31,
            "target": 29
        },
        {
            "source": 31,
            "target": 66
        },
        {
            "source": 17,
            "target": 107
        },
        {
            "source": 55,
            "target": 79
        },
        {
            "source": 213,
            "target": 239
        },
        {
            "source": 213,
            "target": 231
        },
        {
            "source": 213,
            "target": 215
        },
        {
            "source": 323,
            "target": 14
        },
        {
            "source": 70,
            "target": 14
        },
        {
            "source": 195,
            "target": 14
        },
        {
            "source": 70,
            "target": 109
        },
        {
            "source": 70,
            "target": 237
        },
        {
            "source": 70,
            "target": 311
        },
        {
            "source": 70,
            "target": 223
        },
        {
            "source": 70,
            "target": 26
        },
        {
            "source": 0,
            "target": 26
        },
        {
            "source": 324,
            "target": 170
        },
        {
            "source": 201,
            "target": 83
        },
        {
            "source": 325,
            "target": 19
        },
        {
            "source": 325,
            "target": 201
        },
        {
            "source": 201,
            "target": 326
        },
        {
            "source": 201,
            "target": 241
        },
        {
            "source": 122,
            "target": 17
        },
        {
            "source": 123,
            "target": 17
        },
        {
            "source": 124,
            "target": 17
        },
        {
            "source": 123,
            "target": 69
        },
        {
            "source": 69,
            "target": 71
        },
        {
            "source": 63,
            "target": 26
        },
        {
            "source": 63,
            "target": 147
        },
        {
            "source": 62,
            "target": 10
        },
        {
            "source": 327,
            "target": 250
        },
        {
            "source": 327,
            "target": 328
        },
        {
            "source": 327,
            "target": 248
        },
        {
            "source": 327,
            "target": 329
        },
        {
            "source": 327,
            "target": 70
        },
        {
            "source": 327,
            "target": 330
        },
        {
            "source": 327,
            "target": 249
        },
        {
            "source": 117,
            "target": 328
        },
        {
            "source": 117,
            "target": 329
        },
        {
            "source": 117,
            "target": 330
        },
        {
            "source": 255,
            "target": 137
        },
        {
            "source": 255,
            "target": 215
        },
        {
            "source": 255,
            "target": 138
        },
        {
            "source": 255,
            "target": 229
        },
        {
            "source": 91,
            "target": 173
        },
        {
            "source": 91,
            "target": 56
        },
        {
            "source": 17,
            "target": 10
        },
        {
            "source": 86,
            "target": 331
        },
        {
            "source": 86,
            "target": 332
        },
        {
            "source": 85,
            "target": 331
        },
        {
            "source": 85,
            "target": 332
        },
        {
            "source": 333,
            "target": 147
        },
        {
            "source": 49,
            "target": 34
        },
        {
            "source": 49,
            "target": 32
        },
        {
            "source": 49,
            "target": 28
        },
        {
            "source": 49,
            "target": 37
        },
        {
            "source": 28,
            "target": 89
        },
        {
            "source": 28,
            "target": 334
        },
        {
            "source": 335,
            "target": 3
        },
        {
            "source": 335,
            "target": 11
        },
        {
            "source": 335,
            "target": 10
        },
        {
            "source": 3,
            "target": 102
        },
        {
            "source": 336,
            "target": 20
        },
        {
            "source": 337,
            "target": 20
        },
        {
            "source": 123,
            "target": 20
        },
        {
            "source": 122,
            "target": 20
        },
        {
            "source": 124,
            "target": 20
        },
        {
            "source": 338,
            "target": 24
        },
        {
            "source": 339,
            "target": 24
        },
        {
            "source": 340,
            "target": 24
        },
        {
            "source": 341,
            "target": 24
        },
        {
            "source": 24,
            "target": 342
        },
        {
            "source": 343,
            "target": 344
        },
        {
            "source": 343,
            "target": 345
        },
        {
            "source": 70,
            "target": 16
        },
        {
            "source": 70,
            "target": 346
        },
        {
            "source": 70,
            "target": 347
        },
        {
            "source": 70,
            "target": 348
        },
        {
            "source": 73,
            "target": 347
        },
        {
            "source": 73,
            "target": 348
        },
        {
            "source": 73,
            "target": 14
        },
        {
            "source": 43,
            "target": 163
        },
        {
            "source": 72,
            "target": 349
        },
        {
            "source": 350,
            "target": 70
        },
        {
            "source": 350,
            "target": 349
        },
        {
            "source": 351,
            "target": 70
        },
        {
            "source": 351,
            "target": 349
        },
        {
            "source": 352,
            "target": 70
        },
        {
            "source": 352,
            "target": 349
        },
        {
            "source": 347,
            "target": 70
        },
        {
            "source": 347,
            "target": 349
        },
        {
            "source": 353,
            "target": 70
        },
        {
            "source": 353,
            "target": 349
        },
        {
            "source": 70,
            "target": 354
        },
        {
            "source": 70,
            "target": 355
        },
        {
            "source": 70,
            "target": 356
        },
        {
            "source": 70,
            "target": 349
        },
        {
            "source": 73,
            "target": 349
        },
        {
            "source": 350,
            "target": 357
        },
        {
            "source": 350,
            "target": 246
        },
        {
            "source": 351,
            "target": 357
        },
        {
            "source": 351,
            "target": 246
        },
        {
            "source": 352,
            "target": 357
        },
        {
            "source": 352,
            "target": 246
        },
        {
            "source": 347,
            "target": 357
        },
        {
            "source": 347,
            "target": 246
        },
        {
            "source": 70,
            "target": 357
        },
        {
            "source": 70,
            "target": 246
        },
        {
            "source": 73,
            "target": 357
        },
        {
            "source": 73,
            "target": 246
        },
        {
            "source": 70,
            "target": 358
        },
        {
            "source": 70,
            "target": 359
        },
        {
            "source": 70,
            "target": 360
        },
        {
            "source": 73,
            "target": 358
        },
        {
            "source": 73,
            "target": 359
        },
        {
            "source": 73,
            "target": 360
        },
        {
            "source": 70,
            "target": 15
        },
        {
            "source": 347,
            "target": 361
        },
        {
            "source": 70,
            "target": 361
        },
        {
            "source": 70,
            "target": 362
        },
        {
            "source": 183,
            "target": 17
        },
        {
            "source": 183,
            "target": 12
        },
        {
            "source": 183,
            "target": 10
        },
        {
            "source": 183,
            "target": 11
        },
        {
            "source": 183,
            "target": 13
        },
        {
            "source": 48,
            "target": 28
        },
        {
            "source": 48,
            "target": 33
        },
        {
            "source": 48,
            "target": 37
        },
        {
            "source": 48,
            "target": 56
        },
        {
            "source": 37,
            "target": 26
        },
        {
            "source": 363,
            "target": 12
        },
        {
            "source": 363,
            "target": 10
        },
        {
            "source": 150,
            "target": 26
        },
        {
            "source": 364,
            "target": 85
        },
        {
            "source": 364,
            "target": 86
        },
        {
            "source": 365,
            "target": 85
        },
        {
            "source": 365,
            "target": 86
        },
        {
            "source": 144,
            "target": 14
        },
        {
            "source": 79,
            "target": 20
        },
        {
            "source": 147,
            "target": 26
        },
        {
            "source": 163,
            "target": 109
        },
        {
            "source": 91,
            "target": 10
        },
        {
            "source": 173,
            "target": 10
        },
        {
            "source": 288,
            "target": 10
        },
        {
            "source": 288,
            "target": 173
        },
        {
            "source": 288,
            "target": 56
        },
        {
            "source": 56,
            "target": 173
        },
        {
            "source": 288,
            "target": 17
        },
        {
            "source": 366,
            "target": 17
        },
        {
            "source": 367,
            "target": 17
        },
        {
            "source": 14,
            "target": 82
        },
        {
            "source": 43,
            "target": 368
        },
        {
            "source": 165,
            "target": 163
        },
        {
            "source": 296,
            "target": 98
        },
        {
            "source": 296,
            "target": 99
        },
        {
            "source": 17,
            "target": 98
        },
        {
            "source": 369,
            "target": 17
        },
        {
            "source": 57,
            "target": 55
        },
        {
            "source": 57,
            "target": 82
        },
        {
            "source": 288,
            "target": 55
        },
        {
            "source": 32,
            "target": 82
        },
        {
            "source": 34,
            "target": 23
        },
        {
            "source": 32,
            "target": 23
        },
        {
            "source": 48,
            "target": 23
        },
        {
            "source": 32,
            "target": 56
        },
        {
            "source": 43,
            "target": 17
        },
        {
            "source": 370,
            "target": 43
        },
        {
            "source": 371,
            "target": 43
        },
        {
            "source": 180,
            "target": 98
        },
        {
            "source": 372,
            "target": 98
        },
        {
            "source": 69,
            "target": 98
        },
        {
            "source": 69,
            "target": 269
        },
        {
            "source": 372,
            "target": 69
        },
        {
            "source": 69,
            "target": 99
        },
        {
            "source": 182,
            "target": 103
        },
        {
            "source": 10,
            "target": 89
        },
        {
            "source": 22,
            "target": 9
        },
        {
            "source": 64,
            "target": 9
        },
        {
            "source": 64,
            "target": 346
        },
        {
            "source": 22,
            "target": 64
        },
        {
            "source": 22,
            "target": 83
        },
        {
            "source": 64,
            "target": 83
        },
        {
            "source": 150,
            "target": 23
        },
        {
            "source": 84,
            "target": 14
        },
        {
            "source": 85,
            "target": 373
        },
        {
            "source": 85,
            "target": 374
        },
        {
            "source": 85,
            "target": 15
        },
        {
            "source": 85,
            "target": 14
        },
        {
            "source": 86,
            "target": 373
        },
        {
            "source": 86,
            "target": 374
        },
        {
            "source": 86,
            "target": 15
        },
        {
            "source": 86,
            "target": 14
        },
        {
            "source": 85,
            "target": 86
        },
        {
            "source": 86,
            "target": 85
        },
        {
            "source": 24,
            "target": 64
        },
        {
            "source": 14,
            "target": 69
        },
        {
            "source": 47,
            "target": 15
        },
        {
            "source": 83,
            "target": 346
        },
        {
            "source": 44,
            "target": 127
        },
        {
            "source": 44,
            "target": 82
        },
        {
            "source": 45,
            "target": 127
        },
        {
            "source": 45,
            "target": 82
        },
        {
            "source": 37,
            "target": 375
        },
        {
            "source": 116,
            "target": 109
        },
        {
            "source": 116,
            "target": 376
        },
        {
            "source": 116,
            "target": 377
        },
        {
            "source": 378,
            "target": 63
        },
        {
            "source": 379,
            "target": 63
        },
        {
            "source": 380,
            "target": 63
        },
        {
            "source": 269,
            "target": 259
        },
        {
            "source": 269,
            "target": 260
        },
        {
            "source": 381,
            "target": 214
        },
        {
            "source": 250,
            "target": 70
        },
        {
            "source": 250,
            "target": 249
        },
        {
            "source": 249,
            "target": 248
        },
        {
            "source": 249,
            "target": 70
        },
        {
            "source": 382,
            "target": 14
        },
        {
            "source": 383,
            "target": 14
        },
        {
            "source": 213,
            "target": 241
        },
        {
            "source": 213,
            "target": 272
        },
        {
            "source": 213,
            "target": 271
        },
        {
            "source": 213,
            "target": 275
        },
        {
            "source": 213,
            "target": 276
        },
        {
            "source": 213,
            "target": 277
        },
        {
            "source": 229,
            "target": 384
        },
        {
            "source": 229,
            "target": 257
        },
        {
            "source": 229,
            "target": 255
        },
        {
            "source": 229,
            "target": 258
        },
        {
            "source": 310,
            "target": 229
        },
        {
            "source": 229,
            "target": 215
        },
        {
            "source": 229,
            "target": 385
        },
        {
            "source": 229,
            "target": 386
        },
        {
            "source": 229,
            "target": 269
        },
        {
            "source": 229,
            "target": 118
        },
        {
            "source": 387,
            "target": 388
        },
        {
            "source": 279,
            "target": 388
        },
        {
            "source": 389,
            "target": 19
        },
        {
            "source": 390,
            "target": 19
        },
        {
            "source": 389,
            "target": 391
        },
        {
            "source": 390,
            "target": 391
        },
        {
            "source": 389,
            "target": 346
        },
        {
            "source": 390,
            "target": 346
        },
        {
            "source": 14,
            "target": 237
        },
        {
            "source": 14,
            "target": 223
        },
        {
            "source": 214,
            "target": 232
        },
        {
            "source": 214,
            "target": 392
        },
        {
            "source": 214,
            "target": 393
        },
        {
            "source": 214,
            "target": 286
        },
        {
            "source": 254,
            "target": 24
        },
        {
            "source": 394,
            "target": 47
        },
        {
            "source": 394,
            "target": 37
        },
        {
            "source": 395,
            "target": 47
        },
        {
            "source": 395,
            "target": 37
        },
        {
            "source": 116,
            "target": 47
        },
        {
            "source": 116,
            "target": 37
        },
        {
            "source": 394,
            "target": 116
        },
        {
            "source": 395,
            "target": 116
        },
        {
            "source": 138,
            "target": 1
        },
        {
            "source": 218,
            "target": 396
        },
        {
            "source": 218,
            "target": 118
        },
        {
            "source": 160,
            "target": 156
        },
        {
            "source": 160,
            "target": 158
        },
        {
            "source": 160,
            "target": 70
        },
        {
            "source": 158,
            "target": 156
        },
        {
            "source": 158,
            "target": 70
        },
        {
            "source": 160,
            "target": 259
        },
        {
            "source": 158,
            "target": 259
        },
        {
            "source": 269,
            "target": 223
        },
        {
            "source": 71,
            "target": 69
        },
        {
            "source": 218,
            "target": 14
        },
        {
            "source": 218,
            "target": 69
        },
        {
            "source": 159,
            "target": 156
        },
        {
            "source": 159,
            "target": 158
        },
        {
            "source": 159,
            "target": 160
        },
        {
            "source": 159,
            "target": 161
        },
        {
            "source": 159,
            "target": 70
        },
        {
            "source": 70,
            "target": 156
        },
        {
            "source": 70,
            "target": 158
        },
        {
            "source": 70,
            "target": 159
        },
        {
            "source": 70,
            "target": 160
        },
        {
            "source": 70,
            "target": 161
        },
        {
            "source": 70,
            "target": 64
        },
        {
            "source": 397,
            "target": 116
        },
        {
            "source": 398,
            "target": 269
        },
        {
            "source": 268,
            "target": 269
        },
        {
            "source": 268,
            "target": 255
        },
        {
            "source": 268,
            "target": 258
        },
        {
            "source": 268,
            "target": 201
        },
        {
            "source": 118,
            "target": 399
        },
        {
            "source": 118,
            "target": 400
        },
        {
            "source": 401,
            "target": 396
        },
        {
            "source": 401,
            "target": 118
        },
        {
            "source": 118,
            "target": 396
        },
        {
            "source": 118,
            "target": 402
        },
        {
            "source": 118,
            "target": 403
        },
        {
            "source": 215,
            "target": 269
        },
        {
            "source": 138,
            "target": 269
        },
        {
            "source": 138,
            "target": 137
        },
        {
            "source": 147,
            "target": 201
        },
        {
            "source": 63,
            "target": 213
        },
        {
            "source": 63,
            "target": 214
        },
        {
            "source": 138,
            "target": 229
        },
        {
            "source": 233,
            "target": 259
        },
        {
            "source": 232,
            "target": 269
        },
        {
            "source": 66,
            "target": 31
        },
        {
            "source": 66,
            "target": 97
        },
        {
            "source": 10,
            "target": 3
        },
        {
            "source": 102,
            "target": 10
        },
        {
            "source": 10,
            "target": 102
        },
        {
            "source": 102,
            "target": 11
        },
        {
            "source": 10,
            "target": 11
        },
        {
            "source": 10,
            "target": 13
        },
        {
            "source": 31,
            "target": 23
        },
        {
            "source": 29,
            "target": 20
        },
        {
            "source": 29,
            "target": 10
        },
        {
            "source": 31,
            "target": 12
        },
        {
            "source": 94,
            "target": 10
        },
        {
            "source": 404,
            "target": 23
        },
        {
            "source": 23,
            "target": 405
        },
        {
            "source": 23,
            "target": 406
        },
        {
            "source": 23,
            "target": 407
        },
        {
            "source": 110,
            "target": 98
        },
        {
            "source": 110,
            "target": 99
        },
        {
            "source": 23,
            "target": 98
        },
        {
            "source": 23,
            "target": 99
        },
        {
            "source": 23,
            "target": 79
        },
        {
            "source": 408,
            "target": 409
        },
        {
            "source": 409,
            "target": 410
        },
        {
            "source": 408,
            "target": 411
        },
        {
            "source": 409,
            "target": 411
        },
        {
            "source": 408,
            "target": 16
        },
        {
            "source": 409,
            "target": 16
        },
        {
            "source": 64,
            "target": 26
        },
        {
            "source": 64,
            "target": 20
        },
        {
            "source": 183,
            "target": 170
        },
        {
            "source": 183,
            "target": 98
        },
        {
            "source": 412,
            "target": 1
        },
        {
            "source": 413,
            "target": 1
        },
        {
            "source": 183,
            "target": 20
        },
        {
            "source": 414,
            "target": 70
        },
        {
            "source": 348,
            "target": 70
        },
        {
            "source": 348,
            "target": 357
        },
        {
            "source": 70,
            "target": 415
        },
        {
            "source": 348,
            "target": 349
        },
        {
            "source": 348,
            "target": 246
        },
        {
            "source": 348,
            "target": 361
        },
        {
            "source": 70,
            "target": 305
        },
        {
            "source": 17,
            "target": 192
        },
        {
            "source": 416,
            "target": 212
        },
        {
            "source": 416,
            "target": 317
        },
        {
            "source": 417,
            "target": 69
        },
        {
            "source": 177,
            "target": 20
        },
        {
            "source": 418,
            "target": 20
        },
        {
            "source": 20,
            "target": 177
        },
        {
            "source": 20,
            "target": 183
        },
        {
            "source": 177,
            "target": 103
        },
        {
            "source": 177,
            "target": 82
        },
        {
            "source": 20,
            "target": 82
        },
        {
            "source": 20,
            "target": 17
        },
        {
            "source": 419,
            "target": 17
        },
        {
            "source": 420,
            "target": 17
        },
        {
            "source": 37,
            "target": 212
        },
        {
            "source": 37,
            "target": 317
        },
        {
            "source": 46,
            "target": 82
        },
        {
            "source": 421,
            "target": 82
        },
        {
            "source": 37,
            "target": 98
        },
        {
            "source": 37,
            "target": 99
        },
        {
            "source": 422,
            "target": 423
        },
        {
            "source": 422,
            "target": 424
        },
        {
            "source": 425,
            "target": 410
        },
        {
            "source": 426,
            "target": 107
        },
        {
            "source": 410,
            "target": 411
        },
        {
            "source": 110,
            "target": 23
        },
        {
            "source": 23,
            "target": 427
        },
        {
            "source": 23,
            "target": 428
        },
        {
            "source": 23,
            "target": 212
        },
        {
            "source": 23,
            "target": 317
        },
        {
            "source": 23,
            "target": 429
        },
        {
            "source": 23,
            "target": 430
        },
        {
            "source": 23,
            "target": 431
        },
        {
            "source": 432,
            "target": 405
        },
        {
            "source": 432,
            "target": 406
        },
        {
            "source": 432,
            "target": 407
        },
        {
            "source": 301,
            "target": 405
        },
        {
            "source": 301,
            "target": 406
        },
        {
            "source": 301,
            "target": 407
        },
        {
            "source": 432,
            "target": 433
        },
        {
            "source": 432,
            "target": 255
        },
        {
            "source": 432,
            "target": 301
        },
        {
            "source": 301,
            "target": 432
        },
        {
            "source": 301,
            "target": 433
        },
        {
            "source": 301,
            "target": 255
        },
        {
            "source": 432,
            "target": 427
        },
        {
            "source": 432,
            "target": 23
        },
        {
            "source": 301,
            "target": 427
        },
        {
            "source": 301,
            "target": 23
        },
        {
            "source": 33,
            "target": 127
        },
        {
            "source": 33,
            "target": 82
        },
        {
            "source": 35,
            "target": 82
        },
        {
            "source": 36,
            "target": 82
        },
        {
            "source": 38,
            "target": 82
        },
        {
            "source": 56,
            "target": 79
        },
        {
            "source": 138,
            "target": 215
        },
        {
            "source": 138,
            "target": 214
        },
        {
            "source": 434,
            "target": 214
        },
        {
            "source": 138,
            "target": 201
        },
        {
            "source": 213,
            "target": 232
        },
        {
            "source": 213,
            "target": 269
        },
        {
            "source": 214,
            "target": 269
        },
        {
            "source": 435,
            "target": 269
        },
        {
            "source": 215,
            "target": 232
        },
        {
            "source": 74,
            "target": 116
        },
        {
            "source": 74,
            "target": 109
        },
        {
            "source": 436,
            "target": 437
        },
        {
            "source": 436,
            "target": 304
        },
        {
            "source": 438,
            "target": 437
        },
        {
            "source": 438,
            "target": 304
        },
        {
            "source": 439,
            "target": 437
        },
        {
            "source": 439,
            "target": 304
        },
        {
            "source": 440,
            "target": 437
        },
        {
            "source": 440,
            "target": 304
        },
        {
            "source": 441,
            "target": 437
        },
        {
            "source": 441,
            "target": 304
        },
        {
            "source": 417,
            "target": 437
        },
        {
            "source": 417,
            "target": 304
        },
        {
            "source": 442,
            "target": 437
        },
        {
            "source": 442,
            "target": 304
        },
        {
            "source": 417,
            "target": 26
        },
        {
            "source": 417,
            "target": 269
        },
        {
            "source": 436,
            "target": 138
        },
        {
            "source": 417,
            "target": 138
        },
        {
            "source": 358,
            "target": 77
        },
        {
            "source": 359,
            "target": 77
        },
        {
            "source": 360,
            "target": 77
        },
        {
            "source": 358,
            "target": 70
        },
        {
            "source": 214,
            "target": 381
        },
        {
            "source": 213,
            "target": 392
        },
        {
            "source": 213,
            "target": 393
        },
        {
            "source": 214,
            "target": 443
        },
        {
            "source": 214,
            "target": 444
        },
        {
            "source": 445,
            "target": 147
        },
        {
            "source": 255,
            "target": 147
        },
        {
            "source": 147,
            "target": 304
        },
        {
            "source": 70,
            "target": 446
        },
        {
            "source": 70,
            "target": 118
        },
        {
            "source": 248,
            "target": 70
        },
        {
            "source": 70,
            "target": 249
        },
        {
            "source": 248,
            "target": 357
        },
        {
            "source": 249,
            "target": 357
        },
        {
            "source": 447,
            "target": 224
        },
        {
            "source": 447,
            "target": 16
        },
        {
            "source": 71,
            "target": 224
        },
        {
            "source": 71,
            "target": 16
        },
        {
            "source": 447,
            "target": 448
        },
        {
            "source": 218,
            "target": 214
        },
        {
            "source": 447,
            "target": 71
        },
        {
            "source": 447,
            "target": 69
        },
        {
            "source": 71,
            "target": 447
        },
        {
            "source": 70,
            "target": 218
        },
        {
            "source": 447,
            "target": 449
        },
        {
            "source": 447,
            "target": 300
        },
        {
            "source": 447,
            "target": 63
        },
        {
            "source": 218,
            "target": 300
        },
        {
            "source": 218,
            "target": 63
        },
        {
            "source": 71,
            "target": 449
        },
        {
            "source": 71,
            "target": 300
        },
        {
            "source": 71,
            "target": 63
        },
        {
            "source": 70,
            "target": 63
        },
        {
            "source": 71,
            "target": 137
        },
        {
            "source": 71,
            "target": 403
        },
        {
            "source": 117,
            "target": 450
        },
        {
            "source": 116,
            "target": 70
        },
        {
            "source": 116,
            "target": 305
        },
        {
            "source": 116,
            "target": 396
        },
        {
            "source": 116,
            "target": 118
        },
        {
            "source": 451,
            "target": 70
        },
        {
            "source": 161,
            "target": 70
        },
        {
            "source": 158,
            "target": 69
        },
        {
            "source": 160,
            "target": 69
        },
        {
            "source": 156,
            "target": 183
        },
        {
            "source": 159,
            "target": 183
        },
        {
            "source": 158,
            "target": 183
        },
        {
            "source": 160,
            "target": 183
        },
        {
            "source": 161,
            "target": 183
        },
        {
            "source": 70,
            "target": 183
        },
        {
            "source": 70,
            "target": 452
        },
        {
            "source": 70,
            "target": 453
        },
        {
            "source": 343,
            "target": 454
        },
        {
            "source": 343,
            "target": 109
        },
        {
            "source": 343,
            "target": 116
        },
        {
            "source": 343,
            "target": 455
        },
        {
            "source": 343,
            "target": 197
        },
        {
            "source": 343,
            "target": 70
        },
        {
            "source": 69,
            "target": 259
        },
        {
            "source": 69,
            "target": 246
        },
        {
            "source": 286,
            "target": 215
        },
        {
            "source": 213,
            "target": 381
        },
        {
            "source": 213,
            "target": 138
        },
        {
            "source": 15,
            "target": 239
        },
        {
            "source": 15,
            "target": 214
        },
        {
            "source": 15,
            "target": 213
        },
        {
            "source": 213,
            "target": 255
        },
        {
            "source": 213,
            "target": 257
        },
        {
            "source": 213,
            "target": 258
        },
        {
            "source": 15,
            "target": 280
        },
        {
            "source": 302,
            "target": 77
        },
        {
            "source": 456,
            "target": 98
        },
        {
            "source": 241,
            "target": 26
        },
        {
            "source": 241,
            "target": 457
        },
        {
            "source": 109,
            "target": 14
        },
        {
            "source": 241,
            "target": 14
        },
        {
            "source": 241,
            "target": 268
        },
        {
            "source": 241,
            "target": 269
        },
        {
            "source": 241,
            "target": 259
        },
        {
            "source": 268,
            "target": 257
        },
        {
            "source": 268,
            "target": 241
        },
        {
            "source": 137,
            "target": 255
        },
        {
            "source": 137,
            "target": 257
        },
        {
            "source": 137,
            "target": 241
        },
        {
            "source": 137,
            "target": 258
        },
        {
            "source": 458,
            "target": 241
        },
        {
            "source": 458,
            "target": 268
        },
        {
            "source": 458,
            "target": 269
        },
        {
            "source": 268,
            "target": 459
        },
        {
            "source": 268,
            "target": 460
        },
        {
            "source": 73,
            "target": 77
        },
        {
            "source": 461,
            "target": 268
        },
        {
            "source": 461,
            "target": 269
        },
        {
            "source": 462,
            "target": 268
        },
        {
            "source": 462,
            "target": 269
        },
        {
            "source": 463,
            "target": 268
        },
        {
            "source": 463,
            "target": 269
        },
        {
            "source": 464,
            "target": 268
        },
        {
            "source": 464,
            "target": 269
        },
        {
            "source": 461,
            "target": 255
        },
        {
            "source": 462,
            "target": 255
        },
        {
            "source": 463,
            "target": 255
        },
        {
            "source": 464,
            "target": 255
        },
        {
            "source": 461,
            "target": 137
        },
        {
            "source": 462,
            "target": 137
        },
        {
            "source": 463,
            "target": 137
        },
        {
            "source": 464,
            "target": 137
        },
        {
            "source": 144,
            "target": 69
        },
        {
            "source": 29,
            "target": 416
        },
        {
            "source": 465,
            "target": 31
        },
        {
            "source": 31,
            "target": 466
        },
        {
            "source": 31,
            "target": 416
        },
        {
            "source": 31,
            "target": 97
        },
        {
            "source": 31,
            "target": 18
        },
        {
            "source": 64,
            "target": 14
        },
        {
            "source": 26,
            "target": 467
        },
        {
            "source": 26,
            "target": 468
        },
        {
            "source": 66,
            "target": 416
        },
        {
            "source": 66,
            "target": 10
        },
        {
            "source": 86,
            "target": 1
        },
        {
            "source": 85,
            "target": 1
        },
        {
            "source": 12,
            "target": 79
        },
        {
            "source": 12,
            "target": 11
        },
        {
            "source": 12,
            "target": 13
        },
        {
            "source": 17,
            "target": 113
        },
        {
            "source": 17,
            "target": 314
        },
        {
            "source": 112,
            "target": 20
        },
        {
            "source": 433,
            "target": 427
        },
        {
            "source": 433,
            "target": 23
        },
        {
            "source": 98,
            "target": 97
        },
        {
            "source": 99,
            "target": 97
        },
        {
            "source": 98,
            "target": 99
        },
        {
            "source": 99,
            "target": 98
        },
        {
            "source": 97,
            "target": 82
        },
        {
            "source": 97,
            "target": 192
        },
        {
            "source": 97,
            "target": 79
        },
        {
            "source": 113,
            "target": 1
        },
        {
            "source": 79,
            "target": 1
        },
        {
            "source": 37,
            "target": 15
        },
        {
            "source": 469,
            "target": 10
        },
        {
            "source": 469,
            "target": 12
        },
        {
            "source": 469,
            "target": 31
        },
        {
            "source": 64,
            "target": 109
        },
        {
            "source": 470,
            "target": 1
        },
        {
            "source": 59,
            "target": 82
        },
        {
            "source": 170,
            "target": 1
        },
        {
            "source": 20,
            "target": 192
        },
        {
            "source": 421,
            "target": 127
        },
        {
            "source": 46,
            "target": 127
        },
        {
            "source": 28,
            "target": 114
        },
        {
            "source": 37,
            "target": 114
        },
        {
            "source": 187,
            "target": 10
        },
        {
            "source": 188,
            "target": 10
        },
        {
            "source": 100,
            "target": 169
        },
        {
            "source": 100,
            "target": 171
        },
        {
            "source": 10,
            "target": 416
        },
        {
            "source": 54,
            "target": 127
        },
        {
            "source": 54,
            "target": 82
        },
        {
            "source": 130,
            "target": 98
        },
        {
            "source": 130,
            "target": 99
        },
        {
            "source": 471,
            "target": 472
        },
        {
            "source": 471,
            "target": 473
        },
        {
            "source": 473,
            "target": 472
        },
        {
            "source": 473,
            "target": 474
        },
        {
            "source": 473,
            "target": 475
        },
        {
            "source": 473,
            "target": 476
        },
        {
            "source": 473,
            "target": 477
        },
        {
            "source": 473,
            "target": 478
        },
        {
            "source": 473,
            "target": 479
        },
        {
            "source": 24,
            "target": 70
        },
        {
            "source": 232,
            "target": 223
        },
        {
            "source": 232,
            "target": 480
        },
        {
            "source": 147,
            "target": 481
        },
        {
            "source": 109,
            "target": 311
        },
        {
            "source": 109,
            "target": 280
        },
        {
            "source": 109,
            "target": 482
        },
        {
            "source": 483,
            "target": 484
        },
        {
            "source": 483,
            "target": 63
        },
        {
            "source": 118,
            "target": 484
        },
        {
            "source": 118,
            "target": 63
        },
        {
            "source": 118,
            "target": 223
        },
        {
            "source": 109,
            "target": 237
        },
        {
            "source": 109,
            "target": 223
        },
        {
            "source": 137,
            "target": 385
        },
        {
            "source": 137,
            "target": 229
        },
        {
            "source": 137,
            "target": 118
        },
        {
            "source": 109,
            "target": 344
        },
        {
            "source": 109,
            "target": 345
        },
        {
            "source": 109,
            "target": 485
        },
        {
            "source": 486,
            "target": 137
        },
        {
            "source": 486,
            "target": 229
        },
        {
            "source": 269,
            "target": 137
        },
        {
            "source": 269,
            "target": 229
        },
        {
            "source": 486,
            "target": 268
        },
        {
            "source": 269,
            "target": 268
        },
        {
            "source": 486,
            "target": 269
        },
        {
            "source": 269,
            "target": 138
        },
        {
            "source": 269,
            "target": 64
        },
        {
            "source": 486,
            "target": 223
        },
        {
            "source": 269,
            "target": 201
        },
        {
            "source": 486,
            "target": 255
        },
        {
            "source": 486,
            "target": 258
        },
        {
            "source": 269,
            "target": 255
        },
        {
            "source": 269,
            "target": 257
        },
        {
            "source": 269,
            "target": 241
        },
        {
            "source": 269,
            "target": 258
        },
        {
            "source": 118,
            "target": 225
        },
        {
            "source": 403,
            "target": 118
        },
        {
            "source": 487,
            "target": 137
        },
        {
            "source": 487,
            "target": 229
        },
        {
            "source": 401,
            "target": 137
        },
        {
            "source": 401,
            "target": 229
        },
        {
            "source": 255,
            "target": 385
        },
        {
            "source": 118,
            "target": 137
        },
        {
            "source": 118,
            "target": 229
        },
        {
            "source": 487,
            "target": 268
        },
        {
            "source": 401,
            "target": 268
        },
        {
            "source": 255,
            "target": 268
        },
        {
            "source": 255,
            "target": 269
        },
        {
            "source": 118,
            "target": 268
        },
        {
            "source": 255,
            "target": 386
        },
        {
            "source": 255,
            "target": 488
        },
        {
            "source": 255,
            "target": 489
        },
        {
            "source": 255,
            "target": 490
        },
        {
            "source": 118,
            "target": 138
        },
        {
            "source": 118,
            "target": 215
        },
        {
            "source": 255,
            "target": 26
        },
        {
            "source": 118,
            "target": 26
        },
        {
            "source": 118,
            "target": 201
        },
        {
            "source": 16,
            "target": 452
        },
        {
            "source": 16,
            "target": 215
        },
        {
            "source": 491,
            "target": 266
        },
        {
            "source": 137,
            "target": 201
        },
        {
            "source": 215,
            "target": 229
        },
        {
            "source": 138,
            "target": 268
        },
        {
            "source": 137,
            "target": 386
        },
        {
            "source": 138,
            "target": 386
        },
        {
            "source": 137,
            "target": 26
        },
        {
            "source": 138,
            "target": 26
        },
        {
            "source": 229,
            "target": 26
        },
        {
            "source": 492,
            "target": 480
        },
        {
            "source": 493,
            "target": 473
        },
        {
            "source": 494,
            "target": 473
        },
        {
            "source": 473,
            "target": 495
        },
        {
            "source": 473,
            "target": 496
        },
        {
            "source": 473,
            "target": 497
        },
        {
            "source": 498,
            "target": 237
        },
        {
            "source": 498,
            "target": 223
        },
        {
            "source": 257,
            "target": 255
        },
        {
            "source": 257,
            "target": 241
        },
        {
            "source": 257,
            "target": 258
        },
        {
            "source": 257,
            "target": 259
        },
        {
            "source": 257,
            "target": 229
        },
        {
            "source": 257,
            "target": 260
        },
        {
            "source": 257,
            "target": 386
        },
        {
            "source": 201,
            "target": 279
        },
        {
            "source": 201,
            "target": 499
        },
        {
            "source": 201,
            "target": 500
        },
        {
            "source": 201,
            "target": 501
        },
        {
            "source": 201,
            "target": 502
        },
        {
            "source": 201,
            "target": 503
        },
        {
            "source": 201,
            "target": 280
        },
        {
            "source": 201,
            "target": 504
        },
        {
            "source": 201,
            "target": 460
        },
        {
            "source": 201,
            "target": 304
        },
        {
            "source": 116,
            "target": 485
        },
        {
            "source": 116,
            "target": 197
        },
        {
            "source": 116,
            "target": 344
        },
        {
            "source": 116,
            "target": 345
        },
        {
            "source": 505,
            "target": 214
        },
        {
            "source": 280,
            "target": 214
        },
        {
            "source": 15,
            "target": 70
        },
        {
            "source": 15,
            "target": 223
        },
        {
            "source": 43,
            "target": 411
        },
        {
            "source": 255,
            "target": 23
        },
        {
            "source": 15,
            "target": 14
        },
        {
            "source": 14,
            "target": 99
        },
        {
            "source": 14,
            "target": 98
        },
        {
            "source": 183,
            "target": 169
        },
        {
            "source": 183,
            "target": 171
        },
        {
            "source": 269,
            "target": 214
        },
        {
            "source": 125,
            "target": 127
        },
        {
            "source": 125,
            "target": 82
        },
        {
            "source": 126,
            "target": 127
        },
        {
            "source": 126,
            "target": 82
        },
        {
            "source": 94,
            "target": 127
        },
        {
            "source": 94,
            "target": 82
        },
        {
            "source": 67,
            "target": 1
        },
        {
            "source": 97,
            "target": 23
        },
        {
            "source": 506,
            "target": 1
        },
        {
            "source": 507,
            "target": 1
        },
        {
            "source": 508,
            "target": 1
        },
        {
            "source": 192,
            "target": 79
        },
        {
            "source": 192,
            "target": 26
        },
        {
            "source": 509,
            "target": 98
        },
        {
            "source": 509,
            "target": 99
        },
        {
            "source": 510,
            "target": 98
        },
        {
            "source": 510,
            "target": 99
        },
        {
            "source": 192,
            "target": 82
        },
        {
            "source": 127,
            "target": 82
        },
        {
            "source": 10,
            "target": 511
        },
        {
            "source": 512,
            "target": 26
        },
        {
            "source": 513,
            "target": 23
        },
        {
            "source": 23,
            "target": 514
        },
        {
            "source": 23,
            "target": 515
        },
        {
            "source": 70,
            "target": 201
        },
        {
            "source": 70,
            "target": 396
        },
        {
            "source": 516,
            "target": 214
        },
        {
            "source": 291,
            "target": 214
        },
        {
            "source": 517,
            "target": 518
        },
        {
            "source": 517,
            "target": 496
        },
        {
            "source": 517,
            "target": 519
        },
        {
            "source": 473,
            "target": 518
        },
        {
            "source": 473,
            "target": 46
        },
        {
            "source": 473,
            "target": 520
        },
        {
            "source": 473,
            "target": 519
        },
        {
            "source": 517,
            "target": 473
        },
        {
            "source": 473,
            "target": 521
        },
        {
            "source": 473,
            "target": 522
        },
        {
            "source": 473,
            "target": 523
        },
        {
            "source": 473,
            "target": 524
        },
        {
            "source": 203,
            "target": 69
        },
        {
            "source": 147,
            "target": 69
        },
        {
            "source": 15,
            "target": 24
        },
        {
            "source": 15,
            "target": 357
        },
        {
            "source": 403,
            "target": 63
        },
        {
            "source": 525,
            "target": 266
        },
        {
            "source": 266,
            "target": 526
        },
        {
            "source": 527,
            "target": 266
        },
        {
            "source": 266,
            "target": 528
        },
        {
            "source": 529,
            "target": 64
        },
        {
            "source": 530,
            "target": 16
        },
        {
            "source": 530,
            "target": 531
        },
        {
            "source": 530,
            "target": 223
        },
        {
            "source": 530,
            "target": 77
        },
        {
            "source": 239,
            "target": 232
        },
        {
            "source": 239,
            "target": 392
        },
        {
            "source": 239,
            "target": 393
        },
        {
            "source": 236,
            "target": 357
        },
        {
            "source": 236,
            "target": 70
        },
        {
            "source": 532,
            "target": 357
        },
        {
            "source": 533,
            "target": 357
        },
        {
            "source": 534,
            "target": 357
        },
        {
            "source": 535,
            "target": 357
        },
        {
            "source": 535,
            "target": 70
        },
        {
            "source": 74,
            "target": 64
        },
        {
            "source": 74,
            "target": 201
        },
        {
            "source": 536,
            "target": 73
        },
        {
            "source": 536,
            "target": 70
        },
        {
            "source": 47,
            "target": 73
        },
        {
            "source": 47,
            "target": 70
        },
        {
            "source": 537,
            "target": 73
        },
        {
            "source": 537,
            "target": 70
        },
        {
            "source": 259,
            "target": 260
        },
        {
            "source": 259,
            "target": 241
        },
        {
            "source": 326,
            "target": 279
        },
        {
            "source": 201,
            "target": 259
        },
        {
            "source": 201,
            "target": 260
        },
        {
            "source": 538,
            "target": 118
        },
        {
            "source": 64,
            "target": 201
        },
        {
            "source": 64,
            "target": 223
        },
        {
            "source": 15,
            "target": 201
        },
        {
            "source": 14,
            "target": 201
        },
        {
            "source": 14,
            "target": 280
        },
        {
            "source": 15,
            "target": 539
        },
        {
            "source": 14,
            "target": 539
        },
        {
            "source": 198,
            "target": 16
        },
        {
            "source": 16,
            "target": 540
        },
        {
            "source": 541,
            "target": 269
        },
        {
            "source": 269,
            "target": 480
        },
        {
            "source": 77,
            "target": 223
        },
        {
            "source": 64,
            "target": 262
        },
        {
            "source": 64,
            "target": 24
        },
        {
            "source": 223,
            "target": 118
        },
        {
            "source": 542,
            "target": 223
        },
        {
            "source": 138,
            "target": 223
        },
        {
            "source": 542,
            "target": 531
        },
        {
            "source": 223,
            "target": 543
        },
        {
            "source": 223,
            "target": 531
        },
        {
            "source": 223,
            "target": 63
        },
        {
            "source": 223,
            "target": 16
        },
        {
            "source": 427,
            "target": 23
        },
        {
            "source": 98,
            "target": 212
        },
        {
            "source": 98,
            "target": 317
        },
        {
            "source": 99,
            "target": 212
        },
        {
            "source": 99,
            "target": 317
        },
        {
            "source": 46,
            "target": 10
        },
        {
            "source": 544,
            "target": 1
        },
        {
            "source": 545,
            "target": 1
        },
        {
            "source": 546,
            "target": 1
        },
        {
            "source": 295,
            "target": 3
        },
        {
            "source": 89,
            "target": 314
        },
        {
            "source": 94,
            "target": 293
        },
        {
            "source": 171,
            "target": 170
        },
        {
            "source": 103,
            "target": 171
        },
        {
            "source": 103,
            "target": 170
        },
        {
            "source": 69,
            "target": 212
        },
        {
            "source": 69,
            "target": 317
        },
        {
            "source": 150,
            "target": 98
        },
        {
            "source": 184,
            "target": 98
        },
        {
            "source": 150,
            "target": 99
        },
        {
            "source": 215,
            "target": 239
        },
        {
            "source": 215,
            "target": 547
        },
        {
            "source": 214,
            "target": 548
        },
        {
            "source": 214,
            "target": 547
        },
        {
            "source": 239,
            "target": 549
        },
        {
            "source": 239,
            "target": 550
        },
        {
            "source": 239,
            "target": 551
        },
        {
            "source": 239,
            "target": 552
        },
        {
            "source": 239,
            "target": 553
        },
        {
            "source": 215,
            "target": 554
        },
        {
            "source": 215,
            "target": 555
        },
        {
            "source": 214,
            "target": 554
        },
        {
            "source": 214,
            "target": 555
        },
        {
            "source": 556,
            "target": 557
        },
        {
            "source": 556,
            "target": 138
        },
        {
            "source": 558,
            "target": 557
        },
        {
            "source": 558,
            "target": 138
        },
        {
            "source": 559,
            "target": 557
        },
        {
            "source": 559,
            "target": 138
        },
        {
            "source": 556,
            "target": 560
        },
        {
            "source": 556,
            "target": 561
        },
        {
            "source": 556,
            "target": 562
        },
        {
            "source": 558,
            "target": 560
        },
        {
            "source": 558,
            "target": 561
        },
        {
            "source": 558,
            "target": 562
        },
        {
            "source": 559,
            "target": 560
        },
        {
            "source": 559,
            "target": 561
        },
        {
            "source": 559,
            "target": 562
        },
        {
            "source": 396,
            "target": 64
        },
        {
            "source": 396,
            "target": 83
        },
        {
            "source": 396,
            "target": 223
        },
        {
            "source": 118,
            "target": 64
        },
        {
            "source": 118,
            "target": 83
        },
        {
            "source": 396,
            "target": 70
        },
        {
            "source": 118,
            "target": 70
        },
        {
            "source": 198,
            "target": 480
        },
        {
            "source": 16,
            "target": 480
        },
        {
            "source": 563,
            "target": 64
        },
        {
            "source": 563,
            "target": 83
        },
        {
            "source": 268,
            "target": 26
        },
        {
            "source": 268,
            "target": 480
        },
        {
            "source": 229,
            "target": 480
        },
        {
            "source": 69,
            "target": 417
        },
        {
            "source": 69,
            "target": 403
        },
        {
            "source": 564,
            "target": 269
        },
        {
            "source": 232,
            "target": 214
        },
        {
            "source": 269,
            "target": 443
        },
        {
            "source": 269,
            "target": 444
        },
        {
            "source": 268,
            "target": 260
        },
        {
            "source": 268,
            "target": 565
        },
        {
            "source": 268,
            "target": 566
        },
        {
            "source": 268,
            "target": 567
        },
        {
            "source": 165,
            "target": 280
        },
        {
            "source": 568,
            "target": 73
        },
        {
            "source": 16,
            "target": 223
        },
        {
            "source": 15,
            "target": 64
        },
        {
            "source": 15,
            "target": 83
        },
        {
            "source": 224,
            "target": 16
        },
        {
            "source": 16,
            "target": 77
        },
        {
            "source": 16,
            "target": 569
        },
        {
            "source": 570,
            "target": 70
        },
        {
            "source": 571,
            "target": 70
        },
        {
            "source": 572,
            "target": 70
        },
        {
            "source": 249,
            "target": 349
        },
        {
            "source": 249,
            "target": 246
        },
        {
            "source": 573,
            "target": 266
        },
        {
            "source": 573,
            "target": 301
        },
        {
            "source": 491,
            "target": 301
        },
        {
            "source": 266,
            "target": 301
        },
        {
            "source": 266,
            "target": 223
        },
        {
            "source": 574,
            "target": 259
        },
        {
            "source": 482,
            "target": 259
        },
        {
            "source": 498,
            "target": 77
        },
        {
            "source": 575,
            "target": 223
        },
        {
            "source": 116,
            "target": 98
        },
        {
            "source": 413,
            "target": 31
        },
        {
            "source": 31,
            "target": 576
        },
        {
            "source": 31,
            "target": 577
        },
        {
            "source": 31,
            "target": 98
        },
        {
            "source": 31,
            "target": 578
        },
        {
            "source": 31,
            "target": 9
        },
        {
            "source": 31,
            "target": 579
        },
        {
            "source": 31,
            "target": 580
        },
        {
            "source": 31,
            "target": 581
        },
        {
            "source": 31,
            "target": 582
        },
        {
            "source": 31,
            "target": 583
        },
        {
            "source": 97,
            "target": 514
        },
        {
            "source": 97,
            "target": 431
        },
        {
            "source": 97,
            "target": 98
        },
        {
            "source": 97,
            "target": 99
        },
        {
            "source": 332,
            "target": 1
        },
        {
            "source": 584,
            "target": 1
        },
        {
            "source": 585,
            "target": 1
        },
        {
            "source": 87,
            "target": 98
        },
        {
            "source": 87,
            "target": 99
        },
        {
            "source": 88,
            "target": 98
        },
        {
            "source": 88,
            "target": 99
        },
        {
            "source": 10,
            "target": 586
        },
        {
            "source": 10,
            "target": 587
        },
        {
            "source": 10,
            "target": 98
        },
        {
            "source": 588,
            "target": 23
        },
        {
            "source": 116,
            "target": 223
        },
        {
            "source": 215,
            "target": 480
        },
        {
            "source": 256,
            "target": 259
        },
        {
            "source": 256,
            "target": 260
        },
        {
            "source": 241,
            "target": 260
        },
        {
            "source": 241,
            "target": 255
        },
        {
            "source": 241,
            "target": 257
        },
        {
            "source": 241,
            "target": 258
        },
        {
            "source": 137,
            "target": 557
        },
        {
            "source": 268,
            "target": 223
        },
        {
            "source": 138,
            "target": 557
        },
        {
            "source": 73,
            "target": 311
        },
        {
            "source": 70,
            "target": 117
        },
        {
            "source": 70,
            "target": 589
        },
        {
            "source": 262,
            "target": 70
        },
        {
            "source": 262,
            "target": 64
        },
        {
            "source": 262,
            "target": 83
        },
        {
            "source": 262,
            "target": 223
        },
        {
            "source": 262,
            "target": 357
        },
        {
            "source": 262,
            "target": 305
        },
        {
            "source": 305,
            "target": 396
        },
        {
            "source": 305,
            "target": 118
        },
        {
            "source": 138,
            "target": 480
        },
        {
            "source": 357,
            "target": 70
        },
        {
            "source": 472,
            "target": 518
        },
        {
            "source": 472,
            "target": 496
        },
        {
            "source": 472,
            "target": 519
        },
        {
            "source": 472,
            "target": 479
        },
        {
            "source": 472,
            "target": 497
        },
        {
            "source": 69,
            "target": 118
        },
        {
            "source": 83,
            "target": 64
        },
        {
            "source": 255,
            "target": 460
        },
        {
            "source": 258,
            "target": 460
        },
        {
            "source": 590,
            "target": 1
        },
        {
            "source": 506,
            "target": 23
        },
        {
            "source": 412,
            "target": 23
        },
        {
            "source": 577,
            "target": 9
        },
        {
            "source": 576,
            "target": 9
        },
        {
            "source": 97,
            "target": 9
        },
        {
            "source": 97,
            "target": 578
        },
        {
            "source": 97,
            "target": 579
        },
        {
            "source": 97,
            "target": 580
        },
        {
            "source": 97,
            "target": 581
        },
        {
            "source": 97,
            "target": 582
        },
        {
            "source": 97,
            "target": 583
        },
        {
            "source": 97,
            "target": 26
        },
        {
            "source": 591,
            "target": 98
        },
        {
            "source": 9,
            "target": 1
        },
        {
            "source": 98,
            "target": 592
        },
        {
            "source": 99,
            "target": 592
        },
        {
            "source": 23,
            "target": 593
        },
        {
            "source": 26,
            "target": 511
        },
        {
            "source": 538,
            "target": 63
        },
        {
            "source": 594,
            "target": 305
        },
        {
            "source": 305,
            "target": 595
        },
        {
            "source": 305,
            "target": 596
        },
        {
            "source": 64,
            "target": 300
        },
        {
            "source": 64,
            "target": 63
        },
        {
            "source": 403,
            "target": 64
        },
        {
            "source": 403,
            "target": 223
        },
        {
            "source": 597,
            "target": 14
        },
        {
            "source": 77,
            "target": 201
        },
        {
            "source": 77,
            "target": 266
        },
        {
            "source": 16,
            "target": 531
        },
        {
            "source": 598,
            "target": 63
        },
        {
            "source": 64,
            "target": 599
        },
        {
            "source": 598,
            "target": 300
        },
        {
            "source": 600,
            "target": 531
        },
        {
            "source": 305,
            "target": 601
        },
        {
            "source": 305,
            "target": 543
        },
        {
            "source": 305,
            "target": 531
        },
        {
            "source": 305,
            "target": 223
        },
        {
            "source": 305,
            "target": 602
        },
        {
            "source": 603,
            "target": 531
        },
        {
            "source": 603,
            "target": 223
        },
        {
            "source": 604,
            "target": 531
        },
        {
            "source": 604,
            "target": 223
        },
        {
            "source": 77,
            "target": 399
        },
        {
            "source": 77,
            "target": 400
        },
        {
            "source": 605,
            "target": 286
        },
        {
            "source": 286,
            "target": 254
        },
        {
            "source": 606,
            "target": 266
        },
        {
            "source": 258,
            "target": 26
        },
        {
            "source": 224,
            "target": 300
        },
        {
            "source": 224,
            "target": 63
        },
        {
            "source": 16,
            "target": 300
        },
        {
            "source": 607,
            "target": 498
        },
        {
            "source": 607,
            "target": 77
        },
        {
            "source": 498,
            "target": 531
        },
        {
            "source": 607,
            "target": 223
        },
        {
            "source": 607,
            "target": 531
        },
        {
            "source": 498,
            "target": 116
        },
        {
            "source": 498,
            "target": 608
        },
        {
            "source": 498,
            "target": 609
        },
        {
            "source": 275,
            "target": 269
        },
        {
            "source": 457,
            "target": 446
        },
        {
            "source": 259,
            "target": 262
        },
        {
            "source": 259,
            "target": 610
        },
        {
            "source": 611,
            "target": 260
        },
        {
            "source": 611,
            "target": 259
        },
        {
            "source": 574,
            "target": 260
        },
        {
            "source": 482,
            "target": 260
        },
        {
            "source": 114,
            "target": 115
        },
        {
            "source": 114,
            "target": 9
        },
        {
            "source": 115,
            "target": 114
        },
        {
            "source": 115,
            "target": 9
        },
        {
            "source": 9,
            "target": 114
        },
        {
            "source": 9,
            "target": 115
        },
        {
            "source": 305,
            "target": 1
        },
        {
            "source": 98,
            "target": 23
        },
        {
            "source": 98,
            "target": 514
        },
        {
            "source": 98,
            "target": 431
        },
        {
            "source": 612,
            "target": 98
        },
        {
            "source": 56,
            "target": 98
        },
        {
            "source": 612,
            "target": 99
        },
        {
            "source": 56,
            "target": 99
        },
        {
            "source": 613,
            "target": 26
        },
        {
            "source": 153,
            "target": 9
        },
        {
            "source": 437,
            "target": 460
        },
        {
            "source": 304,
            "target": 460
        },
        {
            "source": 437,
            "target": 504
        },
        {
            "source": 304,
            "target": 504
        },
        {
            "source": 304,
            "target": 138
        },
        {
            "source": 437,
            "target": 19
        },
        {
            "source": 304,
            "target": 19
        },
        {
            "source": 304,
            "target": 499
        },
        {
            "source": 304,
            "target": 500
        },
        {
            "source": 304,
            "target": 501
        },
        {
            "source": 304,
            "target": 502
        },
        {
            "source": 304,
            "target": 503
        },
        {
            "source": 437,
            "target": 201
        },
        {
            "source": 437,
            "target": 614
        },
        {
            "source": 304,
            "target": 201
        },
        {
            "source": 304,
            "target": 614
        },
        {
            "source": 262,
            "target": 615
        },
        {
            "source": 262,
            "target": 616
        },
        {
            "source": 225,
            "target": 223
        },
        {
            "source": 607,
            "target": 399
        },
        {
            "source": 607,
            "target": 400
        },
        {
            "source": 498,
            "target": 399
        },
        {
            "source": 498,
            "target": 400
        },
        {
            "source": 64,
            "target": 19
        },
        {
            "source": 63,
            "target": 223
        },
        {
            "source": 63,
            "target": 485
        },
        {
            "source": 63,
            "target": 118
        },
        {
            "source": 63,
            "target": 305
        },
        {
            "source": 617,
            "target": 63
        },
        {
            "source": 618,
            "target": 504
        },
        {
            "source": 618,
            "target": 460
        },
        {
            "source": 257,
            "target": 446
        },
        {
            "source": 255,
            "target": 446
        },
        {
            "source": 241,
            "target": 446
        },
        {
            "source": 258,
            "target": 446
        },
        {
            "source": 241,
            "target": 138
        },
        {
            "source": 258,
            "target": 241
        },
        {
            "source": 619,
            "target": 201
        },
        {
            "source": 259,
            "target": 346
        },
        {
            "source": 266,
            "target": 620
        },
        {
            "source": 147,
            "target": 599
        },
        {
            "source": 63,
            "target": 599
        },
        {
            "source": 147,
            "target": 621
        },
        {
            "source": 599,
            "target": 621
        },
        {
            "source": 599,
            "target": 622
        },
        {
            "source": 63,
            "target": 621
        },
        {
            "source": 305,
            "target": 16
        },
        {
            "source": 300,
            "target": 623
        },
        {
            "source": 300,
            "target": 63
        },
        {
            "source": 624,
            "target": 304
        },
        {
            "source": 304,
            "target": 26
        },
        {
            "source": 555,
            "target": 286
        },
        {
            "source": 286,
            "target": 530
        },
        {
            "source": 286,
            "target": 16
        },
        {
            "source": 305,
            "target": 423
        },
        {
            "source": 305,
            "target": 424
        },
        {
            "source": 625,
            "target": 626
        },
        {
            "source": 625,
            "target": 305
        },
        {
            "source": 305,
            "target": 626
        },
        {
            "source": 26,
            "target": 627
        },
        {
            "source": 437,
            "target": 304
        },
        {
            "source": 16,
            "target": 530
        },
        {
            "source": 403,
            "target": 269
        },
        {
            "source": 137,
            "target": 259
        },
        {
            "source": 138,
            "target": 259
        },
        {
            "source": 547,
            "target": 609
        },
        {
            "source": 272,
            "target": 305
        },
        {
            "source": 98,
            "target": 114
        },
        {
            "source": 99,
            "target": 114
        },
        {
            "source": 98,
            "target": 429
        },
        {
            "source": 98,
            "target": 430
        },
        {
            "source": 99,
            "target": 429
        },
        {
            "source": 99,
            "target": 430
        },
        {
            "source": 98,
            "target": 628
        },
        {
            "source": 99,
            "target": 431
        },
        {
            "source": 99,
            "target": 628
        },
        {
            "source": 99,
            "target": 23
        },
        {
            "source": 98,
            "target": 629
        },
        {
            "source": 99,
            "target": 629
        },
        {
            "source": 305,
            "target": 609
        },
        {
            "source": 305,
            "target": 452
        },
        {
            "source": 116,
            "target": 609
        },
        {
            "source": 116,
            "target": 452
        },
        {
            "source": 225,
            "target": 26
        },
        {
            "source": 279,
            "target": 19
        },
        {
            "source": 305,
            "target": 485
        },
        {
            "source": 480,
            "target": 215
        },
        {
            "source": 630,
            "target": 26
        },
        {
            "source": 631,
            "target": 26
        },
        {
            "source": 615,
            "target": 262
        },
        {
            "source": 616,
            "target": 262
        },
        {
            "source": 74,
            "target": 609
        },
        {
            "source": 632,
            "target": 609
        },
        {
            "source": 633,
            "target": 609
        },
        {
            "source": 163,
            "target": 609
        },
        {
            "source": 632,
            "target": 116
        },
        {
            "source": 633,
            "target": 116
        },
        {
            "source": 633,
            "target": 109
        },
        {
            "source": 163,
            "target": 116
        },
        {
            "source": 531,
            "target": 223
        },
        {
            "source": 531,
            "target": 77
        },
        {
            "source": 531,
            "target": 225
        },
        {
            "source": 531,
            "target": 634
        },
        {
            "source": 531,
            "target": 635
        },
        {
            "source": 346,
            "target": 1
        },
        {
            "source": 402,
            "target": 530
        },
        {
            "source": 636,
            "target": 530
        },
        {
            "source": 636,
            "target": 402
        },
        {
            "source": 636,
            "target": 637
        },
        {
            "source": 305,
            "target": 638
        },
        {
            "source": 305,
            "target": 639
        },
        {
            "source": 305,
            "target": 640
        },
        {
            "source": 349,
            "target": 357
        },
        {
            "source": 349,
            "target": 246
        },
        {
            "source": 349,
            "target": 362
        },
        {
            "source": 349,
            "target": 361
        },
        {
            "source": 349,
            "target": 70
        },
        {
            "source": 227,
            "target": 1
        },
        {
            "source": 434,
            "target": 304
        },
        {
            "source": 138,
            "target": 446
        },
        {
            "source": 300,
            "target": 118
        },
        {
            "source": 605,
            "target": 641
        },
        {
            "source": 642,
            "target": 641
        },
        {
            "source": 559,
            "target": 641
        },
        {
            "source": 559,
            "target": 16
        },
        {
            "source": 643,
            "target": 609
        },
        {
            "source": 609,
            "target": 452
        },
        {
            "source": 643,
            "target": 116
        },
        {
            "source": 609,
            "target": 116
        },
        {
            "source": 609,
            "target": 109
        },
        {
            "source": 644,
            "target": 70
        },
        {
            "source": 246,
            "target": 70
        },
        {
            "source": 304,
            "target": 446
        },
        {
            "source": 269,
            "target": 459
        },
        {
            "source": 269,
            "target": 565
        },
        {
            "source": 269,
            "target": 566
        },
        {
            "source": 269,
            "target": 567
        },
        {
            "source": 269,
            "target": 645
        },
        {
            "source": 77,
            "target": 225
        },
        {
            "source": 646,
            "target": 77
        },
        {
            "source": 77,
            "target": 531
        },
        {
            "source": 646,
            "target": 531
        },
        {
            "source": 646,
            "target": 223
        },
        {
            "source": 77,
            "target": 609
        },
        {
            "source": 259,
            "target": 647
        },
        {
            "source": 259,
            "target": 648
        },
        {
            "source": 357,
            "target": 349
        },
        {
            "source": 357,
            "target": 246
        },
        {
            "source": 357,
            "target": 361
        },
        {
            "source": 246,
            "target": 357
        },
        {
            "source": 246,
            "target": 349
        },
        {
            "source": 246,
            "target": 361
        },
        {
            "source": 77,
            "target": 452
        },
        {
            "source": 609,
            "target": 1
        },
        {
            "source": 114,
            "target": 318
        },
        {
            "source": 114,
            "target": 578
        },
        {
            "source": 114,
            "target": 579
        },
        {
            "source": 114,
            "target": 580
        },
        {
            "source": 114,
            "target": 581
        },
        {
            "source": 114,
            "target": 582
        },
        {
            "source": 114,
            "target": 583
        },
        {
            "source": 334,
            "target": 9
        },
        {
            "source": 9,
            "target": 578
        },
        {
            "source": 9,
            "target": 579
        },
        {
            "source": 9,
            "target": 580
        },
        {
            "source": 9,
            "target": 581
        },
        {
            "source": 9,
            "target": 582
        },
        {
            "source": 9,
            "target": 583
        },
        {
            "source": 116,
            "target": 595
        },
        {
            "source": 116,
            "target": 596
        },
        {
            "source": 63,
            "target": 609
        },
        {
            "source": 98,
            "target": 1
        },
        {
            "source": 452,
            "target": 1
        },
        {
            "source": 530,
            "target": 225
        },
        {
            "source": 649,
            "target": 286
        },
        {
            "source": 650,
            "target": 286
        },
        {
            "source": 391,
            "target": 651
        },
        {
            "source": 391,
            "target": 652
        },
        {
            "source": 652,
            "target": 637
        },
        {
            "source": 653,
            "target": 1
        },
        {
            "source": 569,
            "target": 654
        },
        {
            "source": 641,
            "target": 254
        },
        {
            "source": 641,
            "target": 547
        },
        {
            "source": 641,
            "target": 655
        },
        {
            "source": 641,
            "target": 548
        },
        {
            "source": 656,
            "target": 1
        },
        {
            "source": 423,
            "target": 424
        },
        {
            "source": 657,
            "target": 9
        },
        {
            "source": 23,
            "target": 658
        },
        {
            "source": 163,
            "target": 305
        },
        {
            "source": 109,
            "target": 609
        },
        {
            "source": 16,
            "target": 305
        },
        {
            "source": 138,
            "target": 565
        },
        {
            "source": 519,
            "target": 497
        },
        {
            "source": 519,
            "target": 496
        },
        {
            "source": 519,
            "target": 524
        },
        {
            "source": 63,
            "target": 659
        },
        {
            "source": 63,
            "target": 660
        },
        {
            "source": 638,
            "target": 305
        },
        {
            "source": 638,
            "target": 640
        },
        {
            "source": 638,
            "target": 639
        },
        {
            "source": 305,
            "target": 661
        },
        {
            "source": 609,
            "target": 485
        },
        {
            "source": 662,
            "target": 116
        },
        {
            "source": 663,
            "target": 116
        },
        {
            "source": 305,
            "target": 664
        },
        {
            "source": 305,
            "target": 163
        },
        {
            "source": 305,
            "target": 665
        },
        {
            "source": 666,
            "target": 667
        },
        {
            "source": 114,
            "target": 668
        },
        {
            "source": 9,
            "target": 668
        },
        {
            "source": 63,
            "target": 452
        },
        {
            "source": 63,
            "target": 531
        },
        {
            "source": 225,
            "target": 609
        },
        {
            "source": 225,
            "target": 452
        },
        {
            "source": 669,
            "target": 138
        },
        {
            "source": 629,
            "target": 98
        },
        {
            "source": 223,
            "target": 77
        },
        {
            "source": 223,
            "target": 225
        },
        {
            "source": 223,
            "target": 634
        },
        {
            "source": 223,
            "target": 635
        },
        {
            "source": 524,
            "target": 1
        },
        {
            "source": 670,
            "target": 266
        },
        {
            "source": 304,
            "target": 669
        },
        {
            "source": 304,
            "target": 671
        },
        {
            "source": 672,
            "target": 667
        },
        {
            "source": 672,
            "target": 673
        },
        {
            "source": 667,
            "target": 666
        },
        {
            "source": 667,
            "target": 674
        },
        {
            "source": 667,
            "target": 675
        },
        {
            "source": 667,
            "target": 676
        },
        {
            "source": 667,
            "target": 673
        },
        {
            "source": 70,
            "target": 609
        },
        {
            "source": 485,
            "target": 1
        },
        {
            "source": 677,
            "target": 1
        },
        {
            "source": 678,
            "target": 679
        },
        {
            "source": 318,
            "target": 114
        },
        {
            "source": 664,
            "target": 595
        },
        {
            "source": 664,
            "target": 596
        },
        {
            "source": 664,
            "target": 305
        },
        {
            "source": 664,
            "target": 665
        },
        {
            "source": 114,
            "target": 98
        },
        {
            "source": 318,
            "target": 98
        },
        {
            "source": 668,
            "target": 609
        },
        {
            "source": 668,
            "target": 452
        },
        {
            "source": 227,
            "target": 680
        },
        {
            "source": 595,
            "target": 596
        },
        {
            "source": 596,
            "target": 595
        },
        {
            "source": 679,
            "target": 681
        },
        {
            "source": 679,
            "target": 678
        },
        {
            "source": 16,
            "target": 595
        },
        {
            "source": 16,
            "target": 596
        },
        {
            "source": 596,
            "target": 305
        },
        {
            "source": 595,
            "target": 305
        },
        {
            "source": 637,
            "target": 682
        },
        {
            "source": 652,
            "target": 682
        },
        {
            "source": 652,
            "target": 683
        },
        {
            "source": 652,
            "target": 684
        },
        {
            "source": 652,
            "target": 685
        },
        {
            "source": 652,
            "target": 686
        },
        {
            "source": 661,
            "target": 305
        },
        {
            "source": 620,
            "target": 266
        },
        {
            "source": 452,
            "target": 609
        },
        {
            "source": 665,
            "target": 305
        },
        {
            "source": 528,
            "target": 266
        },
        {
            "source": 528,
            "target": 526
        },
        {
            "source": 687,
            "target": 688
        }
    ],
    "nodes": [
        {
            "name": "Schreck, T.",
            "value": 150,
            "numPapers": 54,
            "cluster": "5",
            "index": 0,
            "weight": 2,
            "x": 535.8478903468572,
            "y": 611.9624791028439,
            "px": 653.3670142848747,
            "py": 702.4935707108328,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Graph-theoretic scagnostics",
                "PaperDOI": "10.1109/INFVIS.2005.1532142",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532142",
                "firstage": "157",
                "Lastage": "164",
                "IEEEXPLOREArticleNumber": "1532142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.",
                "AuthorNames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "FirstAuthorAffiliation": "SPSS Inc., Chicago, IL, USA|c|;;",
                "AuthorIDs": "37560536200;37548165700;37270222000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "filename": "wilkinso_infovis_05",
                "Citations": "1249006;1382892;1382895"
            }
        },
        {
            "name": "Cox, D. C.",
            "value": 2987,
            "numPapers": 1,
            "cluster": "5",
            "index": 1,
            "weight": 72,
            "x": 121.94201576870724,
            "y": 371.2110852583716,
            "px": 170.62330312581682,
            "py": 391.2005728139921,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Interdisciplinary visualization: lessons learned at NCSA",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846",
                "firstage": "457",
                "Lastage": "457",
                "IEEEXPLOREArticleNumber": "",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "",
                "AuthorNames": "Cox, D. C.",
                "FirstAuthorAffiliation": "National Center for Supercomputing Applications",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cox, D. C.",
                "filename": "",
                "Citations": ""
            }
        },
        {
            "name": "Bradel, L.",
            "value": 18,
            "numPapers": 12,
            "cluster": "3",
            "index": 2,
            "weight": 1,
            "x": 349.5974727170855,
            "y": -335.7360708579721,
            "px": 694.6486113474431,
            "py": -979.8438631232307,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "North, C.",
            "value": 213,
            "numPapers": 75,
            "cluster": "3",
            "index": 3,
            "weight": 18,
            "x": -113.53663381341292,
            "y": 451.8890694897244,
            "px": -117.68299776020449,
            "py": 457.24668996823755,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "Endert, A.",
            "value": 84,
            "numPapers": 17,
            "cluster": "3",
            "index": 4,
            "weight": 1,
            "x": -374.79793154338165,
            "y": -240.23989501245737,
            "px": -607.8574680250799,
            "py": -797.8374007890768,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "Chao Han",
            "value": 45,
            "numPapers": 1,
            "cluster": "3",
            "index": 5,
            "weight": 1,
            "x": -811.714504074722,
            "y": 852.255219945434,
            "px": -1401.256916625149,
            "py": 1163.718216709551,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "Maiti, D.",
            "value": 63,
            "numPapers": 6,
            "cluster": "3",
            "index": 6,
            "weight": 1,
            "x": -795.1354973857127,
            "y": 1009.7940536280629,
            "px": -1375.3701045122914,
            "py": 1448.0729229027856,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "House, L.",
            "value": 63,
            "numPapers": 6,
            "cluster": "3",
            "index": 7,
            "weight": 1,
            "x": 200.20367359857096,
            "y": -362.24767581141424,
            "px": 428.1401035953151,
            "py": -1023.2343389355914,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "Leman, S.",
            "value": 63,
            "numPapers": 13,
            "cluster": "3",
            "index": 8,
            "weight": 2,
            "x": 371.8027267701036,
            "y": 866.0597390007339,
            "px": -173.31994631647714,
            "py": 381.0749780259475,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "firstage": "121",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "6102449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "filename": "endert_vast_11",
                "Citations": ""
            }
        },
        {
            "name": "Thomas, J.",
            "value": 318,
            "numPapers": 31,
            "cluster": "2",
            "index": 9,
            "weight": 23,
            "x": -70.26737713565352,
            "y": 336.19873060302,
            "px": -384.20705142198926,
            "py": 308.4982263120171,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "firstage": "105",
                "Lastage": "111",
                "IEEEXPLOREArticleNumber": "885097",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as AÔåÆBÔåÆCÔåÆD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "filename": "wong_infovis_00",
                "Citations": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Stasko, J.",
            "value": 941,
            "numPapers": 143,
            "cluster": "3",
            "index": 10,
            "weight": 73,
            "x": 112.9423947067192,
            "y": 586.3721914387186,
            "px": 99.66212305705565,
            "py": 586.4088250631695,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Jigsaw: Supporting Investigative Analysis through Interactive Visualization",
                "PaperDOI": "10.1109/VAST.2007.4389006",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389006",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "4389006",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.",
                "AuthorNames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": "37267736900;37428446300;37592993600;37968367000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "filename": "stasko_vast_07",
                "Citations": "528686;1382887;4035749"
            }
        },
        {
            "name": "Gorg, C.",
            "value": 222,
            "numPapers": 11,
            "cluster": "3",
            "index": 11,
            "weight": 9,
            "x": -426.51214104553856,
            "y": 76.47343981403426,
            "px": -443.755857514372,
            "py": 66.008845266282,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Jigsaw: Supporting Investigative Analysis through Interactive Visualization",
                "PaperDOI": "10.1109/VAST.2007.4389006",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389006",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "4389006",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.",
                "AuthorNames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": "37267736900;37428446300;37592993600;37968367000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "filename": "stasko_vast_07",
                "Citations": "528686;1382887;4035749"
            }
        },
        {
            "name": "Zhicheng Liu",
            "value": 340,
            "numPapers": 42,
            "cluster": "3",
            "index": 12,
            "weight": 16,
            "x": 330.034350176271,
            "y": 528.4699659406918,
            "px": 370.66796581101164,
            "py": 571.0423185176928,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Jigsaw: Supporting Investigative Analysis through Interactive Visualization",
                "PaperDOI": "10.1109/VAST.2007.4389006",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389006",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "4389006",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.",
                "AuthorNames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": "37267736900;37428446300;37592993600;37968367000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "filename": "stasko_vast_07",
                "Citations": "528686;1382887;4035749"
            }
        },
        {
            "name": "Singhal, K.",
            "value": 197,
            "numPapers": 5,
            "cluster": "3",
            "index": 13,
            "weight": 6,
            "x": -903.2691887842991,
            "y": -213.9894178770408,
            "px": -788.5768045582096,
            "py": -114.11868691652597,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Jigsaw: Supporting Investigative Analysis through Interactive Visualization",
                "PaperDOI": "10.1109/VAST.2007.4389006",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389006",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "4389006",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.",
                "AuthorNames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": "37267736900;37428446300;37592993600;37968367000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "filename": "stasko_vast_07",
                "Citations": "528686;1382887;4035749"
            }
        },
        {
            "name": "Kwan-Liu Ma",
            "value": 643,
            "numPapers": 224,
            "cluster": "5",
            "index": 14,
            "weight": 50,
            "x": 179.33384292524025,
            "y": 362.7025533984249,
            "px": 185.28204853983337,
            "py": 351.86087831798216,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "firstage": "2467",
                "Lastage": "2476",
                "IEEEXPLOREArticleNumber": "6327252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "filename": "landge_infovis_12",
                "Citations": "5290721;1382906"
            }
        },
        {
            "name": "Correa, C.",
            "value": 232,
            "numPapers": 74,
            "cluster": "5",
            "index": 15,
            "weight": 20,
            "x": 158.07544957262536,
            "y": 369.33858866643186,
            "px": 138.91888948911077,
            "py": 372.89011351112066,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Proximity-based visualization of movement trace data",
                "PaperDOI": "10.1109/VAST.2009.5332593",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332593",
                "firstage": "11",
                "Lastage": "18",
                "IEEEXPLOREArticleNumber": "5332593",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.",
                "AuthorNames": "Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, CA, USA|c|;;;",
                "AuthorIDs": "37597152500;37299311900;37282925900;37275869400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma",
                "filename": "crnovrsa_vast_09",
                "Citations": "1382887;146402;4376136;4376135"
            }
        },
        {
            "name": "Silva, C.T.",
            "value": 502,
            "numPapers": 171,
            "cluster": "5",
            "index": 16,
            "weight": 41,
            "x": 169.83013995060483,
            "y": 327.98173988920666,
            "px": 209.950665980506,
            "py": 353.69612125160324,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "SnapShot: Visualization to Propel Ice Hockey Analytics",
                "PaperDOI": "10.1109/TVCG.2012.263",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.263",
                "firstage": "2819",
                "Lastage": "2828",
                "IEEEXPLOREArticleNumber": "6327288",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.",
                "AuthorNames": "Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.T.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38488862800;38490190000;38490191800;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.",
                "filename": "pileggi_infovis_12",
                "Citations": "5613452;4376130;636793;6064996;4376131;559229"
            }
        },
        {
            "name": "Fekete, J.",
            "value": 530,
            "numPapers": 105,
            "cluster": "3",
            "index": 17,
            "weight": 36,
            "x": 15.810868665930629,
            "y": 623.7485699093485,
            "px": 46.53278081665865,
            "py": 634.816948795657,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "SoccerStories: A Kick-off for Visual Soccer Analysis",
                "PaperDOI": "10.1109/TVCG.2013.192",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.192",
                "firstage": "2506",
                "Lastage": "2515",
                "IEEEXPLOREArticleNumber": "6634087",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.",
                "AuthorNames": "Perin, C.;Vuillemot, R.;Fekete, J.-D.",
                "FirstAuthorAffiliation": "INRIA, Univ. Paris-Sud, Paris, France|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Perin, C.;Vuillemot, R.;Fekete, J.",
                "filename": "perin_infovis_13",
                "Citations": "4376154;6064994;6064996;6327288"
            }
        },
        {
            "name": "Ziemkiewicz, C.",
            "value": 78,
            "numPapers": 30,
            "cluster": "3",
            "index": 18,
            "weight": 2,
            "x": 183.36281691106058,
            "y": 392.37336357859243,
            "px": 426.7139056795669,
            "py": 311.28085298154696,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "How Capacity Limits of Attention Influence Information Visualization Effectiveness",
                "PaperDOI": "10.1109/TVCG.2012.233",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.233",
                "firstage": "2402",
                "Lastage": "2410",
                "IEEEXPLOREArticleNumber": "6327245",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.",
                "AuthorNames": "Haroz, S.;Whitney, D.",
                "FirstAuthorAffiliation": "Univ. of California, Davis, CA, USA|c|;",
                "AuthorIDs": "37697696900;38489136700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Haroz, S.;Whitney, D.",
                "filename": "haroz_infovis_12",
                "Citations": "963274;568118;5613436;1532838"
            }
        },
        {
            "name": "Laidlaw, D.H.",
            "value": 246,
            "numPapers": 71,
            "cluster": "6",
            "index": 19,
            "weight": 10,
            "x": 633.0974196873497,
            "y": 586.3618058165287,
            "px": 669.6167372188398,
            "py": 587.483977172696,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "How Capacity Limits of Attention Influence Information Visualization Effectiveness",
                "PaperDOI": "10.1109/TVCG.2012.233",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.233",
                "firstage": "2402",
                "Lastage": "2410",
                "IEEEXPLOREArticleNumber": "6327245",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.",
                "AuthorNames": "Haroz, S.;Whitney, D.",
                "FirstAuthorAffiliation": "Univ. of California, Davis, CA, USA|c|;",
                "AuthorIDs": "37697696900;38489136700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Haroz, S.;Whitney, D.",
                "filename": "haroz_infovis_12",
                "Citations": "963274;568118;5613436;1532838"
            }
        },
        {
            "name": "Heer, J.",
            "value": 679,
            "numPapers": 101,
            "cluster": "3",
            "index": 20,
            "weight": 51,
            "x": 57.258446405459466,
            "y": 630.7255362022325,
            "px": 90.38130882272898,
            "py": 632.958973828008,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "firstage": "2301",
                "Lastage": "2309",
                "IEEEXPLOREArticleNumber": "6064996",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "filename": "bostock_infovis_11",
                "Citations": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Janetzko, H.",
            "value": 43,
            "numPapers": 21,
            "cluster": "5",
            "index": 21,
            "weight": 1,
            "x": -38.46573589801023,
            "y": 146.03634130766582,
            "px": -381.77040524466554,
            "py": -145.2046274449881,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "SnapShot: Visualization to Propel Ice Hockey Analytics",
                "PaperDOI": "10.1109/TVCG.2012.263",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.263",
                "firstage": "2819",
                "Lastage": "2828",
                "IEEEXPLOREArticleNumber": "6327288",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.",
                "AuthorNames": "Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.T.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38488862800;38490190000;38490191800;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.",
                "filename": "pileggi_infovis_12",
                "Citations": "5613452;4376130;636793;6064996;4376131;559229"
            }
        },
        {
            "name": "Yun Jang",
            "value": 119,
            "numPapers": 67,
            "cluster": "2",
            "index": 22,
            "weight": 6,
            "x": 283.1723587161355,
            "y": 633.1046696786369,
            "px": 68.00993022875774,
            "py": 293.19635446635334,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems",
                "PaperDOI": "10.1109/VAST.2012.6400554",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400554",
                "firstage": "173",
                "Lastage": "182",
                "IEEEXPLOREArticleNumber": "6400554",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions.",
                "AuthorNames": "Leishi Zhang;Stoffel, A.;Behrisch, M.;Mittelstadt, S.;Schreck, T.;Pompl, R.;Weber, S.;Last, H.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;;;",
                "AuthorIDs": ";;;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Leishi Zhang;Stoffel, A.;Behrisch, M.;Mittelstadt, S.;Schreck, T.;Pompl, R.;Weber, S.;Last, H.;Keim, D.A.",
                "filename": "zhang_vast_12",
                "Citations": "1382904;1382905;885098"
            }
        },
        {
            "name": "Keim, D.A.",
            "value": 549,
            "numPapers": 157,
            "cluster": "2",
            "index": 23,
            "weight": 49,
            "x": 632.791556240277,
            "y": 784.9400936531196,
            "px": 624.4728773622451,
            "py": 803.858071538658,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Literature Fingerprinting: A New Method for Visual Literary Analysis",
                "PaperDOI": "10.1109/VAST.2007.4389004",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389004",
                "firstage": "115",
                "Lastage": "122",
                "IEEEXPLOREArticleNumber": "4389004",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In computer-based literary analysis different types of features are used to characterize a text. Usually, only a single feature value or vector is calculated for the whole text. In this paper, we combine automatic literature analysis methods with an effective visualization technique to analyze the behavior of the feature values across the text. For an interactive visual analysis, we calculate a sequence of feature values per text and present them to the user as a characteristic fingerprint. The feature values may be calculated on different hierarchy levels, allowing the analysis to be done on different resolution levels. A case study shows several successful applications of our new method to known literature problems and demonstrates the advantage of our new visual literature fingerprinting.",
                "AuthorNames": "Keim, D.A.;Oelke, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz|c|;",
                "AuthorIDs": "37283138700;37591207400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keim, D.A.;Oelke, D.",
                "filename": "keim_vast_07",
                "Citations": ""
            }
        },
        {
            "name": "Chen, M.",
            "value": 222,
            "numPapers": 83,
            "cluster": "10",
            "index": 24,
            "weight": 13,
            "x": 141.99189424130037,
            "y": 180.85320210925096,
            "px": 63.38557449726688,
            "py": 89.01271722550435,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "firstage": "2109",
                "Lastage": "2118",
                "IEEEXPLOREArticleNumber": "6634165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.",
                "filename": "legg_vast_13",
                "Citations": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Malik, A.",
            "value": 31,
            "numPapers": 32,
            "cluster": "3",
            "index": 25,
            "weight": 4,
            "x": 682.9407626496907,
            "y": 92.57569760121633,
            "px": -87.76418428170369,
            "py": 395.42752057948763,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems",
                "PaperDOI": "10.1109/VAST.2012.6400554",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400554",
                "firstage": "173",
                "Lastage": "182",
                "IEEEXPLOREArticleNumber": "6400554",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions.",
                "AuthorNames": "Leishi Zhang;Stoffel, A.;Behrisch, M.;Mittelstadt, S.;Schreck, T.;Pompl, R.;Weber, S.;Last, H.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;;;",
                "AuthorIDs": ";;;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Leishi Zhang;Stoffel, A.;Behrisch, M.;Mittelstadt, S.;Schreck, T.;Pompl, R.;Weber, S.;Last, H.;Keim, D.A.",
                "filename": "zhang_vast_12",
                "Citations": "1382904;1382905;885098"
            }
        },
        {
            "name": "van Wijk, J.J.",
            "value": 798,
            "numPapers": 120,
            "cluster": "6",
            "index": 26,
            "weight": 41,
            "x": 512.1906406893808,
            "y": 364.00518202995505,
            "px": 507.8772862616257,
            "py": 348.89236443474925,
            "node": {
                "Conference": "InfoVis",
                "Year": "1999",
                "PaperTitle": "Cluster and calendar based visualization of time series data",
                "PaperDOI": "10.1109/INFVIS.1999.801851",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1999.801851",
                "firstage": "4",
                "Lastage": "9, 140",
                "IEEEXPLOREArticleNumber": "801851",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented",
                "AuthorNames": "van Wijk, J.J.;Van Selow, E.R.",
                "FirstAuthorAffiliation": "Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;",
                "AuthorIDs": "37267249200;37444386900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Wijk, J.J.;Van Selow, E.R.",
                "filename": "vanwijk2_infovis_99",
                "Citations": ""
            }
        },
        {
            "name": "Van Selow, E.R.",
            "value": 98,
            "numPapers": 1,
            "cluster": "3",
            "index": 27,
            "weight": 1,
            "x": -2628.678279440427,
            "y": 1017.2354121343616,
            "px": -3218.3978656982313,
            "py": 976.7177453461693,
            "node": {
                "Conference": "InfoVis",
                "Year": "1999",
                "PaperTitle": "Cluster and calendar based visualization of time series data",
                "PaperDOI": "10.1109/INFVIS.1999.801851",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1999.801851",
                "firstage": "4",
                "Lastage": "9, 140",
                "IEEEXPLOREArticleNumber": "801851",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented",
                "AuthorNames": "van Wijk, J.J.;Van Selow, E.R.",
                "FirstAuthorAffiliation": "Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;",
                "AuthorIDs": "37267249200;37444386900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Wijk, J.J.;Van Selow, E.R.",
                "filename": "vanwijk2_infovis_99",
                "Citations": ""
            }
        },
        {
            "name": "Shixia Liu",
            "value": 382,
            "numPapers": 163,
            "cluster": "4",
            "index": 28,
            "weight": 71,
            "x": 463.46628825453183,
            "y": 463.6310417653668,
            "px": 389.46266002246864,
            "py": 647.4726546958173,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Wenwen Dou",
            "value": 145,
            "numPapers": 47,
            "cluster": "4",
            "index": 29,
            "weight": 13,
            "x": 459.3492512220403,
            "y": 1117.7839724418448,
            "px": 321.13103653774783,
            "py": 1103.2450178459337,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Xiaoyu Wang",
            "value": 116,
            "numPapers": 49,
            "cluster": "4",
            "index": 30,
            "weight": 10,
            "x": 981.3113053502319,
            "y": -49.61976644144428,
            "px": 790.3725984201441,
            "py": 84.87193601889568,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Ribarsky, W.",
            "value": 321,
            "numPapers": 109,
            "cluster": "2",
            "index": 31,
            "weight": 37,
            "x": 284.1242132111467,
            "y": 647.8195076495091,
            "px": 100.50780934623393,
            "py": 621.9811303969718,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Weiwei Cui",
            "value": 215,
            "numPapers": 61,
            "cluster": "4",
            "index": 32,
            "weight": 12,
            "x": 308.7424103954251,
            "y": 385.3269263928403,
            "px": 112.85651027467043,
            "py": 451.0858271423484,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Li Tan",
            "value": 150,
            "numPapers": 21,
            "cluster": "4",
            "index": 33,
            "weight": 13,
            "x": 647.0446180134632,
            "y": 394.2223491914653,
            "px": 494.43488475798574,
            "py": 609.3492725595092,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Conglei Shi",
            "value": 123,
            "numPapers": 43,
            "cluster": "4",
            "index": 34,
            "weight": 11,
            "x": 1251.2223955378115,
            "y": 148.13185360262432,
            "px": 1237.812786291005,
            "py": 147.43331297296922,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Yangqiu Song",
            "value": 95,
            "numPapers": 10,
            "cluster": "4",
            "index": 35,
            "weight": 4,
            "x": 519.8270972109686,
            "y": 1780.1161947296916,
            "px": 441.17680406365645,
            "py": 1632.6830966864202,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Zekai Gao",
            "value": 95,
            "numPapers": 10,
            "cluster": "4",
            "index": 36,
            "weight": 4,
            "x": 2009.8286648407884,
            "y": 892.1331857393105,
            "px": 1643.7305203592296,
            "py": 922.7880846760219,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Huamin Qu",
            "value": 477,
            "numPapers": 233,
            "cluster": "4",
            "index": 37,
            "weight": 70,
            "x": 460.1904673519048,
            "y": 641.5643536922205,
            "px": 395.91915283516346,
            "py": 753.6005634494547,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Xin Tong",
            "value": 95,
            "numPapers": 10,
            "cluster": "4",
            "index": 38,
            "weight": 4,
            "x": 1020.6897571784567,
            "y": 685.1979772204347,
            "px": 831.1420489030817,
            "py": 751.7049941218365,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Xiting Wang",
            "value": 4,
            "numPapers": 20,
            "cluster": "4",
            "index": 39,
            "weight": 3,
            "x": 3334.59314853433,
            "y": 2356.8790014548313,
            "px": 2290.947944308005,
            "py": 1876.9976951754852,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Jianfei Chen",
            "value": 4,
            "numPapers": 20,
            "cluster": "4",
            "index": 40,
            "weight": 3,
            "x": 1263.0649260197647,
            "y": 381.9003831984548,
            "px": 896.5923866288102,
            "py": 572.0046624008696,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Jun Zhu",
            "value": 4,
            "numPapers": 20,
            "cluster": "4",
            "index": 41,
            "weight": 3,
            "x": -177.3978920810746,
            "y": 1709.7169952616696,
            "px": -31.87461558420857,
            "py": 1429.7712771931087,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Baining Guo",
            "value": 4,
            "numPapers": 20,
            "cluster": "4",
            "index": 42,
            "weight": 3,
            "x": 1290.7404045632265,
            "y": 417.01697515546545,
            "px": 912.0254397555942,
            "py": 591.7843614220764,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "ParallelTopics: A probabilistic approach to exploring document collections",
                "PaperDOI": "10.1109/VAST.2011.6102461",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102461",
                "firstage": "231",
                "Lastage": "240",
                "IEEEXPLOREArticleNumber": "6102461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.",
                "AuthorNames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "FirstAuthorAffiliation": "UNC Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": "37606064200;38241251900;37592409400;37300425000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Xiaoyu Wang;Chang, R.;Ribarsky, W.",
                "filename": "dou_vast_11",
                "Citations": "5652931;5333428;5613439;5652940;5290725;885098"
            }
        },
        {
            "name": "Munzner, T.",
            "value": 589,
            "numPapers": 153,
            "cluster": "3",
            "index": 43,
            "weight": 37,
            "x": 94.53464273253577,
            "y": 558.7060531928148,
            "px": 122.27017648980154,
            "py": 559.7838526476637,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Multi-Level Typology of Abstract Visualization Tasks",
                "PaperDOI": "10.1109/TVCG.2013.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.124",
                "firstage": "2376",
                "Lastage": "2385",
                "IEEEXPLOREArticleNumber": "6634168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.",
                "AuthorNames": "Brehmer, M.;Munzner, T.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brehmer, M.;Munzner, T.",
                "filename": "brehmer_infovis_13",
                "Citations": "4376134;6327298;559213;6327248;6327297;1532136;5613437;4376146;1173148;4376144;6327275;5290695;4658124;235203;1382903;4677365;6102438;4658127;4658129;729560;1382902;6327277;146375"
            }
        },
        {
            "name": "Nan Cao",
            "value": 102,
            "numPapers": 50,
            "cluster": "4",
            "index": 44,
            "weight": 5,
            "x": -352.26519930772747,
            "y": -433.0301540210249,
            "px": -225.57027243030177,
            "py": -183.87191523121834,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "FacetAtlas: Multifaceted Visualization for Rich Text Corpora",
                "PaperDOI": "10.1109/TVCG.2010.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.154",
                "firstage": "1172",
                "Lastage": "1181",
                "IEEEXPLOREArticleNumber": "5613456",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.",
                "AuthorNames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": "37604309600;37281417100;37598450200;37601397400;37406039100;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "filename": "cao_infovis_10",
                "Citations": "4015419;5333443;885098;5290725;4658140;4658133;5290723;5290722;1532126;4015432;4015425;745302;5290726;528686;4015423"
            }
        },
        {
            "name": "Yu-Ru Lin",
            "value": 81,
            "numPapers": 36,
            "cluster": "4",
            "index": 45,
            "weight": 4,
            "x": -569.8788641925368,
            "y": -522.9374566364875,
            "px": -387.51850063787765,
            "py": -237.6746415298689,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "FacetAtlas: Multifaceted Visualization for Rich Text Corpora",
                "PaperDOI": "10.1109/TVCG.2010.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.154",
                "firstage": "1172",
                "Lastage": "1181",
                "IEEEXPLOREArticleNumber": "5613456",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.",
                "AuthorNames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": "37604309600;37281417100;37598450200;37601397400;37406039100;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "filename": "cao_infovis_10",
                "Citations": "4015419;5333443;885098;5290725;4658140;4658133;5290723;5290722;1532126;4015432;4015425;745302;5290726;528686;4015423"
            }
        },
        {
            "name": "Gotz, D.",
            "value": 212,
            "numPapers": 82,
            "cluster": "3",
            "index": 46,
            "weight": 12,
            "x": 768.5753792596878,
            "y": 404.170670716919,
            "px": 460.5945576339517,
            "py": 408.76415872472455,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization",
                "PaperDOI": "10.1109/TVCG.2012.225",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.225",
                "firstage": "2659",
                "Lastage": "2668",
                "IEEEXPLOREArticleNumber": "6327272",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.",
                "AuthorNames": "Wongsuphasawat, K.;Gotz, D.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;",
                "AuthorIDs": "37670523200;37601397400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wongsuphasawat, K.;Gotz, D.",
                "filename": "wongsuphasawat_infovis_12",
                "Citations": "5290701;6102453;4015418;1532150;5332595;5290698;1532152;4035762"
            }
        },
        {
            "name": "Yingcai Wu",
            "value": 136,
            "numPapers": 114,
            "cluster": "4",
            "index": 47,
            "weight": 34,
            "x": 441.66284759216177,
            "y": 279.84944453963834,
            "px": 200.10235891680887,
            "py": 329.31839493414867,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Flow of Uncertainty through Analytical Processes",
                "PaperDOI": "10.1109/TVCG.2012.285",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.285",
                "firstage": "2526",
                "Lastage": "2535",
                "IEEEXPLOREArticleNumber": "6327258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.",
                "AuthorNames": "Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, CA, USA|c|;;",
                "AuthorIDs": "38489887500;38468805500;37275869400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma",
                "filename": "wu_infovis_12",
                "Citations": "4658129;6065027;1382890;1173145;398857;5332611;5613449;5290731;6065022;5613435"
            }
        },
        {
            "name": "Panpan Xu",
            "value": 65,
            "numPapers": 34,
            "cluster": "4",
            "index": 48,
            "weight": 7,
            "x": -101.31398218863185,
            "y": 243.736339366397,
            "px": -141.5693792452075,
            "py": 338.33059504256937,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analysis of Topic Competition on Social Media",
                "PaperDOI": "10.1109/TVCG.2013.221",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.221",
                "firstage": "2012",
                "Lastage": "2021",
                "IEEEXPLOREArticleNumber": "6634134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",
                "AuthorNames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "filename": "xu_vast_13",
                "Citations": "4658136;6065008;6327273;6327272;5333437;5613457;6327271;5652931;6634164;963273;6327274;5652922;5613451;801851"
            }
        },
        {
            "name": "Enxun Wei",
            "value": 59,
            "numPapers": 25,
            "cluster": "4",
            "index": 49,
            "weight": 6,
            "x": 776.6844915896195,
            "y": 1171.0247803254447,
            "px": 650.4859384215371,
            "py": 1307.3425764859821,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analysis of Topic Competition on Social Media",
                "PaperDOI": "10.1109/TVCG.2013.221",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.221",
                "firstage": "2012",
                "Lastage": "2021",
                "IEEEXPLOREArticleNumber": "6634134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",
                "AuthorNames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "filename": "xu_vast_13",
                "Citations": "4658136;6065008;6327273;6327272;5333437;5613457;6327271;5652931;6634164;963273;6327274;5652922;5613451;801851"
            }
        },
        {
            "name": "Tai-Quan Peng",
            "value": 47,
            "numPapers": 24,
            "cluster": "4",
            "index": 50,
            "weight": 8,
            "x": 1170.5794400135746,
            "y": -310.34275086153383,
            "px": 1186.177079869655,
            "py": -210.02057978613163,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analysis of Topic Competition on Social Media",
                "PaperDOI": "10.1109/TVCG.2013.221",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.221",
                "firstage": "2012",
                "Lastage": "2021",
                "IEEEXPLOREArticleNumber": "6634134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",
                "AuthorNames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "filename": "xu_vast_13",
                "Citations": "4658136;6065008;6327273;6327272;5333437;5613457;6327271;5652931;6634164;963273;6327274;5652922;5613451;801851"
            }
        },
        {
            "name": "Zhu, J.J.H.",
            "value": 47,
            "numPapers": 24,
            "cluster": "4",
            "index": 51,
            "weight": 8,
            "x": 1025.0490065259667,
            "y": 20.260441010943197,
            "px": 1005.0074243907593,
            "py": 178.91364722418965,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analysis of Topic Competition on Social Media",
                "PaperDOI": "10.1109/TVCG.2013.221",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.221",
                "firstage": "2012",
                "Lastage": "2021",
                "IEEEXPLOREArticleNumber": "6634134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",
                "AuthorNames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "filename": "xu_vast_13",
                "Citations": "4658136;6065008;6327273;6327272;5333437;5613457;6327271;5652931;6634164;963273;6327274;5652922;5613451;801851"
            }
        },
        {
            "name": "Li Yu",
            "value": 46,
            "numPapers": 5,
            "cluster": "4",
            "index": 52,
            "weight": 1,
            "x": 493.48464582304166,
            "y": -6.708841712160028,
            "px": 469.1184342904861,
            "py": -482.1422819427879,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies",
                "PaperDOI": "10.1109/TVCG.2013.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.162",
                "firstage": "2002",
                "Lastage": "2011",
                "IEEEXPLOREArticleNumber": "6634160",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.",
                "AuthorNames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "filename": "duo_vast_13",
                "Citations": "5652931;6400557;6065008;6102461;6400485"
            }
        },
        {
            "name": "Zhiqiang Ma",
            "value": 46,
            "numPapers": 5,
            "cluster": "4",
            "index": 53,
            "weight": 1,
            "x": 224.72379192149452,
            "y": -66.09801538573065,
            "px": -28.12293081157941,
            "py": -606.9263004042766,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies",
                "PaperDOI": "10.1109/TVCG.2013.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.162",
                "firstage": "2002",
                "Lastage": "2011",
                "IEEEXPLOREArticleNumber": "6634160",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.",
                "AuthorNames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "filename": "duo_vast_13",
                "Citations": "5652931;6400557;6065008;6102461;6400485"
            }
        },
        {
            "name": "Furu Wei",
            "value": 85,
            "numPapers": 17,
            "cluster": "4",
            "index": 54,
            "weight": 5,
            "x": 246.52595908193314,
            "y": 1440.3782393248682,
            "px": 243.3643908686602,
            "py": 1426.7133323888906,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "OpinionSeer: Interactive Visualization of Hotel Customer Feedback",
                "PaperDOI": "10.1109/TVCG.2010.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.183",
                "firstage": "1109",
                "Lastage": "1118",
                "IEEEXPLOREArticleNumber": "5613449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.",
                "AuthorNames": "Yingcai Wu;Furu Wei;Shixia Liu;Au, N.;Weiwei Cui;Hong Zhou;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;;;",
                "AuthorIDs": "37407308300;37396839900;37406039100;37590967500;37391623900;37405368200;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Furu Wei;Shixia Liu;Au, N.;Weiwei Cui;Hong Zhou;Huamin Qu",
                "filename": "wu_infovis_10",
                "Citations": "4035748;5290722;5332611;4658130;5333919;1173151"
            }
        },
        {
            "name": "Collins, C.",
            "value": 246,
            "numPapers": 66,
            "cluster": "4",
            "index": 55,
            "weight": 14,
            "x": -60.189234167896814,
            "y": -3.1505036511776012,
            "px": -118.33621075073229,
            "py": -23.483663262878444,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "VisLink: Revealing Relationships Amongst Visualizations",
                "PaperDOI": "10.1109/TVCG.2007.70521",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70521",
                "firstage": "1192",
                "Lastage": "1199",
                "IEEEXPLOREArticleNumber": "4376140",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.",
                "AuthorNames": "Collins, C.;Carpendale, S.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Collins, C.;Carpendale, S.",
                "filename": "collins_infovis_07",
                "Citations": "1250400;146402;4015424;175815;1249008;963279;4015425"
            }
        },
        {
            "name": "Carpendale, S.",
            "value": 458,
            "numPapers": 102,
            "cluster": "4",
            "index": 56,
            "weight": 34,
            "x": 423.53760516856926,
            "y": 482.94734983713926,
            "px": 460.42094984617717,
            "py": 579.4541148441521,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "VisLink: Revealing Relationships Amongst Visualizations",
                "PaperDOI": "10.1109/TVCG.2007.70521",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70521",
                "firstage": "1192",
                "Lastage": "1199",
                "IEEEXPLOREArticleNumber": "4376140",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.",
                "AuthorNames": "Collins, C.;Carpendale, S.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Collins, C.;Carpendale, S.",
                "filename": "collins_infovis_07",
                "Citations": "1250400;146402;4015424;175815;1249008;963279;4015425"
            }
        },
        {
            "name": "Dork, M.",
            "value": 129,
            "numPapers": 28,
            "cluster": "4",
            "index": 57,
            "weight": 5,
            "x": 543.0317792033958,
            "y": 843.3424377915399,
            "px": 605.9428208637496,
            "py": 971.9530419818138,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "MatrixExplorer: a Dual-Representation System to Explore Social Networks",
                "PaperDOI": "10.1109/TVCG.2006.160",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.160",
                "firstage": "677",
                "Lastage": "684",
                "IEEEXPLOREArticleNumber": "4015417",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process",
                "AuthorNames": "Henry, N.;Fekete, J.",
                "FirstAuthorAffiliation": "LRI|c|;",
                "AuthorIDs": "37839948300;37407972900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Henry, N.;Fekete, J.",
                "filename": "henry_infovis_06",
                "Citations": "1382905"
            }
        },
        {
            "name": "Gruen, D.",
            "value": 60,
            "numPapers": 8,
            "cluster": "4",
            "index": 58,
            "weight": 2,
            "x": 812.102661220617,
            "y": 1628.3413955178728,
            "px": 424.0807873525725,
            "py": 807.7947326678946,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "A Visual Backchannel for Large-Scale Events",
                "PaperDOI": "10.1109/TVCG.2010.129",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.129",
                "firstage": "1129",
                "Lastage": "1138",
                "IEEEXPLOREArticleNumber": "5613451",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.",
                "AuthorNames": "Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37590950400;37603901200;37276124700;38268267300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.",
                "filename": "doerk_infovis_10",
                "Citations": "5333443;4376134;4658136;4658131;1532133;1249028;4677364;5333437"
            }
        },
        {
            "name": "Williamson, C.",
            "value": 102,
            "numPapers": 14,
            "cluster": "4",
            "index": 59,
            "weight": 3,
            "x": 806.500831778876,
            "y": 447.9995824625235,
            "px": 597.1351059678389,
            "py": 561.1083349755684,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "A Visual Backchannel for Large-Scale Events",
                "PaperDOI": "10.1109/TVCG.2010.129",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.129",
                "firstage": "1129",
                "Lastage": "1138",
                "IEEEXPLOREArticleNumber": "5613451",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.",
                "AuthorNames": "Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37590950400;37603901200;37276124700;38268267300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.",
                "filename": "doerk_infovis_10",
                "Citations": "5333443;4376134;4658136;4658131;1532133;1249028;4677364;5333437"
            }
        },
        {
            "name": "",
            "value": 0,
            "numPapers": 14,
            "cluster": "5",
            "index": 60,
            "weight": 1,
            "x": 304.7957387004336,
            "y": 182.1117981427935,
            "px": 259.44978838906377,
            "py": -25.970056072591117,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "A correlative analysis process in a visual analytics environment",
                "PaperDOI": "10.1109/VAST.2012.6400491",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400491",
                "firstage": "33",
                "Lastage": "42",
                "IEEEXPLOREArticleNumber": "6400491",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.",
                "AuthorNames": "Malik, A.;Maciejewski, R.;Elmqvist, N.;Yun Jang;Ebert, D.S.;Huang, W.",
                "FirstAuthorAffiliation": "Purdue Univ., West Lafayette, IN, USA|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Malik, A.;Maciejewski, R.;Elmqvist, N.;Yun Jang;Ebert, D.S.;Huang, W.",
                "filename": "malik_vast_12",
                "Citations": "1532148;6065010;5613426;801851;801851;4389006;4376146;5613429;6065009"
            }
        },
        {
            "name": "Koch, S.",
            "value": 62,
            "numPapers": 55,
            "cluster": "3",
            "index": 61,
            "weight": 10,
            "x": -98.788354944795,
            "y": 605.3838369406615,
            "px": -66.50793155802698,
            "py": 584.0577752335297,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "firstage": "2839",
                "Lastage": "2848",
                "IEEEXPLOREArticleNumber": "6327290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "filename": "heimerl_vast_12",
                "Citations": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Bosch, H.",
            "value": 86,
            "numPapers": 23,
            "cluster": "3",
            "index": 62,
            "weight": 3,
            "x": 204.8568256924646,
            "y": 809.5451180052235,
            "px": -8.203280175305782,
            "py": 391.5868691045707,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "firstage": "2839",
                "Lastage": "2848",
                "IEEEXPLOREArticleNumber": "6327290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "filename": "heimerl_vast_12",
                "Citations": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Ertl, T.",
            "value": 558,
            "numPapers": 202,
            "cluster": "5",
            "index": 63,
            "weight": 50,
            "x": 140.33305448090567,
            "y": 323.17641029533166,
            "px": 139.9187778129507,
            "py": 320.8748145155749,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "firstage": "2839",
                "Lastage": "2848",
                "IEEEXPLOREArticleNumber": "6327290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "filename": "heimerl_vast_12",
                "Citations": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Ebert, D.S.",
            "value": 566,
            "numPapers": 169,
            "cluster": "5",
            "index": 64,
            "weight": 39,
            "x": 133.60640087351706,
            "y": 397.2613229798638,
            "px": 147.53972707696605,
            "py": 378.5468113376956,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "The shape of Shakespeare: visualizing text using implicit surfaces",
                "PaperDOI": "10.1109/INFVIS.1998.729568",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729568",
                "firstage": "121",
                "Lastage": "129, 160",
                "IEEEXPLOREArticleNumber": "729570",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Information visualization focuses on the use of visual means for exploring non-visual information. While free-form text is a rich, common source of information, visualization of text is a challenging problem since text is inherently non-spatial. The paper explores the use of implicit surface models for visualizing text. The authors describe several techniques for text visualization that aid in understanding document content and document relationships. A simple method is defined for mapping document content to shape. By comparing the shapes of multiple documents, global content similarities and differences may be noted. In addition, they describe a visual clustering method in which documents are arranged in 3D based upon similarity scoring. Documents deemed closely related blend together as a single connected shape. Hence, a document corpus becomes a collection of shapes that reflect inter-document relationships. These techniques provide methods to visualize individual documents as well as corpus meta-data. They then combine the two techniques to produce transparent clusters enclosing individual document shapes. This provides a way to visualize both local and global contextual information. Finally, they elaborate on several potential applications of these methods",
                "AuthorNames": "Rohrer, R.M.;Ebert, D.S.;Sibert, J.L.",
                "FirstAuthorAffiliation": "Dept. of Electr. Eng. & Comput. Sci., George Washington Univ., Washington, DC, USA|c|;;",
                "AuthorIDs": "37373506600;38472155600;37265573100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rohrer, R.M.;Ebert, D.S.;Sibert, J.L.",
                "filename": "rohrer_infovis_98",
                "Citations": "636761;636759;528686;568110;559228"
            }
        },
        {
            "name": "Maciejewski, R.",
            "value": 164,
            "numPapers": 79,
            "cluster": "3",
            "index": 65,
            "weight": 7,
            "x": -58.30742307735517,
            "y": 420.8953465370673,
            "px": -60.98554863711126,
            "py": 365.03007500348036,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "A correlative analysis process in a visual analytics environment",
                "PaperDOI": "10.1109/VAST.2012.6400491",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400491",
                "firstage": "33",
                "Lastage": "42",
                "IEEEXPLOREArticleNumber": "6400491",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.",
                "AuthorNames": "Malik, A.;Maciejewski, R.;Elmqvist, N.;Yun Jang;Ebert, D.S.;Huang, W.",
                "FirstAuthorAffiliation": "Purdue Univ., West Lafayette, IN, USA|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Malik, A.;Maciejewski, R.;Elmqvist, N.;Yun Jang;Ebert, D.S.;Huang, W.",
                "filename": "malik_vast_12",
                "Citations": "1532148;6065010;5613426;801851;801851;4389006;4376146;5613429;6065009"
            }
        },
        {
            "name": "Chang, R.",
            "value": 222,
            "numPapers": 78,
            "cluster": "5",
            "index": 66,
            "weight": 11,
            "x": -39.20278547679542,
            "y": 374.1835821357554,
            "px": -50.481056360734335,
            "py": 315.3786985567612,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Dis-function: Learning distance functions interactively",
                "PaperDOI": "10.1109/VAST.2012.6400486",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400486",
                "firstage": "83",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "6400486",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.",
                "AuthorNames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "filename": "brown_vast_12",
                "Citations": "146402;6102449;4388999;5332584;6102448;4677352;5652443"
            }
        },
        {
            "name": "MacEachren, A.M.",
            "value": 117,
            "numPapers": 24,
            "cluster": "3",
            "index": 67,
            "weight": 2,
            "x": -273.11410661762756,
            "y": 44.40561013887654,
            "px": -428.0404865978088,
            "py": -156.73255876854995,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visual Semiotics &amp;amp; Uncertainty Visualization: An Empirical Study",
                "PaperDOI": "10.1109/TVCG.2012.279",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.279",
                "firstage": "2496",
                "Lastage": "2505",
                "IEEEXPLOREArticleNumber": "6327255",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.",
                "AuthorNames": "MacEachren, A.M.;Roth, R.E.;O'Brien, J.;Li, B.;Swingley, D.;Gahegan, M.",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37374699000;38489149900;38490350000;38490350500;38489925400;38490482800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "MacEachren, A.M.;Roth, R.E.;O'Brien, J.;Li, B.;Swingley, D.;Gahegan, M.",
                "filename": "maceachren_infovis_12",
                "Citations": "235199;6065022;5290731"
            }
        },
        {
            "name": "Matkovic, K.",
            "value": 166,
            "numPapers": 48,
            "cluster": "2",
            "index": 68,
            "weight": 12,
            "x": 1001.8335562849733,
            "y": 791.5893185784681,
            "px": 915.3490954663341,
            "py": 773.1020131197895,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Interactive Visual Analysis of Perfusion Data",
                "PaperDOI": "10.1109/TVCG.2007.70569",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70569",
                "firstage": "1392",
                "Lastage": "1399",
                "IEEEXPLOREArticleNumber": "4376166",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.",
                "AuthorNames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "FirstAuthorAffiliation": "Univ. of Magdeburg, Magdeburg|c|;;;;",
                "AuthorIDs": "37424645600;37546620400;37274158800;37546620600;37424645300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "filename": "oeltze_vis_07",
                "Citations": "885739"
            }
        },
        {
            "name": "Hauser, H.",
            "value": 622,
            "numPapers": 171,
            "cluster": "2",
            "index": 69,
            "weight": 46,
            "x": 574.4903592636214,
            "y": 424.29304947830485,
            "px": 586.0787091532354,
            "py": 441.2043278249888,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Interactive Visual Analysis of Perfusion Data",
                "PaperDOI": "10.1109/TVCG.2007.70569",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70569",
                "firstage": "1392",
                "Lastage": "1399",
                "IEEEXPLOREArticleNumber": "4376166",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.",
                "AuthorNames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "FirstAuthorAffiliation": "Univ. of Magdeburg, Magdeburg|c|;;;;",
                "AuthorIDs": "37424645600;37546620400;37274158800;37546620600;37424645300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "filename": "oeltze_vis_07",
                "Citations": "885739"
            }
        },
        {
            "name": "Groller, E.",
            "value": 1002,
            "numPapers": 259,
            "cluster": "5",
            "index": 70,
            "weight": 112,
            "x": 242.2121467532583,
            "y": 383.4495205745892,
            "px": 247.74826029295394,
            "py": 405.6718295821594,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Visual Human+Machine Learning",
                "PaperDOI": "10.1109/TVCG.2009.199",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.199",
                "firstage": "1327",
                "Lastage": "1334",
                "IEEEXPLOREArticleNumber": "5290745",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.",
                "AuthorNames": "Fuchs, R.;Waser, J.;Groller, M.E.",
                "FirstAuthorAffiliation": "ETH Zurich, Zurich, Switzerland|c|;;",
                "AuthorIDs": "38099765400;38111592300;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fuchs, R.;Waser, J.;Groller, E.",
                "filename": "fuchs_vis_09",
                "Citations": "4376165;4658178;4389001;4389000"
            }
        },
        {
            "name": "Doleisch, H.",
            "value": 199,
            "numPapers": 58,
            "cluster": "5",
            "index": 71,
            "weight": 12,
            "x": 195.6779728124967,
            "y": 218.23568347657474,
            "px": 250.40502082847453,
            "py": 252.19516646889866,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Interactive Visual Analysis of Perfusion Data",
                "PaperDOI": "10.1109/TVCG.2007.70569",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70569",
                "firstage": "1392",
                "Lastage": "1399",
                "IEEEXPLOREArticleNumber": "4376166",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.",
                "AuthorNames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "FirstAuthorAffiliation": "Univ. of Magdeburg, Magdeburg|c|;;;;",
                "AuthorIDs": "37424645600;37546620400;37274158800;37546620600;37424645300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "filename": "oeltze_vis_07",
                "Citations": "885739"
            }
        },
        {
            "name": "Auzinger, T.",
            "value": 6,
            "numPapers": 16,
            "cluster": "5",
            "index": 72,
            "weight": 2,
            "x": 137.28106568011083,
            "y": 808.5193378449075,
            "px": 303.57504165118047,
            "py": 639.3418299362703,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Angular brushing of extended parallel coordinates",
                "PaperDOI": "10.1109/INFVIS.2002.1173157",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173157",
                "firstage": "127",
                "Lastage": "130",
                "IEEEXPLOREArticleNumber": "1173157",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.",
                "AuthorNames": "Hauser, H.;Ledermann, F.;Doleisch, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;",
                "AuthorIDs": "37274158800;37689207700;37546620400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hauser, H.;Ledermann, F.;Doleisch, H.",
                "filename": "hauser_infovis_02",
                "Citations": "559216;885739;346302;485139;146402"
            }
        },
        {
            "name": "Bruckner, S.",
            "value": 326,
            "numPapers": 133,
            "cluster": "5",
            "index": 73,
            "weight": 28,
            "x": 256.1028334187109,
            "y": 358.81318000970924,
            "px": 267.13816950504753,
            "py": 406.3604342085169,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "VAICo: Visual Analysis for Image Comparison",
                "PaperDOI": "10.1109/TVCG.2013.213",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.213",
                "firstage": "2090",
                "Lastage": "2099",
                "IEEEXPLOREArticleNumber": "6634107",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.",
                "AuthorNames": "Schmidt, J.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schmidt, J.;Groller, E.;Bruckner, S.",
                "filename": "schmidt_vast_13",
                "Citations": "4376187;4376150;6400555;5613488;809871;809873;6064952;1183790"
            }
        },
        {
            "name": "Wei Chen",
            "value": 80,
            "numPapers": 118,
            "cluster": "5",
            "index": 74,
            "weight": 13,
            "x": 125.33979722598255,
            "y": 451.2657129982114,
            "px": 108.36822798453956,
            "py": 409.30956019136937,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "SAVE: Sensor anomaly visualization engine",
                "PaperDOI": "10.1109/VAST.2011.6102458",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102458",
                "firstage": "201",
                "Lastage": "210",
                "IEEEXPLOREArticleNumber": "6102458",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.",
                "AuthorNames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "FirstAuthorAffiliation": "IBM Res., Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37543450800;37398853200;38240137400;37298955400;37588016000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "filename": "shi_vast_11",
                "Citations": "5290694;5333880;1532126;1382886;5652910"
            }
        },
        {
            "name": "Ronghua Liang",
            "value": 10,
            "numPapers": 17,
            "cluster": "4",
            "index": 75,
            "weight": 2,
            "x": 1409.0395147057154,
            "y": 365.53575572557025,
            "px": 509.0794434576015,
            "py": 627.3372477609981,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "firstage": "1753",
                "Lastage": "1762",
                "IEEEXPLOREArticleNumber": "6875992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Cooperation and competition (jointly called ÔÇ£coopetitionÔÇØ) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., ÔÇ£topic leadersÔÇØ) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "filename": "sun1_vast_14",
                "Citations": "shi_vast_10,cao_infovis_12,byron_infovis_08,cui_infovis_11,shi_infovis_12,wu2_vast_14,xu_vast_13,liu_infovis_13,duo_vast_13,"
            }
        },
        {
            "name": "Hujun Bao",
            "value": 2,
            "numPapers": 20,
            "cluster": "5",
            "index": 76,
            "weight": 1,
            "x": 508.9435018923758,
            "y": 353.29693671030833,
            "px": 494.48077704227524,
            "py": 358.82276647169806,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "SAVE: Sensor anomaly visualization engine",
                "PaperDOI": "10.1109/VAST.2011.6102458",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102458",
                "firstage": "201",
                "Lastage": "210",
                "IEEEXPLOREArticleNumber": "6102458",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.",
                "AuthorNames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "FirstAuthorAffiliation": "IBM Res., Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37543450800;37398853200;38240137400;37298955400;37588016000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "filename": "shi_vast_11",
                "Citations": "5290694;5333880;1532126;1382886;5652910"
            }
        },
        {
            "name": "Han-Wei Shen",
            "value": 417,
            "numPapers": 141,
            "cluster": "5",
            "index": 77,
            "weight": 34,
            "x": 136.47371772206444,
            "y": 321.6085091791005,
            "px": 182.8992687118583,
            "py": 332.1665320597348,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Visualizing Changes of Hierarchical Data using Treemaps",
                "PaperDOI": "10.1109/TVCG.2007.70529",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70529",
                "firstage": "1286",
                "Lastage": "1293",
                "IEEEXPLOREArticleNumber": "4376152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.",
                "AuthorNames": "Ying Tu;Han-Wei Shen",
                "FirstAuthorAffiliation": "Ohio State Univ., Columbus|c|;",
                "AuthorIDs": "37875062100;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ying Tu;Han-Wei Shen",
                "filename": "tu_infovis_07",
                "Citations": "801860;1532145;4015431;175815"
            }
        },
        {
            "name": "Wongsuphasawat, K.",
            "value": 41,
            "numPapers": 24,
            "cluster": "3",
            "index": 78,
            "weight": 3,
            "x": -491.56620046199504,
            "y": 625.0253286348255,
            "px": -677.7818738381549,
            "py": 508.32777059405254,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization",
                "PaperDOI": "10.1109/TVCG.2012.225",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.225",
                "firstage": "2659",
                "Lastage": "2668",
                "IEEEXPLOREArticleNumber": "6327272",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.",
                "AuthorNames": "Wongsuphasawat, K.;Gotz, D.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;",
                "AuthorIDs": "37670523200;37601397400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wongsuphasawat, K.;Gotz, D.",
                "filename": "wongsuphasawat_infovis_12",
                "Citations": "5290701;6102453;4015418;1532150;5332595;5290698;1532152;4035762"
            }
        },
        {
            "name": "Shneiderman, B.",
            "value": 502,
            "numPapers": 39,
            "cluster": "3",
            "index": 79,
            "weight": 19,
            "x": 65.97629951871615,
            "y": 649.9063899121145,
            "px": -16.315871333385147,
            "py": 633.3048087796578,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Network Visualization by Semantic Substrates",
                "PaperDOI": "10.1109/TVCG.2006.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.166",
                "firstage": "733",
                "Lastage": "740",
                "IEEEXPLOREArticleNumber": "4015424",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations",
                "AuthorNames": "Shneiderman, B.;Aris, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;",
                "AuthorIDs": "37283016400;37561646300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shneiderman, B.;Aris, A.",
                "filename": "shneiderman_infovis_06",
                "Citations": "1382886;1532124;1532126"
            }
        },
        {
            "name": "Lin, J.",
            "value": 0,
            "numPapers": 15,
            "cluster": "3",
            "index": 80,
            "weight": 1,
            "x": -929.1798382329204,
            "y": 1039.2021233763403,
            "px": -1551.568541037788,
            "py": 1487.4361412857293,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations",
                "PaperDOI": "10.1109/INFVIS.2000.885091",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885091",
                "firstage": "57",
                "Lastage": "65",
                "IEEEXPLOREArticleNumber": "885091",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space",
                "AuthorNames": "Stasko, J.;Zhang, E.",
                "FirstAuthorAffiliation": "GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;",
                "AuthorIDs": "37267736900;38020590400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stasko, J.;Zhang, E.",
                "filename": "stasko_infovis_00",
                "Citations": "801860;235217;729567;175815"
            }
        },
        {
            "name": "Byron, L.",
            "value": 72,
            "numPapers": 4,
            "cluster": "4",
            "index": 81,
            "weight": 2,
            "x": 434.32080107234424,
            "y": 2455.397242949244,
            "px": 369.1166210390091,
            "py": 968.3547912240047,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Stacked Graphs - Geometry & Aesthetics",
                "PaperDOI": "10.1109/TVCG.2008.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.166",
                "firstage": "1245",
                "Lastage": "1252",
                "IEEEXPLOREArticleNumber": "4658136",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.",
                "AuthorNames": "Byron, L.;Wattenberg, M.",
                "FirstAuthorAffiliation": "New York Times, New York, NY|c|;",
                "AuthorIDs": "37868017200;37550759700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Byron, L.;Wattenberg, M.",
                "filename": "byron_infovis_08",
                "Citations": "4015420;1532122;4376131;885098"
            }
        },
        {
            "name": "Wattenberg, M.",
            "value": 593,
            "numPapers": 34,
            "cluster": "4",
            "index": 82,
            "weight": 34,
            "x": 511.9868887675435,
            "y": 705.0323545342322,
            "px": 502.69365320285965,
            "py": 821.7317278665195,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Stacked Graphs - Geometry & Aesthetics",
                "PaperDOI": "10.1109/TVCG.2008.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.166",
                "firstage": "1245",
                "Lastage": "1252",
                "IEEEXPLOREArticleNumber": "4658136",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.",
                "AuthorNames": "Byron, L.;Wattenberg, M.",
                "FirstAuthorAffiliation": "New York Times, New York, NY|c|;",
                "AuthorIDs": "37868017200;37550759700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Byron, L.;Wattenberg, M.",
                "filename": "byron_infovis_08",
                "Citations": "4015420;1532122;4376131;885098"
            }
        },
        {
            "name": "Rheingans, P.",
            "value": 341,
            "numPapers": 68,
            "cluster": "5",
            "index": 83,
            "weight": 13,
            "x": 76.90497189086096,
            "y": 268.10364630122666,
            "px": 115.34118059229746,
            "py": 269.35624479632776,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Temporal visualization of planning polygons for efficient partitioning of geo-spatial data",
                "PaperDOI": "10.1109/INFVIS.2005.1532149",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532149",
                "firstage": "211",
                "Lastage": "218",
                "IEEEXPLOREArticleNumber": "1532149",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Partitioning of geo-spatial data for efficient allocation of resources such as schools and emergency health care services is driven by a need to provide better and more effective services. Partitioning of spatial data is a complex process that depends on numerous factors such as population, costs incurred in deploying or utilizing resources and target capacity of a resource. Moreover, complex data such as population distributions are dynamic i.e. they may change over time. Simple animation may not effectively show temporal changes in spatial data. We propose the use of three temporal visualization techniques -wedges, rings and time slices - to display the nature of change in temporal data in a single view. Along with maximizing resource utilization and minimizing utilization costs, a partition should also ensure the long term effectiveness of the plan. We use multi-attribute visualization techniques to highlight the strengths and identify the weaknesses of a partition. Comparative visualization techniques allow multiple partitions to be viewed simultaneously. Users can make informed decisions about how to partition geo spatial data by using a combination of our techniques for multi-attribute visualization, temporal visualization and comparative visualization.",
                "AuthorNames": "Poonam Shanbhag;Rheingans, P.;desJardins, M.",
                "FirstAuthorAffiliation": "Maryland Univ., Baltimore, MD, USA|c|;;",
                "AuthorIDs": "37550761800;37282292000;37552291200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Poonam Shanbhag;Rheingans, P.;desJardins, M.",
                "filename": "shanbhag_infovis_05",
                "Citations": "963273;963274"
            }
        },
        {
            "name": "Schumann, H.",
            "value": 120,
            "numPapers": 59,
            "cluster": "4",
            "index": 84,
            "weight": 2,
            "x": 80.7924907868994,
            "y": 632.7263851266974,
            "px": -538.0768176344676,
            "py": 893.9839309308786,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Design Space of Visualization Tasks",
                "PaperDOI": "10.1109/TVCG.2013.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.120",
                "firstage": "2366",
                "Lastage": "2375",
                "IEEEXPLOREArticleNumber": "6634156",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.",
                "AuthorNames": "Schulz, H.-J.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "FirstAuthorAffiliation": "Univ. of Rostock, Rostock, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schulz, H.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "filename": "schulz_infovis_13",
                "Citations": "559213;1532136;4376144;146372;6327265;235203;1382903;4677365;559211;1382902;636792;885093;885092;146375"
            }
        },
        {
            "name": "Andrienko, G.",
            "value": 195,
            "numPapers": 42,
            "cluster": "2",
            "index": 85,
            "weight": 21,
            "x": 665.4921481413652,
            "y": 354.67807046868825,
            "px": 551.6369820220738,
            "py": 264.27331452265605,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Space Transformation for Understanding Group Movement",
                "PaperDOI": "10.1109/TVCG.2013.193",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.193",
                "firstage": "2169",
                "Lastage": "2178",
                "IEEEXPLOREArticleNumber": "6634194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.",
                "AuthorNames": "Andrienko, N.;Andrienko, G.;Barrett, L.;Dostie, M.;Henzi, P.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Andrienko, N.;Andrienko, G.;Barrett, L.;Dostie, M.;Henzi, P.",
                "filename": "andrienko_vast_13",
                "Citations": "1532142;1382887"
            }
        },
        {
            "name": "Andrienko, N.",
            "value": 195,
            "numPapers": 42,
            "cluster": "2",
            "index": 86,
            "weight": 21,
            "x": 466.8242143660103,
            "y": 201.19164826362348,
            "px": 385.09873562231843,
            "py": 130.7788518439571,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Space Transformation for Understanding Group Movement",
                "PaperDOI": "10.1109/TVCG.2013.193",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.193",
                "firstage": "2169",
                "Lastage": "2178",
                "IEEEXPLOREArticleNumber": "6634194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.",
                "AuthorNames": "Andrienko, N.;Andrienko, G.;Barrett, L.;Dostie, M.;Henzi, P.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Andrienko, N.;Andrienko, G.;Barrett, L.;Dostie, M.;Henzi, P.",
                "filename": "andrienko_vast_13",
                "Citations": "1532142;1382887"
            }
        },
        {
            "name": "Ellis, G.",
            "value": 121,
            "numPapers": 35,
            "cluster": "2",
            "index": 87,
            "weight": 4,
            "x": -288.13182722344317,
            "y": -103.91989989308836,
            "px": 389.7385617332244,
            "py": 234.7348923570518,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "A Taxonomy of Clutter Reduction for Information Visualisation",
                "PaperDOI": "10.1109/TVCG.2007.70535",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70535",
                "firstage": "1216",
                "Lastage": "1223",
                "IEEEXPLOREArticleNumber": "4376143",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.",
                "AuthorNames": "Ellis, G.;Dix, A.",
                "FirstAuthorAffiliation": "Lancaster Univ, Lancaster|c|;",
                "AuthorIDs": "37283380700;37283381700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ellis, G.;Dix, A.",
                "filename": "ellis_infovis_07",
                "Citations": "1249018;885092;4015422;1532819;1249008;809866;885091;745301;636789;1173156;1249019;636792;528685;1382895;4015444"
            }
        },
        {
            "name": "Dix, A.",
            "value": 121,
            "numPapers": 20,
            "cluster": "2",
            "index": 88,
            "weight": 3,
            "x": 97.97502352862423,
            "y": 52.155749561682974,
            "px": 633.5997865729158,
            "py": 332.25361419117627,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "A Taxonomy of Clutter Reduction for Information Visualisation",
                "PaperDOI": "10.1109/TVCG.2007.70535",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70535",
                "firstage": "1216",
                "Lastage": "1223",
                "IEEEXPLOREArticleNumber": "4376143",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.",
                "AuthorNames": "Ellis, G.;Dix, A.",
                "FirstAuthorAffiliation": "Lancaster Univ, Lancaster|c|;",
                "AuthorIDs": "37283380700;37283381700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ellis, G.;Dix, A.",
                "filename": "ellis_infovis_07",
                "Citations": "1249018;885092;4015422;1532819;1249008;809866;885091;745301;636789;1173156;1249019;636792;528685;1382895;4015444"
            }
        },
        {
            "name": "Robertson, G.",
            "value": 244,
            "numPapers": 19,
            "cluster": "3",
            "index": 89,
            "weight": 9,
            "x": 141.5859546344962,
            "y": 773.2953839896702,
            "px": 131.43027988171914,
            "py": 729.5078742358475,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Effectiveness of Animation in Trend Visualization",
                "PaperDOI": "10.1109/TVCG.2008.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.125",
                "firstage": "1325",
                "Lastage": "1332",
                "IEEEXPLOREArticleNumber": "4658146",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.",
                "AuthorNames": "Robertson, G.;Fernandez, R.;Fisher, D.;Bongshin Lee;Stasko, J.",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA|c|;;;;",
                "AuthorIDs": "37448060300;37603822300;37542391000;37293389400;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Robertson, G.;Fernandez, R.;Fisher, D.;Bongshin Lee;Stasko, J.",
                "filename": "robertso_infovis_08",
                "Citations": "801854;4376146"
            }
        },
        {
            "name": "Fisher, D.",
            "value": 162,
            "numPapers": 30,
            "cluster": "3",
            "index": 90,
            "weight": 6,
            "x": 270.94054673477575,
            "y": 817.4304902302057,
            "px": 224.69078575865043,
            "py": 709.0680760927776,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Effectiveness of Animation in Trend Visualization",
                "PaperDOI": "10.1109/TVCG.2008.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.125",
                "firstage": "1325",
                "Lastage": "1332",
                "IEEEXPLOREArticleNumber": "4658146",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.",
                "AuthorNames": "Robertson, G.;Fernandez, R.;Fisher, D.;Bongshin Lee;Stasko, J.",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA|c|;;;;",
                "AuthorIDs": "37448060300;37603822300;37542391000;37293389400;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Robertson, G.;Fernandez, R.;Fisher, D.;Bongshin Lee;Stasko, J.",
                "filename": "robertso_infovis_08",
                "Citations": "801854;4376146"
            }
        },
        {
            "name": "Bongshin Lee",
            "value": 226,
            "numPapers": 54,
            "cluster": "4",
            "index": 91,
            "weight": 9,
            "x": 678.1883226472074,
            "y": 926.1816670689486,
            "px": 635.402932151576,
            "py": 866.9849925044682,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "SparkClouds: Visualizing Trends in Tag Clouds",
                "PaperDOI": "10.1109/TVCG.2010.194",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.194",
                "firstage": "1182",
                "Lastage": "1189",
                "IEEEXPLOREArticleNumber": "5613457",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.",
                "AuthorNames": "Bongshin Lee;Riche, N.H.;Karlson, A.K.;Carpendale, S.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37293389400;37590950700;37590950600;37285000100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bongshin Lee;Riche, N.H.;Karlson, A.;Carpendale, S.",
                "filename": "lee_infovis_10",
                "Citations": "5290722;1532122;4376132"
            }
        },
        {
            "name": "Worring, M.",
            "value": 30,
            "numPapers": 26,
            "cluster": "3",
            "index": 92,
            "weight": 1,
            "x": -526.1817421442234,
            "y": -414.2192789087189,
            "px": -990.1591052241844,
            "py": -1248.7374939566905,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "firstage": "191",
                "Lastage": "198",
                "IEEEXPLOREArticleNumber": "4035765",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "filename": "yang_vast_06",
                "Citations": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Jian Zhao",
            "value": 30,
            "numPapers": 41,
            "cluster": "4",
            "index": 93,
            "weight": 2,
            "x": 65.60290860964405,
            "y": 247.20294134805934,
            "px": 336.00167054103196,
            "py": 627.1418389102118,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Zhou, M.X.",
            "value": 187,
            "numPapers": 54,
            "cluster": "4",
            "index": 94,
            "weight": 10,
            "x": 173.57760417371233,
            "y": 590.0006353508286,
            "px": 71.1928404717129,
            "py": 625.6633803699846,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "firstage": "2412",
                "Lastage": "2421",
                "IEEEXPLOREArticleNumber": "6065008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "filename": "cui_infovis_11",
                "Citations": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Bum Chul Kwon",
            "value": 27,
            "numPapers": 44,
            "cluster": "3",
            "index": 95,
            "weight": 3,
            "x": 310.0648427251326,
            "y": 733.8745028552446,
            "px": 145.37425313521908,
            "py": 694.9004339987438,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "The value of visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532781",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532781",
                "firstage": "79",
                "Lastage": "86",
                "IEEEXPLOREArticleNumber": "1532781",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.",
                "AuthorNames": "van Wijk, J.J.",
                "FirstAuthorAffiliation": "Dept. of Math. & Comput. Sci., Technische Univ. Eindhoven, Netherlands|c|",
                "AuthorIDs": "37267249200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Wijk, J.J.",
                "filename": "wijk_vis_05",
                "Citations": "175815;1382885;964505;1250354;963285;801851"
            }
        },
        {
            "name": "Bertini, E.",
            "value": 71,
            "numPapers": 76,
            "cluster": "2",
            "index": 96,
            "weight": 5,
            "x": 905.8098804723242,
            "y": 698.2474759635824,
            "px": 821.4747417003014,
            "py": 602.9581650299317,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Subspace search and visualization to make sense of alternative clusterings in high-dimensional data",
                "PaperDOI": "10.1109/VAST.2012.6400488",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400488",
                "firstage": "63",
                "Lastage": "72",
                "IEEEXPLOREArticleNumber": "6400488",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.",
                "AuthorNames": "Tatu, A.;Maas, F.;Farber, I.;Bertini, E.;Schreck, T.;Seidl, T.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tatu, A.;Maas, F.;Farber, I.;Bertini, E.;Schreck, T.;Seidl, T.;Keim, D.A.",
                "filename": "tatu_vast_12",
                "Citations": "1532142;5613440;5652392;1382893;5652450;6102439;6065026;1382892;5290704"
            }
        },
        {
            "name": "Jing Yang",
            "value": 254,
            "numPapers": 90,
            "cluster": "2",
            "index": 97,
            "weight": 26,
            "x": 400.55940210372995,
            "y": 413.51821139089526,
            "px": 204.68123981554479,
            "py": 345.3071427826403,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "firstage": "191",
                "Lastage": "198",
                "IEEEXPLOREArticleNumber": "4035765",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "filename": "yang_vast_06",
                "Citations": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Ward, M.O.",
            "value": 746,
            "numPapers": 100,
            "cluster": "2",
            "index": 98,
            "weight": 51,
            "x": 332.1544039569836,
            "y": 411.0581948790428,
            "px": 404.34558547755375,
            "py": 448.4475910959274,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "firstage": "191",
                "Lastage": "198",
                "IEEEXPLOREArticleNumber": "4035765",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "filename": "yang_vast_06",
                "Citations": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Rundensteiner, E.A.",
            "value": 408,
            "numPapers": 80,
            "cluster": "2",
            "index": 99,
            "weight": 34,
            "x": 350.95064596051594,
            "y": 439.2216272888095,
            "px": 450.91014065287936,
            "py": 514.6699703818693,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Value and Relation Display for Interactive Exploration of High Dimensional Datasets",
                "PaperDOI": "10.1109/INFVIS.2004.71",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.71",
                "firstage": "73",
                "Lastage": "80",
                "IEEEXPLOREArticleNumber": "1382893",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items",
                "AuthorNames": "Jing Yang;Anilkumar Patro;Huang Shiping;Nishant Mehta;Ward, M.O.;Rundensteiner, E.A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;;;;",
                "AuthorIDs": "37292632600;37932988400;37557769100;37554158700;37268441700;37279217900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Anilkumar Patro;Huang Shiping;Nishant Mehta;Ward, M.O.;Rundensteiner, E.A.",
                "filename": "yang_infovis_04",
                "Citations": "729568;1249015;346302;1249014;528686;485140"
            }
        },
        {
            "name": "Tory, M.",
            "value": 163,
            "numPapers": 86,
            "cluster": "3",
            "index": 100,
            "weight": 13,
            "x": 146.02750541631298,
            "y": 625.2646701467081,
            "px": 103.32928256241784,
            "py": 607.9704134035659,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "A closer look at note taking in the co-located collaborative visual analytics process",
                "PaperDOI": "10.1109/VAST.2010.5652879",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652879",
                "firstage": "171",
                "Lastage": "178",
                "IEEEXPLOREArticleNumber": "5652879",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.",
                "AuthorNames": "Mahyar, N.;Sarvghad, A.;Tory, M.",
                "FirstAuthorAffiliation": "Univ. of Victoria, Victoria, BC, Canada|c|;;",
                "AuthorIDs": "37591344800;37591344300;37275861300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Mahyar, N.;Sarvghad, A.;Tory, M.",
                "filename": "mahyar_vast_10",
                "Citations": "4658129;4677358;4376145;5333020;4677365;5333023;4376131"
            }
        },
        {
            "name": "Robinson, A.",
            "value": 85,
            "numPapers": 14,
            "cluster": "3",
            "index": 101,
            "weight": 1,
            "x": 401.92171740122154,
            "y": -364.9909974791161,
            "px": 750.1484485874785,
            "py": -1008.2476251366568,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "SensePlace2: GeoTwitter analytics support for situational awareness",
                "PaperDOI": "10.1109/VAST.2011.6102456",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102456",
                "firstage": "181",
                "Lastage": "190",
                "IEEEXPLOREArticleNumber": "6102456",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.",
                "AuthorNames": "MacEachren, A.M.;Jaiswal, A.;Robinson, A.C.;Pezanowski, S.;Savelyev, A.;Mitra, P.;Zhang, X.;Blanford, J.",
                "FirstAuthorAffiliation": "GeoVISTA Center, Pennsylvania State Univ., University Park, PA, USA|c|;;;;;;;",
                "AuthorIDs": "37374699000;37966902300;37829187900;38233564100;38237834200;37286730000;38239991000;38242393000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "MacEachren, A.M.;Jaiswal, A.;Robinson, A.;Pezanowski, S.;Savelyev, A.;Mitra, P.;Zhang, X.;Blanford, J.",
                "filename": "maceachr_vast_11",
                "Citations": "5652478;4388994;5613451;1532134;5652922"
            }
        },
        {
            "name": "Youn-ah Kang",
            "value": 144,
            "numPapers": 25,
            "cluster": "3",
            "index": 102,
            "weight": 6,
            "x": 197.6521219835152,
            "y": 234.99966843899358,
            "px": 208.817910899995,
            "py": 281.0269530687921,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Toward a Deeper Understanding of the Role of Interaction in Information Visualization",
                "PaperDOI": "10.1109/TVCG.2007.70515",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70515",
                "firstage": "1224",
                "Lastage": "1231",
                "IEEEXPLOREArticleNumber": "4376144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.",
                "AuthorNames": "Ji Soo Yi;Youn ah Kang;Stasko, J.T.;Jacko, J.A.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ji Soo Yi;Youn-ah Kang;Stasko, J.;Jacko, J.A.",
                "filename": "yi_infovis_07",
                "Citations": "346302;1532136;559213;175794;1532126;885091;801860;885086"
            }
        },
        {
            "name": "Agrawala, M.",
            "value": 240,
            "numPapers": 40,
            "cluster": "3",
            "index": 103,
            "weight": 10,
            "x": 166.55891378802818,
            "y": 777.3846125677177,
            "px": 193.81007822484338,
            "py": 745.7877786079329,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Multi-Scale Banking to 45 Degrees",
                "PaperDOI": "10.1109/TVCG.2006.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.163",
                "firstage": "701",
                "Lastage": "708",
                "IEEEXPLOREArticleNumber": "4015420",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst's perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples",
                "AuthorNames": "Heer, J.;Agrawala, M.",
                "FirstAuthorAffiliation": "Comput. Sci. Div., California Univ., Berkeley, CA|c|;",
                "AuthorIDs": "37550791300;37282718200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heer, J.;Agrawala, M.",
                "filename": "heer1_infovis_06",
                "Citations": ""
            }
        },
        {
            "name": "Piringer, H.",
            "value": 74,
            "numPapers": 109,
            "cluster": "3",
            "index": 104,
            "weight": 12,
            "x": 265.8255556446217,
            "y": 539.6448906753172,
            "px": 272.30157698811763,
            "py": 482.02110536549094,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "A Partition-Based Framework for Building and Validating Regression Models",
                "PaperDOI": "10.1109/TVCG.2013.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.125",
                "firstage": "1962",
                "Lastage": "1971",
                "IEEEXPLOREArticleNumber": "6634169",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.",
                "AuthorNames": "Muhlbacher, T.;Piringer, H.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Muhlbacher, T.;Piringer, H.",
                "filename": "muehlbacher_vast_13",
                "Citations": "6327298;5290702;398859;6400486;6102453;5333431;5613467;6327265;5332628;146402;6102450;4677368;5652460;6064952;1532142;4388999;1382902;5290719;6102448;1382892"
            }
        },
        {
            "name": "Sedlmair, M.",
            "value": 145,
            "numPapers": 114,
            "cluster": "3",
            "index": 105,
            "weight": 13,
            "x": 269.6855929846514,
            "y": 761.4462511608597,
            "px": 284.35565050999617,
            "py": 739.9937211448544,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "firstage": "2818",
                "Lastage": "2827",
                "IEEEXPLOREArticleNumber": "6634108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "filename": "isenberg_vis_13",
                "Citations": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Streit, M.",
            "value": 130,
            "numPapers": 75,
            "cluster": "4",
            "index": 106,
            "weight": 14,
            "x": 989.748718675731,
            "y": 718.6394345786258,
            "px": 1091.1723458463118,
            "py": 805.3982639093387,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Dis-function: Learning distance functions interactively",
                "PaperDOI": "10.1109/VAST.2012.6400486",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400486",
                "firstage": "83",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "6400486",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.",
                "AuthorNames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "filename": "brown_vast_12",
                "Citations": "146402;6102449;4388999;5332584;6102448;4677352;5652443"
            }
        },
        {
            "name": "McGuffin, M.J.",
            "value": 254,
            "numPapers": 61,
            "cluster": "3",
            "index": 107,
            "weight": 9,
            "x": -175.67341990814623,
            "y": 493.83074113653436,
            "px": -174.18592742174133,
            "py": 439.0621413211702,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data",
                "PaperDOI": "10.1109/TVCG.2013.160",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.160",
                "firstage": "2606",
                "Lastage": "2614",
                "IEEEXPLOREArticleNumber": "6634192",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.",
                "AuthorNames": "Im, J.-F.;McGuffin, M.J.;Leung, R.",
                "FirstAuthorAffiliation": "Ecole de Technol. Super., Montreal, QC, Canada|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Im, J.-F.;McGuffin, M.J.;Leung, R.",
                "filename": "im_infovis_13",
                "Citations": "1532142;4376168;5290705;5332586;4376133;146386;6064996;5613448;6064990;398859;6064997;5613431;885086;4376140;1382895;4658123;175796"
            }
        },
        {
            "name": "Muhlbacher, T.",
            "value": 28,
            "numPapers": 38,
            "cluster": "3",
            "index": 108,
            "weight": 1,
            "x": 1159.4456298289208,
            "y": -80.73221173483427,
            "px": 1983.2166849172436,
            "py": -428.4072862243963,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "A Partition-Based Framework for Building and Validating Regression Models",
                "PaperDOI": "10.1109/TVCG.2013.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.125",
                "firstage": "1962",
                "Lastage": "1971",
                "IEEEXPLOREArticleNumber": "6634169",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.",
                "AuthorNames": "Muhlbacher, T.;Piringer, H.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Muhlbacher, T.;Piringer, H.",
                "filename": "muehlbacher_vast_13",
                "Citations": "6327298;5290702;398859;6400486;6102453;5333431;5613467;6327265;5332628;146402;6102450;4677368;5652460;6064952;1532142;4388999;1382902;5290719;6102448;1382892"
            }
        },
        {
            "name": "Moller, T.",
            "value": 373,
            "numPapers": 137,
            "cluster": "5",
            "index": 109,
            "weight": 32,
            "x": 142.17339110257464,
            "y": 381.6043213149803,
            "px": 160.33631611845414,
            "py": 368.2336226524174,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "firstage": "2818",
                "Lastage": "2827",
                "IEEEXPLOREArticleNumber": "6634108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "filename": "isenberg_vis_13",
                "Citations": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Tatu, A.",
            "value": 75,
            "numPapers": 37,
            "cluster": "2",
            "index": 110,
            "weight": 4,
            "x": -69.58947641076242,
            "y": 44.07341077119323,
            "px": 192.5625705877358,
            "py": 141.45067383135157,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Subspace search and visualization to make sense of alternative clusterings in high-dimensional data",
                "PaperDOI": "10.1109/VAST.2012.6400488",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400488",
                "firstage": "63",
                "Lastage": "72",
                "IEEEXPLOREArticleNumber": "6400488",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.",
                "AuthorNames": "Tatu, A.;Maas, F.;Farber, I.;Bertini, E.;Schreck, T.;Seidl, T.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tatu, A.;Maas, F.;Farber, I.;Bertini, E.;Schreck, T.;Seidl, T.;Keim, D.A.",
                "filename": "tatu_vast_12",
                "Citations": "1532142;5613440;5652392;1382893;5652450;6102439;6065026;1382892;5290704"
            }
        },
        {
            "name": "Stolper, C.D.",
            "value": 17,
            "numPapers": 32,
            "cluster": "3",
            "index": 111,
            "weight": 2,
            "x": -59.732495605172694,
            "y": 561.5791312165649,
            "px": -80.93230769674413,
            "py": 483.4633264062478,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "SnapShot: Visualization to Propel Ice Hockey Analytics",
                "PaperDOI": "10.1109/TVCG.2012.263",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.263",
                "firstage": "2819",
                "Lastage": "2828",
                "IEEEXPLOREArticleNumber": "6327288",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.",
                "AuthorNames": "Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.T.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38488862800;38490190000;38490191800;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pileggi, H.;Stolper, C.D.;Boyle, J.M.;Stasko, J.",
                "filename": "pileggi_infovis_12",
                "Citations": "5613452;4376130;636793;6064996;4376131;559229"
            }
        },
        {
            "name": "Perer, A.",
            "value": 82,
            "numPapers": 47,
            "cluster": "3",
            "index": 112,
            "weight": 5,
            "x": -16.04417755220021,
            "y": 671.3611593784003,
            "px": 21.451111658805424,
            "py": 638.9074503127763,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Value and Relation Display for Interactive Exploration of High Dimensional Datasets",
                "PaperDOI": "10.1109/INFVIS.2004.71",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.71",
                "firstage": "73",
                "Lastage": "80",
                "IEEEXPLOREArticleNumber": "1382893",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items",
                "AuthorNames": "Jing Yang;Anilkumar Patro;Huang Shiping;Nishant Mehta;Ward, M.O.;Rundensteiner, E.A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;;;;",
                "AuthorIDs": "37292632600;37932988400;37557769100;37554158700;37268441700;37279217900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Anilkumar Patro;Huang Shiping;Nishant Mehta;Ward, M.O.;Rundensteiner, E.A.",
                "filename": "yang_infovis_04",
                "Citations": "729568;1249015;346302;1249014;528686;485140"
            }
        },
        {
            "name": "Plaisant, C.",
            "value": 212,
            "numPapers": 35,
            "cluster": "3",
            "index": 113,
            "weight": 5,
            "x": -77.11906710730395,
            "y": 469.00666458526234,
            "px": 12.177850591224882,
            "py": 474.5870171572752,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView",
                "PaperDOI": "10.1109/TVCG.2013.231",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.231",
                "firstage": "2566",
                "Lastage": "2575",
                "IEEEXPLOREArticleNumber": "6634101",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.",
                "AuthorNames": "Guerra-Gomez, J.;Pack, M.L.;Plaisant, C.;Shneiderman, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guerra-Gomez, J.;Pack, M.L.;Plaisant, C.;Shneiderman, B.",
                "filename": "guerra-gomez_infovis_13",
                "Citations": "6102439;4015425;6064996;175815;4376153;1173150;4035741;1173148;1249026;4376152"
            }
        },
        {
            "name": "Pak Chung Wong",
            "value": 268,
            "numPapers": 59,
            "cluster": "2",
            "index": 114,
            "weight": 20,
            "x": 197.3578506558535,
            "y": 226.01138603257914,
            "px": -88.27878288918052,
            "py": 154.6422887596199,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "firstage": "105",
                "Lastage": "111",
                "IEEEXPLOREArticleNumber": "885097",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as AÔåÆBÔåÆCÔåÆD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "filename": "wong_infovis_00",
                "Citations": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Foote, H.",
            "value": 120,
            "numPapers": 28,
            "cluster": "2",
            "index": 115,
            "weight": 5,
            "x": 835.9726915871671,
            "y": 120.15697639218064,
            "px": 439.76175758768,
            "py": 124.91226503109753,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "firstage": "105",
                "Lastage": "111",
                "IEEEXPLOREArticleNumber": "885097",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as AÔåÆBÔåÆCÔåÆD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "filename": "wong_infovis_00",
                "Citations": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Mueller, K.",
            "value": 355,
            "numPapers": 122,
            "cluster": "5",
            "index": 116,
            "weight": 34,
            "x": 116.79146439736785,
            "y": 399.95985326494036,
            "px": 80.98384654857374,
            "py": 395.9105431111756,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Toward a Multi-Analyst, Collaborative Framework for Visual Analytics",
                "PaperDOI": "10.1109/VAST.2006.261439",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261439",
                "firstage": "129",
                "Lastage": "136",
                "IEEEXPLOREArticleNumber": "4035757",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts",
                "AuthorNames": "Brennan, S.E.;Mueller, K.;Zelinsky, G.;Ramakrishnan, I.;Warren, D.S.;Kaufman, A.",
                "FirstAuthorAffiliation": "Stony Brook Univ., NY|c|;;;;;",
                "AuthorIDs": "37840264500;37273119700;37418690100;37284911300;37344836300;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brennan, S.E.;Mueller, K.;Zelinsky, G.;Ramakrishnan, I.;Warren, D.S.;Kaufman, A.",
                "filename": "brennan_vast_06",
                "Citations": ""
            }
        },
        {
            "name": "Preim, B.",
            "value": 140,
            "numPapers": 61,
            "cluster": "5",
            "index": 117,
            "weight": 12,
            "x": 207.3065114156846,
            "y": 413.02306347432426,
            "px": 245.45978309009755,
            "py": 420.83043068745576,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Interactive Visual Analysis of Perfusion Data",
                "PaperDOI": "10.1109/TVCG.2007.70569",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70569",
                "firstage": "1392",
                "Lastage": "1399",
                "IEEEXPLOREArticleNumber": "4376166",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.",
                "AuthorNames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "FirstAuthorAffiliation": "Univ. of Magdeburg, Magdeburg|c|;;;;",
                "AuthorIDs": "37424645600;37546620400;37274158800;37546620600;37424645300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "filename": "oeltze_vis_07",
                "Citations": "885739"
            }
        },
        {
            "name": "Westermann, R.",
            "value": 406,
            "numPapers": 151,
            "cluster": "5",
            "index": 118,
            "weight": 35,
            "x": 213.21710686063054,
            "y": 353.63600851633703,
            "px": 226.76263909992724,
            "py": 351.34944786623856,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Direct Volume Editing",
                "PaperDOI": "10.1109/TVCG.2008.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.120",
                "firstage": "1388",
                "Lastage": "1395",
                "IEEEXPLOREArticleNumber": "4658154",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.",
                "AuthorNames": "Burger, K.;Kruger, J.;Westermann, R.",
                "FirstAuthorAffiliation": "Tech. Univ. Munchen, Munich|c|;;",
                "AuthorIDs": ";;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Burger, K.;Kruger, J.;Westermann, R.",
                "filename": "buorger_vis_08",
                "Citations": "4015450;568110;1250384;1183762;1183777;4376160;1250381;885694;1372190;1532856;568108"
            }
        },
        {
            "name": "Yu-Hsuan Chan",
            "value": 53,
            "numPapers": 8,
            "cluster": "5",
            "index": 119,
            "weight": 1,
            "x": -383.6367704826595,
            "y": 500.7811477983639,
            "px": -730.6450636434295,
            "py": 799.5929970990429,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Flow-based scatterplots for sensitivity analysis",
                "PaperDOI": "10.1109/VAST.2010.5652460",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652460",
                "firstage": "43",
                "Lastage": "50",
                "IEEEXPLOREArticleNumber": "5652460",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.",
                "AuthorNames": "Yu-Hsuan Chan;Correa, C.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis, CA, USA|c|;;",
                "AuthorIDs": "37593323300;37282925900;37275869400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yu-Hsuan Chan;Correa, C.;Kwan-Liu Ma",
                "filename": "chan_vast_10",
                "Citations": "4658159;4677368;5332611;4389000;4015424;4658123"
            }
        },
        {
            "name": "Groller, M.E.",
            "value": 0,
            "numPapers": 18,
            "cluster": "5",
            "index": 120,
            "weight": 2,
            "x": 443.94588068243274,
            "y": 616.520776885131,
            "px": 319.88405503654076,
            "py": 585.6482920304012,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles",
                "PaperDOI": "10.1109/TVCG.2013.147",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.147",
                "firstage": "2783",
                "Lastage": "2791",
                "IEEEXPLOREArticleNumber": "6634138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.",
                "AuthorNames": "Coffey, D.;Chi-Lun Lin;Erdman, A.G.;Keefe, D.F.",
                "FirstAuthorAffiliation": "Univ. of Minnesota, Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Coffey, D.;Chi-Lun Lin;Erdman, A.G.;Keefe, D.F.",
                "filename": "coffey_vis_13",
                "Citations": "6327230;5613487;5613488;6064952;885734;5613486;4376186"
            }
        },
        {
            "name": "Kehrer, J.",
            "value": 45,
            "numPapers": 26,
            "cluster": "2",
            "index": 121,
            "weight": 1,
            "x": 535.4100850786836,
            "y": 551.5529892354201,
            "px": 269.50520728917655,
            "py": 585.4441474840372,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles",
                "PaperDOI": "10.1109/TVCG.2013.147",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.147",
                "firstage": "2783",
                "Lastage": "2791",
                "IEEEXPLOREArticleNumber": "6634138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.",
                "AuthorNames": "Coffey, D.;Chi-Lun Lin;Erdman, A.G.;Keefe, D.F.",
                "FirstAuthorAffiliation": "Univ. of Minnesota, Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Coffey, D.;Chi-Lun Lin;Erdman, A.G.;Keefe, D.F.",
                "filename": "coffey_vis_13",
                "Citations": "6327230;5613487;5613488;6064952;885734;5613486;4376186"
            }
        },
        {
            "name": "Alsallakh, B.",
            "value": 36,
            "numPapers": 38,
            "cluster": "3",
            "index": 122,
            "weight": 6,
            "x": 1065.9148867930983,
            "y": 560.6998749731603,
            "px": 912.5767918285148,
            "py": 647.7760269559094,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Visualizing high-dimensional predictive model quality",
                "PaperDOI": "10.1109/VISUAL.2000.885740",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885740",
                "firstage": "493",
                "Lastage": "496",
                "IEEEXPLOREArticleNumber": "885740",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Using inductive learning techniques to construct classification models from large, high-dimensional data sets is a useful way to make predictions in complex domains. However, these models can be difficult for users to understand. We have developed a set of visualization methods that help users to understand and analyze the behavior of learned models, including techniques for high-dimensional data space projection, display of probabilistic predictions, variable/class correlation, and instance mapping. We show the results of applying these techniques to models constructed from a benchmark data set of census data, and draw conclusions about the utility of these methods for model understanding.",
                "AuthorNames": "Rheingans, P.;desJardins, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA|c|;",
                "AuthorIDs": "37282292000;37552291200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rheingans, P.;desJardins, M.",
                "filename": "rheingans_vis_00",
                "Citations": "663922;729553;146402;663868"
            }
        },
        {
            "name": "Aigner, W.",
            "value": 41,
            "numPapers": 29,
            "cluster": "3",
            "index": 123,
            "weight": 5,
            "x": 625.9962355073178,
            "y": 1538.2890237871206,
            "px": 494.36626641304406,
            "py": 1396.9352829875274,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Radial Sets: Interactive Visual Analysis of Large Overlapping Sets",
                "PaperDOI": "10.1109/TVCG.2013.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.184",
                "firstage": "2496",
                "Lastage": "2505",
                "IEEEXPLOREArticleNumber": "6634104",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.",
                "AuthorNames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "filename": "alsallakh_infovis_13",
                "Citations": "4015417;5290706;4658148;6064991;1382886;5613447;6327291;1173157"
            }
        },
        {
            "name": "Miksch, S.",
            "value": 58,
            "numPapers": 43,
            "cluster": "3",
            "index": 124,
            "weight": 7,
            "x": -158.2688604108407,
            "y": 476.86314973626367,
            "px": -162.89726795244525,
            "py": 578.4980267250163,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Visualizing high-dimensional predictive model quality",
                "PaperDOI": "10.1109/VISUAL.2000.885740",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885740",
                "firstage": "493",
                "Lastage": "496",
                "IEEEXPLOREArticleNumber": "885740",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Using inductive learning techniques to construct classification models from large, high-dimensional data sets is a useful way to make predictions in complex domains. However, these models can be difficult for users to understand. We have developed a set of visualization methods that help users to understand and analyze the behavior of learned models, including techniques for high-dimensional data space projection, display of probabilistic predictions, variable/class correlation, and instance mapping. We show the results of applying these techniques to models constructed from a benchmark data set of census data, and draw conclusions about the utility of these methods for model understanding.",
                "AuthorNames": "Rheingans, P.;desJardins, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA|c|;",
                "AuthorIDs": "37282292000;37552291200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rheingans, P.;desJardins, M.",
                "filename": "rheingans_vis_00",
                "Citations": "663922;729553;146402;663868"
            }
        },
        {
            "name": "Shi, L.",
            "value": 71,
            "numPapers": 16,
            "cluster": "4",
            "index": 125,
            "weight": 4,
            "x": -554.4137083791741,
            "y": 533.9284093765912,
            "px": -367.66765424432026,
            "py": 596.6311612191544,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "SAVE: Sensor anomaly visualization engine",
                "PaperDOI": "10.1109/VAST.2011.6102458",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102458",
                "firstage": "201",
                "Lastage": "210",
                "IEEEXPLOREArticleNumber": "6102458",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.",
                "AuthorNames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "FirstAuthorAffiliation": "IBM Res., Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37543450800;37398853200;38240137400;37298955400;37588016000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "filename": "shi_vast_11",
                "Citations": "5290694;5333880;1532126;1382886;5652910"
            }
        },
        {
            "name": "Xiaoxiao Lian",
            "value": 55,
            "numPapers": 11,
            "cluster": "4",
            "index": 126,
            "weight": 4,
            "x": -141.80145465502716,
            "y": -2.7207268590402034,
            "px": -39.13845922142382,
            "py": 178.49987948176587,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Understanding text corpora with multiple facets",
                "PaperDOI": "10.1109/VAST.2010.5652931",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652931",
                "firstage": "99",
                "Lastage": "106",
                "IEEEXPLOREArticleNumber": "5652931",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.",
                "AuthorNames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "FirstAuthorAffiliation": "IBM Res. - China, Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37396839900;37406039100;37597343100;37604004300;37399569300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "filename": "shi_vast_10",
                "Citations": "5333443;4389005;4658133;5290722;4658136;5290726;1173155;801866;4389006;1532122;885097"
            }
        },
        {
            "name": "Viegas, F.B.",
            "value": 336,
            "numPapers": 19,
            "cluster": "4",
            "index": 127,
            "weight": 16,
            "x": 216.33007337894634,
            "y": 620.8192990963471,
            "px": 240.84183506585583,
            "py": 681.367461137112,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "The Word Tree, an Interactive Visual Concordance",
                "PaperDOI": "10.1109/TVCG.2008.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.172",
                "firstage": "1221",
                "Lastage": "1228",
                "IEEEXPLOREArticleNumber": "4658133",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional \"keyword-in-context\" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.",
                "AuthorNames": "Wattenberg, M.;Viegas, F.B.",
                "FirstAuthorAffiliation": "IBM Res., Cambridge, MA|c|;",
                "AuthorIDs": "37550759700;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wattenberg, M.;Viegas, F.B.",
                "filename": "wattenbe_infovis_08",
                "Citations": "1173155;4389006;4376131;1173148"
            }
        },
        {
            "name": "Feinberg, J.",
            "value": 51,
            "numPapers": 2,
            "cluster": "4",
            "index": 128,
            "weight": 2,
            "x": -23.979577115314207,
            "y": 62.83273798395436,
            "px": 318.6598134232721,
            "py": 595.3718120214231,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Participatory Visualization with Wordle",
                "PaperDOI": "10.1109/TVCG.2009.171",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.171",
                "firstage": "1137",
                "Lastage": "1144",
                "IEEEXPLOREArticleNumber": "5290722",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;Feinberg, J.",
                "FirstAuthorAffiliation": "IBM Res., Hawthorne, CA, USA|c|;;",
                "AuthorIDs": "37681355300;37550759700;38102505300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;Feinberg, J.",
                "filename": "viegas_infovis_09",
                "Citations": "1532122;4376131"
            }
        },
        {
            "name": "Tanahashi, Y.",
            "value": 27,
            "numPapers": 9,
            "cluster": "4",
            "index": 129,
            "weight": 1,
            "x": -737.4971688424306,
            "y": 998.4611990044599,
            "px": -1903.4747472612744,
            "py": 1408.718543436808,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Design Considerations for Optimizing Storyline Visualizations",
                "PaperDOI": "10.1109/TVCG.2012.212",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.212",
                "firstage": "2679",
                "Lastage": "2688",
                "IEEEXPLOREArticleNumber": "6327274",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's â€œMovie Narrative Chartsâ€ [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.",
                "AuthorNames": "Tanahashi, Y.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "ViDi Res. Group, Univ. of California, Davis, CA, USA|c|;",
                "AuthorIDs": "38490419400;38490054000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tanahashi, Y.;Kwan-Liu Ma",
                "filename": "tanahashi_infovis_12",
                "Citations": "4658136;4658140;6065002;6065008;4015433;4376143;1249008;4658146;1173160"
            }
        },
        {
            "name": "Hong Zhou",
            "value": 118,
            "numPapers": 48,
            "cluster": "2",
            "index": 130,
            "weight": 3,
            "x": -56.37049161621701,
            "y": -71.33628903721227,
            "px": 618.948033753235,
            "py": 299.4500128663704,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "OpinionSeer: Interactive Visualization of Hotel Customer Feedback",
                "PaperDOI": "10.1109/TVCG.2010.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.183",
                "firstage": "1109",
                "Lastage": "1118",
                "IEEEXPLOREArticleNumber": "5613449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.",
                "AuthorNames": "Yingcai Wu;Furu Wei;Shixia Liu;Au, N.;Weiwei Cui;Hong Zhou;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;;;",
                "AuthorIDs": "37407308300;37396839900;37406039100;37590967500;37391623900;37405368200;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Furu Wei;Shixia Liu;Au, N.;Weiwei Cui;Hong Zhou;Huamin Qu",
                "filename": "wu_infovis_10",
                "Citations": "4035748;5290722;5332611;4658130;5333919;1173151"
            }
        },
        {
            "name": "Barlowe, S.",
            "value": 30,
            "numPapers": 30,
            "cluster": "3",
            "index": 131,
            "weight": 1,
            "x": 159.62846801404186,
            "y": 260.17678068905883,
            "px": 281.4110346495239,
            "py": 115.98226331445876,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics",
                "PaperDOI": "10.1109/VAST.2011.6102447",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102447",
                "firstage": "101",
                "Lastage": "110",
                "IEEEXPLOREArticleNumber": "6102447",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness.",
                "AuthorNames": "Yang Chen;Alsakran, J.;Barlowe, S.;Jing Yang;Ye Zhao",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": "37600587200;37846905500;37591128900;37292632600;37277701200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yang Chen;Alsakran, J.;Barlowe, S.;Jing Yang;Ye Zhao",
                "filename": "chen_vast_11",
                "Citations": "4376134;5333023;4376131;5652879;4677358;5652932;4389011;4677365;4015424;5652885"
            }
        },
        {
            "name": "Guodao Sun",
            "value": 10,
            "numPapers": 10,
            "cluster": "4",
            "index": 132,
            "weight": 2,
            "x": 92.80677324941392,
            "y": 257.6312053579175,
            "px": 344.303748400407,
            "py": 630.3287588254884,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "firstage": "1753",
                "Lastage": "1762",
                "IEEEXPLOREArticleNumber": "6875992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Cooperation and competition (jointly called ÔÇ£coopetitionÔÇØ) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., ÔÇ£topic leadersÔÇØ) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "filename": "sun1_vast_14",
                "Citations": "shi_vast_10,cao_infovis_12,byron_infovis_08,cui_infovis_11,shi_infovis_12,wu2_vast_14,xu_vast_13,liu_infovis_13,duo_vast_13,"
            }
        },
        {
            "name": "Mengchen Liu",
            "value": 32,
            "numPapers": 24,
            "cluster": "4",
            "index": 133,
            "weight": 6,
            "x": -300.44070481153864,
            "y": 303.862371368933,
            "px": -298.2815001840022,
            "py": 466.8193134035808,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346920",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346920",
                "firstage": "1763",
                "Lastage": "1772",
                "IEEEXPLOREArticleNumber": "6876032",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.",
                "AuthorNames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "filename": "wu2_vast_14",
                "Citations": "cui_infovis_11,duo_vast_13,xu_vast_13,cui_infovis_14,riehmann_infovis_05,cao_infovis_12,chen_vast_06,doerk_infovis_10,liu_infovis_13,sun1_vast_14,wu_infovis_10,oelke_vast_09,"
            }
        },
        {
            "name": "Yang Liu",
            "value": 22,
            "numPapers": 11,
            "cluster": "4",
            "index": 134,
            "weight": 1,
            "x": -795.5749052347323,
            "y": 379.9485825335209,
            "px": -2013.0482402873852,
            "py": 218.19306324513855,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "StoryFlow: Tracking the Evolution of Stories",
                "PaperDOI": "10.1109/TVCG.2013.196",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.196",
                "firstage": "2436",
                "Lastage": "2445",
                "IEEEXPLOREArticleNumber": "6634164",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.",
                "AuthorNames": "Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu",
                "filename": "liu_infovis_13",
                "Citations": "6327273;6064988;5613452;6065001;4677364;6327274;6634134;6327272;4035762;5333437;6065008"
            }
        },
        {
            "name": "Kai Yan",
            "value": 10,
            "numPapers": 13,
            "cluster": "4",
            "index": 135,
            "weight": 3,
            "x": 1115.3253400604558,
            "y": -1950.787949136651,
            "px": 811.7417300853065,
            "py": -978.6002928317724,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346920",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346920",
                "firstage": "1763",
                "Lastage": "1772",
                "IEEEXPLOREArticleNumber": "6876032",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.",
                "AuthorNames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "filename": "wu2_vast_14",
                "Citations": "cui_infovis_11,duo_vast_13,xu_vast_13,cui_infovis_14,riehmann_infovis_05,cao_infovis_12,chen_vast_06,doerk_infovis_10,liu_infovis_13,sun1_vast_14,wu_infovis_10,oelke_vast_09,"
            }
        },
        {
            "name": "Fangzhao Wu",
            "value": 10,
            "numPapers": 13,
            "cluster": "4",
            "index": 136,
            "weight": 3,
            "x": -1358.7281597837634,
            "y": 1062.290544196118,
            "px": -814.5439570442413,
            "py": 1013.6743043880315,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346920",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346920",
                "firstage": "1763",
                "Lastage": "1772",
                "IEEEXPLOREArticleNumber": "6876032",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.",
                "AuthorNames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "filename": "wu2_vast_14",
                "Citations": "cui_infovis_11,duo_vast_13,xu_vast_13,cui_infovis_14,riehmann_infovis_05,cao_infovis_12,chen_vast_06,doerk_infovis_10,liu_infovis_13,sun1_vast_14,wu_infovis_10,oelke_vast_09,"
            }
        },
        {
            "name": "Garth, C.",
            "value": 257,
            "numPapers": 91,
            "cluster": "6",
            "index": 137,
            "weight": 34,
            "x": 451.34923918749706,
            "y": 311.6154841897083,
            "px": 468.0385666807543,
            "py": 328.04075999981285,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research",
                "PaperDOI": "10.1109/TVCG.2012.280",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.280",
                "firstage": "2275",
                "Lastage": "2284",
                "IEEEXPLOREArticleNumber": "6327232",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.",
                "AuthorNames": "Engel, D.;Greff, K.;Garth, C.;Bein, K.;Wexler, A.;Hamann, B.;Hagen, H.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;;",
                "AuthorIDs": "38489527100;38489177000;37282573700;38490554500;38227083700;37282068700;37282578800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Engel, D.;Greff, K.;Garth, C.;Bein, K.;Wexler, A.;Hamann, B.;Hagen, H.",
                "filename": "engel_vis_12",
                "Citations": "1382894;1382895;1532138;4658163;885734;1249015;5613487;1532850;1173157;4658123"
            }
        },
        {
            "name": "Hagen, H.",
            "value": 390,
            "numPapers": 111,
            "cluster": "6",
            "index": 138,
            "weight": 35,
            "x": 496.87511751674896,
            "y": 314.9546416913702,
            "px": 512.1377775234653,
            "py": 344.7637097264372,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research",
                "PaperDOI": "10.1109/TVCG.2012.280",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.280",
                "firstage": "2275",
                "Lastage": "2284",
                "IEEEXPLOREArticleNumber": "6327232",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.",
                "AuthorNames": "Engel, D.;Greff, K.;Garth, C.;Bein, K.;Wexler, A.;Hamann, B.;Hagen, H.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;;",
                "AuthorIDs": "38489527100;38489177000;37282573700;38490554500;38227083700;37282068700;37282578800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Engel, D.;Greff, K.;Garth, C.;Bein, K.;Wexler, A.;Hamann, B.;Hagen, H.",
                "filename": "engel_vis_12",
                "Citations": "1382894;1382895;1532138;4658163;885734;1249015;5613487;1532850;1173157;4658123"
            }
        },
        {
            "name": "Gracanin, D.",
            "value": 108,
            "numPapers": 24,
            "cluster": "2",
            "index": 139,
            "weight": 6,
            "x": 733.4408434961891,
            "y": -144.6846142190389,
            "px": 649.9543552998474,
            "py": -98.13653324002641,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces",
                "PaperDOI": "10.1109/TVCG.2009.155",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.155",
                "firstage": "1351",
                "Lastage": "1358",
                "IEEEXPLOREArticleNumber": "5290748",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.",
                "AuthorNames": "Matkovic, K.;Gracanin, D.;Klarin, B.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;",
                "AuthorIDs": "38220979200;37272650400;38246833000;37274158800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Matkovic, K.;Gracanin, D.;Klarin, B.;Hauser, H.",
                "filename": "matkovic_vis_09",
                "Citations": "663867;4658193;963273;4015444"
            }
        },
        {
            "name": "Jelovic, M.",
            "value": 86,
            "numPapers": 19,
            "cluster": "2",
            "index": 140,
            "weight": 6,
            "x": 955.2558921936266,
            "y": 699.5339087881467,
            "px": 862.5002278428457,
            "py": 708.1169426309197,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "firstage": "1458",
                "Lastage": "1467",
                "IEEEXPLOREArticleNumber": "5613487",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "filename": "waser_vis_10",
                "Citations": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Zuchao Wang",
            "value": 51,
            "numPapers": 46,
            "cluster": "2",
            "index": 141,
            "weight": 4,
            "x": 608.7655210547723,
            "y": 736.5822809420469,
            "px": 563.7578535916894,
            "py": 543.9674932142838,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "firstage": "2159",
                "Lastage": "2168",
                "IEEEXPLOREArticleNumber": "6634174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "filename": "wang2_vast_13",
                "Citations": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Tangzhi Ye",
            "value": 0,
            "numPapers": 15,
            "cluster": "2",
            "index": 142,
            "weight": 2,
            "x": 392.53083367232324,
            "y": -145.80511456424145,
            "px": 81.01403127905436,
            "py": -284.0359086045342,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "AlVis: Situation awareness in the surveillance of road tunnels",
                "PaperDOI": "10.1109/VAST.2012.6400556",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400556",
                "firstage": "153",
                "Lastage": "162",
                "IEEEXPLOREArticleNumber": "6400556",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.",
                "AuthorNames": "Piringer, H.;Buchetics, M.;Benedik, R.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Piringer, H.;Buchetics, M.;Benedik, R.",
                "filename": "piringer_vast_12",
                "Citations": "1173149;1532134;6102456;4376188;4376140;4376136;1382887;528685;4658139;4388994;4388998;4677353"
            }
        },
        {
            "name": "Min Lu",
            "value": 40,
            "numPapers": 28,
            "cluster": "2",
            "index": 143,
            "weight": 2,
            "x": 373.4662204131596,
            "y": -200.63031068076893,
            "px": 75.47407552720149,
            "py": -266.7436762785888,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "firstage": "2159",
                "Lastage": "2168",
                "IEEEXPLOREArticleNumber": "6634174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "filename": "wang2_vast_13",
                "Citations": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Xiaoru Yuan",
            "value": 119,
            "numPapers": 155,
            "cluster": "2",
            "index": 144,
            "weight": 20,
            "x": 372.08660031699674,
            "y": 389.48850128055597,
            "px": 345.64924078615684,
            "py": 338.3358797792476,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "firstage": "2159",
                "Lastage": "2168",
                "IEEEXPLOREArticleNumber": "6634174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "filename": "wang2_vast_13",
                "Citations": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Yuan, J.",
            "value": 0,
            "numPapers": 15,
            "cluster": "2",
            "index": 145,
            "weight": 2,
            "x": 245.4840027874912,
            "y": -195.10953621348736,
            "px": 88.41714402787429,
            "py": -274.7235869759964,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "AlVis: Situation awareness in the surveillance of road tunnels",
                "PaperDOI": "10.1109/VAST.2012.6400556",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400556",
                "firstage": "153",
                "Lastage": "162",
                "IEEEXPLOREArticleNumber": "6400556",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.",
                "AuthorNames": "Piringer, H.;Buchetics, M.;Benedik, R.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Piringer, H.;Buchetics, M.;Benedik, R.",
                "filename": "piringer_vast_12",
                "Citations": "1173149;1532134;6102456;4376188;4376140;4376136;1382887;528685;4658139;4388994;4388998;4677353"
            }
        },
        {
            "name": "Qianliang Wu",
            "value": 0,
            "numPapers": 15,
            "cluster": "2",
            "index": 146,
            "weight": 2,
            "x": 236.6361224157808,
            "y": -2.449697554941128,
            "px": 138.59968728935453,
            "py": -321.11322980885194,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "AlVis: Situation awareness in the surveillance of road tunnels",
                "PaperDOI": "10.1109/VAST.2012.6400556",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400556",
                "firstage": "153",
                "Lastage": "162",
                "IEEEXPLOREArticleNumber": "6400556",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.",
                "AuthorNames": "Piringer, H.;Buchetics, M.;Benedik, R.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Piringer, H.;Buchetics, M.;Benedik, R.",
                "filename": "piringer_vast_12",
                "Citations": "1173149;1532134;6102456;4376188;4376140;4376136;1382887;528685;4658139;4388994;4388998;4677353"
            }
        },
        {
            "name": "Weiskopf, D.",
            "value": 335,
            "numPapers": 149,
            "cluster": "5",
            "index": 147,
            "weight": 26,
            "x": -27.456031936197924,
            "y": 344.541035384295,
            "px": -84.55175124183381,
            "py": 312.4666510937309,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Visualizing Fuzzy Overlapping Communities in Networks",
                "PaperDOI": "10.1109/TVCG.2013.232",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.232",
                "firstage": "2486",
                "Lastage": "2495",
                "IEEEXPLOREArticleNumber": "6634179",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.",
                "AuthorNames": "Vehlow, C.;Reinhardt, T.;Weiskopf, D.",
                "FirstAuthorAffiliation": "VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Vehlow, C.;Reinhardt, T.;Weiskopf, D.",
                "filename": "vehlow_infovis_13",
                "Citations": "398872;1532126;6064991;5613447;5290706;1382909;5290741"
            }
        },
        {
            "name": "Vo, H.T.",
            "value": 155,
            "numPapers": 17,
            "cluster": "5",
            "index": 148,
            "weight": 3,
            "x": 124.50099629298353,
            "y": 182.39323921091128,
            "px": 125.3512854705671,
            "py": 115.4953547720501,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips",
                "PaperDOI": "10.1109/TVCG.2013.226",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.226",
                "firstage": "2149",
                "Lastage": "2158",
                "IEEEXPLOREArticleNumber": "6634127",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.",
                "AuthorNames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "filename": "ferreira_vast_13",
                "Citations": "1382904;4677356;6102454;4376143;5652467;1532150;4677370;885086"
            }
        },
        {
            "name": "Freire, J.",
            "value": 172,
            "numPapers": 45,
            "cluster": "5",
            "index": 149,
            "weight": 7,
            "x": 224.46775999198698,
            "y": 292.5244383234497,
            "px": 210.7031323320608,
            "py": 249.6697675313257,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips",
                "PaperDOI": "10.1109/TVCG.2013.226",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.226",
                "firstage": "2149",
                "Lastage": "2158",
                "IEEEXPLOREArticleNumber": "6634127",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.",
                "AuthorNames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "filename": "ferreira_vast_13",
                "Citations": "1382904;4677356;6102454;4376143;5652467;1532150;4677370;885086"
            }
        },
        {
            "name": "Elmqvist, N.",
            "value": 203,
            "numPapers": 98,
            "cluster": "3",
            "index": 150,
            "weight": 11,
            "x": 294.7374660989304,
            "y": 809.691186555185,
            "px": 225.6068069065052,
            "py": 752.5604056160029,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data",
                "PaperDOI": "10.1109/VAST.2007.4389013",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389013",
                "firstage": "187",
                "Lastage": "194",
                "IEEEXPLOREArticleNumber": "4389013",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.",
                "AuthorNames": "Elmqvist, N.;Stasko, J.;Tsigas, P.",
                "FirstAuthorAffiliation": "Univ. Paris-Sud, Paris|c|;;",
                "AuthorIDs": "37295438200;37267736900;37295439000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Elmqvist, N.;Stasko, J.;Tsigas, P.",
                "filename": "elmqvist_vast_07",
                "Citations": "885086;146386;175815;1249026;4035757;1532139;4035764;4035743;1532136;636793;4035763;4035747;1249016;809866;146375"
            }
        },
        {
            "name": "Dykes, J.",
            "value": 255,
            "numPapers": 94,
            "cluster": "3",
            "index": 151,
            "weight": 16,
            "x": 163.7518540411973,
            "y": 613.9917624012382,
            "px": 192.3425246615891,
            "py": 609.8270672387522,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Configuring Hierarchical Layouts to Address Research Questions",
                "PaperDOI": "10.1109/TVCG.2009.128",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.128",
                "firstage": "977",
                "Lastage": "984",
                "IEEEXPLOREArticleNumber": "5290702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.",
                "AuthorNames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., City Univ. London, London, UK|c|;;",
                "AuthorIDs": "37590960700;37605079900;37399045100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "filename": "slingsby_infovis_09",
                "Citations": "4376144;1249006;146386;4658146;4376146;1183791"
            }
        },
        {
            "name": "Havre, S.",
            "value": 114,
            "numPapers": 8,
            "cluster": "2",
            "index": 152,
            "weight": 1,
            "x": 1399.184156806717,
            "y": -468.1155232657259,
            "px": 2535.1970161907184,
            "py": -1059.987327559373,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "firstage": "115",
                "Lastage": "123",
                "IEEEXPLOREArticleNumber": "885098",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The “river” flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored “currents” flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "filename": "havre_infovis_00",
                "Citations": "528686;636789;729555"
            }
        },
        {
            "name": "Hetzler, E.",
            "value": 189,
            "numPapers": 21,
            "cluster": "2",
            "index": 153,
            "weight": 2,
            "x": -584.2124605039628,
            "y": -220.01417015638367,
            "px": -320.96931351097874,
            "py": 139.3495757343435,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "firstage": "115",
                "Lastage": "123",
                "IEEEXPLOREArticleNumber": "885098",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The “river” flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored “currents” flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "filename": "havre_infovis_00",
                "Citations": "528686;636789;729555"
            }
        },
        {
            "name": "Nowell, L.",
            "value": 118,
            "numPapers": 9,
            "cluster": "2",
            "index": 154,
            "weight": 1,
            "x": 641.021117403537,
            "y": 2030.8892582559713,
            "px": 1096.5482740597831,
            "py": 3706.182208442353,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "firstage": "115",
                "Lastage": "123",
                "IEEEXPLOREArticleNumber": "885098",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The “river” flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored “currents” flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "filename": "havre_infovis_00",
                "Citations": "528686;636789;729555"
            }
        },
        {
            "name": "Gaither, K.",
            "value": 36,
            "numPapers": 33,
            "cluster": "5",
            "index": 155,
            "weight": 1,
            "x": 250.78081457142966,
            "y": 291.28486516934987,
            "px": 184.56264730597132,
            "py": 192.46612878926376,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "firstage": "115",
                "Lastage": "123",
                "IEEEXPLOREArticleNumber": "885098",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The “river” flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored “currents” flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "filename": "havre_infovis_00",
                "Citations": "528686;636789;729555"
            }
        },
        {
            "name": "Waser, J.",
            "value": 162,
            "numPapers": 40,
            "cluster": "1",
            "index": 156,
            "weight": 13,
            "x": 1307.6958597797866,
            "y": 809.7015882557022,
            "px": 1276.3289896169092,
            "py": 763.7380318841365,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Visual Human+Machine Learning",
                "PaperDOI": "10.1109/TVCG.2009.199",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.199",
                "firstage": "1327",
                "Lastage": "1334",
                "IEEEXPLOREArticleNumber": "5290745",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.",
                "AuthorNames": "Fuchs, R.;Waser, J.;Groller, M.E.",
                "FirstAuthorAffiliation": "ETH Zurich, Zurich, Switzerland|c|;;",
                "AuthorIDs": "38099765400;38111592300;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fuchs, R.;Waser, J.;Groller, E.",
                "filename": "fuchs_vis_09",
                "Citations": "4376165;4658178;4389001;4389000"
            }
        },
        {
            "name": "Sadransky, B.",
            "value": 4,
            "numPapers": 12,
            "cluster": "1",
            "index": 157,
            "weight": 6,
            "x": 1255.6008940497359,
            "y": 816.3846682219357,
            "px": 1235.5358696148824,
            "py": 735.5860390146996,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Process visualization with levels of detail",
                "PaperDOI": "10.1109/INFVIS.2002.1173149",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173149",
                "firstage": "67",
                "Lastage": "70",
                "IEEEXPLOREArticleNumber": "1173149",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We demonstrate how we apply information visualization techniques to process monitoring. Virtual instruments are enhanced using history encoding instruments are capable of displaying the current value and the value from the near past. Multi-instruments are capable of displaying several data sources simultaneously. Levels of detail for virtual instruments are introduced where the screen area is inversely proportional to the information amount displayed. Furthermore the monitoring system is enhanced by using: 3D anchoring attachment of instruments to positions on a 3D model, collision avoidance a physically based spring model prevents instruments from overlapping, and focus+context rendering - giving the user a possibility to examine particular instruments in detail without loosing the context information.",
                "AuthorNames": "Matkovic, K.;Hauser, H.;Sainitzer, R.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;",
                "AuthorIDs": "38220979200;37274158800;38221553100;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Matkovic, K.;Hauser, H.;Sainitzer, R.;Groller, E.",
                "filename": "matkovic_infovis_02",
                "Citations": "729558;963286"
            }
        },
        {
            "name": "Fuchs, R.",
            "value": 158,
            "numPapers": 35,
            "cluster": "1",
            "index": 158,
            "weight": 10,
            "x": 1079.512816979599,
            "y": 544.9411072936402,
            "px": 1065.1197681353854,
            "py": 518.8529911299734,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Visual Human+Machine Learning",
                "PaperDOI": "10.1109/TVCG.2009.199",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.199",
                "firstage": "1327",
                "Lastage": "1334",
                "IEEEXPLOREArticleNumber": "5290745",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.",
                "AuthorNames": "Fuchs, R.;Waser, J.;Groller, M.E.",
                "FirstAuthorAffiliation": "ETH Zurich, Zurich, Switzerland|c|;;",
                "AuthorIDs": "38099765400;38111592300;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fuchs, R.;Waser, J.;Groller, E.",
                "filename": "fuchs_vis_09",
                "Citations": "4376165;4658178;4389001;4389000"
            }
        },
        {
            "name": "Ribicic, H.",
            "value": 133,
            "numPapers": 24,
            "cluster": "1",
            "index": 159,
            "weight": 9,
            "x": 1036.8730183952905,
            "y": 454.16768958778897,
            "px": 1040.1487211214112,
            "py": 455.8521769959876,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "firstage": "1458",
                "Lastage": "1467",
                "IEEEXPLOREArticleNumber": "5613487",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "filename": "waser_vis_10",
                "Citations": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Schindler, B.",
            "value": 129,
            "numPapers": 31,
            "cluster": "1",
            "index": 160,
            "weight": 10,
            "x": 1069.504673214607,
            "y": 547.7542536803618,
            "px": 1055.6965377295348,
            "py": 517.9319285527271,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "firstage": "1458",
                "Lastage": "1467",
                "IEEEXPLOREArticleNumber": "5613487",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "filename": "waser_vis_10",
                "Citations": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Bloschl, G.",
            "value": 129,
            "numPapers": 19,
            "cluster": "1",
            "index": 161,
            "weight": 6,
            "x": 1105.739413555357,
            "y": 528.3504721058464,
            "px": 1125.7532125059392,
            "py": 539.2402903107239,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "firstage": "1458",
                "Lastage": "1467",
                "IEEEXPLOREArticleNumber": "5613487",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "filename": "waser_vis_10",
                "Citations": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Lex, A.",
            "value": 130,
            "numPapers": 65,
            "cluster": "4",
            "index": 162,
            "weight": 12,
            "x": 510.3370235743418,
            "y": 153.00067894518588,
            "px": 620.343555788566,
            "py": 265.518881945191,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Comparative Analysis of Multidimensional; Quantitative Data",
                "PaperDOI": "10.1109/TVCG.2010.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.138",
                "firstage": "1027",
                "Lastage": "1035",
                "IEEEXPLOREArticleNumber": "5613440",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.",
                "AuthorNames": "Lex, A.;Streit, M.;Partl, C.;Kashofer, K.;Schmalstieg, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37395933400;37403918900;37591066400;37591065600;37297103800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lex, A.;Streit, M.;Partl, C.;Kashofer, K.;Schmalstieg, D.",
                "filename": "lex_infovis_10",
                "Citations": "568118;146402;4015425;4376153;4376152;5290692;885086"
            }
        },
        {
            "name": "Pfister, H.",
            "value": 278,
            "numPapers": 156,
            "cluster": "5",
            "index": 163,
            "weight": 29,
            "x": 171.7742251582665,
            "y": 346.4451844520518,
            "px": 235.57810412901785,
            "py": 364.60546819295666,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "MizBee: A Multiscale Synteny Browser",
                "PaperDOI": "10.1109/TVCG.2009.167",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.167",
                "firstage": "897",
                "Lastage": "904",
                "IEEEXPLOREArticleNumber": "5290692",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.",
                "AuthorNames": "Meyer, M.;Munzner, T.;Pfister, H.",
                "FirstAuthorAffiliation": "Harvard Univ., Cambridge, MA, USA|c|;;",
                "AuthorIDs": "37564728700;37349490300;37275698100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Meyer, M.;Munzner, T.;Pfister, H.",
                "filename": "meyer_infovis_09",
                "Citations": "1532134;4015425"
            }
        },
        {
            "name": "Schmalstieg, D.",
            "value": 135,
            "numPapers": 46,
            "cluster": "4",
            "index": 164,
            "weight": 8,
            "x": 1151.9615232353458,
            "y": 1082.3585368853924,
            "px": 1223.361826589854,
            "py": 1154.4970972051046,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data",
                "PaperDOI": "10.1109/TVCG.2013.180",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.180",
                "firstage": "2926",
                "Lastage": "2935",
                "IEEEXPLOREArticleNumber": "6634151",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.",
                "AuthorNames": "Khlebnikov, R.;Kainz, B.;Steinberger, M.;Schmalstieg, D.",
                "FirstAuthorAffiliation": "Graz Univ. of Technol., Graz, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Khlebnikov, R.;Kainz, B.;Steinberger, M.;Schmalstieg, D.",
                "filename": "khlebnikov_vis_13",
                "Citations": "146373;1250412;4015502;1532807;4376150;6327216;1250362"
            }
        },
        {
            "name": "Meyer, M.",
            "value": 194,
            "numPapers": 49,
            "cluster": "3",
            "index": 165,
            "weight": 7,
            "x": -403.08030250102206,
            "y": 15.142016266439978,
            "px": -257.0221794262107,
            "py": 131.1770933130858,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "MizBee: A Multiscale Synteny Browser",
                "PaperDOI": "10.1109/TVCG.2009.167",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.167",
                "firstage": "897",
                "Lastage": "904",
                "IEEEXPLOREArticleNumber": "5290692",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.",
                "AuthorNames": "Meyer, M.;Munzner, T.;Pfister, H.",
                "FirstAuthorAffiliation": "Harvard Univ., Cambridge, MA, USA|c|;;",
                "AuthorIDs": "37564728700;37349490300;37275698100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Meyer, M.;Munzner, T.;Pfister, H.",
                "filename": "meyer_infovis_09",
                "Citations": "1532134;4015425"
            }
        },
        {
            "name": "Aris, A.",
            "value": 109,
            "numPapers": 3,
            "cluster": "4",
            "index": 166,
            "weight": 2,
            "x": 869.187212235456,
            "y": 581.5157395482737,
            "px": 1444.8261793578047,
            "py": 747.3921544760705,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Network Visualization by Semantic Substrates",
                "PaperDOI": "10.1109/TVCG.2006.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.166",
                "firstage": "733",
                "Lastage": "740",
                "IEEEXPLOREArticleNumber": "4015424",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations",
                "AuthorNames": "Shneiderman, B.;Aris, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;",
                "AuthorIDs": "37283016400;37561646300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shneiderman, B.;Aris, A.",
                "filename": "shneiderman_infovis_06",
                "Citations": "1382886;1532124;1532126"
            }
        },
        {
            "name": "Strobelt, H.",
            "value": 31,
            "numPapers": 34,
            "cluster": "5",
            "index": 167,
            "weight": 2,
            "x": 413.9663296018411,
            "y": 445.1105414123694,
            "px": 479.8392533846666,
            "py": 406.3549140322838,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Interactive Level-of-Detail Rendering of Large Graphs",
                "PaperDOI": "10.1109/TVCG.2012.238",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.238",
                "firstage": "2486",
                "Lastage": "2495",
                "IEEEXPLOREArticleNumber": "6327254",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.",
                "AuthorNames": "Zinsmaier, M.;Brandes, U.;Deussen, O.;Strobelt, H.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38489526500;37550836200;37266781000;38108845300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zinsmaier, M.;Brandes, U.;Deussen, O.;Strobelt, H.",
                "filename": "zinsmaier_infovis_12",
                "Citations": "1532150;4015416;6065003;4658140;4015436;4015425;5613456;1382906"
            }
        },
        {
            "name": "Dransch, D.",
            "value": 9,
            "numPapers": 17,
            "cluster": "2",
            "index": 168,
            "weight": 1,
            "x": 401.97846126755053,
            "y": 161.41213523568246,
            "px": -8.32376402116291,
            "py": -101.34267826723695,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "A Visual Analysis Concept for the Validation of Geoscientific Simulation Models",
                "PaperDOI": "10.1109/TVCG.2012.190",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.190",
                "firstage": "2216",
                "Lastage": "2225",
                "IEEEXPLOREArticleNumber": "6327226",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.",
                "AuthorNames": "Unger, A.;Schulte, S.;Klemann, V.;Dransch, D.",
                "FirstAuthorAffiliation": "GFZ German Reserach Center For Geosci., Potsdam, Germany|c|;;;",
                "AuthorIDs": "37628385900;38489773300;38490271000;38490186800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Unger, A.;Schulte, S.;Klemann, V.;Dransch, D.",
                "filename": "unger_vis_12",
                "Citations": "5613482;5652895;6064952;4658193;6064950;5613487;5613486;5613488;398859;5613483;4658178"
            }
        },
        {
            "name": "Mackinlay, J.",
            "value": 185,
            "numPapers": 17,
            "cluster": "3",
            "index": 169,
            "weight": 4,
            "x": 252.52355485482335,
            "y": 827.7892027518582,
            "px": 322.67850100000203,
            "py": 836.3802287683664,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Visualizing data with bounded uncertainty",
                "PaperDOI": "10.1109/INFVIS.2002.1173145",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173145",
                "firstage": "37",
                "Lastage": "40",
                "IEEEXPLOREArticleNumber": "1173145",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization is a powerful way to facilitate data analysis, but it is crucial that visualization systems explicitly convey the presence, nature, and degree of uncertainty to users. Otherwise, there is a danger that data will be falsely interpreted, potentially leading to inaccurate conclusions. A common method for denoting uncertainty is to use error bars or similar techniques designed to convey the degree of statistical uncertainty. While uncertainty can often be modeled statistically, a second form of uncertainty, bounded uncertainty, can also arise that has very different properties than statistical uncertainty. Error bars should not be used for bounded uncertainty because they do not convey the correct properties, so a different technique should be used instead. We describe a technique for conveying bounded uncertainty in visualizations and show how it can be applied systematically to common displays of abstract charts and graphs. Interestingly, it is not always possible to show the exact degree of uncertainty, and in some cases it can only be displayed approximately.",
                "AuthorNames": "Olston, C.;Mackinlay, J.",
                "FirstAuthorAffiliation": "Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37371920000;37372036700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Olston, C.;Mackinlay, J.",
                "filename": "olston_infovis_02",
                "Citations": "346317;885679;801858"
            }
        },
        {
            "name": "Hanrahan, P.",
            "value": 400,
            "numPapers": 27,
            "cluster": "3",
            "index": 170,
            "weight": 8,
            "x": 252.99037383450514,
            "y": 862.5130466265826,
            "px": 326.0380870533245,
            "py": 879.9563901884974,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Visualization of Heterogeneous Data",
                "PaperDOI": "10.1109/TVCG.2007.70617",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70617",
                "firstage": "1200",
                "Lastage": "1207",
                "IEEEXPLOREArticleNumber": "4376141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.",
                "AuthorNames": "Cammarano, M.;Xin Dong;Bryan Chan;Klingner, J.;Talbot, J.;Halevy, A.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Stanford Univ., Stanford|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cammarano, M.;Xin Dong;Bryan Chan;Klingner, J.;Talbot, J.;Halevy, A.;Hanrahan, P.",
                "filename": "cammarano_infovis_07",
                "Citations": "885086;346302;559210"
            }
        },
        {
            "name": "Stolte, C.",
            "value": 308,
            "numPapers": 18,
            "cluster": "3",
            "index": 171,
            "weight": 9,
            "x": 128.23519018694776,
            "y": 712.4759821713479,
            "px": 181.56743311052233,
            "py": 713.978183846821,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Polaris: a system for query, analysis and visualization of multi-dimensional relational databases",
                "PaperDOI": "10.1109/INFVIS.2000.885086",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885086",
                "firstage": "5",
                "Lastage": "14",
                "IEEEXPLOREArticleNumber": "885086",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations",
                "AuthorNames": "Stolte, C.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37442008700;37349803800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stolte, C.;Hanrahan, P.",
                "filename": "stolte_infovis_00",
                "Citations": "559210"
            }
        },
        {
            "name": "Harrison, L.",
            "value": 1,
            "numPapers": 9,
            "cluster": "5",
            "index": 172,
            "weight": 1,
            "x": 327.3599158712771,
            "y": 499.40301329684866,
            "px": 335.73666143394746,
            "py": 501.1450768012039,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation",
                "PaperDOI": "10.1109/TVCG.2013.187",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.187",
                "firstage": "2326",
                "Lastage": "2335",
                "IEEEXPLOREArticleNumber": "6634178",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.",
                "AuthorNames": "Fink, M.;Haunert, J.-H.;Spoerhase, J.;Wolff, A.",
                "FirstAuthorAffiliation": "Inst. fur Inf., Univ. Wurzburg, Wurzburg, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fink, M.;Haunert, J.-H.;Spoerhase, J.;Wolff, A.",
                "filename": "fink_infovis_13",
                "Citations": "4015420;6327267;6064993"
            }
        },
        {
            "name": "Isenberg, P.",
            "value": 162,
            "numPapers": 81,
            "cluster": "3",
            "index": 173,
            "weight": 12,
            "x": 95.96970669778119,
            "y": 691.3521872214791,
            "px": 173.13822928130548,
            "py": 709.4577268094403,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "firstage": "2818",
                "Lastage": "2827",
                "IEEEXPLOREArticleNumber": "6634108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "filename": "isenberg_vis_13",
                "Citations": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Bezerianos, A.",
            "value": 62,
            "numPapers": 35,
            "cluster": "3",
            "index": 174,
            "weight": 3,
            "x": 429.4327116238689,
            "y": 980.0114126820249,
            "px": 431.5674846885708,
            "py": 913.3626483712065,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty",
                "PaperDOI": "10.1109/TVCG.2012.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.220",
                "firstage": "2769",
                "Lastage": "2778",
                "IEEEXPLOREArticleNumber": "6327283",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.",
                "AuthorNames": "Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA, Sophia Antipolis, France|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.",
                "filename": "boukhelifa_infovis_12",
                "Citations": "1532853;235199;4376197;5290731;5332611;4035764;6327281;4376132;885679"
            }
        },
        {
            "name": "Vuillemot, R.",
            "value": 36,
            "numPapers": 27,
            "cluster": "3",
            "index": 175,
            "weight": 1,
            "x": 252.5515695153455,
            "y": 667.4695520219393,
            "px": 222.89864947761623,
            "py": 577.083337300934,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "SoccerStories: A Kick-off for Visual Soccer Analysis",
                "PaperDOI": "10.1109/TVCG.2013.192",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.192",
                "firstage": "2506",
                "Lastage": "2515",
                "IEEEXPLOREArticleNumber": "6634087",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.",
                "AuthorNames": "Perin, C.;Vuillemot, R.;Fekete, J.-D.",
                "FirstAuthorAffiliation": "INRIA, Univ. Paris-Sud, Paris, France|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Perin, C.;Vuillemot, R.;Fekete, J.",
                "filename": "perin_infovis_13",
                "Citations": "4376154;6064994;6064996;6327288"
            }
        },
        {
            "name": "Gehlenborg, N.",
            "value": 12,
            "numPapers": 28,
            "cluster": "4",
            "index": 176,
            "weight": 3,
            "x": 2106.357949704705,
            "y": -112.05739663126816,
            "px": 1661.9917459380179,
            "py": 295.4518265446363,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Interactive Visual Analysis of Set-Typed Data",
                "PaperDOI": "10.1109/TVCG.2008.144",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.144",
                "firstage": "1340",
                "Lastage": "1347",
                "IEEEXPLOREArticleNumber": "4658148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.",
                "AuthorNames": "Freiler, W.;Matkovic, K.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna|c|;;",
                "AuthorIDs": "38017008700;38220979200;37274158800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Freiler, W.;Matkovic, K.;Hauser, H.",
                "filename": "freiler_infovis_08",
                "Citations": "801860;146402;963288;1249016;4389006;1532139;175815"
            }
        },
        {
            "name": "Bostock, M.",
            "value": 180,
            "numPapers": 31,
            "cluster": "3",
            "index": 177,
            "weight": 6,
            "x": 103.09982818342719,
            "y": 689.9624499182441,
            "px": 124.05949905749019,
            "py": 662.5494752426407,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "firstage": "2301",
                "Lastage": "2309",
                "IEEEXPLOREArticleNumber": "6064996",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "filename": "bostock_infovis_11",
                "Citations": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Gratzl, S.",
            "value": 19,
            "numPapers": 44,
            "cluster": "4",
            "index": 178,
            "weight": 3,
            "x": 881.4250861339178,
            "y": 914.0776071360638,
            "px": 1083.3136448123637,
            "py": 772.3785669472093,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Dis-function: Learning distance functions interactively",
                "PaperDOI": "10.1109/VAST.2012.6400486",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400486",
                "firstage": "83",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "6400486",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.",
                "AuthorNames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "filename": "brown_vast_12",
                "Citations": "146402;6102449;4388999;5332584;6102448;4677352;5652443"
            }
        },
        {
            "name": "Partl, C.",
            "value": 68,
            "numPapers": 29,
            "cluster": "4",
            "index": 179,
            "weight": 3,
            "x": 1081.1988329731478,
            "y": 629.0548375093239,
            "px": 1299.116249928083,
            "py": 664.8181025662914,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Comparative Analysis of Multidimensional; Quantitative Data",
                "PaperDOI": "10.1109/TVCG.2010.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.138",
                "firstage": "1027",
                "Lastage": "1035",
                "IEEEXPLOREArticleNumber": "5613440",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.",
                "AuthorNames": "Lex, A.;Streit, M.;Partl, C.;Kashofer, K.;Schmalstieg, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37395933400;37403918900;37591066400;37591065600;37297103800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lex, A.;Streit, M.;Partl, C.;Kashofer, K.;Schmalstieg, D.",
                "filename": "lex_infovis_10",
                "Citations": "568118;146402;4015425;4376153;4376152;5290692;885086"
            }
        },
        {
            "name": "Turkay, C.",
            "value": 37,
            "numPapers": 35,
            "cluster": "2",
            "index": 180,
            "weight": 2,
            "x": 952.0735257365851,
            "y": 549.8125226207894,
            "px": 857.6583278393041,
            "py": 534.8782555525062,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2011.178",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.178",
                "firstage": "2591",
                "Lastage": "2599",
                "IEEEXPLOREArticleNumber": "6065027",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user's ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis.",
                "AuthorNames": "Turkay, C.;Filzmoser,P.;Hauser H.",
                "FirstAuthorAffiliation": "Dept. of Inf., Univ. of Bergen, Bergen, Norway",
                "AuthorIDs": "37567685600;38017354300;37274158800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Turkay, C.;Filzmoser, P.;Hauser, H.",
                "filename": "turkay_infovis_11",
                "Citations": "885086;346302;4658163;5290745;485139;5332611;1382891;1382892;5333431"
            }
        },
        {
            "name": "Slingsby, A.",
            "value": 167,
            "numPapers": 73,
            "cluster": "3",
            "index": 181,
            "weight": 8,
            "x": 180.73143469527943,
            "y": 800.6963157664999,
            "px": 168.39477742923395,
            "py": 762.3504222447644,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Configuring Hierarchical Layouts to Address Research Questions",
                "PaperDOI": "10.1109/TVCG.2009.128",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.128",
                "firstage": "977",
                "Lastage": "984",
                "IEEEXPLOREArticleNumber": "5290702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.",
                "AuthorNames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., City Univ. London, London, UK|c|;;",
                "AuthorIDs": "37590960700;37605079900;37399045100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "filename": "slingsby_infovis_09",
                "Citations": "4376144;1249006;146386;4658146;4376146;1183791"
            }
        },
        {
            "name": "Wood, J.",
            "value": 240,
            "numPapers": 105,
            "cluster": "3",
            "index": 182,
            "weight": 15,
            "x": 175.8217248320749,
            "y": 744.7768325072587,
            "px": 186.0694551035357,
            "py": 749.1527941130448,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Configuring Hierarchical Layouts to Address Research Questions",
                "PaperDOI": "10.1109/TVCG.2009.128",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.128",
                "firstage": "977",
                "Lastage": "984",
                "IEEEXPLOREArticleNumber": "5290702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.",
                "AuthorNames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., City Univ. London, London, UK|c|;;",
                "AuthorIDs": "37590960700;37605079900;37399045100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "filename": "slingsby_infovis_09",
                "Citations": "4376144;1249006;146386;4658146;4376146;1183791"
            }
        },
        {
            "name": "Weaver, C.",
            "value": 187,
            "numPapers": 67,
            "cluster": "3",
            "index": 183,
            "weight": 20,
            "x": 161.68907265281265,
            "y": 661.7016072105217,
            "px": 195.6054312923938,
            "py": 685.0241831924644,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Visual Analysis of Conflicting Opinions",
                "PaperDOI": "10.1109/VAST.2006.261431",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261431",
                "firstage": "59",
                "Lastage": "66",
                "IEEEXPLOREArticleNumber": "4035748",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time",
                "AuthorNames": "Chen, C.;Ibekwe-SanJuan, F.;SanJuan, E.;Weaver, C.",
                "FirstAuthorAffiliation": "Drexel Univ., Philadelphia, PA|c|;;;",
                "AuthorIDs": "37280749300;;37840812000;37564883300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chen, C.;Ibekwe-SanJuan, F.;SanJuan, E.;Weaver, C.",
                "filename": "chen_vast_06",
                "Citations": "1173155"
            }
        },
        {
            "name": "Dragicevic, P.",
            "value": 141,
            "numPapers": 51,
            "cluster": "3",
            "index": 184,
            "weight": 6,
            "x": 203.90457713756211,
            "y": 763.4687554866075,
            "px": 284.65476061056006,
            "py": 781.3665453444307,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation",
                "PaperDOI": "10.1109/TVCG.2008.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.153",
                "firstage": "1141",
                "Lastage": "1148",
                "IEEEXPLOREArticleNumber": "4658123",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.",
                "AuthorNames": "Elmqvist, N.;Dragicevic, P.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA, Paris|c|;;",
                "AuthorIDs": "37295438200;37590932700;37407972900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Elmqvist, N.;Dragicevic, P.;Fekete, J.",
                "filename": "elmqvist_infovis_08",
                "Citations": "4376144;4389013;4376131;146386;4035743;1532136;346302;729568;485139;1249016;885086;1382892;1382905;4376146;1382895"
            }
        },
        {
            "name": "Henry, N.",
            "value": 147,
            "numPapers": 11,
            "cluster": "3",
            "index": 185,
            "weight": 1,
            "x": -33.15045456857441,
            "y": 560.0669522170169,
            "px": -290.0954898583462,
            "py": 353.2935180282642,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "NodeTrix: a Hybrid Visualization of Social Networks",
                "PaperDOI": "10.1109/TVCG.2007.70582",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70582",
                "firstage": "1302",
                "Lastage": "1309",
                "IEEEXPLOREArticleNumber": "4376154",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.",
                "AuthorNames": "Henry, N.;Fekete, J.;McGuffin, M.J.",
                "FirstAuthorAffiliation": "Univ. of Sydney, Sydney|c|;;",
                "AuthorIDs": "37839948300;37407972900;37403234300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Henry, N.;Fekete, J.;McGuffin, M.J.",
                "filename": "henry_infovis_07",
                "Citations": "4015417;4035752;1532126;1382907;4015433;1532129;4015424;4015425;1382905;1249011"
            }
        },
        {
            "name": "Jansen, Y.",
            "value": 14,
            "numPapers": 25,
            "cluster": "4",
            "index": 186,
            "weight": 2,
            "x": 1424.9348853430618,
            "y": 20.40421862432997,
            "px": 2352.8306092666153,
            "py": -566.8600335526249,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Constructing Visual Representations: Investigating the Use of Tangible Tokens",
                "PaperDOI": "10.1109/TVCG.2014.2346292",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346292",
                "firstage": "2102",
                "Lastage": "2111",
                "IEEEXPLOREArticleNumber": "6875946",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.",
                "AuthorNames": "Huron, S.;Jansen, Y.;Carpendale, S.",
                "FirstAuthorAffiliation": "IRI, Inria, Orsay, France|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Huron, S.;Jansen, Y.;Carpendale, S.",
                "filename": "huron_infovis_14",
                "Citations": "clarkson_infovis_09,bostock_infovis_11,huron_infovis_13,viegas_infovis_07,fekete_infovis_04,walny_infovis_11,wood_vis_97,walny_infovis_12,jansen_infovis_13,grammel_infovis_10,pousman_infovis_07,micallef_infovis_12,"
            }
        },
        {
            "name": "Grammel, Lars",
            "value": 26,
            "numPapers": 17,
            "cluster": "4",
            "index": 187,
            "weight": 2,
            "x": 943.9119753666334,
            "y": -151.55877618416181,
            "px": 1199.6679346966125,
            "py": -941.0195911994574,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "How Information Visualization Novices Construct Visualizations",
                "PaperDOI": "10.1109/TVCG.2010.164",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.164",
                "firstage": "943",
                "Lastage": "952",
                "IEEEXPLOREArticleNumber": "5613431",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.",
                "AuthorNames": "Grammel, Lars;Tory, M.;Storey, M.",
                "FirstAuthorAffiliation": "Univ. of Victoria, Victoria, BC, Canada|c|;;",
                "AuthorIDs": "37322138200;37275861300;37268043300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Grammel, Lars;Tory, M.;Storey, M.",
                "filename": "grammel_infovis_10",
                "Citations": "4376144;4015420;4376134;5333878;4658124;4035745;4376131;4677358;4677365;4376143;1532136;729560;4376133;885086;963289;885092;4658129"
            }
        },
        {
            "name": "Storey, M.",
            "value": 31,
            "numPapers": 18,
            "cluster": "4",
            "index": 188,
            "weight": 2,
            "x": 516.2166656491777,
            "y": 649.9536841432335,
            "px": 263.40631103334727,
            "py": 848.6985032991836,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "How Information Visualization Novices Construct Visualizations",
                "PaperDOI": "10.1109/TVCG.2010.164",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.164",
                "firstage": "943",
                "Lastage": "952",
                "IEEEXPLOREArticleNumber": "5613431",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.",
                "AuthorNames": "Grammel, Lars;Tory, M.;Storey, M.",
                "FirstAuthorAffiliation": "Univ. of Victoria, Victoria, BC, Canada|c|;;",
                "AuthorIDs": "37322138200;37275861300;37268043300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Grammel, Lars;Tory, M.;Storey, M.",
                "filename": "grammel_infovis_10",
                "Citations": "4376144;4015420;4376134;5333878;4658124;4035745;4376131;4677358;4677365;4376143;1532136;729560;4376133;885086;963289;885092;4658129"
            }
        },
        {
            "name": "Drucker, S.",
            "value": 2,
            "numPapers": 29,
            "cluster": "3",
            "index": 189,
            "weight": 5,
            "x": 287.1868544408512,
            "y": 778.0265583801602,
            "px": 403.8348140362486,
            "py": 831.7532449070286,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Polaris: a system for query, analysis and visualization of multi-dimensional relational databases",
                "PaperDOI": "10.1109/INFVIS.2000.885086",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885086",
                "firstage": "5",
                "Lastage": "14",
                "IEEEXPLOREArticleNumber": "885086",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations",
                "AuthorNames": "Stolte, C.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37442008700;37349803800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stolte, C.;Hanrahan, P.",
                "filename": "stolte_infovis_00",
                "Citations": "559210"
            }
        },
        {
            "name": "Zgraggen, E.",
            "value": 0,
            "numPapers": 14,
            "cluster": "4",
            "index": 190,
            "weight": 1,
            "x": 2459.7563284490325,
            "y": -568.699763433986,
            "px": 3960.9921096706394,
            "py": -1483.6937512024074,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Polaris: a system for query, analysis and visualization of multi-dimensional relational databases",
                "PaperDOI": "10.1109/INFVIS.2000.885086",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885086",
                "firstage": "5",
                "Lastage": "14",
                "IEEEXPLOREArticleNumber": "885086",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations",
                "AuthorNames": "Stolte, C.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37442008700;37349803800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stolte, C.;Hanrahan, P.",
                "filename": "stolte_infovis_00",
                "Citations": "559210"
            }
        },
        {
            "name": "Zeleznik, R.",
            "value": 0,
            "numPapers": 14,
            "cluster": "4",
            "index": 191,
            "weight": 1,
            "x": 469.4963477341795,
            "y": 395.88267532549816,
            "px": 234.9487494196651,
            "py": 367.60934540482293,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Polaris: a system for query, analysis and visualization of multi-dimensional relational databases",
                "PaperDOI": "10.1109/INFVIS.2000.885086",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885086",
                "firstage": "5",
                "Lastage": "14",
                "IEEEXPLOREArticleNumber": "885086",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations",
                "AuthorNames": "Stolte, C.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37442008700;37349803800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stolte, C.;Hanrahan, P.",
                "filename": "stolte_infovis_00",
                "Citations": "559210"
            }
        },
        {
            "name": "van Ham, F.",
            "value": 401,
            "numPapers": 33,
            "cluster": "3",
            "index": 192,
            "weight": 13,
            "x": -13.034872866195752,
            "y": 615.0374773897679,
            "px": -15.499248621671425,
            "py": 567.9146315958907,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "ManyEyes: a Site for Visualization at Internet Scale",
                "PaperDOI": "10.1109/TVCG.2007.70577",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70577",
                "firstage": "1121",
                "Lastage": "1128",
                "IEEEXPLOREArticleNumber": "4376131",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "FirstAuthorAffiliation": "IBM Res., Yorktown Heights|c|;;;;",
                "AuthorIDs": "37681355300;37550759700;37326291000;37830149600;37542455400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "filename": "viegas_infovis_07",
                "Citations": "1532122;175820;1249007"
            }
        },
        {
            "name": "Kriss, J.",
            "value": 162,
            "numPapers": 3,
            "cluster": "4",
            "index": 193,
            "weight": 1,
            "x": -276.15738531665016,
            "y": 784.716198362491,
            "px": -1061.1645837510641,
            "py": 1021.8767501165689,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "ManyEyes: a Site for Visualization at Internet Scale",
                "PaperDOI": "10.1109/TVCG.2007.70577",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70577",
                "firstage": "1121",
                "Lastage": "1128",
                "IEEEXPLOREArticleNumber": "4376131",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "FirstAuthorAffiliation": "IBM Res., Yorktown Heights|c|;;;;",
                "AuthorIDs": "37681355300;37550759700;37326291000;37830149600;37542455400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "filename": "viegas_infovis_07",
                "Citations": "1532122;175820;1249007"
            }
        },
        {
            "name": "McKeon, M.",
            "value": 176,
            "numPapers": 11,
            "cluster": "4",
            "index": 194,
            "weight": 2,
            "x": 985.0821220897612,
            "y": 1232.8583747108723,
            "px": 1450.859953478089,
            "py": 2117.508971600561,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "ManyEyes: a Site for Visualization at Internet Scale",
                "PaperDOI": "10.1109/TVCG.2007.70577",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70577",
                "firstage": "1121",
                "Lastage": "1128",
                "IEEEXPLOREArticleNumber": "4376131",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "FirstAuthorAffiliation": "IBM Res., Yorktown Heights|c|;;;;",
                "AuthorIDs": "37681355300;37550759700;37326291000;37830149600;37542455400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "filename": "viegas_infovis_07",
                "Citations": "1532122;175820;1249007"
            }
        },
        {
            "name": "Heinzl, C.",
            "value": 28,
            "numPapers": 51,
            "cluster": "5",
            "index": 195,
            "weight": 4,
            "x": 237.0690154644244,
            "y": 386.6625420474942,
            "px": 284.162483671407,
            "py": 425.3110043094215,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Visual Parameter Space Analysis: A Conceptual Framework",
                "PaperDOI": "10.1109/TVCG.2014.2346321",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346321",
                "firstage": "2161",
                "Lastage": "2170",
                "IEEEXPLOREArticleNumber": "6876043",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.",
                "AuthorNames": "Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.",
                "FirstAuthorAffiliation": "Univ. of Vienna, Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.",
                "filename": "sedlmair_infovis_14",
                "Citations": "spence_infovis_95,liu_infovis_10,matkovic_vis_08,kandel_vast_12,matkovic_vis_09,waser_vis_10,kang_vast_12,sedlmair_infovis_12,bruckner_vis_10,amar_infovis_05,vanwijk1_vis_93,guo_vast_09,smith_vis_07,beyer_vis_13,ingram_vast_10,wilkinso_infovis_05,roth_infovis_13,coffey_vis_13,brehmer_infovis_13,unger_vis_12,munzner_infovis_09,bertini_infovis_11,gleicher_vast_13,muehlbacher_vast_13,guo_vast_11,bavoil_vis_05,isenberg_vis_13,torsneyweir_vis_11,amirkhan_vis_10,brecheis_vis_09,afzal_vast_11,schulz_infovis_13,pretorius_infovis_11,"
            }
        },
        {
            "name": "Zhenyu Guo",
            "value": 21,
            "numPapers": 13,
            "cluster": "3",
            "index": 196,
            "weight": 1,
            "x": -82.24988998922808,
            "y": 716.827316743279,
            "px": -188.08882700027453,
            "py": 934.375721353614,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Model space visualization for multivariate linear trend discovery",
                "PaperDOI": "10.1109/VAST.2009.5333431",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5333431",
                "firstage": "75",
                "Lastage": "82",
                "IEEEXPLOREArticleNumber": "5333431",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations.",
                "AuthorNames": "Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Worcester Polytech. Inst., Worcester, MA, USA|c|;;",
                "AuthorIDs": "37668783300;37268441700;37279217900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.",
                "filename": "guo_vast_09",
                "Citations": "4677350;4389000;4677363;4388999;146402;4677352;4677368"
            }
        },
        {
            "name": "MÃ¶ller, T.",
            "value": 84,
            "numPapers": 16,
            "cluster": "5",
            "index": 197,
            "weight": 3,
            "x": -943.1435474255163,
            "y": -430.55506174483304,
            "px": -500.10601222249414,
            "py": -253.50929640181843,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "DimStiller: Workflows for dimensional analysis and reduction",
                "PaperDOI": "10.1109/VAST.2010.5652392",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652392",
                "firstage": "3",
                "Lastage": "10",
                "IEEEXPLOREArticleNumber": "5652392",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.",
                "AuthorNames": "Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;Möller, T.",
                "FirstAuthorAffiliation": "Univ. of British Columbia, Vancouver, BC, Canada|c|;;;;;",
                "AuthorIDs": "37587716200;37349490300;37589529600;37275861300;37418878100;37275858700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;MÃ¶ller, T.",
                "filename": "ingram_vast_10",
                "Citations": "1249013;346302;4015439;1249015;5290704;1382893"
            }
        },
        {
            "name": "Scheidegger, C.E.",
            "value": 190,
            "numPapers": 62,
            "cluster": "5",
            "index": 198,
            "weight": 6,
            "x": 308.87654462892453,
            "y": 449.56169900486753,
            "px": 365.2153045895836,
            "py": 474.45153613941125,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Nanocubes for Real-Time Exploration of Spatiotemporal Datasets",
                "PaperDOI": "10.1109/TVCG.2013.179",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.179",
                "firstage": "2456",
                "Lastage": "2465",
                "IEEEXPLOREArticleNumber": "6634137",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.",
                "AuthorNames": "Lins, L.;Klosowski, J.T.;Scheidegger, C.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lins, L.;Klosowski, J.T.;Scheidegger, C.E.",
                "filename": "lins_infovis_13",
                "Citations": "4015421;1173141;5290718;4677357;4376133;1173156;146386;6064996"
            }
        },
        {
            "name": "Beecham, R.",
            "value": 0,
            "numPapers": 13,
            "cluster": "3",
            "index": 199,
            "weight": 1,
            "x": 379.4139277954009,
            "y": 508.8068013190506,
            "px": 563.6971600117088,
            "py": 476.0074591613033,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning",
                "PaperDOI": "10.1109/TVCG.2012.272",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.272",
                "firstage": "2789",
                "Lastage": "2798",
                "IEEEXPLOREArticleNumber": "6327285",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.",
                "AuthorNames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37884160900;38490270400;38490599200;38489620500;38490437100;38490180100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "filename": "block_infovis_12",
                "Citations": "963285;636718;5290695;4376146;1173153;4658128;1173148;4376134"
            }
        },
        {
            "name": "Lloyd, D.",
            "value": 46,
            "numPapers": 2,
            "cluster": "3",
            "index": 200,
            "weight": 2,
            "x": -287.7265544052364,
            "y": -201.05748296847517,
            "px": 142.40544460748455,
            "py": 763.1237995171211,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study",
                "PaperDOI": "10.1109/TVCG.2011.209",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.209",
                "firstage": "2498",
                "Lastage": "2507",
                "IEEEXPLOREArticleNumber": "6065017",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.",
                "AuthorNames": "Lloyd, D.;Dykes, J.",
                "FirstAuthorAffiliation": "giCentre, City Univ. London, London, UK|c|;",
                "AuthorIDs": "38030446400;37605079900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lloyd, D.;Dykes, J.",
                "filename": "lloyd_infovis_11",
                "Citations": "5613425;5290720"
            }
        },
        {
            "name": "Kindlmann, G.",
            "value": 519,
            "numPapers": 105,
            "cluster": "6",
            "index": 201,
            "weight": 36,
            "x": 454.4196201346945,
            "y": 436.410646606297,
            "px": 473.8887408374646,
            "py": 480.87241746602524,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "LineUp: Visual Analysis of Multi-Attribute Rankings",
                "PaperDOI": "10.1109/TVCG.2013.173",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.173",
                "firstage": "2277",
                "Lastage": "2286",
                "IEEEXPLOREArticleNumber": "6634146",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.",
                "AuthorNames": "Gratzl, S.;Lex, A.;Gehlenborg, N.;Pfister, H.;Streit, M.",
                "FirstAuthorAffiliation": "Johannes Kepler Univ. Linz, Linz, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gratzl, S.;Lex, A.;Gehlenborg, N.;Pfister, H.;Streit, M.",
                "filename": "gratzl_infovis_13",
                "Citations": "6327273;4658136;568118;4658150;4376146"
            }
        },
        {
            "name": "Burch, M.",
            "value": 55,
            "numPapers": 23,
            "cluster": "5",
            "index": 202,
            "weight": 2,
            "x": 361.7654895250857,
            "y": 389.5314155954504,
            "px": -139.9579215054913,
            "py": 71.92866900142694,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Analytics Methodology for Eye Movement Studies",
                "PaperDOI": "10.1109/TVCG.2012.276",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.276",
                "firstage": "2889",
                "Lastage": "2898",
                "IEEEXPLOREArticleNumber": "6327295",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37283047100;37283047700;37586953400;37268045000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.",
                "filename": "andrienko_vast_12",
                "Citations": "5332593;6065011;1532150"
            }
        },
        {
            "name": "Heinrich, J.",
            "value": 44,
            "numPapers": 22,
            "cluster": "2",
            "index": 203,
            "weight": 2,
            "x": 629.1881448956069,
            "y": 133.394925526447,
            "px": 606.3742786275271,
            "py": 115.82503945618824,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study",
                "PaperDOI": "10.1109/TVCG.2011.193",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.193",
                "firstage": "2440",
                "Lastage": "2448",
                "IEEEXPLOREArticleNumber": "6065011",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.",
                "AuthorNames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": "VISUS, Univ. of Stuttgart, Germany|c|;;;;",
                "AuthorIDs": "37586953400;38017426500;37665271000;;38470313100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "filename": "burch2_infovis_11",
                "Citations": "5613430;1382885"
            }
        },
        {
            "name": "Brehmer, M.",
            "value": 25,
            "numPapers": 37,
            "cluster": "3",
            "index": 204,
            "weight": 2,
            "x": 87.90357961731155,
            "y": 343.30850821046704,
            "px": 53.91853685654911,
            "py": 550.0643177842537,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Multi-Level Typology of Abstract Visualization Tasks",
                "PaperDOI": "10.1109/TVCG.2013.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.124",
                "firstage": "2376",
                "Lastage": "2385",
                "IEEEXPLOREArticleNumber": "6634168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.",
                "AuthorNames": "Brehmer, M.;Munzner, T.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brehmer, M.;Munzner, T.",
                "filename": "brehmer_infovis_13",
                "Citations": "4376134;6327298;559213;6327248;6327297;1532136;5613437;4376146;1173148;4376144;6327275;5290695;4658124;235203;1382903;4677365;6102438;4658127;4658129;729560;1382902;6327277;146375"
            }
        },
        {
            "name": "Zhuofeng Wu",
            "value": 10,
            "numPapers": 12,
            "cluster": "4",
            "index": 205,
            "weight": 1,
            "x": 2160.441202050845,
            "y": 609.8729691745913,
            "px": 3702.95211016373,
            "py": 659.5893915805239,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "How Hierarchical Topics Evolve in Large Text Corpora",
                "PaperDOI": "10.1109/TVCG.2014.2346433",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346433",
                "firstage": "2281",
                "Lastage": "2290",
                "IEEEXPLOREArticleNumber": "6875938",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "filename": "cui_infovis_14",
                "Citations": "liu_infovis_13,vanham1_infovis_09,liu_vast_14,munzner_infovis_09,cui_infovis_11,wu2_vast_14,tanahashi_infovis_12,xu_vast_13,wongsuphasawat_infovis_12,duo_vast_13,monroe_vast_13,"
            }
        },
        {
            "name": "Hao Wei",
            "value": 10,
            "numPapers": 12,
            "cluster": "4",
            "index": 206,
            "weight": 1,
            "x": -378.51459855494124,
            "y": 905.3105204684721,
            "px": -1191.7830634910224,
            "py": 1218.3241577615624,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "How Hierarchical Topics Evolve in Large Text Corpora",
                "PaperDOI": "10.1109/TVCG.2014.2346433",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346433",
                "firstage": "2281",
                "Lastage": "2290",
                "IEEEXPLOREArticleNumber": "6875938",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "filename": "cui_infovis_14",
                "Citations": "liu_infovis_13,vanham1_infovis_09,liu_vast_14,munzner_infovis_09,cui_infovis_11,wu2_vast_14,tanahashi_infovis_12,xu_vast_13,wongsuphasawat_infovis_12,duo_vast_13,monroe_vast_13,"
            }
        },
        {
            "name": "Kahng, M.",
            "value": 0,
            "numPapers": 16,
            "cluster": "3",
            "index": 207,
            "weight": 1,
            "x": 178.39400738922043,
            "y": 1048.2319564868062,
            "px": 65.39035588900434,
            "py": 1197.9265456536507,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "firstage": "1189",
                "Lastage": "1196",
                "IEEEXPLOREArticleNumber": "4658129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "filename": "heer_infovis_08",
                "Citations": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Zhiyuan Lin",
            "value": 0,
            "numPapers": 16,
            "cluster": "3",
            "index": 208,
            "weight": 1,
            "x": 409.3112189536957,
            "y": 1190.5069476235321,
            "px": 466.3054224056828,
            "py": 1468.5841547048703,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "firstage": "1189",
                "Lastage": "1196",
                "IEEEXPLOREArticleNumber": "4658129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "filename": "heer_infovis_08",
                "Citations": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Foerster, F.",
            "value": 0,
            "numPapers": 16,
            "cluster": "3",
            "index": 209,
            "weight": 1,
            "x": 671.3073601998351,
            "y": 463.03571991992743,
            "px": 925.6951199480152,
            "py": 182.27671574566136,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "firstage": "1189",
                "Lastage": "1196",
                "IEEEXPLOREArticleNumber": "4658129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "filename": "heer_infovis_08",
                "Citations": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Goel, A.",
            "value": 6,
            "numPapers": 21,
            "cluster": "3",
            "index": 210,
            "weight": 1,
            "x": 515.8395176397349,
            "y": 392.98002251917,
            "px": 644.6074200751849,
            "py": 63.41623911443394,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "firstage": "1189",
                "Lastage": "1196",
                "IEEEXPLOREArticleNumber": "4658129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "filename": "heer_infovis_08",
                "Citations": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Duen Horng Chau",
            "value": 0,
            "numPapers": 16,
            "cluster": "3",
            "index": 211,
            "weight": 1,
            "x": 604.5103775559215,
            "y": 404.08215196297954,
            "px": 805.781523258743,
            "py": 77.85415687606621,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "firstage": "1189",
                "Lastage": "1196",
                "IEEEXPLOREArticleNumber": "4658129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "filename": "heer_infovis_08",
                "Citations": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Inselberg, A.",
            "value": 299,
            "numPapers": 6,
            "cluster": "2",
            "index": 212,
            "weight": 8,
            "x": 531.9978754486104,
            "y": 467.597137156778,
            "px": 483.10407985251345,
            "py": 406.1336470099574,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Parallel coordinates: a tool for visualizing multi-dimensional geometry",
                "PaperDOI": "10.1109/VISUAL.1990.146402",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146402",
                "firstage": "361",
                "Lastage": "378",
                "IEEEXPLOREArticleNumber": "146402",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A methodology for visualizing analytic and synthetic geometry in RN is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point - line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R N. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications to Air Traffic Control, Robotics, Computer Vision, Computational Geometry, Statistics, Instrumentation and other areas are discussed.",
                "AuthorNames": "Inselberg, A.;Dimsdale, Bernard",
                "FirstAuthorAffiliation": "IBM Sci. Center, Los Angeles, CA, USA|c|;",
                "AuthorIDs": "37294162600;37426169800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Inselberg, A.;Dimsdale, Bernard",
                "filename": "inselberg_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Bremer, P.-T.",
            "value": 178,
            "numPapers": 68,
            "cluster": "7",
            "index": 213,
            "weight": 27,
            "x": 721.3013873217386,
            "y": -459.8001205348453,
            "px": 734.1986224074254,
            "py": -524.3711769432126,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "firstage": "2467",
                "Lastage": "2476",
                "IEEEXPLOREArticleNumber": "6327252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "filename": "landge_infovis_12",
                "Citations": "5290721;1382906"
            }
        },
        {
            "name": "Pascucci, V.",
            "value": 471,
            "numPapers": 135,
            "cluster": "7",
            "index": 214,
            "weight": 46,
            "x": 544.9328883293123,
            "y": 466.93645987665934,
            "px": 545.4646859991603,
            "py": 497.35073424381306,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "firstage": "2467",
                "Lastage": "2476",
                "IEEEXPLOREArticleNumber": "6327252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "filename": "landge_infovis_12",
                "Citations": "5290721;1382906"
            }
        },
        {
            "name": "Hamann, B.",
            "value": 404,
            "numPapers": 107,
            "cluster": "7",
            "index": 215,
            "weight": 24,
            "x": 406.4347411052517,
            "y": 463.37120130760064,
            "px": 402.57424698842266,
            "py": 579.358618160413,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "Visualization of water quality data for the Chesapeake Bay",
                "PaperDOI": "10.1109/VISUAL.1996.568146",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568146",
                "firstage": "417",
                "Lastage": "420",
                "IEEEXPLOREArticleNumber": "568146",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We discuss a visualization system for the comparison of simulated and measured water quality. The system extends SCIRT (Site Characterization Interactive Research Toolkit), an interactive system originally developed at the NSF Engineering Research Center for Computational Field Simulation at Mississippi State University. The ongoing study of the Chesapeake Bay presents research in 3D visualization of model-data comparisons.",
                "AuthorNames": "Forgang, A.B.;Hamann, B.;Cerco, C.F.",
                "FirstAuthorAffiliation": "Dept. of Comput. Eng., California Univ., Davis, CA, USA|c|;;",
                "AuthorIDs": "37860455000;37282068700;37860461300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Forgang, A.B.;Hamann, B.;Cerco, C.F.",
                "filename": "forgang_vis_96",
                "Citations": "485141"
            }
        },
        {
            "name": "Al-Awami, A.",
            "value": 21,
            "numPapers": 19,
            "cluster": "5",
            "index": 216,
            "weight": 3,
            "x": -272.3602735835913,
            "y": -560.9395692255509,
            "px": 57.45584485355875,
            "py": -189.50194210800768,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Beyer, J.",
            "value": 73,
            "numPapers": 34,
            "cluster": "5",
            "index": 217,
            "weight": 8,
            "x": -62.34150695392076,
            "y": -245.21299378180333,
            "px": 75.74374859158459,
            "py": -254.04392230496296,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Hadwiger, M.",
            "value": 154,
            "numPapers": 83,
            "cluster": "5",
            "index": 218,
            "weight": 24,
            "x": 205.49369779861422,
            "y": 296.80148014804655,
            "px": 250.87680031233015,
            "py": 304.02534340106956,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Kasthuri, N.",
            "value": 28,
            "numPapers": 22,
            "cluster": "5",
            "index": 219,
            "weight": 3,
            "x": -769.3402377688634,
            "y": 1112.9710207191358,
            "px": -225.44581824414547,
            "py": 733.8073322084184,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Lichtman, J.",
            "value": 28,
            "numPapers": 30,
            "cluster": "5",
            "index": 220,
            "weight": 3,
            "x": 561.595854397709,
            "y": 186.06002558606383,
            "px": 489.01487254387047,
            "py": 217.86953818875517,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Won-Ki Jeong",
            "value": 29,
            "numPapers": 13,
            "cluster": "5",
            "index": 221,
            "weight": 1,
            "x": 721.8340789947913,
            "y": 2321.9541295704053,
            "px": 1215.8120146719752,
            "py": 4221.034684503794,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach",
                "PaperDOI": "10.1109/TVCG.2012.240",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.240",
                "firstage": "2285",
                "Lastage": "2294",
                "IEEEXPLOREArticleNumber": "6327233",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.",
                "AuthorNames": "Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37394809600;37409575800;38490133400;37275698100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.",
                "filename": "hadwiger_vis_12",
                "Citations": "809908;1250384;5290773"
            }
        },
        {
            "name": "Buhler, K.",
            "value": 54,
            "numPapers": 15,
            "cluster": "5",
            "index": 222,
            "weight": 2,
            "x": 541.1874317647166,
            "y": 674.5012921079733,
            "px": 342.9971714137553,
            "py": 4.482791813632063,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "BrainGazer - Visual Queries for Neurobiology Research",
                "PaperDOI": "10.1109/TVCG.2009.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.121",
                "firstage": "1497",
                "Lastage": "1504",
                "IEEEXPLOREArticleNumber": "5290766",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.",
                "AuthorNames": "Bruckner, S.;Solteszova, V.;Groller, E.;Hladuvka, J.;Buhler, K.;Yu, J.Y.;Dickson, B.J.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;",
                "AuthorIDs": "37265895700;;37284271200;38108878100;37267821300;38105995800;38100422000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bruckner, S.;Solteszova, V.;Groller, E.;Hladuvka, J.;Buhler, K.;Yu, J.Y.;Dickson, B.J.",
                "filename": "bruckner_vis_09",
                "Citations": "1372221;146378;1250412;4015478;485139;568136;4015489;4677354"
            }
        },
        {
            "name": "Hansen, C.",
            "value": 733,
            "numPapers": 117,
            "cluster": "5",
            "index": 223,
            "weight": 48,
            "x": 136.5169324989475,
            "y": 317.00086779478664,
            "px": 159.9358065162865,
            "py": 326.40127052968194,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Scout: a hardware-accelerated system for quantitatively driven visualization and analysis",
                "PaperDOI": "10.1109/VISUAL.2004.95",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.95",
                "firstage": "171",
                "Lastage": "178",
                "IEEEXPLOREArticleNumber": "1372194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Quantitative techniques for visualization are critical to the successful analysis of both acquired and simulated scientific data. Many visualization techniques rely on indirect mappings, such as transfer functions, to produce the final imagery. In many situations, it is preferable and more powerful to express these mappings as mathematical expressions, or queries, that can then be directly applied to the data. We present a hardware-accelerated system that provides such capabilities and exploits current graphics hardware for portions of the computational tasks that would otherwise be executed on the CPU. In our approach, the direct programming of the graphics processor using a concise data parallel language, gives scientists the capability to efficiently explore and visualize data sets.",
                "AuthorNames": "McCormick, P.S.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.",
                "FirstAuthorAffiliation": "Advanced Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;",
                "AuthorIDs": "37282708700;37282707800;37282713700;37266777200;37269487100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "McCormick, P.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.",
                "filename": "mccormic_vis_04",
                "Citations": "480821;809864;964519;1250357"
            }
        },
        {
            "name": "Callahan, S.P.",
            "value": 116,
            "numPapers": 27,
            "cluster": "5",
            "index": 224,
            "weight": 6,
            "x": 144.7764193629349,
            "y": 224.1966827204095,
            "px": 167.17089831805785,
            "py": 208.4101221686165,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Progressive Volume Rendering of Large Unstructured Grids",
                "PaperDOI": "10.1109/TVCG.2006.171",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.171",
                "firstage": "1307",
                "Lastage": "1314",
                "IEEEXPLOREArticleNumber": "4015496",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations",
                "AuthorNames": "Callahan, S.P.;Bavoil, L.;Pascucci, V.;Silva, C.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT|c|;;;",
                "AuthorIDs": "37426872800;37565304300;38262213600;37275249200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Callahan, S.P.;Bavoil, L.;Pascucci, V.;Silva, C.T.",
                "filename": "bavoil_vis_06",
                "Citations": "1532796;745713;1250390;1372227;1532793"
            }
        },
        {
            "name": "Johnson, C.R.",
            "value": 156,
            "numPapers": 49,
            "cluster": "5",
            "index": 225,
            "weight": 10,
            "x": 225.6846067534048,
            "y": 397.2427869239229,
            "px": 230.34404751742377,
            "py": 384.09773522224936,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Differential volume rendering: a fast volume visualization technique for flow animation",
                "PaperDOI": "10.1109/VISUAL.1994.346321",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346321",
                "firstage": "180",
                "Lastage": "187, C20",
                "IEEEXPLOREArticleNumber": "346321",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a direct volume rendering algorithm to speed up volume animation for flow visualizations. Data coherency between consecutive simulation time steps is used to avoid casting rays from those pixels retaining color values assigned to the previous image. The algorithm calculates the differential information among a sequence of 3D volumetric simulation data. At each time step the differential information is used to compute the locations of pixels that need updating and a ray-casting method as utilized to produce the updated image. We illustrate the utility and speed of the differential volume rendering algorithm with simulation data from computational bioelectric and fluid dynamics applications. We can achieve considerable disk-space savings and nearly real-time rendering of 3D flows using low-cost, single processor workstations for models which contain hundreds of thousands of data points",
                "AuthorNames": "Han-Wei Shen;Johnson, C.R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;",
                "AuthorIDs": "37350367200;37276931400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Han-Wei Shen;Johnson, C.R.",
                "filename": "shen_vis_94",
                "Citations": "398877;235227;235210;175772;398852;175773;398846"
            }
        },
        {
            "name": " Kaufman, A.",
            "value": 75,
            "numPapers": 4,
            "cluster": "5",
            "index": 226,
            "weight": 1,
            "x": 406.36697152484953,
            "y": -433.79852774772104,
            "px": 723.7707101409989,
            "py": -928.5262881442492,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Image based rendering with stable frame rates",
                "PaperDOI": "10.1109/VISUAL.2000.885702",
                "Link": "http://dl.acm.org/citation.cfm?id=375249",
                "firstage": "251",
                "Lastage": "258",
                "IEEEXPLOREArticleNumber": "885702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents an efficient keyframeless image-based rendering technique. An intermediate image is used to exploit the coherences among neighboring frames. The pixels in the intermediate image are first rendered by a ray-casting method and then warped to the intermediate image at the current viewpoint and view direction. We use an offset buffer to record the precise positions of these pixels in the intermediate image. Every frame is generated in three steps: warping the intermediate image onto the frame, filling in holes, and selectively rendering a group of ”old” pixels. By dynamically adjusting the number of those ”old” pixels in the last step, the workload at every frame can be balanced. The pixels generated by the last two steps make contributions to the new intermediate image. Unlike occasional keyframes in conventional image-based rendering which need to be totally rerendered, intermediate images only need to be partially updated at every frame. In this way, we guarantee more stable frame rates and more uniform image qualities. The intermediate image can be warped efficiently by a modified incremental 3D warp algorithm. As a specific application, we demonstrate our technique with a voxel-based terrain rendering system.\"",
                "AuthorNames": "Qu, H.; Wan, M; Qin, J.; Kaufman, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "x",
                "Dedupedauthornames": "Qu, H.; Wan, M.; Qin, J.; Kaufman, A.",
                "filename": "qu_vis_00",
                "Citations": "235190;745305;809900"
            }
        },
        {
            "name": "Moorhead, R.J.",
            "value": 141,
            "numPapers": 29,
            "cluster": "5",
            "index": 227,
            "weight": 3,
            "x": 177.5207539958194,
            "y": 377.18218705932145,
            "px": 172.96981031064016,
            "py": 301.75295587958425,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets",
                "PaperDOI": "10.1109/TVCG.2009.114",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.114",
                "firstage": "1209",
                "Lastage": "1218",
                "IEEEXPLOREArticleNumber": "5290731",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig- - n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.",
                "AuthorNames": "Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.",
                "FirstAuthorAffiliation": "Geosystems Res. Inst., Mississippi State Univ., Starkville, MS, USA|c|;;;;",
                "AuthorIDs": "37567906800;37277708500;38100000900;37411386700;37282559500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.",
                "filename": "sanyal_vis_09",
                "Citations": "4376198;568105;885679;1173145;1382903;4376197"
            }
        },
        {
            "name": "La Mar, E.C.",
            "value": 62,
            "numPapers": 1,
            "cluster": "5",
            "index": 228,
            "weight": 1,
            "x": -29.83104851226534,
            "y": -743.4970905157212,
            "px": -186.0766171230959,
            "py": -1503.6158969986668,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Multiresolution Techniques for Interactive Texture-based Volume Visualization",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=834140",
                "firstage": "355",
                "Lastage": "",
                "IEEEXPLOREArticleNumber": "809908",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a multiresolution technique for interactive texture-basedvolume visualization of very large data sets. This method uses anadaptive scheme that renders the volume in a region-of-interest ata high resolution and the volume away from this region at progressivelylower resolutions. The algorithm is based on the segmentationof texture space into an octree, where the leaves of the tree definethe original data and the internal nodes define lower-resolutionversions. Rendering is done adaptively by selecting high-resolutioncells close to a center of attention and low-resolution cells awayfrom this area. We limit the artifacts introduced by this method bymodifying the transfer functions in the lower-resolution data setsand utilizing spherical shells as a proxy geometry. It is possibleto use this technique to produce viewpoint-dependent renderings ofvery large data sets.",
                "AuthorNames": "La Mar, E. C.;Hamann, B.;Joy K. I.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "x",
                "Dedupedauthornames": "La Mar, E.C.;Hamann, B.;Joy, K.I.",
                "filename": "lamar_vis_99",
                "Citations": ""
            }
        },
        {
            "name": "Joy, K.I.",
            "value": 331,
            "numPapers": 121,
            "cluster": "6",
            "index": 229,
            "weight": 29,
            "x": 545.3418559923748,
            "y": 409.6554844197142,
            "px": 563.8549345338956,
            "py": 417.2060173409944,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Multiresolution Techniques for Interactive Texture-based Volume Visualization",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=834140",
                "firstage": "355",
                "Lastage": "",
                "IEEEXPLOREArticleNumber": "809908",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a multiresolution technique for interactive texture-basedvolume visualization of very large data sets. This method uses anadaptive scheme that renders the volume in a region-of-interest ata high resolution and the volume away from this region at progressivelylower resolutions. The algorithm is based on the segmentationof texture space into an octree, where the leaves of the tree definethe original data and the internal nodes define lower-resolutionversions. Rendering is done adaptively by selecting high-resolutioncells close to a center of attention and low-resolution cells awayfrom this area. We limit the artifacts introduced by this method bymodifying the transfer functions in the lower-resolution data setsand utilizing spherical shells as a proxy geometry. It is possibleto use this technique to produce viewpoint-dependent renderings ofvery large data sets.",
                "AuthorNames": "La Mar, E. C.;Hamann, B.;Joy K. I.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "x",
                "Dedupedauthornames": "La Mar, E.C.;Hamann, B.;Joy, K.I.",
                "filename": "lamar_vis_99",
                "Citations": ""
            }
        },
        {
            "name": "Thomas, D.M.",
            "value": 6,
            "numPapers": 19,
            "cluster": "7",
            "index": 230,
            "weight": 2,
            "x": 73.24888551815444,
            "y": 932.8955864936705,
            "px": 519.2947185484757,
            "py": -30.777710758072605,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Natarajan, V.",
            "value": 45,
            "numPapers": 29,
            "cluster": "7",
            "index": 231,
            "weight": 5,
            "x": 494.07563228989096,
            "y": 571.4741290257293,
            "px": 420.64346989335405,
            "py": 595.1189702642507,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
                "PaperDOI": "10.1109/TVCG.2013.142",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.142",
                "firstage": "2868",
                "Lastage": "2877",
                "IEEEXPLOREArticleNumber": "6634132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
                "AuthorNames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beyer, J.;Al-Awami, A.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "filename": "beyer_vis_13",
                "Citations": "885086;1532792;5290767;6327233;4015489;485139;4376204;5290765;5290766"
            }
        },
        {
            "name": "Carr, H.",
            "value": 156,
            "numPapers": 48,
            "cluster": "7",
            "index": 232,
            "weight": 10,
            "x": 467.21288072262246,
            "y": 911.2785783248027,
            "px": 403.51240289777945,
            "py": 957.3306686818723,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2008.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.143",
                "firstage": "1475",
                "Lastage": "1482",
                "IEEEXPLOREArticleNumber": "4658165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.",
                "AuthorNames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Leipzig Univ., Leipzig|c|;;;;",
                "AuthorIDs": "37869538100;37565763400;37282624500;37403333700;37282574800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "filename": "schneide_vis_08",
                "Citations": "4015446;964519;1372214;4376165;1532830;4015447;1372235;1250374;4376167;1532848;663875;1532835"
            }
        },
        {
            "name": "Sadlo, F.",
            "value": 72,
            "numPapers": 65,
            "cluster": "5",
            "index": 233,
            "weight": 5,
            "x": 76.54996280634982,
            "y": 289.80632017555297,
            "px": 77.08297943679644,
            "py": 242.28177853888738,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Visualization of Temporal Similarity in field Data",
                "PaperDOI": "10.1109/TVCG.2012.284",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.284",
                "firstage": "2023",
                "Lastage": "2032",
                "IEEEXPLOREArticleNumber": "6327206",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.",
                "AuthorNames": "Frey, S.;Sadlo, F.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;;",
                "AuthorIDs": "37553894500;37282541900;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Frey, S.;Sadlo, F.;Ertl, T.",
                "filename": "frey_vis_12",
                "Citations": "4658178;4015451;4015447;5613467;5613484;5613487;5290745;4658174;5613443;5290749;6064968;5290751"
            }
        },
        {
            "name": "Ament, M.",
            "value": 10,
            "numPapers": 40,
            "cluster": "5",
            "index": 234,
            "weight": 5,
            "x": -3.840737693678763,
            "y": 164.59481607599352,
            "px": 8.510094793954089,
            "py": 140.86758521811834,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Lighting Design for Globally Illuminated Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2013.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.172",
                "firstage": "2946",
                "Lastage": "2955",
                "IEEEXPLOREArticleNumber": "6634193",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.",
                "AuthorNames": "Yubo Zhang;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, Davis, CA, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yubo Zhang;Kwan-Liu Ma",
                "filename": "zhang_vis_13",
                "Citations": "1532812;1372208;6064942;6327242;1183785"
            }
        },
        {
            "name": "Ynnerman, A.",
            "value": 91,
            "numPapers": 39,
            "cluster": "5",
            "index": 235,
            "weight": 5,
            "x": 23.706602239178764,
            "y": 101.25945612164116,
            "px": 23.045406567297583,
            "py": 110.43099723653368,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Image Plane Sweep Volume Illumination",
                "PaperDOI": "10.1109/TVCG.2011.211",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.211",
                "firstage": "2125",
                "Lastage": "2134",
                "IEEEXPLOREArticleNumber": "6064977",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In recent years, many volumetric illumination models have been proposed, which have the potential to simulate advanced lighting effects and thus support improved image comprehension. Although volume ray-casting is widely accepted as the volume rendering technique which achieves the highest image quality, so far no volumetric illumination algorithm has been designed to be directly incorporated into the ray-casting process. In this paper we propose image plane sweep volume illumination (IPSVI), which allows the integration of advanced illumination effects into a GPU-based volume ray-caster by exploiting the plane sweep paradigm. Thus, we are able to reduce the problem complexity and achieve interactive frame rates, while supporting scattering as well as shadowing. Since all illumination computations are performed directly within a single rendering pass, IPSVI does not require any preprocessing nor does it need to store intermediate results within an illumination volume. It therefore has a significantly lower memory footprint than other techniques. This makes IPSVI directly applicable to large data sets. Furthermore, the integration into a GPU-based ray-caster allows for high image quality as well as improved rendering performance by exploiting early ray termination. This paper discusses the theory behind IPSVI, describes its implementation, demonstrates its visual results and provides performance measurements.",
                "AuthorNames": "Sunden, E.;Ynnerman, A.;Ropinski, T.",
                "FirstAuthorAffiliation": "Sci. Visualization Group, Linkoping Univ., Linkoping, Sweden|c|;;",
                "AuthorIDs": "38243026500;37284192000;38471794200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sunden, E.;Ynnerman, A.;Ropinski, T.",
                "filename": "sunden_vis_11",
                "Citations": "6064955;1183761;1250394;1183764;4376189;1250384;5290774"
            }
        },
        {
            "name": "Ropinski, T.",
            "value": 78,
            "numPapers": 37,
            "cluster": "5",
            "index": 236,
            "weight": 5,
            "x": 31.857961869283145,
            "y": 308.7720711104984,
            "px": 29.494276236563238,
            "py": 283.60391947052216,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2008.136",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.136",
                "firstage": "1499",
                "Lastage": "1506",
                "IEEEXPLOREArticleNumber": "4658168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.",
                "AuthorNames": "Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster|c|;;;;",
                "AuthorIDs": "37869986400;37273031400;;37295281400;37267218300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.",
                "filename": "meyerspr_vis_08",
                "Citations": "1250425;4015499;4376196;745294"
            }
        },
        {
            "name": "Kniss, J.",
            "value": 308,
            "numPapers": 18,
            "cluster": "5",
            "index": 237,
            "weight": 8,
            "x": 82.1477755054216,
            "y": 255.92977993574323,
            "px": 88.22693343626295,
            "py": 242.95918495042673,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Interactive translucent volume rendering and procedural modeling",
                "PaperDOI": "10.1109/VISUAL.2002.1183764",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183764",
                "firstage": "109",
                "Lastage": "116",
                "IEEEXPLOREArticleNumber": "1183764",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Direct volume rendering is a commonly used technique in visualization applications. Many of these applications require sophisticated shading models to capture subtle lighting effects and characteristics of volumetric data and materials. Many common objects and natural phenomena exhibit visual quality that cannot be captured using simple lighting models or cannot be solved at interactive rates using more sophisticated methods. We present a simple yet effective interactive shading model which captures volumetric light attenuation effects to produce volumetric shadows and the subtle appearance of translucency. We also present a technique for volume displacement or perturbation that allows realistic interactive modeling of high frequency detail for real and synthetic volumetric data.",
                "AuthorNames": "Kniss, J.;Premoze, S.;Hansen, C.;Ebert, D.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": "37324263400;38149547900;37266777200;38472157400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kniss, J.;Premoze, S.;Hansen, C.;Ebert, D.S.",
                "filename": "kniss_vis_02",
                "Citations": "146391"
            }
        },
        {
            "name": "Gunther, D.",
            "value": 11,
            "numPapers": 25,
            "cluster": "7",
            "index": 238,
            "weight": 4,
            "x": -884.5839888731425,
            "y": 1260.9678468626432,
            "px": -660.0108547316938,
            "py": 1270.220739099084,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees",
                "PaperDOI": "10.1109/TVCG.2009.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.163",
                "firstage": "1177",
                "Lastage": "1184",
                "IEEEXPLOREArticleNumber": "5290727",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf3. We introduce a procedure called \"loop surgery\" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.",
                "AuthorNames": "Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": "37298870300;37870001700;38113906300;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.",
                "filename": "tierny_vis_09",
                "Citations": "1372235;4376169;663875"
            }
        },
        {
            "name": "Gyulassy, A.",
            "value": 154,
            "numPapers": 41,
            "cluster": "7",
            "index": 239,
            "weight": 20,
            "x": 267.46088098997666,
            "y": 133.35540523950124,
            "px": 174.28736002317254,
            "py": 216.4927533078791,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees",
                "PaperDOI": "10.1109/TVCG.2009.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.163",
                "firstage": "1177",
                "Lastage": "1184",
                "IEEEXPLOREArticleNumber": "5290727",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf3. We introduce a procedure called \"loop surgery\" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.",
                "AuthorNames": "Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": "37298870300;37870001700;38113906300;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.",
                "filename": "tierny_vis_09",
                "Citations": "1372235;4376169;663875"
            }
        },
        {
            "name": "Tierny, J.",
            "value": 24,
            "numPapers": 24,
            "cluster": "7",
            "index": 240,
            "weight": 4,
            "x": 992.6773283820157,
            "y": -53.350981615577425,
            "px": 791.7740766269043,
            "py": 252.20780575101858,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees",
                "PaperDOI": "10.1109/TVCG.2009.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.163",
                "firstage": "1177",
                "Lastage": "1184",
                "IEEEXPLOREArticleNumber": "5290727",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf3. We introduce a procedure called \"loop surgery\" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.",
                "AuthorNames": "Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": "37298870300;37870001700;38113906300;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tierny, J.;Gyulassy, A.;Simon, E.;Pascucci, V.",
                "filename": "tierny_vis_09",
                "Citations": "1372235;4376169;663875"
            }
        },
        {
            "name": "Hege, H.-C.",
            "value": 340,
            "numPapers": 99,
            "cluster": "6",
            "index": 241,
            "weight": 24,
            "x": 459.7828338177332,
            "y": 397.0920822657795,
            "px": 468.22500372541384,
            "py": 433.0587077860431,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Tuner: Principled Parameter finding for Image Segmentation Algorithms Using Visual Response Surface Exploration",
                "PaperDOI": "10.1109/TVCG.2011.248",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.248",
                "firstage": "1892",
                "Lastage": "1901",
                "IEEEXPLOREArticleNumber": "6064952",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the \"goodness\" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans.",
                "AuthorNames": "Torsney-Weir, T.;Saad, A.;Moller, T.;Hege, H.-C.;Weber, B.;Verbavatz, J.;Bergner, S.",
                "FirstAuthorAffiliation": "Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;",
                "AuthorIDs": "38229404800;37405565700;37275858700;37282272000;38002090200;38229406100;37418878100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Torsney-Weir, T.;Saad, A.;Moller, T.;Hege, H.-C.;Weber, B.;Verbavatz, J.;Bergner, S.",
                "filename": "torsneyweir_vis_11",
                "Citations": "4376187;4658159;5613487;5613488;346302;5613441;398859;809871;6065007;885678"
            }
        },
        {
            "name": "Kretschmer, J.",
            "value": 0,
            "numPapers": 9,
            "cluster": "5",
            "index": 242,
            "weight": 1,
            "x": 25.281312963664256,
            "y": 630.1681454301523,
            "px": -216.24887451289678,
            "py": 704.3320640137458,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Advanced curved planar reformation: flattening of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2003.1250353",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250353",
                "firstage": "43",
                "Lastage": "50",
                "IEEEXPLOREArticleNumber": "1250353",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.",
                "AuthorNames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37282727500;37267822600;37282581000;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, E.",
                "filename": "kanitsar_vis_03",
                "Citations": "1183754;964555;964538"
            }
        },
        {
            "name": "Soza, G.",
            "value": 0,
            "numPapers": 7,
            "cluster": "5",
            "index": 243,
            "weight": 1,
            "x": 7.216272820220603,
            "y": 613.0826937533129,
            "px": -245.72630507076252,
            "py": 680.8863248072623,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Advanced curved planar reformation: flattening of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2003.1250353",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250353",
                "firstage": "43",
                "Lastage": "50",
                "IEEEXPLOREArticleNumber": "1250353",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.",
                "AuthorNames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37282727500;37267822600;37282581000;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, E.",
                "filename": "kanitsar_vis_03",
                "Citations": "1183754;964555;964538"
            }
        },
        {
            "name": "Tietjen, C.",
            "value": 10,
            "numPapers": 8,
            "cluster": "5",
            "index": 244,
            "weight": 1,
            "x": 532.0558041329209,
            "y": 211.36375300835536,
            "px": 669.6357447970855,
            "py": -19.337809653898354,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Advanced curved planar reformation: flattening of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2003.1250353",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250353",
                "firstage": "43",
                "Lastage": "50",
                "IEEEXPLOREArticleNumber": "1250353",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.",
                "AuthorNames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37282727500;37267822600;37282581000;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, E.",
                "filename": "kanitsar_vis_03",
                "Citations": "1183754;964555;964538"
            }
        },
        {
            "name": "Suehling, M.",
            "value": 0,
            "numPapers": 7,
            "cluster": "5",
            "index": 245,
            "weight": 1,
            "x": 497.3973372886449,
            "y": 187.92630220097422,
            "px": 610.8442589261488,
            "py": -63.66839344257755,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Advanced curved planar reformation: flattening of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2003.1250353",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250353",
                "firstage": "43",
                "Lastage": "50",
                "IEEEXPLOREArticleNumber": "1250353",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.",
                "AuthorNames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37282727500;37267822600;37282581000;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, E.",
                "filename": "kanitsar_vis_03",
                "Citations": "1183754;964555;964538"
            }
        },
        {
            "name": "Wegenkittl, R.",
            "value": 269,
            "numPapers": 32,
            "cluster": "5",
            "index": 246,
            "weight": 17,
            "x": 339.6265408207945,
            "y": 378.61281553803855,
            "px": 314.6078447034068,
            "py": 448.49390837442525,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "firstage": "37",
                "Lastage": "44",
                "IEEEXPLOREArticleNumber": "1183754",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "filename": "kanitsar1_vis_02",
                "Citations": "964555;964538"
            }
        },
        {
            "name": "Stamminger, M.",
            "value": 33,
            "numPapers": 19,
            "cluster": "5",
            "index": 247,
            "weight": 1,
            "x": 117.564709724617,
            "y": 539.345397408383,
            "px": -15.10360307677876,
            "py": 542.99651333103,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Advanced curved planar reformation: flattening of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2003.1250353",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250353",
                "firstage": "43",
                "Lastage": "50",
                "IEEEXPLOREArticleNumber": "1250353",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.",
                "AuthorNames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37282727500;37267822600;37282581000;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Wegenkittl, R.;Fleischmann, D.;Groller, E.",
                "filename": "kanitsar_vis_03",
                "Citations": "1183754;964555;964538"
            }
        },
        {
            "name": "Breeuwer, M.",
            "value": 73,
            "numPapers": 18,
            "cluster": "5",
            "index": 248,
            "weight": 5,
            "x": 148.9775575576469,
            "y": 389.6791184722841,
            "px": 177.22911227157692,
            "py": 388.5833780531297,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "firstage": "1632",
                "Lastage": "1639",
                "IEEEXPLOREArticleNumber": "4376196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "filename": "termeer_vis_07",
                "Citations": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Vilanova, A.",
            "value": 137,
            "numPapers": 44,
            "cluster": "5",
            "index": 249,
            "weight": 9,
            "x": 449.46735949570416,
            "y": 617.0225321807054,
            "px": 440.8780073321516,
            "py": 680.352843605495,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Parameter Sensitivity Visualization for DTI fiber Tracking",
                "PaperDOI": "10.1109/TVCG.2009.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.170",
                "firstage": "1441",
                "Lastage": "1448",
                "IEEEXPLOREArticleNumber": "5290759",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.",
                "AuthorNames": "Brecheisen, R.;Vilanova, A.;Platel, B.;ter Haar Romeny, B.",
                "FirstAuthorAffiliation": "Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;;",
                "AuthorIDs": "38108879500;37282551500;37428377700;38180036400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brecheisen, R.;Vilanova, A.;Platel, B.;ter Haar Romenij, B.",
                "filename": "brecheis_vis_09",
                "Citations": "4658169;1532853;4376198;1532778;1532779;568116;809894;1372220;964552"
            }
        },
        {
            "name": "van Pelt, R.",
            "value": 40,
            "numPapers": 18,
            "cluster": "5",
            "index": 250,
            "weight": 4,
            "x": 108.85154298535795,
            "y": 256.1963928939421,
            "px": 170.89747888496203,
            "py": 285.2208374266046,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms",
                "PaperDOI": "10.1109/TVCG.2012.202",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.202",
                "firstage": "2178",
                "Lastage": "2187",
                "IEEEXPLOREArticleNumber": "6327222",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",
                "AuthorNames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "FirstAuthorAffiliation": "Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;;;",
                "AuthorIDs": "38017015100;37601992200;37390973400;37833255000;38017002900;37282551500;37266875400;37424645300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "filename": "gasteiger_vis_12",
                "Citations": "6064980;6064968;6064983;5290742;5613474;5613472"
            }
        },
        {
            "name": "Bista, S.",
            "value": 0,
            "numPapers": 12,
            "cluster": "5",
            "index": 251,
            "weight": 1,
            "x": -468.37031562950716,
            "y": -37.94909894145978,
            "px": -885.3987213460409,
            "py": -184.5103043546115,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Lighting Design for Globally Illuminated Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2013.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.172",
                "firstage": "2946",
                "Lastage": "2955",
                "IEEEXPLOREArticleNumber": "6634193",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.",
                "AuthorNames": "Yubo Zhang;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, Davis, CA, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yubo Zhang;Kwan-Liu Ma",
                "filename": "zhang_vis_13",
                "Citations": "1532812;1372208;6064942;6327242;1183785"
            }
        },
        {
            "name": "Jiachen Zhuo",
            "value": 0,
            "numPapers": 12,
            "cluster": "5",
            "index": 252,
            "weight": 1,
            "x": 93.13155061022636,
            "y": -314.92566914092777,
            "px": 141.2253667871313,
            "py": -677.0209223926122,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Lighting Design for Globally Illuminated Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2013.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.172",
                "firstage": "2946",
                "Lastage": "2955",
                "IEEEXPLOREArticleNumber": "6634193",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.",
                "AuthorNames": "Yubo Zhang;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, Davis, CA, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yubo Zhang;Kwan-Liu Ma",
                "filename": "zhang_vis_13",
                "Citations": "1532812;1372208;6064942;6327242;1183785"
            }
        },
        {
            "name": "Gullapalli, R.P.",
            "value": 0,
            "numPapers": 12,
            "cluster": "5",
            "index": 253,
            "weight": 1,
            "x": 448.3690296570342,
            "y": -398.3794899165025,
            "px": 800.9465122214239,
            "py": -860.2395311722453,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Lighting Design for Globally Illuminated Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2013.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.172",
                "firstage": "2946",
                "Lastage": "2955",
                "IEEEXPLOREArticleNumber": "6634193",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.",
                "AuthorNames": "Yubo Zhang;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, Davis, CA, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yubo Zhang;Kwan-Liu Ma",
                "filename": "zhang_vis_13",
                "Citations": "1532812;1372208;6064942;6327242;1183785"
            }
        },
        {
            "name": "Varshney, A.",
            "value": 163,
            "numPapers": 57,
            "cluster": "5",
            "index": 254,
            "weight": 6,
            "x": 68.03021325812271,
            "y": 215.9702172169931,
            "px": 125.94274743270455,
            "py": 167.88946760377368,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Saliency-guided Enhancement for Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2006.174",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.174",
                "firstage": "925",
                "Lastage": "932",
                "IEEEXPLOREArticleNumber": "4015448",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator",
                "AuthorNames": "Youngmin Kim;Varshney, A.",
                "FirstAuthorAffiliation": "Maryland Univ., College Park, MD|c|;",
                "AuthorIDs": "37836140000;37282560200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Youngmin Kim;Varshney, A.",
                "filename": "kimyoung_vis_06",
                "Citations": "1250414;1250412;885694;1183777;1372209;885696"
            }
        },
        {
            "name": "Theisel, H.",
            "value": 334,
            "numPapers": 125,
            "cluster": "6",
            "index": 255,
            "weight": 36,
            "x": 484.43634762257796,
            "y": 353.050983411758,
            "px": 485.3568801018767,
            "py": 381.72467963594727,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Combining automated analysis and visualization techniques for effective exploration of high-dimensional data",
                "PaperDOI": "10.1109/VAST.2009.5332628",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332628",
                "firstage": "59",
                "Lastage": "66",
                "IEEEXPLOREArticleNumber": "5332628",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.",
                "AuthorNames": "Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;",
                "AuthorIDs": "37590724000;37603943800;37546817000;37669961800;37266875400;37273816400;37283138700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.A.",
                "filename": "tatu_vast_09",
                "Citations": "1532142;729568;1249017;346302;4035766"
            }
        },
        {
            "name": "Sahner, J.",
            "value": 41,
            "numPapers": 11,
            "cluster": "6",
            "index": 256,
            "weight": 3,
            "x": 1442.9314252857491,
            "y": -381.5766774471403,
            "px": 980.7629661377728,
            "py": -23.898238596133968,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking",
                "PaperDOI": "10.1109/VISUAL.2005.1532851",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532851",
                "firstage": "631",
                "Lastage": "638",
                "IEEEXPLOREArticleNumber": "1532851",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.",
                "AuthorNames": "Theisel, H.;Sahner, J.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.",
                "FirstAuthorAffiliation": "MPI Saarbrucken, Germany|c|;;;;",
                "AuthorIDs": ";37565764600;37282635100;37282272000;37271851300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Theisel, H.;Sahner, J.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.",
                "filename": "theisel_vis_05",
                "Citations": "1372213;346327;809896;235211;398875;964506;745290;745296"
            }
        },
        {
            "name": "Weinkauf, T.",
            "value": 177,
            "numPapers": 64,
            "cluster": "6",
            "index": 257,
            "weight": 18,
            "x": 453.8352569930363,
            "y": 393.4936311972738,
            "px": 466.168266593973,
            "py": 410.5807989984499,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data",
                "PaperDOI": "10.1109/TVCG.2009.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.152",
                "firstage": "1383",
                "Lastage": "1390",
                "IEEEXPLOREArticleNumber": "5290752",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.",
                "AuthorNames": "Keefe, Daniel F.;Ewert, M.;Ribarsky, W.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "37267356000;38108838100;37300425000;37592409400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keefe, D.F.;Ewert, M.;Ribarsky, W.;Chang, R.",
                "filename": "keefe_vis_09",
                "Citations": "4658146;4376166;4658124"
            }
        },
        {
            "name": "Seidel, H.-P.",
            "value": 256,
            "numPapers": 74,
            "cluster": "6",
            "index": 258,
            "weight": 16,
            "x": 532.3039300860813,
            "y": 335.82564537602315,
            "px": 550.6386843948759,
            "py": 361.8265312537736,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data",
                "PaperDOI": "10.1109/TVCG.2009.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.152",
                "firstage": "1383",
                "Lastage": "1390",
                "IEEEXPLOREArticleNumber": "5290752",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.",
                "AuthorNames": "Keefe, Daniel F.;Ewert, M.;Ribarsky, W.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "37267356000;38108838100;37300425000;37592409400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keefe, D.F.;Ewert, M.;Ribarsky, W.;Chang, R.",
                "filename": "keefe_vis_09",
                "Citations": "4658146;4376166;4658124"
            }
        },
        {
            "name": "Peikert, R.",
            "value": 250,
            "numPapers": 62,
            "cluster": "6",
            "index": 259,
            "weight": 23,
            "x": 458.6644598599653,
            "y": 461.5689711133957,
            "px": 414.74611689036016,
            "py": 519.71272330345,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "The \"Parallel Vectors\" operator-a vector field visualization primitive",
                "PaperDOI": "10.1109/VISUAL.1999.809896",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809896",
                "firstage": "263",
                "Lastage": "532",
                "IEEEXPLOREArticleNumber": "809896",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We propose an elementary operation on a pair of vector fields as a building block for defining and computing global line-type features of vector or scalar fields. While usual feature definitions often are procedural and therefore implicit, our operator allows precise mathematical definitions. It can serve as a basis for comparing feature definitions and for reuse of algorithms and implementations. Applications focus on vortex core methods.",
                "AuthorNames": "Peikert, R.;Roth, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;",
                "AuthorIDs": "37282541100;37365755100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Peikert, R.;Roth, M.",
                "filename": "peikert_vis_99",
                "Citations": "745290;568137;745296;480795;346327;663894;745297;567807"
            }
        },
        {
            "name": "Roth, M.",
            "value": 153,
            "numPapers": 20,
            "cluster": "6",
            "index": 260,
            "weight": 11,
            "x": 181.6922204349927,
            "y": 252.98148936552732,
            "px": 65.56238878167694,
            "py": 321.37247529220247,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "The \"Parallel Vectors\" operator-a vector field visualization primitive",
                "PaperDOI": "10.1109/VISUAL.1999.809896",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809896",
                "firstage": "263",
                "Lastage": "532",
                "IEEEXPLOREArticleNumber": "809896",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We propose an elementary operation on a pair of vector fields as a building block for defining and computing global line-type features of vector or scalar fields. While usual feature definitions often are procedural and therefore implicit, our operator allows precise mathematical definitions. It can serve as a basis for comparing feature definitions and for reuse of algorithms and implementations. Applications focus on vortex core methods.",
                "AuthorNames": "Peikert, R.;Roth, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;",
                "AuthorIDs": "37282541100;37365755100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Peikert, R.;Roth, M.",
                "filename": "peikert_vis_99",
                "Citations": "745290;568137;745296;480795;346327;663894;745297;567807"
            }
        },
        {
            "name": "Hanqi Guo",
            "value": 23,
            "numPapers": 48,
            "cluster": "5",
            "index": 261,
            "weight": 2,
            "x": 524.724784454083,
            "y": 429.54249271644346,
            "px": 542.6070115276759,
            "py": 430.6128570793892,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "WYSIWYG (What You See is What You Get) Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2011.261",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.261",
                "firstage": "2106",
                "Lastage": "2114",
                "IEEEXPLOREArticleNumber": "6064975",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.",
                "AuthorNames": "Hanqi Guo;Ningyu Mao;Xiaoru Yuan",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;",
                "AuthorIDs": "37595201300;38027433600;37403856700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hanqi Guo;Ningyu Mao;Xiaoru Yuan",
                "filename": "guo_vis_11",
                "Citations": "5613492;745319;4658154;1250414;4376159;568112;5290762;4658153;1250386;1250413;885694;1532856;663875;4015460"
            }
        },
        {
            "name": "Silver, D.",
            "value": 206,
            "numPapers": 52,
            "cluster": "5",
            "index": 262,
            "weight": 13,
            "x": 122.66092331414218,
            "y": 372.5355842460031,
            "px": 90.24181311539047,
            "py": 314.91339524950934,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "Volume tracking",
                "PaperDOI": "10.1109/VISUAL.1996.567807",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567807",
                "firstage": "157",
                "Lastage": "164",
                "IEEEXPLOREArticleNumber": "567807",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "3D time varying datasets are difficult to visualize and analyze because of the immense amount of data involved. This is especially true when the datasets are turbulent with many evolving amorphous regions, as it is difficult to observe patterns and follow regions of interest. We present our volume based feature tracking algorithm and discuss how it can be used to help visualize and analyze large time varying datasets. We also address efficiency issues in dealing with massive time varying datasets.",
                "AuthorNames": "Silver, D.;Wang, X.",
                "FirstAuthorAffiliation": "Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;",
                "AuthorIDs": "37274132700;37367862600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Silver, D.;Wang, X.",
                "filename": "silver_vis_96",
                "Citations": "485141;480789"
            }
        },
        {
            "name": "Hongfeng Yu",
            "value": 31,
            "numPapers": 15,
            "cluster": "5",
            "index": 263,
            "weight": 1,
            "x": 476.5989231759187,
            "y": 340.7783453128037,
            "px": 451.79231846385477,
            "py": 341.00283367589384,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "Isosurface extraction using particle systems",
                "PaperDOI": "10.1109/VISUAL.1997.663930",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663930",
                "firstage": "495",
                "Lastage": "498",
                "IEEEXPLOREArticleNumber": "663930",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.",
                "AuthorNames": "Crossno, P.;Angel, E.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., New Mexico Univ., Albuquerque, NM, USA|c|;",
                "AuthorIDs": "37282576500;37284249400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Crossno, P.;Angel, E.",
                "filename": "crossno_vis_97",
                "Citations": "398880"
            }
        },
        {
            "name": "Jianguang Weng",
            "value": 3,
            "numPapers": 10,
            "cluster": "0",
            "index": 264,
            "weight": 2,
            "x": 877.7585999330192,
            "y": 586.6696634394468,
            "px": 879.343490965233,
            "py": 538.4687415472172,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves",
                "PaperDOI": "10.1109/TVCG.2012.242",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.242",
                "firstage": "2051",
                "Lastage": "2060",
                "IEEEXPLOREArticleNumber": "6327209",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.",
                "AuthorNames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "FirstAuthorAffiliation": "Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;;",
                "AuthorIDs": "38490442700;38490274900;38489766500;38490597900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "filename": "zhang_vis_12",
                "Citations": "1532804;1532843;4376203"
            }
        },
        {
            "name": "Hui Zhang",
            "value": 27,
            "numPapers": 13,
            "cluster": "0",
            "index": 265,
            "weight": 2,
            "x": 859.2345183286341,
            "y": 600.9163905961167,
            "px": 848.7278521306779,
            "py": 554.3368635808894,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves",
                "PaperDOI": "10.1109/TVCG.2012.242",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.242",
                "firstage": "2051",
                "Lastage": "2060",
                "IEEEXPLOREArticleNumber": "6327209",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.",
                "AuthorNames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "FirstAuthorAffiliation": "Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;;",
                "AuthorIDs": "38490442700;38490274900;38489766500;38490597900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "filename": "zhang_vis_12",
                "Citations": "1532804;1532843;4376203"
            }
        },
        {
            "name": "Hanson, A.J.",
            "value": 185,
            "numPapers": 61,
            "cluster": "0",
            "index": 266,
            "weight": 16,
            "x": 887.7431964725494,
            "y": 672.9899155441352,
            "px": 889.5278168319933,
            "py": 635.9831776084632,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Multimodal exploration of the fourth dimension",
                "PaperDOI": "10.1109/VISUAL.2005.1532804",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532804",
                "firstage": "263",
                "Lastage": "270",
                "IEEEXPLOREArticleNumber": "1532804",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.",
                "AuthorNames": "Hanson, A.J.;Hui Zhang",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37333439100;37559775500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hanson, A.J.;Hui Zhang",
                "filename": "hanson_vis_05",
                "Citations": "480804"
            }
        },
        {
            "name": "Reininghaus, J.",
            "value": 19,
            "numPapers": 13,
            "cluster": "7",
            "index": 267,
            "weight": 1,
            "x": 134.6838615287629,
            "y": -317.946354615431,
            "px": -85.106495701629,
            "py": -1003.6704868859143,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Generalized Topological Simplification of Scalar fields on Surfaces",
                "PaperDOI": "10.1109/TVCG.2012.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.228",
                "firstage": "2005",
                "Lastage": "2013",
                "IEEEXPLOREArticleNumber": "6327204",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a combinatorial algorithm for the general topological simplification of scalar fields on surfaces. Given a scalar field f, our algorithm generates a simplified field g that provably admits only critical points from a constrained subset of the singularities of f, while guaranteeing a small distance ||f - g||∞ for data-fitting purpose. In contrast to previous algorithms, our approach is oblivious to the strategy used for selecting features of interest and allows critical points to be removed arbitrarily. When topological persistence is used to select the features of interest, our algorithm produces a standard ϵ-simplification. Our approach is based on a new iterative algorithm for the constrained reconstruction of sub- and sur-level sets. Extensive experiments show that the number of iterations required for our algorithm to converge is rarely greater than 2 and never greater than 5, yielding O(n log(n)) practical time performances. The algorithm handles triangulated surfaces with or without boundary and is robust to the presence of multi-saddles in the input. It is simple to implement, fast in practice and more general than previous techniques. Practically, our approach allows a user to arbitrarily simplify the topology of an input function and robustly generate the corresponding simplified function. An appealing application area of our algorithm is in scalar field design since it enables, without any threshold parameter, the robust pruning of topological noise as selected by the user. This is needed for example to get rid of inaccuracies introduced by numerical solvers, thereby providing topological guarantees needed for certified geometry processing. Experiments show this ability to eliminate numerical noise as well as validate the time efficiency and accuracy of our algorithm. We provide a lightweight C++ implementation as supplemental material that can be used for topological cleaning on surface meshes.",
                "AuthorNames": "Tierny, J.;Pascucci, V.",
                "FirstAuthorAffiliation": "Telecom ParisTech, Paris, France|c|;",
                "AuthorIDs": "37298870300;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tierny, J.;Pascucci, V.",
                "filename": "tierny_vis_12",
                "Citations": "4658183;5290727;1372235;6064947"
            }
        },
        {
            "name": "Tricoche, X.",
            "value": 317,
            "numPapers": 88,
            "cluster": "6",
            "index": 268,
            "weight": 38,
            "x": 483.0861842831117,
            "y": 361.7899627887899,
            "px": 498.7206363119895,
            "py": 385.18724476161935,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Invariant Crease Lines for Topological and Structural Analysis of Tensor fields",
                "PaperDOI": "10.1109/TVCG.2008.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.148",
                "firstage": "1627",
                "Lastage": "1634",
                "IEEEXPLOREArticleNumber": "4658184",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.",
                "AuthorNames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;",
                "AuthorIDs": "37282575100;37282742400;37294318400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "filename": "tricoche_vis_08",
                "Citations": "1372212;4376179;809896;175773;346326;346326;146359;4376174"
            }
        },
        {
            "name": "Scheuermann, G.",
            "value": 457,
            "numPapers": 120,
            "cluster": "6",
            "index": 269,
            "weight": 48,
            "x": 517.731381984556,
            "y": 307.9849604607468,
            "px": 524.1835879272944,
            "py": 308.0487588576574,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Visual Exploration of Climate Variability Changes Using Wavelet Analysis",
                "PaperDOI": "10.1109/TVCG.2009.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.197",
                "firstage": "1375",
                "Lastage": "1382",
                "IEEEXPLOREArticleNumber": "5290751",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.",
                "AuthorNames": "Janicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig, Germany|c|;;;",
                "AuthorIDs": "37393638200;37869987100;38108879000;37282574800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jänicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.",
                "filename": "janicke_vis_09",
                "Citations": "4658163;1250383;663871"
            }
        },
        {
            "name": "Levine, J.A.",
            "value": 10,
            "numPapers": 10,
            "cluster": "7",
            "index": 270,
            "weight": 2,
            "x": 319.23011138294225,
            "y": 636.8552568218298,
            "px": 369.51563114799904,
            "py": 586.9999251916634,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "firstage": "2467",
                "Lastage": "2476",
                "IEEEXPLOREArticleNumber": "6327252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "filename": "landge_infovis_12",
                "Citations": "5290721;1382906"
            }
        },
        {
            "name": "Vijay Natarajan",
            "value": 93,
            "numPapers": 10,
            "cluster": "7",
            "index": 271,
            "weight": 3,
            "x": 487.3033869047026,
            "y": 806.3595453173781,
            "px": 357.7190351510383,
            "py": 867.3317810567597,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Topologically Clean Distance fields",
                "PaperDOI": "10.1109/TVCG.2007.70603",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70603",
                "firstage": "1432",
                "Lastage": "1439",
                "IEEEXPLOREArticleNumber": "4376171",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.",
                "AuthorNames": "Gyulassy, A.G.;Duchaineau, M.A.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis|c|;;;;;;",
                "AuthorIDs": "37870001700;37267813100;37278509300;;37320622500;37848485600;37282068700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "filename": "gyulassy1_vis_07",
                "Citations": "1532839;1532783;1250356;1372235;885680;885703"
            }
        },
        {
            "name": "Duchaineau, M.",
            "value": 115,
            "numPapers": 36,
            "cluster": "7",
            "index": 272,
            "weight": 3,
            "x": 398.61039322655637,
            "y": 706.5589250351876,
            "px": 238.75884786559908,
            "py": 721.7170936113594,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Topologically Clean Distance fields",
                "PaperDOI": "10.1109/TVCG.2007.70603",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70603",
                "firstage": "1432",
                "Lastage": "1439",
                "IEEEXPLOREArticleNumber": "4376171",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.",
                "AuthorNames": "Gyulassy, A.G.;Duchaineau, M.A.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis|c|;;;;;;",
                "AuthorIDs": "37870001700;37267813100;37278509300;;37320622500;37848485600;37282068700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "filename": "gyulassy1_vis_07",
                "Citations": "1532839;1532783;1250356;1372235;885680;885703"
            }
        },
        {
            "name": "Bringa, E.M.",
            "value": 40,
            "numPapers": 6,
            "cluster": "7",
            "index": 273,
            "weight": 1,
            "x": -527.0596049437153,
            "y": 1447.7590881670747,
            "px": -1355.0065993987869,
            "py": 2327.68818360802,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Topologically Clean Distance fields",
                "PaperDOI": "10.1109/TVCG.2007.70603",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70603",
                "firstage": "1432",
                "Lastage": "1439",
                "IEEEXPLOREArticleNumber": "4376171",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.",
                "AuthorNames": "Gyulassy, A.G.;Duchaineau, M.A.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis|c|;;;;;;",
                "AuthorIDs": "37870001700;37267813100;37278509300;;37320622500;37848485600;37282068700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "filename": "gyulassy1_vis_07",
                "Citations": "1532839;1532783;1250356;1372235;885680;885703"
            }
        },
        {
            "name": "Higginbotham, A.",
            "value": 40,
            "numPapers": 6,
            "cluster": "7",
            "index": 274,
            "weight": 1,
            "x": 2174.480855105767,
            "y": 123.89197101977878,
            "px": 3827.840516598099,
            "py": -204.8077824648261,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Topologically Clean Distance fields",
                "PaperDOI": "10.1109/TVCG.2007.70603",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70603",
                "firstage": "1432",
                "Lastage": "1439",
                "IEEEXPLOREArticleNumber": "4376171",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.",
                "AuthorNames": "Gyulassy, A.G.;Duchaineau, M.A.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis|c|;;;;;;",
                "AuthorIDs": "37870001700;37267813100;37278509300;;37320622500;37848485600;37282068700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "filename": "gyulassy1_vis_07",
                "Citations": "1532839;1532783;1250356;1372235;885680;885703"
            }
        },
        {
            "name": "Laney, D.",
            "value": 61,
            "numPapers": 17,
            "cluster": "7",
            "index": 275,
            "weight": 3,
            "x": 131.76040511709382,
            "y": 1110.5045009005719,
            "px": 246.125775974112,
            "py": 775.0981932608918,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities",
                "PaperDOI": "10.1109/TVCG.2006.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.186",
                "firstage": "1053",
                "Lastage": "1060",
                "IEEEXPLOREArticleNumber": "4015464",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",
                "AuthorNames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;",
                "AuthorIDs": "37281901900;37564112000;37284319900;;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "filename": "laney_vis_06",
                "Citations": "1250376;1183772;1532842;885716;1372235;1250408;1372214;809907;745288;1532839"
            }
        },
        {
            "name": "Mascarenhas, A.",
            "value": 58,
            "numPapers": 11,
            "cluster": "7",
            "index": 276,
            "weight": 2,
            "x": 15.440552008181335,
            "y": 1100.737670508441,
            "px": 267.3852056135364,
            "py": 729.151205143689,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities",
                "PaperDOI": "10.1109/TVCG.2006.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.186",
                "firstage": "1053",
                "Lastage": "1060",
                "IEEEXPLOREArticleNumber": "4015464",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",
                "AuthorNames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;",
                "AuthorIDs": "37281901900;37564112000;37284319900;;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "filename": "laney_vis_06",
                "Citations": "1250376;1183772;1532842;885716;1372235;1250408;1372214;809907;745288;1532839"
            }
        },
        {
            "name": "Miller, P.",
            "value": 56,
            "numPapers": 10,
            "cluster": "7",
            "index": 277,
            "weight": 2,
            "x": 102.88116766886523,
            "y": 1150.793127255052,
            "px": 262.1646138944284,
            "py": 724.382006440682,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities",
                "PaperDOI": "10.1109/TVCG.2006.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.186",
                "firstage": "1053",
                "Lastage": "1060",
                "IEEEXPLOREArticleNumber": "4015464",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",
                "AuthorNames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;",
                "AuthorIDs": "37281901900;37564112000;37284319900;;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "filename": "laney_vis_06",
                "Citations": "1250376;1183772;1532842;885716;1372235;1250408;1372214;809907;745288;1532839"
            }
        },
        {
            "name": "Ferreira, N.",
            "value": 39,
            "numPapers": 27,
            "cluster": "2",
            "index": 278,
            "weight": 2,
            "x": 174.49790824602636,
            "y": -285.54718387228354,
            "px": 164.29405735686163,
            "py": -226.20234026606363,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips",
                "PaperDOI": "10.1109/TVCG.2013.226",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.226",
                "firstage": "2149",
                "Lastage": "2158",
                "IEEEXPLOREArticleNumber": "6634127",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.",
                "AuthorNames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "filename": "ferreira_vast_13",
                "Citations": "1382904;4677356;6102454;4376143;5652467;1532150;4677370;885086"
            }
        },
        {
            "name": "Kirby, R.M.",
            "value": 144,
            "numPapers": 54,
            "cluster": "6",
            "index": 279,
            "weight": 5,
            "x": 649.9064101192097,
            "y": 625.3112777344579,
            "px": 653.948120867564,
            "py": 581.0435929192189,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles",
                "PaperDOI": "10.1109/TVCG.2013.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.143",
                "firstage": "2713",
                "Lastage": "2722",
                "IEEEXPLOREArticleNumber": "6634129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.",
                "AuthorNames": "Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.",
                "filename": "whitaker_vis_13",
                "Citations": "1183769;568105;1532807;5613483"
            }
        },
        {
            "name": "Whitaker, R.T.",
            "value": 206,
            "numPapers": 52,
            "cluster": "5",
            "index": 280,
            "weight": 13,
            "x": 192.45997963791706,
            "y": 329.56357989803865,
            "px": 210.84952822793798,
            "py": 310.169515040064,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles",
                "PaperDOI": "10.1109/TVCG.2013.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.143",
                "firstage": "2713",
                "Lastage": "2722",
                "IEEEXPLOREArticleNumber": "6634129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.",
                "AuthorNames": "Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.",
                "filename": "whitaker_vis_13",
                "Citations": "1183769;568105;1532807;5613483"
            }
        },
        {
            "name": "Jiaxi Hu",
            "value": 10,
            "numPapers": 11,
            "cluster": "11",
            "index": 281,
            "weight": 2,
            "x": 964.1738601476159,
            "y": 711.4683708481375,
            "px": 899.9075491237961,
            "py": 701.7224901838551,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Geodesic Distance-weighted Shape Vector Image Diffusion",
                "PaperDOI": "10.1109/TVCG.2008.134",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.134",
                "firstage": "1643",
                "Lastage": "1650",
                "IEEEXPLOREArticleNumber": "4658186",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",
                "AuthorNames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "FirstAuthorAffiliation": "Wayne State Univ., Detroit, MI|c|;;;;",
                "AuthorIDs": "37285799200;37868989800;37290589700;37276603700;37276553900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "filename": "hua_vis_08",
                "Citations": ""
            }
        },
        {
            "name": "Jing Hua",
            "value": 68,
            "numPapers": 20,
            "cluster": "11",
            "index": 282,
            "weight": 4,
            "x": 973.6319988767744,
            "y": 680.0159514094019,
            "px": 914.6228798064943,
            "py": 660.2558449134058,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Visualization of Shape Motions in Shape Space",
                "PaperDOI": "10.1109/TVCG.2013.230",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.230",
                "firstage": "2644",
                "Lastage": "2652",
                "IEEEXPLOREArticleNumber": "6634092",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods.",
                "AuthorNames": "Taimouri, V.;Jing Hua",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Taimouri, V.;Jing Hua",
                "filename": "taimouri_infovis_13",
                "Citations": "4015471;1249025;5290729;1382896"
            }
        },
        {
            "name": "Xianfeng Gu",
            "value": 44,
            "numPapers": 26,
            "cluster": "11",
            "index": 283,
            "weight": 4,
            "x": 952.3105944169585,
            "y": 705.9225449488858,
            "px": 917.4202472490156,
            "py": 684.0094877870788,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Geodesic Distance-weighted Shape Vector Image Diffusion",
                "PaperDOI": "10.1109/TVCG.2008.134",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.134",
                "firstage": "1643",
                "Lastage": "1650",
                "IEEEXPLOREArticleNumber": "4658186",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",
                "AuthorNames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "FirstAuthorAffiliation": "Wayne State Univ., Detroit, MI|c|;;;;",
                "AuthorIDs": "37285799200;37868989800;37290589700;37276603700;37276553900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "filename": "hua_vis_08",
                "Citations": ""
            }
        },
        {
            "name": "Zhaoqiang Lai",
            "value": 18,
            "numPapers": 2,
            "cluster": "11",
            "index": 284,
            "weight": 1,
            "x": 1071.985850288492,
            "y": 709.8055046410276,
            "px": 1044.2053809891713,
            "py": 710.1037006681211,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Geodesic Distance-weighted Shape Vector Image Diffusion",
                "PaperDOI": "10.1109/TVCG.2008.134",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.134",
                "firstage": "1643",
                "Lastage": "1650",
                "IEEEXPLOREArticleNumber": "4658186",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",
                "AuthorNames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "FirstAuthorAffiliation": "Wayne State Univ., Detroit, MI|c|;;;;",
                "AuthorIDs": "37285799200;37868989800;37290589700;37276603700;37276553900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "filename": "hua_vis_08",
                "Citations": ""
            }
        },
        {
            "name": "Ming Dong",
            "value": 48,
            "numPapers": 4,
            "cluster": "11",
            "index": 285,
            "weight": 1,
            "x": 860.9799130440871,
            "y": 683.2907384562214,
            "px": 777.0518872061714,
            "py": 669.2536393060832,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Exemplar-based Visualization of Large Document Corpus",
                "PaperDOI": "10.1109/TVCG.2009.140",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.140",
                "firstage": "1161",
                "Lastage": "1168",
                "IEEEXPLOREArticleNumber": "5290725",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.",
                "AuthorNames": "Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;;",
                "AuthorIDs": "37965966100;37900114200;37290589700;37285799200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua",
                "filename": "chenyanh_infovis_09",
                "Citations": "809866;4658134"
            }
        },
        {
            "name": "Lindstrom, P.",
            "value": 133,
            "numPapers": 83,
            "cluster": "7",
            "index": 286,
            "weight": 13,
            "x": 446.9617467531957,
            "y": 820.8691295965864,
            "px": 365.96942693092984,
            "py": 931.00451459412,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Fast and Efficient Compression of Floating-Point Data",
                "PaperDOI": "10.1109/TVCG.2006.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.143",
                "firstage": "1245",
                "Lastage": "1250",
                "IEEEXPLOREArticleNumber": "4015488",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data",
                "AuthorNames": "Lindstrom, P.;Isenburg, M.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;",
                "AuthorIDs": "37269320000;37281897600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lindstrom, P.;Isenburg, M.",
                "filename": "lindstro_vis_06",
                "Citations": "809867;885711;1183768;568138"
            }
        },
        {
            "name": "Isenburg, M.",
            "value": 47,
            "numPapers": 18,
            "cluster": "7",
            "index": 287,
            "weight": 1,
            "x": 540.9627059482401,
            "y": -297.2674691474095,
            "px": 772.6649217797894,
            "py": -1003.7252450741506,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Fast and Efficient Compression of Floating-Point Data",
                "PaperDOI": "10.1109/TVCG.2006.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.143",
                "firstage": "1245",
                "Lastage": "1250",
                "IEEEXPLOREArticleNumber": "4015488",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data",
                "AuthorNames": "Lindstrom, P.;Isenburg, M.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;",
                "AuthorIDs": "37269320000;37281897600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lindstrom, P.;Isenburg, M.",
                "filename": "lindstro_vis_06",
                "Citations": "809867;885711;1183768;568138"
            }
        },
        {
            "name": "Riche, N.H.",
            "value": 169,
            "numPapers": 61,
            "cluster": "3",
            "index": 288,
            "weight": 9,
            "x": 126.2646408886398,
            "y": 690.2324051908439,
            "px": 159.73596958518078,
            "py": 671.197025702615,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "SparkClouds: Visualizing Trends in Tag Clouds",
                "PaperDOI": "10.1109/TVCG.2010.194",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.194",
                "firstage": "1182",
                "Lastage": "1189",
                "IEEEXPLOREArticleNumber": "5613457",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.",
                "AuthorNames": "Bongshin Lee;Riche, N.H.;Karlson, A.K.;Carpendale, S.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37293389400;37590950700;37590950600;37285000100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bongshin Lee;Riche, N.H.;Karlson, A.;Carpendale, S.",
                "filename": "lee_infovis_10",
                "Citations": "5290722;1532122;4376132"
            }
        },
        {
            "name": "Hullman, J.",
            "value": 56,
            "numPapers": 19,
            "cluster": "3",
            "index": 289,
            "weight": 1,
            "x": 150.88973205640391,
            "y": 998.0871171390717,
            "px": 22.796066854416186,
            "py": 1108.6620853011027,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Benefitting InfoVis with Visual Difficulties",
                "PaperDOI": "10.1109/TVCG.2011.175",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.175",
                "firstage": "2213",
                "Lastage": "2222",
                "IEEEXPLOREArticleNumber": "6064986",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative \"chartjunk\" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.",
                "AuthorNames": "Hullman, J.;Adar, E.;Shah, P.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "38016234500;37331417100;38018860000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hullman, J.;Adar, E.;Shah, P.",
                "filename": "hullman1_infovis_11",
                "Citations": "528688;4658146;4376146;5613437;963279;5290695"
            }
        },
        {
            "name": "Adar, E.",
            "value": 34,
            "numPapers": 15,
            "cluster": "3",
            "index": 290,
            "weight": 1,
            "x": 162.6755797736445,
            "y": 912.849742143445,
            "px": 62.65653367425542,
            "py": 950.3329077516637,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Benefitting InfoVis with Visual Difficulties",
                "PaperDOI": "10.1109/TVCG.2011.175",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.175",
                "firstage": "2213",
                "Lastage": "2222",
                "IEEEXPLOREArticleNumber": "6064986",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative \"chartjunk\" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.",
                "AuthorNames": "Hullman, J.;Adar, E.;Shah, P.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "38016234500;37331417100;38018860000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hullman, J.;Adar, E.;Shah, P.",
                "filename": "hullman1_infovis_11",
                "Citations": "528688;4658146;4376146;5613437;963279;5290695"
            }
        },
        {
            "name": "Fujishiro, I.",
            "value": 115,
            "numPapers": 26,
            "cluster": "7",
            "index": 291,
            "weight": 2,
            "x": -156.83740434902884,
            "y": 798.9663543080965,
            "px": -883.1669722588292,
            "py": 1288.8496623840742,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "GADGET/IV: a taxonomic approach to semi-automatic design of information visualization applications using modular visualization environment",
                "PaperDOI": "10.1109/INFVIS.2000.885093",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885093",
                "firstage": "77",
                "Lastage": "83",
                "IEEEXPLOREArticleNumber": "885093",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Since novice users of visualization systems lack knowledge and expertise in data visualization, it is a tough task for them to generate efficient and effective visualizations that allow them to comprehend information that is embedded in the data. Therefore, systems supporting the users to design appropriate visualizations are of great importance. The GADGET (Goal-oriented Application Design Guidance for modular visualization EnvironmenTs) system, which has been developed by the authors (1997), interactively helps users to design scientific visualization applications by presenting appropriate MVE (Modular Visualization Environment) prototypes according to the specification of the visualization goals expressed mainly with the Wehrend matrix (S. Wehrend & C. Lewis, 1990). This paper extends this approach in order to develop a system named GADGET/IV, which is intended to provide the users with an environment for semi-automatic design of information visualization (IV) applications. To this end, a novel goal-oriented taxonomy of IV techniques is presented. Also, an initial design of the system architecture and user assistance flow is described. The usefulness of the GADGET/IV system is illustrated with example problems of Web site access frequency analysis",
                "AuthorNames": "Fujishiro, I.;Ichikawa, Y.;Furuhata, R.;Takeshima, Y.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;;",
                "AuthorIDs": "37282596600;37618383200;38015236500;37282600100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fujishiro, I.;Ichikawa, Y.;Furuhata, R.;Takeshima, Y.",
                "filename": "fujishir_infovis_00",
                "Citations": "636788;663889;636792;146375"
            }
        },
        {
            "name": "Takeshima, Y.",
            "value": 96,
            "numPapers": 15,
            "cluster": "5",
            "index": 292,
            "weight": 1,
            "x": 553.164685482316,
            "y": -343.80209571039325,
            "px": 995.7483708843032,
            "py": -760.9287523519598,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "GADGET/IV: a taxonomic approach to semi-automatic design of information visualization applications using modular visualization environment",
                "PaperDOI": "10.1109/INFVIS.2000.885093",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885093",
                "firstage": "77",
                "Lastage": "83",
                "IEEEXPLOREArticleNumber": "885093",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Since novice users of visualization systems lack knowledge and expertise in data visualization, it is a tough task for them to generate efficient and effective visualizations that allow them to comprehend information that is embedded in the data. Therefore, systems supporting the users to design appropriate visualizations are of great importance. The GADGET (Goal-oriented Application Design Guidance for modular visualization EnvironmenTs) system, which has been developed by the authors (1997), interactively helps users to design scientific visualization applications by presenting appropriate MVE (Modular Visualization Environment) prototypes according to the specification of the visualization goals expressed mainly with the Wehrend matrix (S. Wehrend & C. Lewis, 1990). This paper extends this approach in order to develop a system named GADGET/IV, which is intended to provide the users with an environment for semi-automatic design of information visualization (IV) applications. To this end, a novel goal-oriented taxonomy of IV techniques is presented. Also, an initial design of the system architecture and user assistance flow is described. The usefulness of the GADGET/IV system is illustrated with example problems of Web site access frequency analysis",
                "AuthorNames": "Fujishiro, I.;Ichikawa, Y.;Furuhata, R.;Takeshima, Y.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;;",
                "AuthorIDs": "37282596600;37618383200;38015236500;37282600100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fujishiro, I.;Ichikawa, Y.;Furuhata, R.;Takeshima, Y.",
                "filename": "fujishir_infovis_00",
                "Citations": "636788;663889;636792;146375"
            }
        },
        {
            "name": "Amar, R.",
            "value": 143,
            "numPapers": 11,
            "cluster": "3",
            "index": 293,
            "weight": 2,
            "x": -126.49523659313716,
            "y": 523.2356588012774,
            "px": -311.3381840689623,
            "py": 485.785504171361,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Low-level components of analytic activity in information visualization",
                "PaperDOI": "10.1109/INFVIS.2005.1532136",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532136",
                "firstage": "111",
                "Lastage": "117",
                "IEEEXPLOREArticleNumber": "1532136",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",
                "AuthorNames": "Amar, R.;Eagan, J.;Stasko, J.",
                "FirstAuthorAffiliation": "Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;",
                "AuthorIDs": "37418696100;37550755100;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Amar, R.;Eagan, J.;Stasko, J.",
                "filename": "amar_infovis_05",
                "Citations": "146375;729560;885092;1382884;963289"
            }
        },
        {
            "name": "Eagan, J.",
            "value": 133,
            "numPapers": 7,
            "cluster": "3",
            "index": 294,
            "weight": 1,
            "x": 332.2691674658504,
            "y": -432.722336843449,
            "px": 543.8199303121575,
            "py": -1268.8904460152726,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Low-level components of analytic activity in information visualization",
                "PaperDOI": "10.1109/INFVIS.2005.1532136",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532136",
                "firstage": "111",
                "Lastage": "117",
                "IEEEXPLOREArticleNumber": "1532136",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",
                "AuthorNames": "Amar, R.;Eagan, J.;Stasko, J.",
                "FirstAuthorAffiliation": "Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;",
                "AuthorIDs": "37418696100;37550755100;37267736900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Amar, R.;Eagan, J.;Stasko, J.",
                "filename": "amar_infovis_05",
                "Citations": "146375;729560;885092;1382884;963289"
            }
        },
        {
            "name": "Lam, H.",
            "value": 81,
            "numPapers": 25,
            "cluster": "3",
            "index": 295,
            "weight": 2,
            "x": -586.776690186485,
            "y": -216.41779063692226,
            "px": 47.32686140831965,
            "py": 516.3261142654393,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Session Viewer: Visual Exploratory Analysis of Web Session Logs",
                "PaperDOI": "10.1109/VAST.2007.4389008",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389008",
                "firstage": "147",
                "Lastage": "154",
                "IEEEXPLOREArticleNumber": "4389008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.",
                "AuthorNames": "Lam, H.;Russell, D.;Tang, D.;Munzner, T.",
                "FirstAuthorAffiliation": "Univ. of British Columbia Google, Vancouver|c|;;;",
                "AuthorIDs": "37873130000;37562313000;37652594600;37349490300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lam, H.;Russell, D.;Tang, D.;Munzner, T.",
                "filename": "lam_vast_07",
                "Citations": "729565;1249006;1382890;559227"
            }
        },
        {
            "name": "Isenberg, T.",
            "value": 134,
            "numPapers": 63,
            "cluster": "2",
            "index": 296,
            "weight": 4,
            "x": 1030.6186629777965,
            "y": 571.2300153453581,
            "px": 1086.438357685192,
            "py": 574.6687780742901,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "firstage": "2818",
                "Lastage": "2827",
                "IEEEXPLOREArticleNumber": "6634108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "filename": "isenberg_vis_13",
                "Citations": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Jian Chen",
            "value": 59,
            "numPapers": 27,
            "cluster": "3",
            "index": 297,
            "weight": 1,
            "x": 1115.844032587881,
            "y": 1971.1394241905293,
            "px": 2042.6070806007106,
            "py": 3281.73955022034,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "firstage": "2818",
                "Lastage": "2827",
                "IEEEXPLOREArticleNumber": "6634108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "filename": "isenberg_vis_13",
                "Citations": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Vos, F.M.",
            "value": 49,
            "numPapers": 14,
            "cluster": "2",
            "index": 298,
            "weight": 1,
            "x": 1341.6859978243622,
            "y": 454.86151691685916,
            "px": 1402.6630085809268,
            "py": 445.30253306634,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "WYSIWYP: What You See Is What You Pick",
                "PaperDOI": "10.1109/TVCG.2012.292",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.292",
                "firstage": "2236",
                "Lastage": "2244",
                "IEEEXPLOREArticleNumber": "6327228",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (â€œwhat you see is what you pickâ€) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.",
                "AuthorNames": "Wiebel, A.;Vos, F.M.;Foerster, D.;Hege, H.-C.",
                "FirstAuthorAffiliation": "Zuse Inst. Berlin (ZIB), Berlin, Germany|c|;;;",
                "AuthorIDs": "37565763400;37271678400;38489178700;37282272000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wiebel, A.;Vos, F.M.;Foerster, D.;Hege, H.-C.",
                "filename": "wiebel_vis_12",
                "Citations": "6327229;745337;1250384;4376185;1532833;5290766"
            }
        },
        {
            "name": "Barakat, S.S.",
            "value": 8,
            "numPapers": 14,
            "cluster": "6",
            "index": 299,
            "weight": 2,
            "x": -105.93305764335487,
            "y": -167.85772817358807,
            "px": 496.103933560717,
            "py": 210.55910494335433,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Adaptive Refinement of the Flow Map Using Sparse Samples",
                "PaperDOI": "10.1109/TVCG.2013.128",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.128",
                "firstage": "2753",
                "Lastage": "2762",
                "IEEEXPLOREArticleNumber": "6634133",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.",
                "AuthorNames": "Barakat, S.S.;Tricoche, X.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Purdue Univ., West Lafayette, IN, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Barakat, S.S.;Tricoche, X.",
                "filename": "barakat_vis_13",
                "Citations": "5290738;4658156;4376174;4376175"
            }
        },
        {
            "name": "Kraus, M.",
            "value": 192,
            "numPapers": 22,
            "cluster": "5",
            "index": 300,
            "weight": 12,
            "x": 130.90110691823807,
            "y": 282.2697715895947,
            "px": 127.64959848740024,
            "py": 259.2393547650703,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated volume and isosurface rendering based on cell-projection",
                "PaperDOI": "10.1109/VISUAL.2000.885683",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885683",
                "firstage": "109",
                "Lastage": "116",
                "IEEEXPLOREArticleNumber": "885683",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.",
                "AuthorNames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37357145300;37284293000;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "filename": "roettger_vis_00",
                "Citations": "398846;346320;809887;346308;885688;346306;663853;809878;568127;480806;745300;568121;745713"
            }
        },
        {
            "name": "Magnor, M.",
            "value": 116,
            "numPapers": 29,
            "cluster": "0",
            "index": 301,
            "weight": 13,
            "x": 1042.6359926607852,
            "y": 1061.6797303830404,
            "px": 1072.2645576416649,
            "py": 1028.92927617873,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Perception-based visual quality measures",
                "PaperDOI": "10.1109/VAST.2011.6102437",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102437",
                "firstage": "13",
                "Lastage": "20",
                "IEEEXPLOREArticleNumber": "6102437",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;",
                "AuthorIDs": "37603943800;37546817000;37273816400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Magnor, M.",
                "filename": "albuquer_vast_11",
                "Citations": "1532142;5652433;4035766;5332628;5613439;5290704"
            }
        },
        {
            "name": "Chaoli Wang",
            "value": 78,
            "numPapers": 24,
            "cluster": "5",
            "index": 302,
            "weight": 3,
            "x": 561.838025172773,
            "y": 362.129704943293,
            "px": 580.0881591781194,
            "py": 371.50748633738095,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data",
                "PaperDOI": "10.1109/TVCG.2011.246",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.246",
                "firstage": "2015",
                "Lastage": "2024",
                "IEEEXPLOREArticleNumber": "6064965",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.",
                "AuthorNames": "Yi Gu;Chaoli Wang",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MA, USA|c|;",
                "AuthorIDs": "38021343000;37405886900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yi Gu;Chaoli Wang",
                "filename": "gu_vis_11",
                "Citations": "4658159;346321;4035742;809871;4015447;1250401;4658163;5613488;1250402;480809;4658174;964531;5290749"
            }
        },
        {
            "name": "Bordoloi, U.D.",
            "value": 79,
            "numPapers": 15,
            "cluster": "5",
            "index": 303,
            "weight": 1,
            "x": 546.242303988817,
            "y": 382.44039239954526,
            "px": 544.5231995411501,
            "py": 393.5160907341734,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "View selection for volume rendering",
                "PaperDOI": "10.1109/VISUAL.2005.1532833",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532833",
                "firstage": "487",
                "Lastage": "494",
                "IEEEXPLOREArticleNumber": "1532833",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint \"goodness\" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests \"interesting\" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the \"interesting\" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.",
                "AuthorNames": "Bordoloi, U.D.;Han-Wei Shen",
                "FirstAuthorAffiliation": "Ohio State Univ., Columbus, OH, USA|c|;",
                "AuthorIDs": "37561558700;37279493500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bordoloi, U.D.;Han-Wei Shen",
                "filename": "bordoloi_vis_05",
                "Citations": "885694;1250386;1532834;964516"
            }
        },
        {
            "name": "Pang, A.",
            "value": 280,
            "numPapers": 94,
            "cluster": "6",
            "index": 304,
            "weight": 28,
            "x": 538.7984614643129,
            "y": 523.7857710486506,
            "px": 553.0491706308785,
            "py": 592.9440041089781,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "UFLOW: visualizing uncertainty in fluid flow",
                "PaperDOI": "10.1109/VISUAL.1996.568116",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568116",
                "firstage": "249",
                "Lastage": "254",
                "IEEEXPLOREArticleNumber": "568116",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.",
                "AuthorNames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;;",
                "AuthorIDs": "37298532100;37267352000;38242145300;37351416000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "filename": "lodha2_vis_96",
                "Citations": "235199;568105;485141;346315"
            }
        },
        {
            "name": "Kaufman, A.",
            "value": 476,
            "numPapers": 137,
            "cluster": "5",
            "index": 305,
            "weight": 46,
            "x": 152.05509297961135,
            "y": 409.14580629535925,
            "px": 190.1516985568858,
            "py": 445.83240404634563,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Toward a Multi-Analyst, Collaborative Framework for Visual Analytics",
                "PaperDOI": "10.1109/VAST.2006.261439",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261439",
                "firstage": "129",
                "Lastage": "136",
                "IEEEXPLOREArticleNumber": "4035757",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts",
                "AuthorNames": "Brennan, S.E.;Mueller, K.;Zelinsky, G.;Ramakrishnan, I.;Warren, D.S.;Kaufman, A.",
                "FirstAuthorAffiliation": "Stony Brook Univ., NY|c|;;;;;",
                "AuthorIDs": "37840264500;37273119700;37418690100;37284911300;37344836300;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brennan, S.E.;Mueller, K.;Zelinsky, G.;Ramakrishnan, I.;Warren, D.S.;Kaufman, A.",
                "filename": "brennan_vast_06",
                "Citations": ""
            }
        },
        {
            "name": "Vilanova Bartroli, A.V.",
            "value": 43,
            "numPapers": 2,
            "cluster": "5",
            "index": 306,
            "weight": 1,
            "x": 51.40192813515158,
            "y": 796.7031392499364,
            "px": -189.9495540107173,
            "py": 985.8252844608803,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Nonlinear virtual colon unfolding",
                "PaperDOI": "10.1109/VISUAL.2001.964540",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964540",
                "firstage": "411",
                "Lastage": "418",
                "IEEEXPLOREArticleNumber": "964540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.",
                "AuthorNames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37728231400;37267822600;38180242000;38471589800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "filename": "bartoli_vis_01",
                "Citations": "636786;809914"
            }
        },
        {
            "name": "Konig, A.",
            "value": 43,
            "numPapers": 2,
            "cluster": "5",
            "index": 307,
            "weight": 1,
            "x": 1177.5123895380561,
            "y": 1333.5183027343694,
            "px": 1904.5647900074825,
            "py": 2044.5561540132678,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Nonlinear virtual colon unfolding",
                "PaperDOI": "10.1109/VISUAL.2001.964540",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964540",
                "firstage": "411",
                "Lastage": "418",
                "IEEEXPLOREArticleNumber": "964540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.",
                "AuthorNames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37728231400;37267822600;38180242000;38471589800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "filename": "bartoli_vis_01",
                "Citations": "636786;809914"
            }
        },
        {
            "name": "Wei Zeng",
            "value": 16,
            "numPapers": 21,
            "cluster": "5",
            "index": 308,
            "weight": 1,
            "x": 955.3186499058924,
            "y": 975.4688430338308,
            "px": 1457.1562195950312,
            "py": 1344.5225819856187,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "Visualizing time-series on spirals",
                "PaperDOI": "10.1109/INFVIS.2001.963273",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963273",
                "firstage": "7",
                "Lastage": "13",
                "IEEEXPLOREArticleNumber": "963273",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identication of periodic patterns.",
                "AuthorNames": "Weber, M.;Alexa, M.;Muller, W.",
                "FirstAuthorAffiliation": "Technische Universitat Darmstadt|c|;;",
                "AuthorIDs": "37734022800;37267466700;38184260700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weber, M.;Alexa, M.;Muller, W.",
                "filename": "alexa_infovis_01",
                "Citations": "175794;885098;528685"
            }
        },
        {
            "name": "Hong, W.",
            "value": 17,
            "numPapers": 11,
            "cluster": "5",
            "index": 309,
            "weight": 1,
            "x": 1011.5277548680623,
            "y": 621.1229678049793,
            "px": 1547.9113165220301,
            "py": 685.5493508955843,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "A Pipeline for Computer Aided Polyp Detection",
                "PaperDOI": "10.1109/TVCG.2006.112",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.112",
                "firstage": "861",
                "Lastage": "868",
                "IEEEXPLOREArticleNumber": "4015440",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy",
                "AuthorNames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stony Brook Univ., NY|c|;;",
                "AuthorIDs": "37277099300;37416126400;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "filename": "hong_vis_06",
                "Citations": "964540;1372236;235231;1250384"
            }
        },
        {
            "name": "Obermaier, H.",
            "value": 3,
            "numPapers": 23,
            "cluster": "6",
            "index": 310,
            "weight": 4,
            "x": 661.8232600306217,
            "y": 425.3118749261919,
            "px": 720.427472634335,
            "py": 463.2538534774524,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles",
                "PaperDOI": "10.1109/TVCG.2013.141",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.141",
                "firstage": "2743",
                "Lastage": "2752",
                "IEEEXPLOREArticleNumber": "6634122",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.",
                "AuthorNames": "Hummel, M.;Obermaier, H.;Garth, C.;Joy, K.I.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hummel, M.;Obermaier, H.;Garth, C.;Joy, K.I.",
                "filename": "hummel_vis_13",
                "Citations": "6064958;568116;5613488;5613483;4376175"
            }
        },
        {
            "name": "Tasdizen, T.",
            "value": 163,
            "numPapers": 11,
            "cluster": "5",
            "index": 311,
            "weight": 4,
            "x": 165.56139150111363,
            "y": 331.6375218428949,
            "px": 163.33505353202315,
            "py": 297.48100559427684,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Statistically quantitative volume visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532807",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532807",
                "firstage": "287",
                "Lastage": "294",
                "IEEEXPLOREArticleNumber": "1532807",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined \"fuzzy\" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.",
                "AuthorNames": "Kniss, J.M.;Van Uitert, R.;Stephens, A.;Li, G.-S.;Tasdizen, T.;Hansen, C.",
                "FirstAuthorAffiliation": "Utah Univ., Salt Lake City, UT, USA|c|;;;;;",
                "AuthorIDs": "37324263400;37266085500;37567174900;37558766900;37265762400;37266777200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kniss, J.;Van Uitert, R.;Stephens, A.;Li, G.-S.;Tasdizen, T.;Hansen, C.",
                "filename": "kniss_vis_05",
                "Citations": "1250386;745311;1372190;663875"
            }
        },
        {
            "name": "Baudel, T.",
            "value": 25,
            "numPapers": 24,
            "cluster": "3",
            "index": 312,
            "weight": 1,
            "x": 1042.029724177966,
            "y": 641.827899478488,
            "px": 1642.780576064642,
            "py": 490.4448491295447,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Decision Exploration Lab: A Visual Analytics Solution for Decision Management",
                "PaperDOI": "10.1109/TVCG.2013.146",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.146",
                "firstage": "1972",
                "Lastage": "1981",
                "IEEEXPLOREArticleNumber": "6634184",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.",
                "AuthorNames": "Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.",
                "FirstAuthorAffiliation": "IBM France Center for Adv. Studies, Univ. of Groningen, Groningen, France|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.",
                "filename": "broeksema_vast_13",
                "Citations": "175815;6102463;5652398;4677361;4677363;6064996;6102457"
            }
        },
        {
            "name": "Grosjean, J.",
            "value": 67,
            "numPapers": 1,
            "cluster": "3",
            "index": 313,
            "weight": 1,
            "x": -1040.4012075860517,
            "y": -9.147309499543617,
            "px": -1725.0349509198988,
            "py": -272.45680679975993,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation",
                "PaperDOI": "10.1109/INFVIS.2002.1173148",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173148",
                "firstage": "57",
                "Lastage": "64",
                "IEEEXPLOREArticleNumber": "1173148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.",
                "AuthorNames": "Plaisant, C.;Grosjean, J.;Bederson, B.B.",
                "FirstAuthorAffiliation": "Human-Comput. Interaction Lab., Maryland Univ., MD, USA|c|;;",
                "AuthorIDs": "37283026800;37279773300;37279760100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Plaisant, C.;Grosjean, J.;Bederson, B.B.",
                "filename": "plaisant_infovis_02",
                "Citations": "567745"
            }
        },
        {
            "name": "Bederson, B.B.",
            "value": 125,
            "numPapers": 7,
            "cluster": "3",
            "index": 314,
            "weight": 3,
            "x": 11.981171343393136,
            "y": 518.804663778502,
            "px": -16.983445028354435,
            "py": 478.87829317016013,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "NetLens: Iterative Exploration of Content-Actor Network Data",
                "PaperDOI": "10.1109/VAST.2006.261426",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261426",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "4035752",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases",
                "AuthorNames": "Hyunmo Kang;Plaisant, C.;Bongshin Lee;Bederson, B.B.",
                "FirstAuthorAffiliation": "Univ. of Maryland Inst. for Adv. Comput. Studies|c|;;;",
                "AuthorIDs": "37291403000;37283026800;37293389400;37279760100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hyunmo Kang;Plaisant, C.;Bongshin Lee;Bederson, B.B.",
                "filename": "kang_vast_06",
                "Citations": "1382886;559210;1532136"
            }
        },
        {
            "name": "Donghao Ren",
            "value": 11,
            "numPapers": 34,
            "cluster": "2",
            "index": 315,
            "weight": 2,
            "x": 316.19545558862427,
            "y": 278.9937548321893,
            "px": 815.7776485846782,
            "py": 386.6832385071223,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2013.150",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.150",
                "firstage": "2625",
                "Lastage": "2633",
                "IEEEXPLOREArticleNumber": "6634155",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.",
                "AuthorNames": "Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception (Minist. of Educ.) & Sch. of EECS, Peking Univ., Beijing, China|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo",
                "filename": "yuan_infovis_13",
                "Citations": "1532142;5290705;5613440;1249015;146402;6400488;663866;485140;5613439;5290702;4035763;809866;1382891;1382892;1382893;5290704;4658123;1173151"
            }
        },
        {
            "name": "Cong Guo",
            "value": 11,
            "numPapers": 18,
            "cluster": "2",
            "index": 316,
            "weight": 2,
            "x": 318.10553218556186,
            "y": 325.2829430357853,
            "px": 816.6943575953128,
            "py": 385.6186563407725,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2013.150",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.150",
                "firstage": "2625",
                "Lastage": "2633",
                "IEEEXPLOREArticleNumber": "6634155",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.",
                "AuthorNames": "Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception (Minist. of Educ.) & Sch. of EECS, Peking Univ., Beijing, China|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo",
                "filename": "yuan_infovis_13",
                "Citations": "1532142;5290705;5613440;1249015;146402;6400488;663866;485140;5613439;5290702;4035763;809866;1382891;1382892;1382893;5290704;4658123;1173151"
            }
        },
        {
            "name": "Dimsdale, Bernard",
            "value": 239,
            "numPapers": 1,
            "cluster": "2",
            "index": 317,
            "weight": 7,
            "x": 570.2444030986607,
            "y": 490.63417902557745,
            "px": 513.9767916643175,
            "py": 421.46702515040704,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Parallel coordinates: a tool for visualizing multi-dimensional geometry",
                "PaperDOI": "10.1109/VISUAL.1990.146402",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146402",
                "firstage": "361",
                "Lastage": "378",
                "IEEEXPLOREArticleNumber": "146402",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A methodology for visualizing analytic and synthetic geometry in RN is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point - line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R N. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications to Air Traffic Control, Robotics, Computer Vision, Computational Geometry, Statistics, Instrumentation and other areas are discussed.",
                "AuthorNames": "Inselberg, A.;Dimsdale, Bernard",
                "FirstAuthorAffiliation": "IBM Sci. Center, Los Angeles, CA, USA|c|;",
                "AuthorIDs": "37294162600;37426169800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Inselberg, A.;Dimsdale, Bernard",
                "filename": "inselberg_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Bergeron, R.D.",
            "value": 107,
            "numPapers": 22,
            "cluster": "2",
            "index": 318,
            "weight": 4,
            "x": 74.35534267639073,
            "y": 598.5439756370099,
            "px": 89.93058047336392,
            "py": 506.49604039219554,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "Multivariate visualization using metric scaling",
                "PaperDOI": "10.1109/VISUAL.1997.663866",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663866",
                "firstage": "111",
                "Lastage": "118",
                "IEEEXPLOREArticleNumber": "663866",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The authors present an efficient visualization approach to support multivariate data exploration through a simple but effective low dimensional data overview based on metric scaling. A multivariate dataset is first transformed into a set of dissimilarities between all pairs of data records. A graph configuration algorithm based on principal components is then wed to determine the display coordinates of the data records in the low dimensional data overview. This overview provides a graphical summary of the multivariate data with reduced data dimensions, reduced data size, and additional data semantics. It can be used to enhance multidimensional data brushing, or to arrange the layout of other conventional multivariate visualization techniques. Real life data is used to demonstrate the approach.",
                "AuthorNames": "Pak Chung Wong;Bergeron, R.D.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;",
                "AuthorIDs": ";37342054500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pak Chung Wong;Bergeron, R.D.",
                "filename": "wong1_vis_97",
                "Citations": "480811;485139;346302;567800;398864;146387"
            }
        },
        {
            "name": "Dwyer, T.",
            "value": 48,
            "numPapers": 27,
            "cluster": "3",
            "index": 319,
            "weight": 1,
            "x": -659.5532848941685,
            "y": 168.43681274640505,
            "px": -1128.7585034208118,
            "py": -19.171848471057107,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Untangling Euler Diagrams",
                "PaperDOI": "10.1109/TVCG.2010.210",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.210",
                "firstage": "1090",
                "Lastage": "1099",
                "IEEEXPLOREArticleNumber": "5613447",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.",
                "AuthorNames": "Riche, N.H.;Dwyer, T.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37590950700;38359965100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Riche, N.H.;Dwyer, T.",
                "filename": "riche_infovis_10",
                "Citations": "4658148;4376154;1532126;4658145;5290706;4015435;4015416;4658142;4015424;398863;4658123"
            }
        },
        {
            "name": "Marriott, K.",
            "value": 15,
            "numPapers": 15,
            "cluster": "3",
            "index": 320,
            "weight": 1,
            "x": 5.554681015662522,
            "y": -16.174255570262943,
            "px": 33.701098990948154,
            "py": -304.5834176941137,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Mapping Text with Phrase Nets",
                "PaperDOI": "10.1109/TVCG.2009.165",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.165",
                "firstage": "1169",
                "Lastage": "1176",
                "IEEEXPLOREArticleNumber": "5290726",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.",
                "AuthorNames": "van Ham, F.;Wattenberg, M.;Viegas, F.B.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37326291000;37550759700;37681355300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Ham, F.;Wattenberg, M.;Viegas, F.B.",
                "filename": "vanham2_infovis_09",
                "Citations": "4658133;1532781;4376131"
            }
        },
        {
            "name": "Teng-Yok Lee",
            "value": 40,
            "numPapers": 27,
            "cluster": "5",
            "index": 321,
            "weight": 2,
            "x": 530.2523224212888,
            "y": 369.1369719501959,
            "px": 526.1156752048373,
            "py": 379.4909227769891,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "An Information-Theoretic Framework for Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2010.131",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.131",
                "firstage": "1216",
                "Lastage": "1224",
                "IEEEXPLOREArticleNumber": "5613461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize 2D and 3D flow data.",
                "AuthorNames": "Lijie Xu;Teng-Yok Lee;Han-Wei Shen",
                "FirstAuthorAffiliation": "Ohio State Univ., Columbus, OH, USA|c|;;",
                "AuthorIDs": "37598369700;37403060100;37279493500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lijie Xu;Teng-Yok Lee;Han-Wei Shen",
                "filename": "xu_vis_10",
                "Citations": "4658159;4376173;4376165;4015449;4015453;1532832;1532831;4658174;885690;1532833;4376210;1183785"
            }
        },
        {
            "name": "Chiricota, Y.",
            "value": 54,
            "numPapers": 18,
            "cluster": "3",
            "index": 322,
            "weight": 1,
            "x": -942.4747425112708,
            "y": 46.71382414037642,
            "px": -1545.5979299756245,
            "py": -173.93994624207005,
            "node": {
                "Conference": "InfoVis",
                "Year": "2003",
                "PaperTitle": "Multiscale Visualization of Small World Networks",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=1947385",
                "firstage": "75",
                "Lastage": "84",
                "IEEEXPLOREArticleNumber": "1249011",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Many networks under study in Information Visualization are \"small world\" networks. These networks first appeared in the study social networks and were shown to be relevant models in other application domains such as software reverse engineering and biology. Furthermore, many of these networks actually have a multiscale nature: they can be viewed as a network of groups that are themselves small world networks. We describe a metric that has been designed in order to identify the weakest edges in a small world network leading to an easy and low cost filtering procedure that breaks up a graph into smaller and highly connected components. We show how this metric can be exploited through an interactive navigation of the network based on semantic zooming. Once the network is decomposed into a hierarchy of sub-networks, a user can easily find groups and subgroups of actors and understand their dynamics.",
                "AuthorNames": "Aubert, D.;Chiricota Y.;Jourdan F.;Melançon, G.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "x",
                "Dedupedauthornames": "Aubert, D.;Chiricota, Y.;Jourdan, F.;MelanÃ§on, G.",
                "filename": "auber_infovis_03",
                "Citations": ""
            }
        },
        {
            "name": "Kastner, J.",
            "value": 3,
            "numPapers": 14,
            "cluster": "5",
            "index": 323,
            "weight": 1,
            "x": -435.8276918026116,
            "y": -433.49454027852585,
            "px": -849.4151198112836,
            "py": -933.9177167461118,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms",
                "PaperDOI": "10.1109/TVCG.2012.231",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.231",
                "firstage": "2355",
                "Lastage": "2363",
                "IEEEXPLOREArticleNumber": "6327240",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.",
                "AuthorNames": "Cheuk Yiu Ip;Varshney, A.;JaJa, J.",
                "FirstAuthorAffiliation": "Inst. for Adv. Comput. Studies, Univ. of Maryland, College Park, MD, USA|c|;;",
                "AuthorIDs": "37586231900;37282560200;37276261200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cheuk Yiu Ip;Varshney, A.;JaJa, J.",
                "filename": "ip_vis_12",
                "Citations": "5613460;5290763;809932;1532795;1250370;5613476;4658153;6064952;6064956;4015448;6064936;4376207;5290751;4015460"
            }
        },
        {
            "name": "Lins, L.",
            "value": 29,
            "numPapers": 17,
            "cluster": "3",
            "index": 324,
            "weight": 1,
            "x": 130.50692078714565,
            "y": 1267.5450780722542,
            "px": -70.93485457465452,
            "py": 1496.2014062542162,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Nanocubes for Real-Time Exploration of Spatiotemporal Datasets",
                "PaperDOI": "10.1109/TVCG.2013.179",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.179",
                "firstage": "2456",
                "Lastage": "2465",
                "IEEEXPLOREArticleNumber": "6634137",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.",
                "AuthorNames": "Lins, L.;Klosowski, J.T.;Scheidegger, C.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lins, L.;Klosowski, J.T.;Scheidegger, C.E.",
                "filename": "lins_infovis_13",
                "Citations": "4015421;1173141;5290718;4677357;4376133;1173156;146386;6064996"
            }
        },
        {
            "name": "Schultz, T.",
            "value": 44,
            "numPapers": 36,
            "cluster": "6",
            "index": 325,
            "weight": 2,
            "x": 710.8918514910816,
            "y": 531.4675874843359,
            "px": 842.5129576089331,
            "py": 630.7015966633743,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Superquadric Glyphs for Symmetric Second-Order Tensors",
                "PaperDOI": "10.1109/TVCG.2010.199",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.199",
                "firstage": "1595",
                "Lastage": "1604",
                "IEEEXPLOREArticleNumber": "5613502",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.",
                "AuthorNames": "Schultz, T.;Kindlmann, G.L.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of Chicago, Chicago, IL, USA|c|;",
                "AuthorIDs": "38264158700;38265362700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schultz, T.;Kindlmann, G.",
                "filename": "schultz_vis_10",
                "Citations": "809905;4015499;745294;4015482;175773;5290754;4015498;5290756;5613473;398849;1250414;346326;663929;1183797;1250376;1532774;1372188;4015487"
            }
        },
        {
            "name": "Westin, C.-F.",
            "value": 72,
            "numPapers": 22,
            "cluster": "6",
            "index": 326,
            "weight": 2,
            "x": 430.4678170160895,
            "y": -15.97503105953982,
            "px": 585.9910843770795,
            "py": 513.9636927653036,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Invariant Crease Lines for Topological and Structural Analysis of Tensor fields",
                "PaperDOI": "10.1109/TVCG.2008.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.148",
                "firstage": "1627",
                "Lastage": "1634",
                "IEEEXPLOREArticleNumber": "4658184",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.",
                "AuthorNames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;",
                "AuthorIDs": "37282575100;37282742400;37294318400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "filename": "tricoche_vis_08",
                "Citations": "1372212;4376179;809896;175773;346326;346326;146359;4376174"
            }
        },
        {
            "name": "Gasteiger, R.",
            "value": 23,
            "numPapers": 20,
            "cluster": "5",
            "index": 327,
            "weight": 7,
            "x": 548.8298651521058,
            "y": 685.8736867676245,
            "px": 487.89983047586173,
            "py": 552.9302206969544,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates",
                "PaperDOI": "10.1109/TVCG.2013.189",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.189",
                "firstage": "2773",
                "Lastage": "2782",
                "IEEEXPLOREArticleNumber": "6634153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.",
                "AuthorNames": "Kohler, B.;Gasteiger, R.;Preim, U.;Theisel, H.;Gutberlet, M.;Preim, B.",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kohler, B.;Gasteiger, R.;Preim, U.;Theisel, H.;Gutberlet, M.;Preim, B.",
                "filename": "kohler_vis_13",
                "Citations": "6064971;809869;5613474;809896;6064983;4376212;1372213;5613472"
            }
        },
        {
            "name": "Olivan Bescos, J.",
            "value": 35,
            "numPapers": 12,
            "cluster": "5",
            "index": 328,
            "weight": 2,
            "x": 241.9707511413619,
            "y": 231.9822245741056,
            "px": 148.35855361674547,
            "py": 208.56887329286064,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Exploration of 4D MRI Blood Flow using Stylistic Visualization",
                "PaperDOI": "10.1109/TVCG.2010.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.153",
                "firstage": "1339",
                "Lastage": "1347",
                "IEEEXPLOREArticleNumber": "5613474",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.",
                "AuthorNames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "FirstAuthorAffiliation": "Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;",
                "AuthorIDs": "37390973400;37591606800;37374875300;37603313200;37284271200;;37282551500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "filename": "vanpelt_vis_10",
                "Citations": "4015467;5290742"
            }
        },
        {
            "name": "Clough, R.E.",
            "value": 35,
            "numPapers": 12,
            "cluster": "5",
            "index": 329,
            "weight": 2,
            "x": 175.83360823644668,
            "y": 373.05210521464227,
            "px": 383.16171149955255,
            "py": 40.90504296708592,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Exploration of 4D MRI Blood Flow using Stylistic Visualization",
                "PaperDOI": "10.1109/TVCG.2010.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.153",
                "firstage": "1339",
                "Lastage": "1347",
                "IEEEXPLOREArticleNumber": "5613474",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.",
                "AuthorNames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "FirstAuthorAffiliation": "Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;",
                "AuthorIDs": "37390973400;37591606800;37374875300;37603313200;37284271200;;37282551500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "filename": "vanpelt_vis_10",
                "Citations": "4015467;5290742"
            }
        },
        {
            "name": "ter Haar Romenij, B.",
            "value": 40,
            "numPapers": 21,
            "cluster": "5",
            "index": 330,
            "weight": 2,
            "x": 303.43506393637495,
            "y": 262.85376768058075,
            "px": 134.29450645209556,
            "py": 157.72135891773723,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Parameter Sensitivity Visualization for DTI fiber Tracking",
                "PaperDOI": "10.1109/TVCG.2009.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.170",
                "firstage": "1441",
                "Lastage": "1448",
                "IEEEXPLOREArticleNumber": "5290759",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.",
                "AuthorNames": "Brecheisen, R.;Vilanova, A.;Platel, B.;ter Haar Romeny, B.",
                "FirstAuthorAffiliation": "Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;;",
                "AuthorIDs": "38108879500;37282551500;37428377700;38180036400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brecheisen, R.;Vilanova, A.;Platel, B.;ter Haar Romenij, B.",
                "filename": "brecheis_vis_09",
                "Citations": "4658169;1532853;4376198;1532778;1532779;568116;809894;1372220;964552"
            }
        },
        {
            "name": "Kapler, T.",
            "value": 150,
            "numPapers": 8,
            "cluster": "2",
            "index": 331,
            "weight": 2,
            "x": -67.55931976159549,
            "y": -648.9481023522704,
            "px": 185.17957949784105,
            "py": -196.44112230134624,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "GeoTime Information Visualization",
                "PaperDOI": "10.1109/INFVIS.2004.27",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.27",
                "firstage": "25",
                "Lastage": "32",
                "IEEEXPLOREArticleNumber": "1382887",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks",
                "AuthorNames": "Kapler, T.;Wright, W.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37704437500;37654961400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kapler, T.;Wright, W.",
                "filename": "kapler_infovis_04",
                "Citations": "1249006"
            }
        },
        {
            "name": "Wright, W.",
            "value": 157,
            "numPapers": 12,
            "cluster": "2",
            "index": 332,
            "weight": 3,
            "x": 261.93676975106314,
            "y": 102.72665733462208,
            "px": 168.37591362908955,
            "py": -230.99332663887037,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "GeoTime Information Visualization",
                "PaperDOI": "10.1109/INFVIS.2004.27",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.27",
                "firstage": "25",
                "Lastage": "32",
                "IEEEXPLOREArticleNumber": "1382887",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks",
                "AuthorNames": "Kapler, T.;Wright, W.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37704437500;37654961400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kapler, T.;Wright, W.",
                "filename": "kapler_infovis_04",
                "Citations": "1249006"
            }
        },
        {
            "name": "Kurzhals, K.",
            "value": 2,
            "numPapers": 9,
            "cluster": "5",
            "index": 333,
            "weight": 1,
            "x": -636.1043009308705,
            "y": 431.295435010079,
            "px": -1074.5688415879938,
            "py": 694.5495950331409,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Evaluation of Fast-Forward Video Visualization",
                "PaperDOI": "10.1109/TVCG.2012.222",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.222",
                "firstage": "2095",
                "Lastage": "2103",
                "IEEEXPLOREArticleNumber": "6327214",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.",
                "AuthorNames": "Hoferlin, M.;Kurzhals, K.;Hoferlin, B.;Heidemann, G.;Weiskopf, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37680797500;38489885500;37571601300;37266102100;37268045000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hoferlin, M.;Kurzhals, K.;Hoferlin, B.;Heidemann, G.;Weiskopf, D.",
                "filename": "hoeferlin_vis_12",
                "Citations": "4376200;4376141;4658146;4376146;4015469"
            }
        },
        {
            "name": "Cowley, W.",
            "value": 81,
            "numPapers": 13,
            "cluster": "2",
            "index": 334,
            "weight": 2,
            "x": -819.966124433419,
            "y": 396.41058149874834,
            "px": -1613.3713640144724,
            "py": 688.8899857228809,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "firstage": "105",
                "Lastage": "111",
                "IEEEXPLOREArticleNumber": "885097",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as AÔåÆBÔåÆCÔåÆD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "filename": "wong_infovis_00",
                "Citations": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Andrews, C.",
            "value": 16,
            "numPapers": 22,
            "cluster": "3",
            "index": 335,
            "weight": 3,
            "x": 185.64932749368597,
            "y": 1542.7588280188072,
            "px": 132.54262943829428,
            "py": 1119.7673545256916,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays",
                "PaperDOI": "10.1109/VAST.2012.6400559",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400559",
                "firstage": "123",
                "Lastage": "131",
                "IEEEXPLOREArticleNumber": "6400559",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.",
                "AuthorNames": "Andrews, C.;North, C.",
                "FirstAuthorAffiliation": "Virginia Tech, Blacksburg, VA, USA|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Andrews, C.;North, C.",
                "filename": "andrews_vast_12",
                "Citations": "4658127;4677362;1382887;4677358;4015437;4388992;5652880;6102449;4389006;6102438;5333878"
            }
        },
        {
            "name": "Rind, A.",
            "value": 18,
            "numPapers": 16,
            "cluster": "3",
            "index": 336,
            "weight": 1,
            "x": 73.97221996001399,
            "y": 1021.2106781939019,
            "px": -125.21820815624963,
            "py": 1164.1701369106627,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data",
                "PaperDOI": "10.1109/TVCG.2013.206",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.206",
                "firstage": "2247",
                "Lastage": "2256",
                "IEEEXPLOREArticleNumber": "6634096",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.",
                "AuthorNames": "Rind, A.;Lammarsch, T.;Aigner, W.;Alsallakh, B.;Miksch, S.",
                "FirstAuthorAffiliation": "Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rind, A.;Lammarsch, T.;Aigner, W.;Alsallakh, B.;Miksch, S.",
                "filename": "rind_vast_13",
                "Citations": "5290720;1382904;6102446;4035745;885086;5613453;4015439;1382905;6634112;1173155;6064996;5613455;636792"
            }
        },
        {
            "name": "Lammarsch, T.",
            "value": 18,
            "numPapers": 17,
            "cluster": "3",
            "index": 337,
            "weight": 1,
            "x": 935.2128955070953,
            "y": 649.5582969980585,
            "px": 1428.7553098016465,
            "py": 507.3388813503803,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data",
                "PaperDOI": "10.1109/TVCG.2013.206",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.206",
                "firstage": "2247",
                "Lastage": "2256",
                "IEEEXPLOREArticleNumber": "6634096",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.",
                "AuthorNames": "Rind, A.;Lammarsch, T.;Aigner, W.;Alsallakh, B.;Miksch, S.",
                "FirstAuthorAffiliation": "Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rind, A.;Lammarsch, T.;Aigner, W.;Alsallakh, B.;Miksch, S.",
                "filename": "rind_vast_13",
                "Citations": "5290720;1382904;6102446;4035745;885086;5613453;4015439;1382905;6634112;1173155;6064996;5613455;636792"
            }
        },
        {
            "name": "Legg, P.A.",
            "value": 13,
            "numPapers": 14,
            "cluster": "10",
            "index": 338,
            "weight": 1,
            "x": -143.3268494544784,
            "y": 384.5880369876774,
            "px": -511.12555860255645,
            "py": 550.420940497679,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "firstage": "2109",
                "Lastage": "2118",
                "IEEEXPLOREArticleNumber": "6634165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.",
                "filename": "legg_vast_13",
                "Citations": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Chung, D.H.S.",
            "value": 13,
            "numPapers": 14,
            "cluster": "10",
            "index": 339,
            "weight": 1,
            "x": -1209.0889963186191,
            "y": -14.909304979467418,
            "px": -2465.7550678155458,
            "py": -143.66349015501444,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "firstage": "2109",
                "Lastage": "2118",
                "IEEEXPLOREArticleNumber": "6634165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.",
                "filename": "legg_vast_13",
                "Citations": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Parry, M.L.",
            "value": 13,
            "numPapers": 14,
            "cluster": "10",
            "index": 340,
            "weight": 1,
            "x": -89.32351732084469,
            "y": 426.1254047796412,
            "px": -408.2726814148407,
            "py": 616.392469485504,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "firstage": "2109",
                "Lastage": "2118",
                "IEEEXPLOREArticleNumber": "6634165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.",
                "filename": "legg_vast_13",
                "Citations": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Griffiths, I.W.",
            "value": 13,
            "numPapers": 14,
            "cluster": "10",
            "index": 341,
            "weight": 1,
            "x": 1731.702557282996,
            "y": -999.1164208642818,
            "px": 2825.645769116384,
            "py": -1918.0285188673497,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "firstage": "2109",
                "Lastage": "2118",
                "IEEEXPLOREArticleNumber": "6634165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.;Griffiths, I.W.;Chen, M.",
                "filename": "legg_vast_13",
                "Citations": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Daniel, G.",
            "value": 42,
            "numPapers": 1,
            "cluster": "10",
            "index": 342,
            "weight": 1,
            "x": -515.2794211817777,
            "y": 204.6483247943331,
            "px": -1187.3808038900297,
            "py": 250.71807343447568,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Video visualization",
                "PaperDOI": "10.1109/VISUAL.2003.1250401",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250401",
                "firstage": "409",
                "Lastage": "416",
                "IEEEXPLOREArticleNumber": "1250401",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for \"summarizing\" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing \"relative\" and \"absolute\" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.",
                "AuthorNames": "Daniel, G.;Chen, M.",
                "FirstAuthorAffiliation": "Univ. of Wales Swansea, UK|c|;",
                "AuthorIDs": "38201565200;37280982800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Daniel, G.;Chen, M.",
                "filename": "daniel_vis_03",
                "Citations": "1183790"
            }
        },
        {
            "name": "Entezari, A.",
            "value": 50,
            "numPapers": 39,
            "cluster": "5",
            "index": 343,
            "weight": 8,
            "x": 314.2811900705538,
            "y": -172.24213646820678,
            "px": 358.401835836449,
            "py": -309.0482659919079,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Texture-based visualization of uncertainty in flow fields",
                "PaperDOI": "10.1109/VISUAL.2005.1532853",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532853",
                "firstage": "647",
                "Lastage": "654",
                "IEEEXPLOREArticleNumber": "1532853",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.",
                "AuthorNames": "Botchen, R.P.;Weiskopf, D.;Ertl, T.",
                "FirstAuthorAffiliation": "Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37565744300;37268045000;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Botchen, R.P.;Weiskopf, D.;Ertl, T.",
                "filename": "botchen_vis_05",
                "Citations": "567784;885689;568116"
            }
        },
        {
            "name": "Marschner, S.R.",
            "value": 88,
            "numPapers": 1,
            "cluster": "5",
            "index": 344,
            "weight": 3,
            "x": -212.31738551041988,
            "y": 1088.2671851261475,
            "px": -87.77568816355738,
            "py": 611.447242295812,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "An evaluation of reconstruction filters for volume rendering",
                "PaperDOI": "10.1109/VISUAL.1994.346331",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346331",
                "firstage": "100",
                "Lastage": "107, C10",
                "IEEEXPLOREArticleNumber": "346331",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter",
                "AuthorNames": "Marschner, S.R.;Lobb, R.J.",
                "FirstAuthorAffiliation": "Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;",
                "AuthorIDs": "37333371500;37659292200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Marschner, S.R.;Lobb, R.J.",
                "filename": "marschner_vis_94",
                "Citations": "398851"
            }
        },
        {
            "name": "Lobb, R.J.",
            "value": 88,
            "numPapers": 1,
            "cluster": "5",
            "index": 345,
            "weight": 3,
            "x": 365.24418419045963,
            "y": 783.1934907336871,
            "px": 235.69220888454305,
            "py": 429.8742549995883,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "An evaluation of reconstruction filters for volume rendering",
                "PaperDOI": "10.1109/VISUAL.1994.346331",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346331",
                "firstage": "100",
                "Lastage": "107, C10",
                "IEEEXPLOREArticleNumber": "346331",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter",
                "AuthorNames": "Marschner, S.R.;Lobb, R.J.",
                "FirstAuthorAffiliation": "Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;",
                "AuthorIDs": "37333371500;37659292200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Marschner, S.R.;Lobb, R.J.",
                "filename": "marschner_vis_94",
                "Citations": "398851"
            }
        },
        {
            "name": "Interrante, V.",
            "value": 200,
            "numPapers": 25,
            "cluster": "5",
            "index": 346,
            "weight": 7,
            "x": 222.88661881558298,
            "y": 434.29050693471845,
            "px": 266.5669219527811,
            "py": 445.5587170102082,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.",
                "PaperDOI": "10.1109/TVCG.2007.70623",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70623",
                "firstage": "1270",
                "Lastage": "1277",
                "IEEEXPLOREArticleNumber": "4376150",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. - - We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.",
                "AuthorNames": "Hagh-Shenas, H.;Sunghee Kim;Interrante, V.;Healey, C.",
                "FirstAuthorAffiliation": "Boston Sci. Corp., Natick|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hagh-Shenas, H.;Sunghee Kim;Interrante, V.;Healey, C.",
                "filename": "shenas_infovis_07",
                "Citations": "1532140;1250362;809905;1532137"
            }
        },
        {
            "name": "Kochl, A.",
            "value": 48,
            "numPapers": 24,
            "cluster": "5",
            "index": 347,
            "weight": 7,
            "x": 415.02293369644445,
            "y": 627.1426594967025,
            "px": 439.78839315318095,
            "py": 716.2522798913446,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "firstage": "2858",
                "Lastage": "2867",
                "IEEEXPLOREArticleNumber": "6634141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "filename": "auzinger_vis_13",
                "Citations": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Sramek, M.",
            "value": 75,
            "numPapers": 18,
            "cluster": "5",
            "index": 348,
            "weight": 7,
            "x": 406.4181802097393,
            "y": 614.2192513814124,
            "px": 434.1081663870152,
            "py": 707.3886513194573,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Smart super views---A knowledge-assisted interface for medical visualization",
                "PaperDOI": "10.1109/VAST.2012.6400555",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400555",
                "firstage": "163",
                "Lastage": "172",
                "IEEEXPLOREArticleNumber": "6400555",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.",
                "AuthorNames": "Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, E.",
                "filename": "mistelbauer_vast_12",
                "Citations": "1250400;4015449;4376185;4376159;1183754;1532856;6064990;1532818;4015460"
            }
        },
        {
            "name": "Fleischmann, D.",
            "value": 215,
            "numPapers": 14,
            "cluster": "5",
            "index": 349,
            "weight": 17,
            "x": 543.4036093825439,
            "y": 158.14646149146205,
            "px": 601.4411999368733,
            "py": 108.51597618615178,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "firstage": "37",
                "Lastage": "44",
                "IEEEXPLOREArticleNumber": "1183754",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "filename": "kanitsar1_vis_02",
                "Citations": "964555;964538"
            }
        },
        {
            "name": "Mistelbauer, G.",
            "value": 9,
            "numPapers": 20,
            "cluster": "5",
            "index": 350,
            "weight": 4,
            "x": 826.4906904431213,
            "y": 1045.4731257031501,
            "px": 671.1053238803751,
            "py": 1016.4618017280228,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "firstage": "2858",
                "Lastage": "2867",
                "IEEEXPLOREArticleNumber": "6634141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "filename": "auzinger_vis_13",
                "Citations": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Baclija, I.",
            "value": 9,
            "numPapers": 20,
            "cluster": "5",
            "index": 351,
            "weight": 4,
            "x": 473.3814983437326,
            "y": 711.9917391620617,
            "px": 395.49335577292743,
            "py": 754.7410370027685,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "firstage": "2858",
                "Lastage": "2867",
                "IEEEXPLOREArticleNumber": "6634141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "filename": "auzinger_vis_13",
                "Citations": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Schernthaner, R.",
            "value": 9,
            "numPapers": 20,
            "cluster": "5",
            "index": 352,
            "weight": 4,
            "x": 149.46250767686072,
            "y": 354.82302708934617,
            "px": 169.13668823841786,
            "py": 507.52307919924226,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "firstage": "2858",
                "Lastage": "2867",
                "IEEEXPLOREArticleNumber": "6634141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "filename": "auzinger_vis_13",
                "Citations": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Wimmer, M.",
            "value": 6,
            "numPapers": 11,
            "cluster": "5",
            "index": 353,
            "weight": 2,
            "x": 566.4414785181814,
            "y": 792.5721595469704,
            "px": 243.2401103067373,
            "py": 644.3816815822012,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "firstage": "2858",
                "Lastage": "2867",
                "IEEEXPLOREArticleNumber": "6634141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "filename": "auzinger_vis_13",
                "Citations": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Straka, M.",
            "value": 39,
            "numPapers": 4,
            "cluster": "5",
            "index": 354,
            "weight": 1,
            "x": -48.106158703628495,
            "y": 522.769621061372,
            "px": -353.89218157753544,
            "py": 523.4661447580326,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "firstage": "385",
                "Lastage": "392",
                "IEEEXPLOREArticleNumber": "1372221",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "filename": "straka_vis_04",
                "Citations": "964538;1183754;964555"
            }
        },
        {
            "name": "Cervenansky, M.",
            "value": 39,
            "numPapers": 3,
            "cluster": "5",
            "index": 355,
            "weight": 1,
            "x": 544.5768156872676,
            "y": 219.6851324883419,
            "px": 689.2750087103947,
            "py": -3.673914568005972,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "firstage": "385",
                "Lastage": "392",
                "IEEEXPLOREArticleNumber": "1372221",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "filename": "straka_vis_04",
                "Citations": "964538;1183754;964555"
            }
        },
        {
            "name": "La Cruz, A.",
            "value": 39,
            "numPapers": 4,
            "cluster": "5",
            "index": 356,
            "weight": 1,
            "x": 621.354053109971,
            "y": -182.1191458591814,
            "px": 867.4113972634417,
            "py": -808.1667014052812,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "firstage": "385",
                "Lastage": "392",
                "IEEEXPLOREArticleNumber": "1372221",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "filename": "straka_vis_04",
                "Citations": "964538;1183754;964555"
            }
        },
        {
            "name": "Kanitsar, A.",
            "value": 300,
            "numPapers": 26,
            "cluster": "5",
            "index": 357,
            "weight": 22,
            "x": 286.92985390661084,
            "y": 403.13815694967377,
            "px": 266.6651833788191,
            "py": 467.62053871182076,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "firstage": "37",
                "Lastage": "44",
                "IEEEXPLOREArticleNumber": "1183754",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "filename": "kanitsar1_vis_02",
                "Citations": "964555;964538"
            }
        },
        {
            "name": "Viola, I.",
            "value": 118,
            "numPapers": 43,
            "cluster": "5",
            "index": 358,
            "weight": 4,
            "x": 364.3280989754281,
            "y": 488.277398909439,
            "px": 387.99662618139894,
            "py": 535.9067275714042,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Hardware-based nonlinear filtering and segmentation using high-level shading languages",
                "PaperDOI": "10.1109/VISUAL.2003.1250387",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250387",
                "firstage": "309",
                "Lastage": "316",
                "IEEEXPLOREArticleNumber": "1250387",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.",
                "AuthorNames": "Viola, I.;Kanitsar, A.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;",
                "AuthorIDs": "37282726800;37282727500;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viola, I.;Kanitsar, A.;Groller, E.",
                "filename": "viola_vis_03",
                "Citations": "1183766;1183762;809934"
            }
        },
        {
            "name": "Feixas, M.",
            "value": 68,
            "numPapers": 17,
            "cluster": "5",
            "index": 359,
            "weight": 3,
            "x": 601.8181539545361,
            "y": 380.1199732749746,
            "px": 529.7434687530398,
            "py": 469.9621831828625,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Importance-Driven Focus of Attention",
                "PaperDOI": "10.1109/TVCG.2006.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.152",
                "firstage": "933",
                "Lastage": "940",
                "IEEEXPLOREArticleNumber": "4015449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views",
                "AuthorNames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;;",
                "AuthorIDs": "37282726800;37426689600;37396572900;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, E.",
                "filename": "viola_vis_06",
                "Citations": "1532856;1532834;963286;1532833"
            }
        },
        {
            "name": "Sbert, M.",
            "value": 68,
            "numPapers": 17,
            "cluster": "5",
            "index": 360,
            "weight": 3,
            "x": 284.4638846657208,
            "y": 604.9131031676922,
            "px": 362.03988331153647,
            "py": 577.9263149125898,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Importance-Driven Focus of Attention",
                "PaperDOI": "10.1109/TVCG.2006.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.152",
                "firstage": "933",
                "Lastage": "940",
                "IEEEXPLOREArticleNumber": "4015449",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views",
                "AuthorNames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;;",
                "AuthorIDs": "37282726800;37426689600;37396572900;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, E.",
                "filename": "viola_vis_06",
                "Citations": "1532856;1532834;963286;1532833"
            }
        },
        {
            "name": "Felkel, P.",
            "value": 134,
            "numPapers": 7,
            "cluster": "5",
            "index": 361,
            "weight": 6,
            "x": -359.25237384915556,
            "y": 499.5014020693117,
            "px": -299.4157643633542,
            "py": 577.4331187280902,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "firstage": "37",
                "Lastage": "44",
                "IEEEXPLOREArticleNumber": "1183754",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "filename": "kanitsar1_vis_02",
                "Citations": "964555;964538"
            }
        },
        {
            "name": "Sandner, D.",
            "value": 45,
            "numPapers": 1,
            "cluster": "5",
            "index": 362,
            "weight": 2,
            "x": 462.0964561294153,
            "y": 871.5868921429831,
            "px": 253.08585452122688,
            "py": 622.9774362733189,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Computed tomography angiography: a case study of peripheral vessel investigation",
                "PaperDOI": "10.1109/VISUAL.2001.964555",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964555",
                "firstage": "477",
                "Lastage": "480",
                "IEEEXPLOREArticleNumber": "964555",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper deals with vessel exploration based on computed tomography angiography. Large image sequences of the lower extremities are investigated in a clinical environment. Two different approaches for peripheral vessel diagnosis dealing with stenosis and calcification detection are introduced. The paper presents an automated vessel-tracking tool for curved planar reformation. An interactive segmentation tool for bone removal is proposed.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Sandner, D.;Felkel, P.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37728392500;37267788200;37284271200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Sandner, D.;Felkel, P.;Groller, E.",
                "filename": "kanitsar_vis_01",
                "Citations": ""
            }
        },
        {
            "name": "Ji Soo Yi",
            "value": 122,
            "numPapers": 43,
            "cluster": "3",
            "index": 363,
            "weight": 2,
            "x": -967.9234758988339,
            "y": 509.33829602416984,
            "px": -97.88913194402816,
            "py": 557.1365392256831,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Toward a Deeper Understanding of the Role of Interaction in Information Visualization",
                "PaperDOI": "10.1109/TVCG.2007.70515",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70515",
                "firstage": "1224",
                "Lastage": "1231",
                "IEEEXPLOREArticleNumber": "4376144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.",
                "AuthorNames": "Ji Soo Yi;Youn ah Kang;Stasko, J.T.;Jacko, J.A.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ji Soo Yi;Youn-ah Kang;Stasko, J.;Jacko, J.A.",
                "filename": "yi_infovis_07",
                "Citations": "346302;1532136;559213;175794;1532126;885091;801860;885086"
            }
        },
        {
            "name": "Junping Zhang",
            "value": 40,
            "numPapers": 13,
            "cluster": "2",
            "index": 364,
            "weight": 2,
            "x": -144.80167712419637,
            "y": -424.48118938498726,
            "px": 217.66347013303402,
            "py": -233.08469922074343,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "firstage": "2159",
                "Lastage": "2168",
                "IEEEXPLOREArticleNumber": "6634174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "filename": "wang2_vast_13",
                "Citations": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Van De Wetering, H.",
            "value": 40,
            "numPapers": 13,
            "cluster": "2",
            "index": 365,
            "weight": 2,
            "x": 117.33864538716003,
            "y": -644.0716623346661,
            "px": 151.1596237503972,
            "py": -174.47909133308102,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "firstage": "2159",
                "Lastage": "2168",
                "IEEEXPLOREArticleNumber": "6634174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Van De Wetering, H.",
                "filename": "wang2_vast_13",
                "Citations": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Dinkla, K.",
            "value": 0,
            "numPapers": 13,
            "cluster": "3",
            "index": 366,
            "weight": 1,
            "x": -311.9458580723056,
            "y": 866.7414408592414,
            "px": -821.0782198385241,
            "py": 904.4977355289147,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Developing and Evaluating Quilts for the Depiction of Large Layered Graphs",
                "PaperDOI": "10.1109/TVCG.2011.187",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.187",
                "firstage": "2268",
                "Lastage": "2275",
                "IEEEXPLOREArticleNumber": "6064992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).",
                "AuthorNames": "Juhee Bae;Watson, B.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37595934400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Juhee Bae;Watson, B.",
                "filename": "bae_infovis_11",
                "Citations": "5613445;1382886;4376154"
            }
        },
        {
            "name": "Westenberg, M.A.",
            "value": 0,
            "numPapers": 14,
            "cluster": "3",
            "index": 367,
            "weight": 1,
            "x": -300.85347178290294,
            "y": 878.476181042081,
            "px": -805.812975029105,
            "py": 920.5717187561224,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Developing and Evaluating Quilts for the Depiction of Large Layered Graphs",
                "PaperDOI": "10.1109/TVCG.2011.187",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.187",
                "firstage": "2268",
                "Lastage": "2275",
                "IEEEXPLOREArticleNumber": "6064992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).",
                "AuthorNames": "Juhee Bae;Watson, B.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37595934400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Juhee Bae;Watson, B.",
                "filename": "bae_infovis_11",
                "Citations": "5613445;1382886;4376154"
            }
        },
        {
            "name": "Kincaid, R.",
            "value": 67,
            "numPapers": 11,
            "cluster": "3",
            "index": 368,
            "weight": 1,
            "x": 762.595153571501,
            "y": -180.82361187771255,
            "px": 1341.896484647426,
            "py": -801.815731066086,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context",
                "PaperDOI": "10.1109/TVCG.2008.117",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.117",
                "firstage": "1253",
                "Lastage": "1260",
                "IEEEXPLOREArticleNumber": "4658137",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.",
                "AuthorNames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC|c|;;;",
                "AuthorIDs": "37869962900;37349490300;37869963200;37587984100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "filename": "barsky_infovis_08",
                "Citations": "1532151;4015435;4015424"
            }
        },
        {
            "name": "Tominski, C.",
            "value": 48,
            "numPapers": 29,
            "cluster": "3",
            "index": 369,
            "weight": 1,
            "x": -104.89503638440739,
            "y": 859.2419966804603,
            "px": -416.6510899945477,
            "py": 879.3219434510896,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Stacking-Based Visualization of Trajectory Attribute Data",
                "PaperDOI": "10.1109/TVCG.2012.265",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.265",
                "firstage": "2565",
                "Lastage": "2574",
                "IEEEXPLOREArticleNumber": "6327262",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.",
                "AuthorNames": "Tominski, C.;Schumann, H.;Andrienko, G.;Andrienko, N.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37283236000;37283240400;37283047100;37283047700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tominski, C.;Schumann, H.;Andrienko, G.;Andrienko, N.",
                "filename": "tominski_infovis_12",
                "Citations": "5613442;6102455;5332593;480803;1382887;1532144;6102454"
            }
        },
        {
            "name": "Frank, A.",
            "value": 8,
            "numPapers": 13,
            "cluster": "3",
            "index": 370,
            "weight": 1,
            "x": -30.387296814280063,
            "y": -155.20595147619187,
            "px": -134.1601619900749,
            "py": -726.1380932288556,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "RelEx: Visualization for Actively Changing Overlay Network Specifications",
                "PaperDOI": "10.1109/TVCG.2012.255",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.255",
                "firstage": "2729",
                "Lastage": "2738",
                "IEEEXPLOREArticleNumber": "6327279",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.",
                "AuthorNames": "Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.",
                "FirstAuthorAffiliation": "Univ. of British Columbia, Vancouver, BC, Canada|c|;;;",
                "AuthorIDs": "37590945600;38490124000;37349490300;37299644000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.",
                "filename": "sedlmair2_infovis_12",
                "Citations": "4015417;1382904;6102443;4376154;5290695;5290690;801869;4658145;4658137;1532126;6327248;1249030;4035752"
            }
        },
        {
            "name": "Butz, A.",
            "value": 8,
            "numPapers": 17,
            "cluster": "3",
            "index": 371,
            "weight": 1,
            "x": -178.4604035529267,
            "y": 141.95153268147513,
            "px": -382.13382814069007,
            "py": -146.25242645436884,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "RelEx: Visualization for Actively Changing Overlay Network Specifications",
                "PaperDOI": "10.1109/TVCG.2012.255",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.255",
                "firstage": "2729",
                "Lastage": "2738",
                "IEEEXPLOREArticleNumber": "6327279",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.",
                "AuthorNames": "Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.",
                "FirstAuthorAffiliation": "Univ. of British Columbia, Vancouver, BC, Canada|c|;;;",
                "AuthorIDs": "37590945600;38490124000;37349490300;37299644000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.",
                "filename": "sedlmair2_infovis_12",
                "Citations": "4015417;1382904;6102443;4376154;5290695;5290690;801869;4658145;4658137;1532126;6327248;1249030;4035752"
            }
        },
        {
            "name": "Lundervold, A.",
            "value": 30,
            "numPapers": 24,
            "cluster": "2",
            "index": 372,
            "weight": 2,
            "x": 731.096359926878,
            "y": 305.0110429645763,
            "px": 719.3856243012488,
            "py": 251.9263786395951,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2012.256",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.256",
                "firstage": "2621",
                "Lastage": "2630",
                "IEEEXPLOREArticleNumber": "6327268",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.",
                "AuthorNames": "Turkay, C.;Lundervold, A.;Lundervold, A.J.;Hauser, H.",
                "FirstAuthorAffiliation": "Dept. of Inf., Univ. of Bergen, Bergen, Norway|c|;;;",
                "AuthorIDs": "37567685600;37373564100;38489275800;37274158800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Turkay, C.;Lundervold, A.;Lundervold, A.;Hauser, H.",
                "filename": "turkay_infovis_12",
                "Citations": "5290745;1532142;6102449;885086;346302;4658163;6065027;4376166;809866;1382891;1382892;5290704"
            }
        },
        {
            "name": "Crnovrsanin, T.",
            "value": 41,
            "numPapers": 11,
            "cluster": "2",
            "index": 373,
            "weight": 2,
            "x": -37.46641092257273,
            "y": -626.9996126846954,
            "px": 189.5332090418526,
            "py": -185.57500882363618,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "firstage": "2467",
                "Lastage": "2476",
                "IEEEXPLOREArticleNumber": "6327252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "filename": "landge_infovis_12",
                "Citations": "5290721;1382906"
            }
        },
        {
            "name": "Muelder, C.",
            "value": 60,
            "numPapers": 19,
            "cluster": "2",
            "index": 374,
            "weight": 2,
            "x": 196.9338438022209,
            "y": -327.5087691727674,
            "px": 136.13370199449406,
            "py": -185.6422502637293,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "firstage": "2467",
                "Lastage": "2476",
                "IEEEXPLOREArticleNumber": "6327252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "filename": "landge_infovis_12",
                "Citations": "5290721;1382906"
            }
        },
        {
            "name": "Holten, D.",
            "value": 142,
            "numPapers": 7,
            "cluster": "4",
            "index": 375,
            "weight": 1,
            "x": 58.93212630889361,
            "y": 714.4701784754376,
            "px": -367.8819742826012,
            "py": 915.8123483655378,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data",
                "PaperDOI": "10.1109/TVCG.2006.147",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.147",
                "firstage": "741",
                "Lastage": "748",
                "IEEEXPLOREArticleNumber": "4015425",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations",
                "AuthorNames": "Holten, D.",
                "FirstAuthorAffiliation": "Technische Univ. Eindhoven|c|",
                "AuthorIDs": "37827881300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Holten, D.",
                "filename": "holten_infovis_06",
                "Citations": "1382886;1249008;1532150;1249030;1532129;636718;1173152"
            }
        },
        {
            "name": "Lujin Wang",
            "value": 63,
            "numPapers": 21,
            "cluster": "5",
            "index": 376,
            "weight": 1,
            "x": 343.47991086414214,
            "y": 1801.4553497574725,
            "px": 702.0557076445275,
            "py": 3256.30416835807,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Color Design for Illustrative Visualization",
                "PaperDOI": "10.1109/TVCG.2008.118",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.118",
                "firstage": "1739",
                "Lastage": "1754",
                "IEEEXPLOREArticleNumber": "4658198",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.",
                "AuthorNames": "Lujin Wang;Giesen, J.;McDonnell, K.T.;Zolliker, P.;Mueller, K.",
                "FirstAuthorAffiliation": "Center for Visual Comput., Stony Brook Univ., Stony Brook, NY|c|;;;;",
                "AuthorIDs": "37280763200;37325999500;37882660300;37680882500;37273119700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lujin Wang;Giesen, J.;McDonnell, K.T.;Zolliker, P.;Mueller, K.",
                "filename": "wangluji_vis_08",
                "Citations": "398874;568118;4376200;4015448;964510"
            }
        },
        {
            "name": "Giesen, J.",
            "value": 40,
            "numPapers": 19,
            "cluster": "5",
            "index": 377,
            "weight": 1,
            "x": 133.3450622122238,
            "y": 1282.0202513910324,
            "px": 299.0977868460089,
            "py": 2242.571597202358,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Hue-Preserving Color Blending",
                "PaperDOI": "10.1109/TVCG.2009.150",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.150",
                "firstage": "1275",
                "Lastage": "1282",
                "IEEEXPLOREArticleNumber": "5290739",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization.",
                "AuthorNames": "Chuang, J.;Weiskopf, D.;Moller, T.",
                "FirstAuthorAffiliation": "Simon Fraser Univ., Burnaby, BC, Canada|c|;;",
                "AuthorIDs": "38100482200;37268045000;37275858700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chuang, J.;Weiskopf, D.;Moller, T.",
                "filename": "chuang_vis_09",
                "Citations": "568118;4658198;4015473"
            }
        },
        {
            "name": "Kaehler, R.",
            "value": 20,
            "numPapers": 12,
            "cluster": "5",
            "index": 378,
            "weight": 1,
            "x": -704.2982243619706,
            "y": 603.4006766784981,
            "px": -1328.7707565157348,
            "py": 1003.9954846128172,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "firstage": "1533",
                "Lastage": "1540",
                "IEEEXPLOREArticleNumber": "5613495",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, München, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "filename": "fraedric_vis_10",
                "Citations": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Hahn, O.",
            "value": 0,
            "numPapers": 9,
            "cluster": "5",
            "index": 379,
            "weight": 1,
            "x": -24.316939813266895,
            "y": -726.534386820455,
            "px": -48.964698644835615,
            "py": -1501.066230844145,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "firstage": "1533",
                "Lastage": "1540",
                "IEEEXPLOREArticleNumber": "5613495",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, München, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "filename": "fraedric_vis_10",
                "Citations": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Abel, T.",
            "value": 17,
            "numPapers": 10,
            "cluster": "5",
            "index": 380,
            "weight": 1,
            "x": -43.44868276928253,
            "y": -467.6385389461075,
            "px": -82.20820343327388,
            "py": -987.8191442062299,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "firstage": "1533",
                "Lastage": "1540",
                "IEEEXPLOREArticleNumber": "5613495",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, München, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "filename": "fraedric_vis_10",
                "Citations": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Weber, G.H.",
            "value": 88,
            "numPapers": 29,
            "cluster": "7",
            "index": 381,
            "weight": 3,
            "x": -557.7007099171506,
            "y": 807.6750105051498,
            "px": -282.61238383054456,
            "py": 802.6886090628384,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Two-stage framework for a topology-based projection and visualization of classified document collections",
                "PaperDOI": "10.1109/VAST.2010.5652940",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652940",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "5652940",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "During the last decades, electronic textual information has become the world's largest and most important information source. Daily newspapers, books, scientific and governmental publications, blogs and private messages have grown into a wellspring of endless information and knowledge. Since neither existing nor new information can be read in its entirety, we rely increasingly on computers to extract and visualize meaningful or interesting topics and documents from this huge information reservoir. In this paper, we extend, improve and combine existing individual approaches into an overall framework that supports topologi-cal analysis of high dimensional document point clouds given by the well-known tf-idf document-term weighting method. We show that traditional distance-based approaches fail in very high dimensional spaces, and we describe an improved two-stage method for topology-based projections from the original high dimensional information space to both two dimensional (2-D) and three dimensional (3-D) visualizations. To demonstrate the accuracy and usability of this framework, we compare it to methods introduced recently and apply it to complex document and patent collections.",
                "AuthorNames": "Oesterling, P.;Scheuermann, G.;Teresniak, S.;Heyer, G.;Koch, S.;Ertl, T.;Weber, G.H.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig, Germany|c|;;;;;;",
                "AuthorIDs": "37403135200;37282574800;37591211600;37591211200;37593029700;37268023800;37411444100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oesterling, P.;Scheuermann, G.;Teresniak, S.;Heyer, G.;Koch, S.;Ertl, T.;Weber, G.H.",
                "filename": "oesterli_vast_10",
                "Citations": "5333564;4376169;146402;528686;5332629;5290728"
            }
        },
        {
            "name": "Lindholm, S.",
            "value": 5,
            "numPapers": 25,
            "cluster": "5",
            "index": 382,
            "weight": 1,
            "x": 166.65117854747072,
            "y": -336.66188190742844,
            "px": 268.3595862667182,
            "py": -723.9374887493564,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation",
                "PaperDOI": "10.1109/TVCG.2007.70518",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70518",
                "firstage": "1648",
                "Lastage": "1655",
                "IEEEXPLOREArticleNumber": "4376198",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a \"sensitivity lens\" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.",
                "AuthorNames": "Lundstrom, C.;Ljung, P.;Persson, A.;Ynnerman, A.",
                "FirstAuthorAffiliation": "Linkoping Univ., Linkoping|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lundstrom, C.;Ljung, P.;Persson, A.;Ynnerman, A.",
                "filename": "lundstroem_vis_07",
                "Citations": "1532807;235199;1250414"
            }
        },
        {
            "name": "Persson, A.",
            "value": 58,
            "numPapers": 30,
            "cluster": "5",
            "index": 383,
            "weight": 1,
            "x": -296.2857331352593,
            "y": 189.0713417255223,
            "px": -540.0448701401748,
            "py": 225.18592665309717,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation",
                "PaperDOI": "10.1109/TVCG.2007.70518",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70518",
                "firstage": "1648",
                "Lastage": "1655",
                "IEEEXPLOREArticleNumber": "4376198",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a \"sensitivity lens\" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.",
                "AuthorNames": "Lundstrom, C.;Ljung, P.;Persson, A.;Ynnerman, A.",
                "FirstAuthorAffiliation": "Linkoping Univ., Linkoping|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lundstrom, C.;Ljung, P.;Persson, A.;Ynnerman, A.",
                "filename": "lundstroem_vis_07",
                "Citations": "1532807;235199;1250414"
            }
        },
        {
            "name": "von Funck, W.",
            "value": 26,
            "numPapers": 5,
            "cluster": "6",
            "index": 384,
            "weight": 1,
            "x": -41.79120622750263,
            "y": 150.12976732616428,
            "px": -471.8408435778301,
            "py": 120.81695795795707,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments",
                "PaperDOI": "10.1109/TVCG.2008.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.163",
                "firstage": "1396",
                "Lastage": "1403",
                "IEEEXPLOREArticleNumber": "4658155",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.",
                "AuthorNames": "von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.",
                "FirstAuthorAffiliation": "MPI Informatlk, Saarbrucken|c|;;;",
                "AuthorIDs": "37869714300;37282635100;37266875400;37271851300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.",
                "filename": "vonfunck_vis_08",
                "Citations": "485141;398846;235211;964506;398877"
            }
        },
        {
            "name": "Krishnan, H.",
            "value": 68,
            "numPapers": 13,
            "cluster": "6",
            "index": 385,
            "weight": 3,
            "x": 480.86485189136204,
            "y": 361.066784114246,
            "px": 514.0502074243454,
            "py": 314.6518221912363,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets",
                "PaperDOI": "10.1109/TVCG.2009.190",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.190",
                "firstage": "1267",
                "Lastage": "1274",
                "IEEEXPLOREArticleNumber": "5290738",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.",
                "AuthorNames": "Krishnan, H.;Garth, C.;Joy, K.I.",
                "FirstAuthorAffiliation": "Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;",
                "AuthorIDs": "37866882400;37282573700;37267811400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Krishnan, H.;Garth, C.;Joy, K.I.",
                "filename": "krishnan_vis_09",
                "Citations": "4376209;235211;398875;964506;4658155;885688;4658156"
            }
        },
        {
            "name": "Hultquist, J.P.M.",
            "value": 121,
            "numPapers": 8,
            "cluster": "6",
            "index": 386,
            "weight": 5,
            "x": 603.4509095117318,
            "y": 361.6580329108343,
            "px": 594.0752012972988,
            "py": 350.14393218487334,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "SuperGlue: a programming environment for scientific visualization",
                "PaperDOI": "10.1109/VISUAL.1992.235202",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235202",
                "firstage": "243",
                "Lastage": "250",
                "IEEEXPLOREArticleNumber": "235202",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "It is suggested that many existing platforms over emphasize ease-of-use and do not adequately address issues of extensibility. A visualization testbed, called SuperGlue, which is particularly suited for the rapid development of new visualization methods, was built. An interpreter supports rapid development of new code, and an extensive class hierarchy encourages code reuse. By explicitly designing for ease of programming, it was possible to produce a visualization system which is powerful, easy to use, and rapidly improving. The motivation of the work, the architecture of the system, and plans for further development are reported",
                "AuthorNames": "Hultquist, J.P.M.;Raible, E.L.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;",
                "AuthorIDs": "37378417700;37378640100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hultquist, J.P.M.;Raible, E.L.",
                "filename": "hultquist2_vis_92",
                "Citations": "175771;146360;235211"
            }
        },
        {
            "name": "Nelson, B.",
            "value": 14,
            "numPapers": 8,
            "cluster": "6",
            "index": 387,
            "weight": 1,
            "x": 765.7180818163861,
            "y": 239.07900321751777,
            "px": 748.1365956267995,
            "py": 225.4052955207055,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields",
                "PaperDOI": "10.1109/TVCG.2011.206",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.206",
                "firstage": "1803",
                "Lastage": "1811",
                "IEEEXPLOREArticleNumber": "6064943",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.",
                "AuthorNames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": "37557887400;37282898700;37275716100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "filename": "nelson_vis_11",
                "Citations": "1532776;1372224;4015486"
            }
        },
        {
            "name": "Haimes, R.",
            "value": 79,
            "numPapers": 13,
            "cluster": "6",
            "index": 388,
            "weight": 2,
            "x": 797.1545486605194,
            "y": 294.62741367780944,
            "px": 795.7365286940561,
            "py": 280.78632062933815,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields",
                "PaperDOI": "10.1109/TVCG.2011.206",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.206",
                "firstage": "1803",
                "Lastage": "1811",
                "IEEEXPLOREArticleNumber": "6064943",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.",
                "AuthorNames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": "37557887400;37282898700;37275716100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "filename": "nelson_vis_11",
                "Citations": "1532776;1372224;4015486"
            }
        },
        {
            "name": "Livingston, M.A.",
            "value": 22,
            "numPapers": 29,
            "cluster": "8",
            "index": 389,
            "weight": 3,
            "x": 49.9823481021607,
            "y": 25.225585464376202,
            "px": -467.11065368372823,
            "py": -267.9786272030709,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Evaluation of Multivariate Visualization on a Multivariate Task",
                "PaperDOI": "10.1109/TVCG.2012.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.223",
                "firstage": "2114",
                "Lastage": "2121",
                "IEEEXPLOREArticleNumber": "6327216",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.",
                "AuthorNames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37300434300;37681593700;37330342700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "filename": "livingston_vis_12",
                "Citations": "6064969;5290732;745292;146387;4376150;146386;175795;745294;1250362"
            }
        },
        {
            "name": "Decker, J.W.",
            "value": 12,
            "numPapers": 19,
            "cluster": "8",
            "index": 390,
            "weight": 3,
            "x": 661.7055614761675,
            "y": 896.6430105655093,
            "px": 509.5241264650986,
            "py": 1066.2209336530154,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Evaluation of Multivariate Visualization on a Multivariate Task",
                "PaperDOI": "10.1109/TVCG.2012.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.223",
                "firstage": "2114",
                "Lastage": "2121",
                "IEEEXPLOREArticleNumber": "6327216",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.",
                "AuthorNames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37300434300;37681593700;37330342700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "filename": "livingston_vis_12",
                "Citations": "6064969;5290732;745292;146387;4376150;146386;175795;745294;1250362"
            }
        },
        {
            "name": "Healey, C.",
            "value": 120,
            "numPapers": 15,
            "cluster": "8",
            "index": 391,
            "weight": 4,
            "x": 202.32298594754863,
            "y": -272.9765241600985,
            "px": 214.4926852607472,
            "py": -263.25338200955815,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.",
                "PaperDOI": "10.1109/TVCG.2007.70623",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70623",
                "firstage": "1270",
                "Lastage": "1277",
                "IEEEXPLOREArticleNumber": "4376150",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. - - We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.",
                "AuthorNames": "Hagh-Shenas, H.;Sunghee Kim;Interrante, V.;Healey, C.",
                "FirstAuthorAffiliation": "Boston Sci. Corp., Natick|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hagh-Shenas, H.;Sunghee Kim;Interrante, V.;Healey, C.",
                "filename": "shenas_infovis_07",
                "Citations": "1532140;1250362;809905;1532137"
            }
        },
        {
            "name": "Snoeyink, J.",
            "value": 94,
            "numPapers": 14,
            "cluster": "7",
            "index": 392,
            "weight": 3,
            "x": 208.58937955070755,
            "y": 1100.169751258862,
            "px": 208.23244069585857,
            "py": 1032.069203220612,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Simplifying flexible isosurfaces using local geometric measures",
                "PaperDOI": "10.1109/VISUAL.2004.96",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.96",
                "firstage": "497",
                "Lastage": "504",
                "IEEEXPLOREArticleNumber": "1372235",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.",
                "AuthorNames": "Carr, H.;Snoeyink, J.;van de Panne, Michiel",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;",
                "AuthorIDs": "37282624500;37282623700;37283212000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Carr, H.;Snoeyink, J.;van de Panne, Michiel",
                "filename": "carr_vis_04",
                "Citations": "964499;1183774"
            }
        },
        {
            "name": "van de Panne, Michiel",
            "value": 70,
            "numPapers": 2,
            "cluster": "7",
            "index": 393,
            "weight": 3,
            "x": 276.15312866399853,
            "y": 1046.7990237895995,
            "px": 245.79917712724708,
            "py": 996.6167810416946,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Simplifying flexible isosurfaces using local geometric measures",
                "PaperDOI": "10.1109/VISUAL.2004.96",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.96",
                "firstage": "497",
                "Lastage": "504",
                "IEEEXPLOREArticleNumber": "1372235",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.",
                "AuthorNames": "Carr, H.;Snoeyink, J.;van de Panne, Michiel",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;",
                "AuthorIDs": "37282624500;37282623700;37283212000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Carr, H.;Snoeyink, J.;van de Panne, Michiel",
                "filename": "carr_vis_04",
                "Citations": "964499;1183774"
            }
        },
        {
            "name": "Ahmed, N.",
            "value": 21,
            "numPapers": 20,
            "cluster": "4",
            "index": 394,
            "weight": 3,
            "x": 33.96652496067502,
            "y": 1226.6249855251692,
            "px": 278.21059550314004,
            "py": 815.3293683923141,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Human Computation in Visualization: Using Purpose Driven Games for Robust Evaluation of Visualization Algorithms",
                "PaperDOI": "10.1109/TVCG.2012.234",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.234",
                "firstage": "2104",
                "Lastage": "2113",
                "IEEEXPLOREArticleNumber": "6327215",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Due to the inherent characteristics of the visualization process, most of the problems in this field have strong ties with human cognition and perception. This makes the human brain and sensory system the only truly appropriate evaluation platform for evaluating and fine-tuning a new visualization method or paradigm. However, getting humans to volunteer for these purposes has always been a significant obstacle, and thus this phase of the development process has traditionally formed a bottleneck, slowing down progress in visualization research. We propose to take advantage of the newly emerging field of Human Computation (HC) to overcome these challenges. HC promotes the idea that rather than considering humans as users of the computational system, they can be made part of a hybrid computational loop consisting of traditional computation resources and the human brain and sensory system. This approach is particularly successful in cases where part of the computational problem is considered intractable using known computer algorithms but is trivial to common sense human knowledge. In this paper, we focus on HC from the perspective of solving visualization problems and also outline a framework by which humans can be easily seduced to volunteer their HC resources. We introduce a purpose-driven game titled â€œDisguiseâ€ which serves as a prototypical example for how the evaluation of visualization algorithms can be mapped into a fun and addicting activity, allowing this task to be accomplished in an extensive yet cost effective way. Finally, we sketch out a framework that transcends from the pure evaluation of existing visualization methods to the design of a new one.",
                "AuthorNames": "Ahmed, N.;Ziyi Zheng;Mueller, K.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "38021380500;37599599100;37273119700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ahmed, N.;Ziyi Zheng;Mueller, K.",
                "filename": "ahmed_vis_12",
                "Citations": "5290740;6064959;5290762;1532781;6327217;4658198;5290739"
            }
        },
        {
            "name": "Ziyi Zheng",
            "value": 23,
            "numPapers": 27,
            "cluster": "4",
            "index": 395,
            "weight": 3,
            "x": 906.7860140541177,
            "y": 183.13797423424344,
            "px": 467.3412843206381,
            "py": 588.1539134120138,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Human Computation in Visualization: Using Purpose Driven Games for Robust Evaluation of Visualization Algorithms",
                "PaperDOI": "10.1109/TVCG.2012.234",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.234",
                "firstage": "2104",
                "Lastage": "2113",
                "IEEEXPLOREArticleNumber": "6327215",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Due to the inherent characteristics of the visualization process, most of the problems in this field have strong ties with human cognition and perception. This makes the human brain and sensory system the only truly appropriate evaluation platform for evaluating and fine-tuning a new visualization method or paradigm. However, getting humans to volunteer for these purposes has always been a significant obstacle, and thus this phase of the development process has traditionally formed a bottleneck, slowing down progress in visualization research. We propose to take advantage of the newly emerging field of Human Computation (HC) to overcome these challenges. HC promotes the idea that rather than considering humans as users of the computational system, they can be made part of a hybrid computational loop consisting of traditional computation resources and the human brain and sensory system. This approach is particularly successful in cases where part of the computational problem is considered intractable using known computer algorithms but is trivial to common sense human knowledge. In this paper, we focus on HC from the perspective of solving visualization problems and also outline a framework by which humans can be easily seduced to volunteer their HC resources. We introduce a purpose-driven game titled â€œDisguiseâ€ which serves as a prototypical example for how the evaluation of visualization algorithms can be mapped into a fun and addicting activity, allowing this task to be accomplished in an extensive yet cost effective way. Finally, we sketch out a framework that transcends from the pure evaluation of existing visualization methods to the design of a new one.",
                "AuthorNames": "Ahmed, N.;Ziyi Zheng;Mueller, K.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "38021380500;37599599100;37273119700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ahmed, N.;Ziyi Zheng;Mueller, K.",
                "filename": "ahmed_vis_12",
                "Citations": "5290740;6064959;5290762;1532781;6327217;4658198;5290739"
            }
        },
        {
            "name": "Kruger, J.",
            "value": 223,
            "numPapers": 35,
            "cluster": "5",
            "index": 396,
            "weight": 10,
            "x": 182.49064398556115,
            "y": 427.6409423308559,
            "px": 204.37657324544003,
            "py": 415.33876730436043,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Direct Volume Editing",
                "PaperDOI": "10.1109/TVCG.2008.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.120",
                "firstage": "1388",
                "Lastage": "1395",
                "IEEEXPLOREArticleNumber": "4658154",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.",
                "AuthorNames": "Burger, K.;Kruger, J.;Westermann, R.",
                "FirstAuthorAffiliation": "Tech. Univ. Munchen, Munich|c|;;",
                "AuthorIDs": ";;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Burger, K.;Kruger, J.;Westermann, R.",
                "filename": "buorger_vis_08",
                "Citations": "4015450;568110;1250384;1183762;1183777;4376160;1250381;885694;1372190;1532856;568108"
            }
        },
        {
            "name": "Clapworthy, G.",
            "value": 2,
            "numPapers": 14,
            "cluster": "5",
            "index": 397,
            "weight": 1,
            "x": 375.37844259613433,
            "y": 1858.0165620875791,
            "px": 760.8066764627997,
            "py": 3357.8312347933934,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Structure-Aware Lighting Design for Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2012.267",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.267",
                "firstage": "2372",
                "Lastage": "2381",
                "IEEEXPLOREArticleNumber": "6327242",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.",
                "AuthorNames": "Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao",
                "FirstAuthorAffiliation": "State Key Lab. of CAD&amp;CG, Zhejiang Univ., Hangzhou, China|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao",
                "filename": "tao_vis_12",
                "Citations": "4015471;6064959;1372208;1532834;1532833;1250395;1183785"
            }
        },
        {
            "name": "Rutten, M.",
            "value": 4,
            "numPapers": 21,
            "cluster": "6",
            "index": 398,
            "weight": 1,
            "x": 343.9313939882692,
            "y": 329.4342699562343,
            "px": 275.53940385742084,
            "py": 428.1485299517709,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Multifield Visualization Using Local Statistical Complexity",
                "PaperDOI": "10.1109/TVCG.2007.70615",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70615",
                "firstage": "1384",
                "Lastage": "1391",
                "IEEEXPLOREArticleNumber": "4376165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.",
                "AuthorNames": "Janicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jänicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "filename": "jaenicke_vis_07",
                "Citations": "809865;1250372;4015447;809905;4015473;1250383"
            }
        },
        {
            "name": "Guthe, S.",
            "value": 115,
            "numPapers": 15,
            "cluster": "5",
            "index": 399,
            "weight": 4,
            "x": 217.3861874583151,
            "y": 184.4316168663566,
            "px": 165.54750961520637,
            "py": 177.41549898272652,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Real-time decompression and visualization of animated volume data",
                "PaperDOI": "10.1109/VISUAL.2001.964531",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964531",
                "firstage": "349",
                "Lastage": "356",
                "IEEEXPLOREArticleNumber": "964531",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.",
                "AuthorNames": "Guthe, S.;Strasser, W.",
                "FirstAuthorAffiliation": "WSI/GRIS, Tubingen Univ., Germany|c|;",
                "AuthorIDs": "37728224400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guthe, S.;Strasser, W.",
                "filename": "guthe_vis_01",
                "Citations": "663878"
            }
        },
        {
            "name": "Strasser, W.",
            "value": 191,
            "numPapers": 20,
            "cluster": "5",
            "index": 400,
            "weight": 4,
            "x": 83.6200736907689,
            "y": 140.4021975244981,
            "px": 102.61466431124178,
            "py": 159.83775918149755,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Real-time decompression and visualization of animated volume data",
                "PaperDOI": "10.1109/VISUAL.2001.964531",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964531",
                "firstage": "349",
                "Lastage": "356",
                "IEEEXPLOREArticleNumber": "964531",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.",
                "AuthorNames": "Guthe, S.;Strasser, W.",
                "FirstAuthorAffiliation": "WSI/GRIS, Tubingen Univ., Germany|c|;",
                "AuthorIDs": "37728224400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guthe, S.;Strasser, W.",
                "filename": "guthe_vis_01",
                "Citations": "663878"
            }
        },
        {
            "name": "Burger, K.",
            "value": 45,
            "numPapers": 37,
            "cluster": "6",
            "index": 401,
            "weight": 5,
            "x": 454.4551066930646,
            "y": 376.43965455150885,
            "px": 492.4315222887844,
            "py": 315.48390152174414,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Direct Volume Editing",
                "PaperDOI": "10.1109/TVCG.2008.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.120",
                "firstage": "1388",
                "Lastage": "1395",
                "IEEEXPLOREArticleNumber": "4658154",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.",
                "AuthorNames": "Burger, K.;Kruger, J.;Westermann, R.",
                "FirstAuthorAffiliation": "Tech. Univ. Munchen, Munich|c|;;",
                "AuthorIDs": ";;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Burger, K.;Kruger, J.;Westermann, R.",
                "filename": "buorger_vis_08",
                "Citations": "4015450;568110;1250384;1183762;1183777;4376160;1250381;885694;1372190;1532856;568108"
            }
        },
        {
            "name": "Ellsworth, D.",
            "value": 82,
            "numPapers": 26,
            "cluster": "5",
            "index": 402,
            "weight": 3,
            "x": 203.9344783368139,
            "y": 199.68400151800708,
            "px": 193.8980139871666,
            "py": 149.40467099054763,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Interactive terascale particle visualization",
                "PaperDOI": "10.1109/VISUAL.2004.55",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.55",
                "firstage": "353",
                "Lastage": "360",
                "IEEEXPLOREArticleNumber": "1372217",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.",
                "AuthorNames": "Ellsworth, D.;Green, B.;Moran, P.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;;",
                "AuthorIDs": "37282594500;37273679700;37264891100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ellsworth, D.;Green, B.;Moran, P.J.",
                "filename": "ellswort_vis_04",
                "Citations": "1250375;745299;663888;1250420;346311;745343;480821"
            }
        },
        {
            "name": "Schneider, J.",
            "value": 126,
            "numPapers": 55,
            "cluster": "5",
            "index": 403,
            "weight": 8,
            "x": 173.11456085782376,
            "y": 276.5315678283925,
            "px": 177.76702112466484,
            "py": 248.5568160579739,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "ClearView: An Interactive Context Preserving Hotspot Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2006.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.124",
                "firstage": "941",
                "Lastage": "948",
                "IEEEXPLOREArticleNumber": "4015450",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Volume rendered imagery often includes a barrage of 3D information like shape, appearance and topology of complex structures, and it thus quickly overwhelms the user. In particular, when focusing on a specific region a user cannot observe the relationship between various structures unless he has a mental picture of the entire data. In this paper we present ClearView, a GPU-based, interactive framework for texture-based volume ray-casting that allows users which do not have the visualization skills for this mental exercise to quickly obtain a picture of the data in a very intuitive and user-friendly way. ClearView is designed to enable the user to focus on particular areas in the data while preserving context information without visual clutter. ClearView does not require additional feature volumes as it derives any features in the data from image information only. A simple point-and-click interface enables the user to interactively highlight structures in the data. ClearView provides an easy to use interface to complex volumetric data as it only uses transparency in combination with a few specific shaders to convey focus and context information",
                "AuthorNames": "Kruger, J.;Schneider, J.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Technische Univ. Munchen|c|;;",
                "AuthorIDs": "37548560500;37560044500;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kruger, J.;Schneider, J.;Westermann, R.",
                "filename": "krueger_vis_06",
                "Citations": "885694;1250400;568110;1183762;1183777;809882;885694;1372190;1250384;1532856;1532818"
            }
        },
        {
            "name": "Kandogan, E.",
            "value": 1,
            "numPapers": 11,
            "cluster": "2",
            "index": 404,
            "weight": 1,
            "x": 1077.3913068736185,
            "y": 2149.744967803809,
            "px": 1601.1769146827055,
            "py": 3914.915609159523,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations",
                "PaperDOI": "10.1109/VAST.2012.6400487",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400487",
                "firstage": "73",
                "Lastage": "82",
                "IEEEXPLOREArticleNumber": "6400487",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.",
                "AuthorNames": "Kandogan, E.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kandogan, E.",
                "filename": "kandogan_vast_12",
                "Citations": "1249015;1532142;1382892;6065024;1382895;729568;4035766;5290704;5652885;5332628;6064985"
            }
        },
        {
            "name": "Wilkinson, L.",
            "value": 109,
            "numPapers": 28,
            "cluster": "0",
            "index": 405,
            "weight": 3,
            "x": 747.8926486986918,
            "y": 406.4135335069833,
            "px": 865.9006088897545,
            "py": 702.881093624381,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Graph-theoretic scagnostics",
                "PaperDOI": "10.1109/INFVIS.2005.1532142",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532142",
                "firstage": "157",
                "Lastage": "164",
                "IEEEXPLOREArticleNumber": "1532142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.",
                "AuthorNames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "FirstAuthorAffiliation": "SPSS Inc., Chicago, IL, USA|c|;;",
                "AuthorIDs": "37560536200;37548165700;37270222000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "filename": "wilkinso_infovis_05",
                "Citations": "1249006;1382892;1382895"
            }
        },
        {
            "name": "Anand, A.",
            "value": 109,
            "numPapers": 21,
            "cluster": "0",
            "index": 406,
            "weight": 3,
            "x": 831.0820685108672,
            "y": 506.23515838474606,
            "px": 821.9962404868091,
            "py": 689.3734491388252,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Graph-theoretic scagnostics",
                "PaperDOI": "10.1109/INFVIS.2005.1532142",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532142",
                "firstage": "157",
                "Lastage": "164",
                "IEEEXPLOREArticleNumber": "1532142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.",
                "AuthorNames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "FirstAuthorAffiliation": "SPSS Inc., Chicago, IL, USA|c|;;",
                "AuthorIDs": "37560536200;37548165700;37270222000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "filename": "wilkinso_infovis_05",
                "Citations": "1249006;1382892;1382895"
            }
        },
        {
            "name": "Grossman, R.",
            "value": 93,
            "numPapers": 3,
            "cluster": "0",
            "index": 407,
            "weight": 3,
            "x": 780.8460975385686,
            "y": 427.11691354977273,
            "px": 846.3362081810856,
            "py": 716.2646923618086,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Graph-theoretic scagnostics",
                "PaperDOI": "10.1109/INFVIS.2005.1532142",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532142",
                "firstage": "157",
                "Lastage": "164",
                "IEEEXPLOREArticleNumber": "1532142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.",
                "AuthorNames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "FirstAuthorAffiliation": "SPSS Inc., Chicago, IL, USA|c|;;",
                "AuthorIDs": "37560536200;37548165700;37270222000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "filename": "wilkinso_infovis_05",
                "Citations": "1249006;1382892;1382895"
            }
        },
        {
            "name": "Joia, P.",
            "value": 16,
            "numPapers": 25,
            "cluster": "9",
            "index": 408,
            "weight": 3,
            "x": 1196.3686628028724,
            "y": 70.25820173657638,
            "px": 926.4981223730647,
            "py": 237.27059399995633,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Local Affine Multidimensional Projection",
                "PaperDOI": "10.1109/TVCG.2011.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.220",
                "firstage": "2563",
                "Lastage": "2571",
                "IEEEXPLOREArticleNumber": "6065024",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",
                "AuthorNames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;",
                "AuthorIDs": "38017343000;37590969400;38017342500;38017346900;37590974800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "filename": "joia_infovis_11",
                "Citations": "567787;5290725;4376155;1173159;5613468;5613498;1173161"
            }
        },
        {
            "name": "Nonato, L.G.",
            "value": 64,
            "numPapers": 57,
            "cluster": "9",
            "index": 409,
            "weight": 4,
            "x": 929.6238826949816,
            "y": 216.90059477099717,
            "px": 1089.9612497392834,
            "py": -104.20978410368863,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Local Affine Multidimensional Projection",
                "PaperDOI": "10.1109/TVCG.2011.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.220",
                "firstage": "2563",
                "Lastage": "2571",
                "IEEEXPLOREArticleNumber": "6065024",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",
                "AuthorNames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;",
                "AuthorIDs": "38017343000;37590969400;38017342500;38017346900;37590974800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "filename": "joia_infovis_11",
                "Citations": "567787;5290725;4376155;1173159;5613468;5613498;1173161"
            }
        },
        {
            "name": "Paulovich, F.V.",
            "value": 87,
            "numPapers": 35,
            "cluster": "9",
            "index": 410,
            "weight": 3,
            "x": 1608.4324676483488,
            "y": -512.5923591921421,
            "px": 1666.5405753414188,
            "py": -885.2186807494477,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Local Affine Multidimensional Projection",
                "PaperDOI": "10.1109/TVCG.2011.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.220",
                "firstage": "2563",
                "Lastage": "2571",
                "IEEEXPLOREArticleNumber": "6065024",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",
                "AuthorNames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;",
                "AuthorIDs": "38017343000;37590969400;38017342500;38017346900;37590974800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "filename": "joia_infovis_11",
                "Citations": "567787;5290725;4376155;1173159;5613468;5613498;1173161"
            }
        },
        {
            "name": "Chalmers, M.",
            "value": 117,
            "numPapers": 12,
            "cluster": "9",
            "index": 411,
            "weight": 4,
            "x": 1205.2208045249251,
            "y": -137.69819679981302,
            "px": 1143.8162492186507,
            "py": -201.7406886285875,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "A linear iteration time layout algorithm for visualising high-dimensional data",
                "PaperDOI": "10.1109/VISUAL.1996.567787",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567787",
                "firstage": "127",
                "Lastage": "131",
                "IEEEXPLOREArticleNumber": "567787",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A technique is presented for the layout of high dimensional data in a low dimensional space. This technique builds upon the force based methods that have been used previously to make visualisations of various types of data such as bibliographies and sets of software modules. The canonical force based model, related to solutions of the N body problem, has a computational complexity of O(N 2) per iteration. The paper presents a stochastically based algorithm of linear complexity per iteration which produces good layouts, has low overhead, and is easy to implement. Its performance and accuracy are discussed, in particular with regard to the data to which it is applied. Experience with application to bibliographic and time series data, which may have a dimensionality in the tens of thousands, is described.",
                "AuthorNames": "Chalmers, M.",
                "FirstAuthorAffiliation": "Union Bank of Switzerland, Switzerland|c|",
                "AuthorIDs": "37283487400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chalmers, M.",
                "filename": "chalmers_vis_96",
                "Citations": "528686;480814"
            }
        },
        {
            "name": "Dayal, U.",
            "value": 87,
            "numPapers": 27,
            "cluster": "5",
            "index": 412,
            "weight": 2,
            "x": 508.78848261550286,
            "y": 603.0818106251388,
            "px": 607.5419582749107,
            "py": 668.7912164642588,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Intelligent Visual Analytics Queries",
                "PaperDOI": "10.1109/VAST.2007.4389001",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389001",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "4389001",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.",
                "AuthorNames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.",
                "FirstAuthorAffiliation": "Hewlett Packard Lab., Palo Alto|c|;;;;",
                "AuthorIDs": "37274264300;37275646700;37283138700;37563668400;37669961800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.",
                "filename": "hao_vast_07",
                "Citations": "4015431;729568;146402;885086;346302"
            }
        },
        {
            "name": "Green, T.M.",
            "value": 42,
            "numPapers": 11,
            "cluster": "2",
            "index": 413,
            "weight": 2,
            "x": 490.70505913800173,
            "y": 407.0580730751484,
            "px": 516.0839089499005,
            "py": 402.0334696055016,
            "node": {
                "Conference": "VAST",
                "Year": "2008",
                "PaperTitle": "Visual analytics for complex concepts using a human cognition model",
                "PaperDOI": "10.1109/VAST.2008.4677361",
                "Link": "http://dx.doi.org/10.1109/VAST.2008.4677361",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "4677361",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples.",
                "AuthorNames": "Green, T.M.;Ribarsky, W.;Fisher, Brian",
                "FirstAuthorAffiliation": "Charlotte Visualization Center, Univ. of North Carolina, Charlotte, NC|c|;;",
                "AuthorIDs": "37403562900;37300425000;37267458000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Green, T.M.;Ribarsky, W.;Fisher, Brian",
                "filename": "green_vast_08",
                "Citations": "1532781;4035765;4376137;4389006;4389005;4389009;528686"
            }
        },
        {
            "name": "Bouzari, H.",
            "value": 3,
            "numPapers": 9,
            "cluster": "5",
            "index": 414,
            "weight": 1,
            "x": 462.1918582334323,
            "y": 108.90579749286381,
            "px": 554.7904020233092,
            "py": -212.57151131919093,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Smart super views---A knowledge-assisted interface for medical visualization",
                "PaperDOI": "10.1109/VAST.2012.6400555",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400555",
                "firstage": "163",
                "Lastage": "172",
                "IEEEXPLOREArticleNumber": "6400555",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.",
                "AuthorNames": "Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, E.",
                "filename": "mistelbauer_vast_12",
                "Citations": "1250400;4015449;4376185;4376159;1183754;1532856;6064990;1532818;4015460"
            }
        },
        {
            "name": "Kohlmann, P.",
            "value": 87,
            "numPapers": 11,
            "cluster": "5",
            "index": 415,
            "weight": 1,
            "x": 450.18409502088247,
            "y": 823.9555604853882,
            "px": 529.5511747196574,
            "py": 1032.3201349464255,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "High-Level User Interfaces for Transfer Function Design with Semantics",
                "PaperDOI": "10.1109/TVCG.2006.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.148",
                "firstage": "1021",
                "Lastage": "1028",
                "IEEEXPLOREArticleNumber": "4015460",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation",
                "AuthorNames": "Salama, C.R.;Keller, M.;Kohlmann, P.",
                "FirstAuthorAffiliation": "Comput. Graphics & Multimedia Syst. Group, Siegen Univ.|c|;;",
                "AuthorIDs": "37840859800;37589324500;37623778100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Salama, C.R.;Keller, M.;Kohlmann, P.",
                "filename": "salama_vis_06",
                "Citations": "1250384;1250413;1183764;745319;964519;1250412;568112;663875"
            }
        },
        {
            "name": "Kosara, R.",
            "value": 182,
            "numPapers": 32,
            "cluster": "2",
            "index": 416,
            "weight": 6,
            "x": 862.6891142905309,
            "y": 395.1069873007421,
            "px": 466.763232284873,
            "py": 244.09974891183307,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Pargnostics: Screen-Space Metrics for Parallel Coordinates",
                "PaperDOI": "10.1109/TVCG.2010.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.184",
                "firstage": "1017",
                "Lastage": "1026",
                "IEEEXPLOREArticleNumber": "5613439",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.",
                "AuthorNames": "Dasgupta, A.;Kosara, R.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;",
                "AuthorIDs": "37593202500;37282563400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Dasgupta, A.;Kosara, R.",
                "filename": "dasgupta_infovis_10",
                "Citations": "1532142;4015422;146402;4035766;5332628;1532136;729568;636793"
            }
        },
        {
            "name": "Laramee, R.S.",
            "value": 74,
            "numPapers": 60,
            "cluster": "6",
            "index": 417,
            "weight": 7,
            "x": 597.7390986426404,
            "y": 449.2716137350598,
            "px": 635.6174413371541,
            "py": 468.4258592485903,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Smooth Graphs for Visual Exploration of Higher-Order State Transitions",
                "PaperDOI": "10.1109/TVCG.2009.181",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.181",
                "firstage": "969",
                "Lastage": "976",
                "IEEEXPLOREArticleNumber": "5290701",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.",
                "AuthorNames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.",
                "FirstAuthorAffiliation": "Visualization Group, Delft Univ. of Technol., Delft, Netherlands|c|;;;;;",
                "AuthorIDs": "37550793100;37373834100;38110391600;37335785800;37267247900;37295045800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.",
                "filename": "blaas_infovis_09",
                "Citations": "528685;4658147;4658140;4015418;963281;963281;4015425"
            }
        },
        {
            "name": "Ogievetsky, V.",
            "value": 109,
            "numPapers": 10,
            "cluster": "3",
            "index": 418,
            "weight": 1,
            "x": 349.2109517732929,
            "y": 268.72771866476296,
            "px": 358.38301025754737,
            "py": -171.85374999540832,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "firstage": "2301",
                "Lastage": "2309",
                "IEEEXPLOREArticleNumber": "6064996",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "filename": "bostock_infovis_11",
                "Citations": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Juhee Bae",
            "value": 12,
            "numPapers": 5,
            "cluster": "3",
            "index": 419,
            "weight": 1,
            "x": 852.6690473604486,
            "y": 925.0767884887032,
            "px": 1290.722154261207,
            "py": 1004.8629014623206,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Developing and Evaluating Quilts for the Depiction of Large Layered Graphs",
                "PaperDOI": "10.1109/TVCG.2011.187",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.187",
                "firstage": "2268",
                "Lastage": "2275",
                "IEEEXPLOREArticleNumber": "6064992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).",
                "AuthorNames": "Juhee Bae;Watson, B.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37595934400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Juhee Bae;Watson, B.",
                "filename": "bae_infovis_11",
                "Citations": "5613445;1382886;4376154"
            }
        },
        {
            "name": "Watson, B.",
            "value": 12,
            "numPapers": 10,
            "cluster": "3",
            "index": 420,
            "weight": 1,
            "x": 682.9801601434834,
            "y": 1046.4838313241917,
            "px": 968.2903541137664,
            "py": 1211.1249887844356,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Laws of Attraction: From Perceptual Forces to Conceptual Similarity",
                "PaperDOI": "10.1109/TVCG.2010.174",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.174",
                "firstage": "1009",
                "Lastage": "1016",
                "IEEEXPLOREArticleNumber": "5613438",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.",
                "AuthorNames": "Ziemkiewicz, C.;Kosara, R.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37548028800;37282563400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ziemkiewicz, C.;Kosara, R.",
                "filename": "ziemkiew_infovis_10",
                "Citations": "4658146"
            }
        },
        {
            "name": "Jimeng Sun",
            "value": 53,
            "numPapers": 29,
            "cluster": "4",
            "index": 421,
            "weight": 2,
            "x": 245.0735628597264,
            "y": 1086.7222038220116,
            "px": 679.9964405920113,
            "py": 624.1894428962995,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "FacetAtlas: Multifaceted Visualization for Rich Text Corpora",
                "PaperDOI": "10.1109/TVCG.2010.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.154",
                "firstage": "1172",
                "Lastage": "1181",
                "IEEEXPLOREArticleNumber": "5613456",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.",
                "AuthorNames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": "37604309600;37281417100;37598450200;37601397400;37406039100;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "filename": "cao_infovis_10",
                "Citations": "4015419;5333443;885098;5290725;4658140;4658133;5290723;5290722;1532126;4015432;4015425;745302;5290726;528686;4015423"
            }
        },
        {
            "name": "Yu-Shuen Wang",
            "value": 14,
            "numPapers": 12,
            "cluster": "12",
            "index": 422,
            "weight": 2,
            "x": 1070.4789904128916,
            "y": 680.8630183507461,
            "px": 998.2394206810252,
            "py": 644.0057857778062,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Focus+Context Metro Maps",
                "PaperDOI": "10.1109/TVCG.2011.205",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.205",
                "firstage": "2528",
                "Lastage": "2535",
                "IEEEXPLOREArticleNumber": "6065020",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.",
                "AuthorNames": "Yu-Shuen Wang;Ming-Te Chi",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37407536000;38019484900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yu-Shuen Wang;Ming-Te Chi",
                "filename": "wang2_infovis_11",
                "Citations": "636786;559214;4658197;729558;1532818"
            }
        },
        {
            "name": "Keahey, T.A.",
            "value": 100,
            "numPapers": 14,
            "cluster": "12",
            "index": 423,
            "weight": 3,
            "x": 1079.2966705163662,
            "y": 691.4948658231297,
            "px": 1018.0980745834845,
            "py": 653.4053795691767,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "The generalized detail in-context problem",
                "PaperDOI": "10.1109/INFVIS.1998.729558",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729558",
                "firstage": "44",
                "Lastage": "51, 152",
                "IEEEXPLOREArticleNumber": "729558",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes a general formulation of the â€œdetail-in-contextâ€ problem, which is a central issue of fundamental importance to a wide variety of nonlinear magnification systems. A number of tools are described for dealing with this problem effectively. These tools can be applied to any continuous nonlinear magnification system, and are not tied to specific implementation features of the system that produced the original transformation. Of particular interest is the development of â€œseamless multi level viewsâ€, which allow multiple global views of an information space (each having different information content) to be integrated into a single view without discontinuity",
                "AuthorNames": "Keahey, T.A.",
                "FirstAuthorAffiliation": "Los Alamos Nat. Lab., NM, USA|c|",
                "AuthorIDs": "37349418300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keahey, T.A.",
                "filename": "keahey_infovis_98",
                "Citations": "636786;636718;559214"
            }
        },
        {
            "name": "Robertson, E.L.",
            "value": 69,
            "numPapers": 2,
            "cluster": "12",
            "index": 424,
            "weight": 3,
            "x": 1019.8154234434663,
            "y": 720.0483175479795,
            "px": 945.3531737150971,
            "py": 683.8938379525526,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "Nonlinear magnification fields",
                "PaperDOI": "10.1109/INFVIS.1997.636786",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636786",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "636786",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce nonlinear magnification fields as an abstract representation of nonlinear magnification, providing methods for converting transformation routines to magnification fields and vice-versa. This new representation provides ease of manipulation and power of expression. By removing the restrictions of explicit foci and allowing precise specification of magnification values, we can achieve magnification effects which were not previously possible. Of particular interest are techniques we introduce for expressing complex and subtle magnification effects through magnification brushing, and allowing intrinsic properties of the data being visualized to create data-driven magnifications.",
                "AuthorNames": "Keahey, T.A.;Robertson, E.L.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keahey, T.A.;Robertson, E.L.",
                "filename": "keahey_infovis_97",
                "Citations": "559214"
            }
        },
        {
            "name": "Minghim, R.",
            "value": 49,
            "numPapers": 15,
            "cluster": "9",
            "index": 425,
            "weight": 1,
            "x": 2112.714890050792,
            "y": -1444.7841735334453,
            "px": 2432.278227440619,
            "py": -1999.4276294538324,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "An illustrated analysis of sonification for scientific visualisation",
                "PaperDOI": "10.1109/VISUAL.1995.480802",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480802",
                "firstage": "110",
                "Lastage": "117",
                "IEEEXPLOREArticleNumber": "480802",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents an analysis of progress in the use of sound as a tool in support of visualisation and gives an insight into its development and future needs. Special emphasis is given to the use of sound in scientific and engineering applications. A system developed to support surface data presentation and interaction by using sound is presented and discussed",
                "AuthorNames": "Minghim, R.;Forrest, A.R.",
                "FirstAuthorAffiliation": "Sch. of Inf. Syst., East Anglia Univ., Norwich, UK|c|;",
                "AuthorIDs": "37371567600;37863405200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Minghim, R.;Forrest, A.R.",
                "filename": "minghim_vis_95",
                "Citations": ""
            }
        },
        {
            "name": "Schulz, H.",
            "value": 62,
            "numPapers": 35,
            "cluster": "3",
            "index": 426,
            "weight": 1,
            "x": -233.58191643318509,
            "y": -177.0186151491975,
            "px": -320.1710197231096,
            "py": -527.6487381041497,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Design Space of Visualization Tasks",
                "PaperDOI": "10.1109/TVCG.2013.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.120",
                "firstage": "2366",
                "Lastage": "2375",
                "IEEEXPLOREArticleNumber": "6634156",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.",
                "AuthorNames": "Schulz, H.-J.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "FirstAuthorAffiliation": "Univ. of Rostock, Rostock, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schulz, H.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "filename": "schulz_infovis_13",
                "Citations": "559213;1532136;4376144;146372;6327265;235203;1382903;4677365;559211;1382902;636792;885093;885092;146375"
            }
        },
        {
            "name": "Schneidewind, J.",
            "value": 111,
            "numPapers": 21,
            "cluster": "0",
            "index": 427,
            "weight": 5,
            "x": 1043.2558673473882,
            "y": 99.24304132679572,
            "px": 1169.1150885995532,
            "py": 412.7639824819916,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Intelligent Visual Analytics Queries",
                "PaperDOI": "10.1109/VAST.2007.4389001",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389001",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "4389001",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.",
                "AuthorNames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.",
                "FirstAuthorAffiliation": "Hewlett Packard Lab., Palo Alto|c|;;;;",
                "AuthorIDs": "37274264300;37275646700;37283138700;37563668400;37669961800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.",
                "filename": "hao_vast_07",
                "Citations": "4015431;729568;146402;885086;346302"
            }
        },
        {
            "name": "Sips, M.",
            "value": 41,
            "numPapers": 18,
            "cluster": "2",
            "index": 428,
            "weight": 1,
            "x": 320.4043716238036,
            "y": 2002.1465429481757,
            "px": 134.94663885349178,
            "py": 3617.359599255517,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Pixnostics: Towards Measuring the Value of Visualization",
                "PaperDOI": "10.1109/VAST.2006.261423",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261423",
                "firstage": "199",
                "Lastage": "206",
                "IEEEXPLOREArticleNumber": "4035766",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach",
                "AuthorNames": "Schneidewind, J.;Sips, M.;Keim, D.A.",
                "FirstAuthorAffiliation": "Konstanz Univ.|c|;;",
                "AuthorIDs": "37669961800;37827860500;37283138700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schneidewind, J.;Sips, M.;Keim, D.A.",
                "filename": "schneidewind_vast_06",
                "Citations": "1532145;1532142;1532782;1532781;885092"
            }
        },
        {
            "name": "LeBlanc, J.",
            "value": 77,
            "numPapers": 1,
            "cluster": "2",
            "index": 429,
            "weight": 3,
            "x": 308.6037004658818,
            "y": -489.37748141113735,
            "px": 448.49110833990665,
            "py": -184.2896911232914,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Exploring N-dimensional databases",
                "PaperDOI": "10.1109/VISUAL.1990.146386",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146386",
                "firstage": "230",
                "Lastage": "237",
                "IEEEXPLOREArticleNumber": "146386",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The ability of researchers in the scientific and engineering community to generate or acquire data far outstrips their ability to analyze it. This problem is even more pronounced when the data is of high dimensionality. Visualization has been identified as a critical technique for exploring data sets, but the visualization tools developed to date have mostly concentrated on the display of low (one to four) dimensional data. Ideally a tool for examining N-dimensional data should allow the presentation of the data in a way that can be intuitively interpreted and allow the display of arbitrary views and subsets of the data. The work presented in this paper describes the creation of such a tool using a technique which we term dimensional stacking.",
                "AuthorNames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA, USA|c|;;",
                "AuthorIDs": "38225805300;37268441700;38223933400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "filename": "leblanc_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Wittels, N.",
            "value": 77,
            "numPapers": 1,
            "cluster": "2",
            "index": 430,
            "weight": 3,
            "x": -238.29808432672377,
            "y": -315.2885950781084,
            "px": 98.46940896222979,
            "py": -76.12528521732331,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Exploring N-dimensional databases",
                "PaperDOI": "10.1109/VISUAL.1990.146386",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146386",
                "firstage": "230",
                "Lastage": "237",
                "IEEEXPLOREArticleNumber": "146386",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The ability of researchers in the scientific and engineering community to generate or acquire data far outstrips their ability to analyze it. This problem is even more pronounced when the data is of high dimensionality. Visualization has been identified as a critical technique for exploring data sets, but the visualization tools developed to date have mostly concentrated on the display of low (one to four) dimensional data. Ideally a tool for examining N-dimensional data should allow the presentation of the data in a way that can be intuitively interpreted and allow the display of arbitrary views and subsets of the data. The work presented in this paper describes the creation of such a tool using a technique which we term dimensional stacking.",
                "AuthorNames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA, USA|c|;;",
                "AuthorIDs": "38225805300;37268441700;38223933400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "filename": "leblanc_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Ankerst, M.",
            "value": 147,
            "numPapers": 9,
            "cluster": "2",
            "index": 431,
            "weight": 4,
            "x": -130.80055989489992,
            "y": -1325.2570741881977,
            "px": 4.01792369028074,
            "py": -1001.0399420079274,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Recursive pattern: a technique for visualizing very large amounts of data",
                "PaperDOI": "10.1109/VISUAL.1995.485140",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.485140",
                "firstage": "279",
                "Lastage": "286, 463",
                "IEEEXPLOREArticleNumber": "485140",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An important goal of visualization technology is to support the exploration and analysis of very large amounts of data. In this paper, we propose a new visualization technique called a `recursive pattern', which has been developed for visualizing large amounts of multidimensional data. The technique is based on a generic recursive scheme which generalizes a wide range of pixel-oriented arrangements for displaying large data sets. By instantiating the technique with adequate data- and application-dependent parameters, the user may greatly influence the structure of the resulting visualizations. Since the technique uses one pixel for presenting each data value, the amount of data which can be displayed is only limited by the resolution of current display technology and by the limitations of human perceptibility. Beside describing the basic idea of the `recursive pattern' technique, we provide several examples of useful parameter settings for the various recursion levels. We further show that our `recursive pattern' technique is particularly advantageous for the large class of data sets which have a natural order according to one dimension (e.g. time series data). We demonstrate the usefulness of our technique by using a stock market application",
                "AuthorNames": "Keim, D.A.;Kriegel, H.-P.;Ankerst, M.",
                "FirstAuthorAffiliation": "Inst. for Comput. Sci., Munchen Univ., Germany|c|;;",
                "AuthorIDs": "37283138700;37276747000;37371609900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keim, D.A.;Kriegel, H.-P.;Ankerst, M.",
                "filename": "keim_vis_95",
                "Citations": "146402;528688;175809;146386;146387;146389"
            }
        },
        {
            "name": "Albuquerque, G.",
            "value": 62,
            "numPapers": 23,
            "cluster": "0",
            "index": 432,
            "weight": 9,
            "x": 1458.7184958645748,
            "y": 1307.2033643198085,
            "px": 1431.532231579558,
            "py": 1275.336042484738,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Perception-based visual quality measures",
                "PaperDOI": "10.1109/VAST.2011.6102437",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102437",
                "firstage": "13",
                "Lastage": "20",
                "IEEEXPLOREArticleNumber": "6102437",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;",
                "AuthorIDs": "37603943800;37546817000;37273816400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Magnor, M.",
                "filename": "albuquer_vast_11",
                "Citations": "1532142;5652433;4035766;5332628;5613439;5290704"
            }
        },
        {
            "name": "Eisemann, M.",
            "value": 59,
            "numPapers": 17,
            "cluster": "0",
            "index": 433,
            "weight": 4,
            "x": 263.3022285008392,
            "y": 1046.1558458465274,
            "px": 725.9600837438419,
            "py": 979.8290321637181,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Perception-based visual quality measures",
                "PaperDOI": "10.1109/VAST.2011.6102437",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102437",
                "firstage": "13",
                "Lastage": "20",
                "IEEEXPLOREArticleNumber": "6102437",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;",
                "AuthorIDs": "37603943800;37546817000;37273816400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Magnor, M.",
                "filename": "albuquer_vast_11",
                "Citations": "1532142;5652433;4035766;5332628;5613439;5290704"
            }
        },
        {
            "name": "Hotz, I.",
            "value": 61,
            "numPapers": 25,
            "cluster": "7",
            "index": 434,
            "weight": 2,
            "x": 450.75632925941954,
            "y": -669.1676287101218,
            "px": 526.6103139757577,
            "py": -2326.3520465447286,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Two-Dimensional Time-Dependent Vortex Regions Based on the Acceleration Magnitude",
                "PaperDOI": "10.1109/TVCG.2011.249",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.249",
                "firstage": "2080",
                "Lastage": "2087",
                "IEEEXPLOREArticleNumber": "6064972",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Acceleration is a fundamental quantity of flow fields that captures Galilean invariant properties of particle motion. Considering the magnitude of this field, minima represent characteristic structures of the flow that can be classified as saddle- or vortex-like. We made the interesting observation that vortex-like minima are enclosed by particularly pronounced ridges. This makes it possible to define boundaries of vortex regions in a parameter-free way. Utilizing scalar field topology, a robust algorithm can be designed to extract such boundaries. They can be arbitrarily shaped. An efficient tracking algorithm allows us to display the temporal evolution of vortices. Various vortex models are used to evaluate the method. We apply our method to two-dimensional model systems from computational fluid dynamics and compare the results to those arising from existing definitions.",
                "AuthorNames": "Kasten, J.;Reininghaus, J.;Hotz, I.;Hege, H.-C.",
                "FirstAuthorAffiliation": "Zuse Inst. Berlin, Berlin, Germany|c|;;;",
                "AuthorIDs": "38028453100;37590998600;37282721800;37282272000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kasten, J.;Reininghaus, J.;Hotz, I.;Hege, H.-C.",
                "filename": "kasten_vis_11",
                "Citations": "1532830;1372214;4658165;1183821;4015452"
            }
        },
        {
            "name": "Hlawitschka, M.",
            "value": 49,
            "numPapers": 20,
            "cluster": "6",
            "index": 435,
            "weight": 1,
            "x": 23.697572927807386,
            "y": 52.55245845942564,
            "px": -328.7412161677072,
            "py": -21.43451432978659,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2008.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.143",
                "firstage": "1475",
                "Lastage": "1482",
                "IEEEXPLOREArticleNumber": "4658165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.",
                "AuthorNames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Leipzig Univ., Leipzig|c|;;;;",
                "AuthorIDs": "37869538100;37565763400;37282624500;37403333700;37282574800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "filename": "schneide_vis_08",
                "Citations": "4015446;964519;1372214;4376165;1532830;4015447;1372235;1250374;4376167;1532848;663875;1532835"
            }
        },
        {
            "name": "Guoning Chen",
            "value": 8,
            "numPapers": 22,
            "cluster": "6",
            "index": 436,
            "weight": 3,
            "x": 644.9954333035464,
            "y": 501.7008374363354,
            "px": 599.3640846688118,
            "py": 425.3006979412789,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "firstage": "1979",
                "Lastage": "1988",
                "IEEEXPLOREArticleNumber": "6064961",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "filename": "palke_vis_11",
                "Citations": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Zheng, X.",
            "value": 89,
            "numPapers": 31,
            "cluster": "6",
            "index": 437,
            "weight": 13,
            "x": 704.4881563662485,
            "y": 815.7049033568551,
            "px": 729.7585203788536,
            "py": 849.6954758069254,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "HyperLIC",
                "PaperDOI": "10.1109/VISUAL.2003.1250379",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250379",
                "firstage": "249",
                "Lastage": "256",
                "IEEEXPLOREArticleNumber": "1250379",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce a new method for visualizing symmetric tensor fields. The technique produces images and animations reminiscent of line integral convolution (LIC). The technique is also slightly related to hyperstreamlines in that it is used to visualize tensor fields. However, the similarity ends there. HyperLIC uses a multi-pass approach to show the anisotropic properties in a 2D or 3D tensor field. We demonstrate this technique using data sets from computational fluid dynamics as well as diffusion-tensor MRI.",
                "AuthorNames": "Zheng, X.;Pang, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37274785100;37267352000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zheng, X.;Pang, A.",
                "filename": "zheng_vis_03",
                "Citations": "1183797;1183799;663912;809886"
            }
        },
        {
            "name": "Palke, D.",
            "value": 2,
            "numPapers": 18,
            "cluster": "6",
            "index": 438,
            "weight": 2,
            "x": 626.7623053129115,
            "y": -242.15829008963937,
            "px": 501.2559907730123,
            "py": 497.7690211480717,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "firstage": "1979",
                "Lastage": "1988",
                "IEEEXPLOREArticleNumber": "6064961",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "filename": "palke_vis_11",
                "Citations": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Zhongzang Lin",
            "value": 2,
            "numPapers": 18,
            "cluster": "6",
            "index": 439,
            "weight": 2,
            "x": -258.9773742164115,
            "y": 855.5217629978521,
            "px": 622.6248011776727,
            "py": 336.3478235340033,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "firstage": "1979",
                "Lastage": "1988",
                "IEEEXPLOREArticleNumber": "6064961",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "filename": "palke_vis_11",
                "Citations": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Yeh, H.",
            "value": 2,
            "numPapers": 18,
            "cluster": "6",
            "index": 440,
            "weight": 2,
            "x": 1012.0115277139739,
            "y": 367.92344971355664,
            "px": 424.4230374145931,
            "py": 400.3254690501643,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "firstage": "1979",
                "Lastage": "1988",
                "IEEEXPLOREArticleNumber": "6064961",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "filename": "palke_vis_11",
                "Citations": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Vincent, P.",
            "value": 2,
            "numPapers": 18,
            "cluster": "6",
            "index": 441,
            "weight": 2,
            "x": 1225.041450977743,
            "y": 669.0939708753887,
            "px": 413.48606942636644,
            "py": 348.2090852824111,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "firstage": "1979",
                "Lastage": "1988",
                "IEEEXPLOREArticleNumber": "6064961",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "filename": "palke_vis_11",
                "Citations": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Zhang, E.",
            "value": 85,
            "numPapers": 33,
            "cluster": "6",
            "index": 442,
            "weight": 2,
            "x": 365.1827430984132,
            "y": 165.80351683807703,
            "px": 573.0881153263105,
            "py": 456.819872167645,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations",
                "PaperDOI": "10.1109/INFVIS.2000.885091",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885091",
                "firstage": "57",
                "Lastage": "65",
                "IEEEXPLOREArticleNumber": "885091",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space",
                "AuthorNames": "Stasko, J.;Zhang, E.",
                "FirstAuthorAffiliation": "GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;",
                "AuthorIDs": "37267736900;38020590400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stasko, J.;Zhang, E.",
                "filename": "stasko_infovis_00",
                "Citations": "801860;235217;729567;175815"
            }
        },
        {
            "name": "Bajaj, C.L.",
            "value": 171,
            "numPapers": 26,
            "cluster": "7",
            "index": 443,
            "weight": 2,
            "x": 781.6368169419194,
            "y": -77.95002120849497,
            "px": 1313.010909281045,
            "py": -806.5561980968212,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "The contour spectrum",
                "PaperDOI": "10.1109/VISUAL.1997.663875",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663875",
                "firstage": "167",
                "Lastage": "173",
                "IEEEXPLOREArticleNumber": "663875",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.",
                "AuthorNames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "FirstAuthorAffiliation": "Shastra Lab., Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "37282899200;37284312600;37355637500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "filename": "bajaj_vis_97",
                "Citations": "568123;480803;745284;568112"
            }
        },
        {
            "name": "Schikore, D.R.",
            "value": 128,
            "numPapers": 15,
            "cluster": "7",
            "index": 444,
            "weight": 2,
            "x": 542.1272848278722,
            "y": 41.5559230418277,
            "px": 720.8085479614683,
            "py": -474.42776862077113,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "The contour spectrum",
                "PaperDOI": "10.1109/VISUAL.1997.663875",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663875",
                "firstage": "167",
                "Lastage": "173",
                "IEEEXPLOREArticleNumber": "663875",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.",
                "AuthorNames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "FirstAuthorAffiliation": "Shastra Lab., Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "37282899200;37284312600;37355637500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "filename": "bajaj_vis_97",
                "Citations": "568123;480803;745284;568112"
            }
        },
        {
            "name": "Lehmann, D.J.",
            "value": 21,
            "numPapers": 23,
            "cluster": "5",
            "index": 445,
            "weight": 1,
            "x": -1263.9830187503783,
            "y": 934.4208633713787,
            "px": -2285.904013049153,
            "py": 1655.9913877769607,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Orthographic Star Coordinates",
                "PaperDOI": "10.1109/TVCG.2013.182",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.182",
                "firstage": "2615",
                "Lastage": "2624",
                "IEEEXPLOREArticleNumber": "6634131",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.",
                "AuthorNames": "Lehmann, D.J.;Theisel, H.",
                "FirstAuthorAffiliation": "Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;",
                "AuthorIDs": ";",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lehmann, D.J.;Theisel, H.",
                "filename": "lehmann_infovis_13",
                "Citations": "663916"
            }
        },
        {
            "name": "de Leeuw, W.",
            "value": 205,
            "numPapers": 27,
            "cluster": "6",
            "index": 446,
            "weight": 8,
            "x": 503.8275992303924,
            "y": 434.17823921238073,
            "px": 553.6465532347811,
            "py": 479.73314166488336,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data",
                "PaperDOI": "10.1109/TVCG.2006.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.195",
                "firstage": "1251",
                "Lastage": "1258",
                "IEEEXPLOREArticleNumber": "4015489",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we propose an approach in which interactive visualization and analysis are combined with batch tools for the processing of large data collections. Large and heterogeneous data collections are difficult to analyze and pose specific problems to interactive visualization. Application of the traditional interactive processing and visualization approaches as well as batch processing encounter considerable drawbacks for such large and heterogeneous data collections due to the amount and type of data. Computing resources are not sufficient for interactive exploration of the data and automated analysis has the disadvantage that the user has only limited control and feedback on the analysis process. In our approach, an analysis procedure with features and attributes of interest for the analysis is defined interactively. This procedure is used for offline processing of large collections of data sets. The results of the batch process along with \"visual summaries\" are used for further analysis. Visualization is not only used for the presentation of the result, but also as a tool to monitor the validity and quality of the operations performed during the batch process. Operations such as feature extraction and attribute calculation of the collected data sets are validated by visual inspection. This approach is illustrated by an extensive case study, in which a collection of confocal microscopy data sets is analyzed",
                "AuthorNames": "de Leeuw, W.;Verschure, P.J.;van Liere, R.",
                "FirstAuthorAffiliation": "Swammerdam Inst. for Life Sci.|c|;;",
                "AuthorIDs": ";37340174000;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "de Leeuw, W.;Verschure, P.J.;van Liere, R.",
                "filename": "leeuw_vis_06",
                "Citations": "745319;146378;885735;885678;1532788;568136"
            }
        },
        {
            "name": "Muigg, P.",
            "value": 104,
            "numPapers": 44,
            "cluster": "5",
            "index": 447,
            "weight": 9,
            "x": 299.0543458862488,
            "y": 194.43978502935713,
            "px": 326.57714674789673,
            "py": 152.17045982797288,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Interactive Visual Analysis of Perfusion Data",
                "PaperDOI": "10.1109/TVCG.2007.70569",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70569",
                "firstage": "1392",
                "Lastage": "1399",
                "IEEEXPLOREArticleNumber": "4376166",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.",
                "AuthorNames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "FirstAuthorAffiliation": "Univ. of Magdeburg, Magdeburg|c|;;;;",
                "AuthorIDs": "37424645600;37546620400;37274158800;37546620600;37424645300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oeltze, S.;Doleisch, H.;Hauser, H.;Muigg, P.;Preim, B.",
                "filename": "oeltze_vis_07",
                "Citations": "885739"
            }
        },
        {
            "name": "Bavoil, L.",
            "value": 92,
            "numPapers": 9,
            "cluster": "5",
            "index": 448,
            "weight": 1,
            "x": 1188.3162273814605,
            "y": -1150.987840325811,
            "px": 1963.3313731234591,
            "py": -2010.3600941034636,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Progressive Volume Rendering of Large Unstructured Grids",
                "PaperDOI": "10.1109/TVCG.2006.171",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.171",
                "firstage": "1307",
                "Lastage": "1314",
                "IEEEXPLOREArticleNumber": "4015496",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations",
                "AuthorNames": "Callahan, S.P.;Bavoil, L.;Pascucci, V.;Silva, C.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT|c|;;;",
                "AuthorIDs": "37426872800;37565304300;38262213600;37275249200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Callahan, S.P.;Bavoil, L.;Pascucci, V.;Silva, C.T.",
                "filename": "bavoil_vis_06",
                "Citations": "1532796;745713;1250390;1372227;1532793"
            }
        },
        {
            "name": "Weiler, Manfred",
            "value": 70,
            "numPapers": 2,
            "cluster": "5",
            "index": 449,
            "weight": 2,
            "x": 233.97074526252925,
            "y": 84.65172067194767,
            "px": 270.45112822115254,
            "py": 116.51623201256187,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Hardware-based ray casting for tetrahedral meshes",
                "PaperDOI": "10.1109/VISUAL.2003.1250390",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250390",
                "firstage": "333",
                "Lastage": "340",
                "IEEEXPLOREArticleNumber": "1250390",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present the first implementation of a volume ray casting algorithm for tetrahedral meshes running on off-the-shelf programmable graphics hardware. Our implementation avoids the memory transfer bottleneck of the graphics bus since the complete mesh data is stored in the local memory of the graphics adapter and all computations, in particular ray traversal and ray integration, are performed by the graphics processing unit. Analogously to other ray casting algorithms, our algorithm does not require an expensive cell sorting. Provided that the graphics adapter offers enough texture memory, our implementation performs comparable to the fastest published volume rendering algorithms for unstructured meshes. Our approach works with cyclic and/or non-convex meshes and supports early ray termination. Accurate ray integration is guaranteed by applying pre-integrated volume rendering. In order to achieve almost interactive modifications of transfer functions, we propose a new method for computing three-dimensional pre-integration tables.",
                "AuthorNames": "Weiler, Manfred;Kraus, M.;Merz, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Univ. of Stutgart, Germany|c|;;;",
                "AuthorIDs": "37268043100;37284293000;38140167100;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weiler, Manfred;Kraus, M.;Merz, M.;Ertl, T.",
                "filename": "weiler_vis_03",
                "Citations": "885683"
            }
        },
        {
            "name": "Bartz, D.",
            "value": 79,
            "numPapers": 27,
            "cluster": "5",
            "index": 450,
            "weight": 1,
            "x": 63.132340533633005,
            "y": 428.7001710316397,
            "px": -106.45805046991141,
            "py": 407.59415103088736,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Illustrative Stream Surfaces",
                "PaperDOI": "10.1109/TVCG.2010.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.166",
                "firstage": "1329",
                "Lastage": "1338",
                "IEEEXPLOREArticleNumber": "5613473",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham & Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.",
                "AuthorNames": "Born, S.;Wiebel, A.;Friedrich, J.;Scheuermann, G.;Bartz, D.",
                "FirstAuthorAffiliation": "Univ. Leipzig, Leipzig, Germany|c|;;;;",
                "AuthorIDs": "37590924500;37565763400;37587961900;37282574800;37448237300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Born, S.;Wiebel, A.;Friedrich, J.;Scheuermann, G.;Bartz, D.",
                "filename": "born_vis_10",
                "Citations": "146395;5290738;4376157;1532857;809905;4658156;5290742;964506;1532858;1532855;4658177;1372196;1250376"
            }
        },
        {
            "name": "Hirsch, C.",
            "value": 23,
            "numPapers": 10,
            "cluster": "5",
            "index": 451,
            "weight": 1,
            "x": -425.63002590103366,
            "y": 472.10016702989515,
            "px": -1117.141619183988,
            "py": 434.31073020029174,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations",
                "PaperDOI": "10.1109/TVCG.2011.225",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.225",
                "firstage": "1872",
                "Lastage": "1881",
                "IEEEXPLOREArticleNumber": "6064950",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.",
                "AuthorNames": "Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;;",
                "AuthorIDs": "38111592300;38229386600;38099765400;37408064900;38102461400;38229402400;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, E.",
                "filename": "waser_vis_11",
                "Citations": "5613487;4376187;1173149;5613489;1382904;1532795;5290771;1532143;5613488;5613487"
            }
        },
        {
            "name": "Max, N.",
            "value": 285,
            "numPapers": 26,
            "cluster": "5",
            "index": 452,
            "weight": 11,
            "x": 52.89417296829528,
            "y": 318.90377570150815,
            "px": 82.82475276455762,
            "py": 346.10082822968553,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "A characterization of the scientific data analysis process",
                "PaperDOI": "10.1109/VISUAL.1992.235203",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235203",
                "firstage": "235",
                "Lastage": "242",
                "IEEEXPLOREArticleNumber": "235203",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "It is shown how data visualization fits into the broader process of scientific data analysis. Scientists from several disciplines were observed while they analyzed their own data. Examination of the observations exposed process elements outside conventional image viewing. For example, analysts queried for quantitative information, made a variety of comparisons, applied math, managed data, and kept records. The characterization of scientific data analysis reveals activity beyond that traditionally supported by computer. It offers an understanding which has the potential to be applied to many future designs, and suggests specific recommendations for improving the support of this important aspect of scientific computing",
                "AuthorNames": "Springmeyer, R.R.;Blattner, M.M.;Max, N.L.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., CA, USA|c|;;",
                "AuthorIDs": "37378533700;37353304700;37267387800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Springmeyer, R.R.;Blattner, M.M.;Max, N.",
                "filename": "springmeyer_vis_92",
                "Citations": "146399"
            }
        },
        {
            "name": "McCormick, P.",
            "value": 55,
            "numPapers": 6,
            "cluster": "5",
            "index": 453,
            "weight": 1,
            "x": -543.759909572643,
            "y": 596.9951451207472,
            "px": -1354.951450276907,
            "py": 672.430660414669,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Scout: a hardware-accelerated system for quantitatively driven visualization and analysis",
                "PaperDOI": "10.1109/VISUAL.2004.95",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.95",
                "firstage": "171",
                "Lastage": "178",
                "IEEEXPLOREArticleNumber": "1372194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Quantitative techniques for visualization are critical to the successful analysis of both acquired and simulated scientific data. Many visualization techniques rely on indirect mappings, such as transfer functions, to produce the final imagery. In many situations, it is preferable and more powerful to express these mappings as mathematical expressions, or queries, that can then be directly applied to the data. We present a hardware-accelerated system that provides such capabilities and exploits current graphics hardware for portions of the computational tasks that would otherwise be executed on the CPU. In our approach, the direct programming of the graphics processor using a concise data parallel language, gives scientists the capability to efficiently explore and visualize data sets.",
                "AuthorNames": "McCormick, P.S.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.",
                "FirstAuthorAffiliation": "Advanced Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;",
                "AuthorIDs": "37282708700;37282707800;37282713700;37266777200;37269487100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "McCormick, P.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.",
                "filename": "mccormic_vis_04",
                "Citations": "480821;809864;964519;1250357"
            }
        },
        {
            "name": "Dyer, R.",
            "value": 22,
            "numPapers": 5,
            "cluster": "5",
            "index": 454,
            "weight": 1,
            "x": 887.5352627653343,
            "y": -2687.9176386770887,
            "px": 1443.6714082758851,
            "py": -4472.813582883415,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Linear and cubic box splines for the body centered cubic lattice",
                "PaperDOI": "10.1109/VISUAL.2004.65",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.65",
                "firstage": "11",
                "Lastage": "18",
                "IEEEXPLOREArticleNumber": "1372174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We derive piecewise linear and piecewise cubic box spline reconstruction filters for data sampled on the body centered cubic (BCC) lattice. We analytically derive a time domain representation of these reconstruction filters and using the Fourier slice-projection theorem we derive their frequency responses. The quality of these filters, when used in reconstructing BCC sampled volumetric data, is discussed and is demonstrated with a raycaster. Moreover, to demonstrate the superiority of the BCC sampling, the resulting reconstructions are compared with those produced from similar filters applied to data sampled on the Cartesian lattice.",
                "AuthorNames": "Entezari, A.;Dyer, R.;Moller, T.",
                "FirstAuthorAffiliation": "Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;",
                "AuthorIDs": "37268675600;37282718000;37275858700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Entezari, A.;Dyer, R.;Moller, T.",
                "filename": "entezari_vis_04",
                "Citations": "398851;964498;663848;346331;964499"
            }
        },
        {
            "name": "Theussl, T.",
            "value": 30,
            "numPapers": 5,
            "cluster": "5",
            "index": 455,
            "weight": 1,
            "x": 165.41253499449763,
            "y": -849.5142431695808,
            "px": 193.8831879428586,
            "py": -1245.7325263818727,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Optimal regular volume sampling",
                "PaperDOI": "10.1109/VISUAL.2001.964498",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964498",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "964498",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.",
                "AuthorNames": "Theussl, T.;Möller, T.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Technische Univ. Wien, Vienna, Austria|c|;;",
                "AuthorIDs": ";37275858700;37282552200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Theussl, T.;MÃ¶ller, T.;Groller, E.",
                "filename": "theussl_vis_01",
                "Citations": "346331"
            }
        },
        {
            "name": "Bergner, S.",
            "value": 73,
            "numPapers": 27,
            "cluster": "2",
            "index": 456,
            "weight": 1,
            "x": 319.09396364810596,
            "y": -405.99450950143665,
            "px": -12.964192652919728,
            "py": -1002.2613535500993,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Tuner: Principled Parameter finding for Image Segmentation Algorithms Using Visual Response Surface Exploration",
                "PaperDOI": "10.1109/TVCG.2011.248",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.248",
                "firstage": "1892",
                "Lastage": "1901",
                "IEEEXPLOREArticleNumber": "6064952",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the \"goodness\" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans.",
                "AuthorNames": "Torsney-Weir, T.;Saad, A.;Moller, T.;Hege, H.-C.;Weber, B.;Verbavatz, J.;Bergner, S.",
                "FirstAuthorAffiliation": "Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;",
                "AuthorIDs": "38229404800;37405565700;37275858700;37282272000;38002090200;38229406100;37418878100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Torsney-Weir, T.;Saad, A.;Moller, T.;Hege, H.-C.;Weber, B.;Verbavatz, J.;Bergner, S.",
                "filename": "torsneyweir_vis_11",
                "Citations": "4376187;4658159;5613487;5613488;346302;5613441;398859;809871;6065007;885678"
            }
        },
        {
            "name": "van Liere, R.",
            "value": 138,
            "numPapers": 28,
            "cluster": "6",
            "index": 457,
            "weight": 2,
            "x": 535.1849263932327,
            "y": 326.09954419747487,
            "px": 448.81739463386754,
            "py": 361.9701607628418,
            "node": {
                "Conference": "SciVis",
                "Year": "1993",
                "PaperTitle": "HyperSlice - Visualization of Scalar Functions of Many Variables",
                "PaperDOI": "10.1109/VISUAL.1993.398859",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398859",
                "firstage": "119",
                "Lastage": "125",
                "IEEEXPLOREArticleNumber": "398859",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "HyperSlice is a new method for the visualization of scalar functions of many variables. With this method the multi-dimensional function is presented in a simple and easy to understand way in which all dimensions are treated identically. The central concept is the representation of a multi-dimensional function as a matrix of orthogonal two-dimensional slices. These two-dimensional slices lend themselves very well to interaction via direct manipulation, due to a one to one relation between screen space and variable space. Several interaction techniques, for navigation, the location of maxima, and the use of user-defined paths, are presented",
                "AuthorNames": "van Wijk, J.J.;van Liere, R.",
                "FirstAuthorAffiliation": "Netherlands Energy Res. Foundation, Petten, Netherlands|c|;",
                "AuthorIDs": "37267249200;37282925600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Wijk, J.J.;van Liere, R.",
                "filename": "vanwijk1_vis_93",
                "Citations": "146387;175809"
            }
        },
        {
            "name": "Sanderson, A.",
            "value": 12,
            "numPapers": 27,
            "cluster": "6",
            "index": 458,
            "weight": 3,
            "x": 38.686941219728844,
            "y": -1017.7422898280845,
            "px": 203.63822470704267,
            "py": -550.9848355833716,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Analysis of Recurrent Patterns in Toroidal Magnetic fields",
                "PaperDOI": "10.1109/TVCG.2010.133",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.133",
                "firstage": "1431",
                "Lastage": "1440",
                "IEEEXPLOREArticleNumber": "5613484",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In the development of magnetic confinement fusion which will potentially be a future source for low cost power, physicists must be able to analyze the magnetic field that confines the burning plasma. While the magnetic field can be described as a vector field, traditional techniques for analyzing the field's topology cannot be used because of its Hamiltonian nature. In this paper we describe a technique developed as a collaboration between physicists and computer scientists that determines the topology of a toroidal magnetic field using fieldlines with near minimal lengths. More specifically, we analyze the Poincare╠ü map of the sampled fieldlines in a Poincare╠ü section including identifying critical points and other topological features of interest to physicists. The technique has been deployed into an interactiveparallel visualization tool which physicists are using to gain new insight into simulations of magnetically confined burning plasmas.",
                "AuthorNames": "Sanderson, A.;Guoning Chen;Tricoche, X.;Pugmire, D.;Kruger, S.;Breslau, J.",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37283733200;37596533600;37282575100;37394779900;37411319500;37591115800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sanderson, A.;Guoning Chen;Tricoche, X.;Pugmire, D.;Kruger, S.;Breslau, J.",
                "filename": "sanderson_vis_10",
                "Citations": "1532842;964507;1250376;663858"
            }
        },
        {
            "name": "Rockwood, A.",
            "value": 46,
            "numPapers": 4,
            "cluster": "6",
            "index": 459,
            "weight": 2,
            "x": 538.4874321707249,
            "y": 444.5414417616124,
            "px": 492.38484632384245,
            "py": 184.7909473300452,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Computing singularities of 3D vector fields with geometric algebra",
                "PaperDOI": "10.1109/VISUAL.2002.1183786",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183786",
                "firstage": "283",
                "Lastage": "289",
                "IEEEXPLOREArticleNumber": "1183786",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.",
                "AuthorNames": "Mann, S.;Rockwood, A.",
                "FirstAuthorAffiliation": "Waterloo Univ., Ont., Canada|c|;",
                "AuthorIDs": "37998748200;37372689000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Mann, S.;Rockwood, A.",
                "filename": "mann_vis_02",
                "Citations": "663858;663871"
            }
        },
        {
            "name": "Hesselink, L.",
            "value": 174,
            "numPapers": 14,
            "cluster": "6",
            "index": 460,
            "weight": 7,
            "x": 76.7237569984228,
            "y": -16.851458200621245,
            "px": 78.9525173997639,
            "py": -26.092510698411655,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "The topology of symmetric, second-order tensor fields",
                "PaperDOI": "10.1109/VISUAL.1994.346326",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346326",
                "firstage": "140",
                "Lastage": "147, C15",
                "IEEEXPLOREArticleNumber": "346326",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data. The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities-such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields. Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Poincare-Hopf theorem for vector fields",
                "AuthorNames": "Delmarcelle, T.;Hesselink, Lambertus",
                "FirstAuthorAffiliation": "Dept. of Appl. Phys., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37378372200;37274095200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Delmarcelle, T.;Hesselink, L.",
                "filename": "delmarcelle_vis_94",
                "Citations": "175773"
            }
        },
        {
            "name": "Koehler, C.",
            "value": 6,
            "numPapers": 21,
            "cluster": "6",
            "index": 461,
            "weight": 4,
            "x": 597.1126678405253,
            "y": 172.98146361878156,
            "px": 565.4850096980168,
            "py": 215.41230692793945,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "firstage": "2071",
                "Lastage": "2079",
                "IEEEXPLOREArticleNumber": "6064971",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "filename": "koehler_vis_11",
                "Citations": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Wischgoll, T.",
            "value": 6,
            "numPapers": 22,
            "cluster": "6",
            "index": 462,
            "weight": 4,
            "x": 659.5779707048675,
            "y": 241.2706365649599,
            "px": 607.5866576376527,
            "py": 261.9000705414778,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "firstage": "2071",
                "Lastage": "2079",
                "IEEEXPLOREArticleNumber": "6064971",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "filename": "koehler_vis_11",
                "Citations": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Haibo Dong",
            "value": 6,
            "numPapers": 21,
            "cluster": "6",
            "index": 463,
            "weight": 4,
            "x": 580.1008890758615,
            "y": 216.09264138132403,
            "px": 550.5991066472235,
            "py": 246.69402629058024,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "firstage": "2071",
                "Lastage": "2079",
                "IEEEXPLOREArticleNumber": "6064971",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "filename": "koehler_vis_11",
                "Citations": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Gaston, Z.",
            "value": 6,
            "numPapers": 21,
            "cluster": "6",
            "index": 464,
            "weight": 4,
            "x": 450.1516602452088,
            "y": 117.52223312556801,
            "px": 471.11298298198994,
            "py": 176.04344027122696,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "firstage": "2071",
                "Lastage": "2079",
                "IEEEXPLOREArticleNumber": "6064971",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "filename": "koehler_vis_11",
                "Citations": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Butkiewicz, T.",
            "value": 15,
            "numPapers": 18,
            "cluster": "2",
            "index": 465,
            "weight": 1,
            "x": 482.6234939535125,
            "y": 1144.0834190112162,
            "px": 772.7702056108978,
            "py": 1974.2866119517746,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Multi-Focused Geospatial Analysis Using Probes",
                "PaperDOI": "10.1109/TVCG.2008.149",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.149",
                "firstage": "1165",
                "Lastage": "1172",
                "IEEEXPLOREArticleNumber": "4658126",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.",
                "AuthorNames": "Butkiewicz, T.;Wenwen Dou;Wartell, Z.;Ribarsky, W.;Chang, R.",
                "FirstAuthorAffiliation": "Charlotte Visualization Center, UNC Charlotte, Charlotte, NC|c|;;;;",
                "AuthorIDs": "37591215700;37606064200;37297344900;37300425000;37592409400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Butkiewicz, T.;Wenwen Dou;Wartell, Z.;Ribarsky, W.;Chang, R.",
                "filename": "butkiewi_infovis_08",
                "Citations": "885102;4376137"
            }
        },
        {
            "name": "Ghoniem, M.",
            "value": 98,
            "numPapers": 11,
            "cluster": "2",
            "index": 466,
            "weight": 1,
            "x": -972.1445679047139,
            "y": 2961.750730930312,
            "px": -2005.5872575454114,
            "py": 5503.220958725536,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations",
                "PaperDOI": "10.1109/INFVIS.2004.1",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.1",
                "firstage": "17",
                "Lastage": "24",
                "IEEEXPLOREArticleNumber": "1382886",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation",
                "AuthorNames": "Ghoniem, M.;Fekete, J.;Castagliola, P.",
                "FirstAuthorAffiliation": "Ecole des Mines de Nantes|c|;;",
                "AuthorIDs": "37928384500;37407972900;37939616200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ghoniem, M.;Fekete, J.;Castagliola, P.",
                "filename": "ghoniem_infovis_04",
                "Citations": "1249030"
            }
        },
        {
            "name": "Barlow, T.",
            "value": 25,
            "numPapers": 3,
            "cluster": "6",
            "index": 467,
            "weight": 1,
            "x": -388.3534239644134,
            "y": 932.2315486056892,
            "px": -1109.0986544802233,
            "py": 1625.1657309294744,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "A comparison of 2-D visualizations of hierarchies",
                "PaperDOI": "10.1109/INFVIS.2001.963290",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963290",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "963290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes two experiments that compare four two-dimensional visualizations of hierarchies: organization chart, icicle plot, treemap, and tree ring. The visualizations are evaluated in the context of decision tree analyses prevalent in data mining applications. The results suggest that either the tree ring or icicle plot is equivalent to the organization chart.",
                "AuthorNames": "Barlow, T.;Neville, P.",
                "FirstAuthorAffiliation": "SAS Institute Inc.|c|;",
                "AuthorIDs": "37733138800;37726433800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Barlow, T.;Neville, P.",
                "filename": "barlow01_infovis_01",
                "Citations": "729567;235217"
            }
        },
        {
            "name": "Neville, P.",
            "value": 25,
            "numPapers": 3,
            "cluster": "6",
            "index": 468,
            "weight": 1,
            "x": 918.4196788858637,
            "y": -474.5488940569172,
            "px": 1349.5573817538148,
            "py": -1019.6954936361527,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "A comparison of 2-D visualizations of hierarchies",
                "PaperDOI": "10.1109/INFVIS.2001.963290",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963290",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "963290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes two experiments that compare four two-dimensional visualizations of hierarchies: organization chart, icicle plot, treemap, and tree ring. The visualizations are evaluated in the context of decision tree analyses prevalent in data mining applications. The results suggest that either the tree ring or icicle plot is equivalent to the organization chart.",
                "AuthorNames": "Barlow, T.;Neville, P.",
                "FirstAuthorAffiliation": "SAS Institute Inc.|c|;",
                "AuthorIDs": "37733138800;37726433800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Barlow, T.;Neville, P.",
                "filename": "barlow01_infovis_01",
                "Citations": "729567;235217"
            }
        },
        {
            "name": "Fisher, Brian",
            "value": 52,
            "numPapers": 25,
            "cluster": "3",
            "index": 469,
            "weight": 3,
            "x": -571.7535053622054,
            "y": 1.4311440309807502,
            "px": -179.02495268701958,
            "py": 475.2870926262617,
            "node": {
                "Conference": "VAST",
                "Year": "2008",
                "PaperTitle": "Visual analytics for complex concepts using a human cognition model",
                "PaperDOI": "10.1109/VAST.2008.4677361",
                "Link": "http://dx.doi.org/10.1109/VAST.2008.4677361",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "4677361",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples.",
                "AuthorNames": "Green, T.M.;Ribarsky, W.;Fisher, Brian",
                "FirstAuthorAffiliation": "Charlotte Visualization Center, Univ. of North Carolina, Charlotte, NC|c|;;",
                "AuthorIDs": "37403562900;37300425000;37267458000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Green, T.M.;Ribarsky, W.;Fisher, Brian",
                "filename": "green_vast_08",
                "Citations": "1532781;4035765;4376137;4389006;4389005;4389009;528686"
            }
        },
        {
            "name": "Rohrdantz, C.",
            "value": 49,
            "numPapers": 5,
            "cluster": "5",
            "index": 470,
            "weight": 1,
            "x": 15.198357595002358,
            "y": 730.6600839644929,
            "px": -260.03800813986476,
            "py": 924.4034618487285,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Visual opinion analysis of customer feedback data",
                "PaperDOI": "10.1109/VAST.2009.5333919",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5333919",
                "firstage": "187",
                "Lastage": "194",
                "IEEEXPLOREArticleNumber": "5333919",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Today, online stores collect a lot of customer feedback in the form of surveys, reviews, and comments. This feedback is categorized and in some cases responded to, but in general it is underutilized - even though customer satisfaction is essential to the success of their business. In this paper, we introduce several new techniques to interactively analyze customer comments and ratings to determine the positive and negative opinions expressed by the customers. First, we introduce a new discrimination-based technique to automatically extract the terms that are the subject of the positive or negative opinion (such as price or customer service) and that are frequently commented on. Second, we derive a Reverse-Distance-Weighting method to map the attributes to the related positive and negative opinions in the text. Third, the resulting high-dimensional feature vectors are visualized in a new summary representation that provides a quick overview. We also cluster the reviews according to the similarity of the comments. Special thumbnails are used to provide insight into the composition of the clusters and their relationship. In addition, an interactive circular correlation map is provided to allow analysts to detect the relationships of the comments to other important attributes and the scores. We have applied these techniques to customer comments from real-world online stores and product reviews from web sites to identify the strength and problems of different products and services, and show the potential of our technique.",
                "AuthorNames": "Oelke, D.;Ming Hao;Rohrdantz, C.;Keim, D.A.;Dayal, U.;Haug, L.;Janetzko, H.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;",
                "AuthorIDs": "37591207400;37274264300;37601356700;37283138700;37275646700;37681663300;37594026300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Oelke, D.;Ming Hao;Rohrdantz, C.;Keim, D.A.;Dayal, U.;Haug, L.;Janetzko, H.",
                "filename": "oelke_vast_09",
                "Citations": ""
            }
        },
        {
            "name": "Lazarov, M.",
            "value": 8,
            "numPapers": 10,
            "cluster": "14",
            "index": 471,
            "weight": 2,
            "x": 894.3670023400741,
            "y": 657.5866922578451,
            "px": 953.4254207632085,
            "py": 682.2127650075204,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "firstage": "1101",
                "Lastage": "1108",
                "IEEEXPLOREArticleNumber": "4015470",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "filename": "bhasker_vis_06",
                "Citations": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Bhasker, E.",
            "value": 25,
            "numPapers": 11,
            "cluster": "14",
            "index": 472,
            "weight": 7,
            "x": 791.8288274694482,
            "y": 646.5200096463776,
            "px": 745.4795441685079,
            "py": 635.5546418198775,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "firstage": "1101",
                "Lastage": "1108",
                "IEEEXPLOREArticleNumber": "4015470",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "filename": "bhasker_vis_06",
                "Citations": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Majumder, A.",
            "value": 51,
            "numPapers": 32,
            "cluster": "14",
            "index": 473,
            "weight": 22,
            "x": 837.5888298994445,
            "y": 589.4878180037449,
            "px": 790.7229318282168,
            "py": 573.4937109165986,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "firstage": "1101",
                "Lastage": "1108",
                "IEEEXPLOREArticleNumber": "4015470",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "filename": "bhasker_vis_06",
                "Citations": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Sinha, P.",
            "value": 13,
            "numPapers": 5,
            "cluster": "14",
            "index": 474,
            "weight": 1,
            "x": 858.0975577323932,
            "y": 466.0956568521468,
            "px": 788.2823021859086,
            "py": 391.2378285704475,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "firstage": "1101",
                "Lastage": "1108",
                "IEEEXPLOREArticleNumber": "4015470",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "filename": "bhasker_vis_06",
                "Citations": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Juang, R.",
            "value": 12,
            "numPapers": 6,
            "cluster": "14",
            "index": 475,
            "weight": 1,
            "x": 1053.4891231294146,
            "y": 492.3812567575487,
            "px": 1083.8461953941144,
            "py": 413.44172994608226,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Registration Techniques for Using Imperfect and Par tially Calibrated Devices in Planar Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2007.70586",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70586",
                "firstage": "1368",
                "Lastage": "1375",
                "IEEEXPLOREArticleNumber": "4376163",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 times 2500 resolution planar multi-projector display made of 3 times 3 array of nine severely distorted projectors using a low resolution (640 times 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.",
                "AuthorNames": "Bhasker, E.;Juang, R.;Majumder, A.",
                "FirstAuthorAffiliation": "Univ. of California, Irvine|c|;;",
                "AuthorIDs": "37828782600;37927188200;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bhasker, E.;Juang, R.;Majumder, A.",
                "filename": "bhasker_vis_07",
                "Citations": "964508;4015470;885685;1183793;885684;809883"
            }
        },
        {
            "name": "Chen, H.",
            "value": 18,
            "numPapers": 3,
            "cluster": "14",
            "index": 476,
            "weight": 1,
            "x": 700.7011131117829,
            "y": 994.3028880318493,
            "px": 522.9538845660825,
            "py": 1229.6255816571183,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "firstage": "339",
                "Lastage": "346",
                "IEEEXPLOREArticleNumber": "1183793",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "filename": "chen_vis_02",
                "Citations": "809883;964508;885685"
            }
        },
        {
            "name": "Sukthankar, R.",
            "value": 18,
            "numPapers": 3,
            "cluster": "14",
            "index": 477,
            "weight": 1,
            "x": 891.4328792065046,
            "y": 823.6763025578136,
            "px": 846.8889511507953,
            "py": 886.3541545827671,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "firstage": "339",
                "Lastage": "346",
                "IEEEXPLOREArticleNumber": "1183793",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "filename": "chen_vis_02",
                "Citations": "809883;964508;885685"
            }
        },
        {
            "name": "Wallace, G.",
            "value": 18,
            "numPapers": 3,
            "cluster": "14",
            "index": 478,
            "weight": 1,
            "x": 947.2268213274689,
            "y": 421.864554555825,
            "px": 924.1600230175006,
            "py": 305.2866074220687,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "firstage": "339",
                "Lastage": "346",
                "IEEEXPLOREArticleNumber": "1183793",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "filename": "chen_vis_02",
                "Citations": "809883;964508;885685"
            }
        },
        {
            "name": "Li, K.",
            "value": 38,
            "numPapers": 4,
            "cluster": "14",
            "index": 479,
            "weight": 2,
            "x": 912.083149298358,
            "y": 687.8774824911553,
            "px": 928.054251731352,
            "py": 697.8229518895572,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "firstage": "339",
                "Lastage": "346",
                "IEEEXPLOREArticleNumber": "1183793",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "filename": "chen_vis_02",
                "Citations": "809883;964508;885685"
            }
        },
        {
            "name": "Nielson, G.M.",
            "value": 211,
            "numPapers": 27,
            "cluster": "6",
            "index": 480,
            "weight": 10,
            "x": 550.4970913670388,
            "y": 199.25457346614073,
            "px": 540.2514704451036,
            "py": 205.409574430511,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "The asymptotic decider: resolving the ambiguity in marching cubes",
                "PaperDOI": "10.1109/VISUAL.1991.175782",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175782",
                "firstage": "83",
                "Lastage": "91, 413",
                "IEEEXPLOREArticleNumber": "175782",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A method for computing isovalue or contour surfaces of a trivariate function is discussed. The input data are values of the trivariate function, Fijk, at the cuberille grid points (xi, yj, zk ), and the output of a collection of triangles representing the surface consisting of all points where F(x,y, z) is a constant value. The method is a modification that is intended to correct a problem with a previous method.",
                "AuthorNames": "Nielson, G.M.;Hamann, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;",
                "AuthorIDs": "37283754100;37282068700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nielson, G.M.;Hamann, B.",
                "filename": "nielson_vis_91",
                "Citations": "146363"
            }
        },
        {
            "name": "Duffy, B.",
            "value": 37,
            "numPapers": 13,
            "cluster": "5",
            "index": 481,
            "weight": 1,
            "x": -664.9225805933668,
            "y": 412.3196699003005,
            "px": -1124.8946138294184,
            "py": 658.1914337165218,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Revisiting Histograms and Isosurface Statistics",
                "PaperDOI": "10.1109/TVCG.2008.160",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.160",
                "firstage": "1659",
                "Lastage": "1666",
                "IEEEXPLOREArticleNumber": "4658188",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.",
                "AuthorNames": "Scheidegger, C.E.;Schreiner, J.M.;Duffy, B.;Carr, H.;Silva, C.T.",
                "FirstAuthorAffiliation": "Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake City, UT|c|;;;;",
                "AuthorIDs": ";;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Scheidegger, C.E.;Schreiner, J.;Duffy, B.;Carr, H.;Silva, C.T.",
                "filename": "scheideg_vis_08",
                "Citations": "4015490;4658159;964519;964515;663875;964516"
            }
        },
        {
            "name": "Machiraju, R.",
            "value": 131,
            "numPapers": 32,
            "cluster": "6",
            "index": 482,
            "weight": 3,
            "x": 726.8036879147262,
            "y": 179.66674766101954,
            "px": 228.81131387929227,
            "py": 484.6984509351387,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Salient iso-surface detection with model-independent statistical signatures",
                "PaperDOI": "10.1109/VISUAL.2001.964516",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964516",
                "firstage": "231",
                "Lastage": "238",
                "IEEEXPLOREArticleNumber": "964516",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume graphics has not been accepted for widespread use. One of the inhibiting reasons is the lack of general methods for data-analysis and simple interfaces for data exploration. An error-and-trial iterative procedure is often used to select a desirable transfer function or mine the dataset for salient iso-values. New semi-automatic methods that are also data-centric have shown much promise. However, general and robust methods are still needed for data-exploration and analysis. In this paper, we propose general model-independent statistical methods based on central moments of data. Using these techniques we show how salient iso-surfaces at material boundaries can be determined. We provide examples from the medical and computational domain to demonstrate the effectiveness of our methods.",
                "AuthorNames": "Tenginakai, S.;Jinho Lee;Machiraju, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;",
                "AuthorIDs": "37728294500;37735408000;38268672500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tenginakai, S.;Jinho Lee;Machiraju, R.",
                "filename": "tenginakai_vis_01",
                "Citations": "745319;663875;568112"
            }
        },
        {
            "name": "Fraedrich, R.",
            "value": 9,
            "numPapers": 20,
            "cluster": "5",
            "index": 483,
            "weight": 2,
            "x": -115.09876425152733,
            "y": -591.0074678084,
            "px": -671.5011962719026,
            "py": -1042.4667195023048,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "firstage": "1533",
                "Lastage": "1540",
                "IEEEXPLOREArticleNumber": "5613495",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, München, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "filename": "fraedric_vis_10",
                "Citations": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Hopf, M.",
            "value": 49,
            "numPapers": 8,
            "cluster": "5",
            "index": 484,
            "weight": 2,
            "x": -612.7371854495481,
            "y": -433.78738681824814,
            "px": -716.20293835749,
            "py": -1047.6528439546198,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Herarchical splatting of scattered data",
                "PaperDOI": "10.1109/VISUAL.2003.1250404",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250404",
                "firstage": "433",
                "Lastage": "440",
                "IEEEXPLOREArticleNumber": "1250404",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Numerical particle simulations and astronomical observations create huge data sets containing uncorrelated 3D points of varying size. These data sets cannot be visualized interactively by simply rendering millions of colored points for each frame. Therefore, in many visualization applications a scalar density corresponding to the point distribution is resampled on a regular grid for direct volume rendering. However, many fine details are usually lost for voxel resolutions which still allow interactive visualization on standard workstations. Since no surface geometry is associated with our data sets, the recently introduced point-based rendering algorithms cannot be applied as well. In this paper we propose to accelerate the visualization of scattered point data by a hierarchical data structure based on a PCA clustering procedure. By traversing this structure for each frame we can trade-off rendering speed vs. image quality. Our scheme also reduces memory consumption by using quantized relative coordinates and it allows for fast sorting of semi-transparent clusters. We analyze various software and hardware implementations of our renderer and demonstrate that we can now visualize data sets with tens of millions of points interactively with sub-pixel screen space error on current PC graphics hardware employing advanced vertex shader functionality.",
                "AuthorNames": "Hopf, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Univ. of Stuttgart, Germany|c|;",
                "AuthorIDs": "37427327200;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hopf, M.;Ertl, T.",
                "filename": "hopf_vis_03",
                "Citations": "663882;1183820;809909;964490;964489;1183771"
            }
        },
        {
            "name": "Yagel, R.",
            "value": 166,
            "numPapers": 15,
            "cluster": "5",
            "index": 485,
            "weight": 6,
            "x": 56.76952692737574,
            "y": 380.8579178117899,
            "px": 66.53673034483454,
            "py": 344.3176929038117,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Volume visualization in cell biology",
                "PaperDOI": "10.1109/VISUAL.1990.146378",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146378",
                "firstage": "160",
                "Lastage": "168, 471-2",
                "IEEEXPLOREArticleNumber": "146378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The authors discuss the special properties of volumetric cell data (e.g., noise, discontinuity, raggedness) and the particular difficulties encountered when trying to visualize them in three dimensions. The authors describe some of the solutions adopted, specifically in surface discrimination and shading. Nerve cells (neuroblastoma) grown in tissue culture were selected as the biological preparation because these cells possess very rich actin structures. The cells were stained with a fluorescent probe specific for actin (rhodamine-phalloidin) and were viewed and optically sectioned using the Bio-Rad MRC 600 confocal fluorescence microscope. The slice dataset was then reconstructed and processed in the BioCube environment, a comprehensive system developed for volume visualization of cellular structures. The actin cytoskeleton of single cells was visualized and manipulated using this system",
                "AuthorNames": "Kaufman, A.;Yagel, R.;Bakalash, R.;Spector, I.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;",
                "AuthorIDs": "37268052800;38335293800;38158765400;38222533200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kaufman, A.;Yagel, R.;Bakalash, R.;Spector, I.",
                "filename": "kaufman_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Wiebel, A.",
            "value": 125,
            "numPapers": 53,
            "cluster": "6",
            "index": 486,
            "weight": 7,
            "x": 537.7047397342327,
            "y": 321.75991300481854,
            "px": 582.7848471689904,
            "py": 369.00339704995963,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2008.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.143",
                "firstage": "1475",
                "Lastage": "1482",
                "IEEEXPLOREArticleNumber": "4658165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.",
                "AuthorNames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Leipzig Univ., Leipzig|c|;;;;",
                "AuthorIDs": "37869538100;37565763400;37282624500;37403333700;37282574800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "filename": "schneide_vis_08",
                "Citations": "4015446;964519;1372214;4376165;1532830;4015447;1372235;1250374;4376167;1532848;663875;1532835"
            }
        },
        {
            "name": "Ferstl, F.",
            "value": 34,
            "numPapers": 18,
            "cluster": "6",
            "index": 487,
            "weight": 3,
            "x": 684.7201744963318,
            "y": 433.1846665231301,
            "px": 743.7733178118214,
            "py": 458.4008698202334,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Interactive Streak Surface Visualization on the GPU",
                "PaperDOI": "10.1109/TVCG.2009.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.154",
                "firstage": "1259",
                "Lastage": "1266",
                "IEEEXPLOREArticleNumber": "5290737",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper we present techniques for the visualization of unsteady flows using streak surfaces, which allow for the first time an adaptive integration and rendering of such surfaces in real-time. The techniques consist of two main components, which are both realized on the GPU to exploit computational and bandwidth capacities for numerical particle integration and to minimize bandwidth requirements in the rendering of the surface. In the construction stage, an adaptive surface representation is generated. Surface refinement and coarsening strategies are based on local surface properties like distortion and curvature. We compare two different methods to generate a streak surface: a) by computing a patch-based surface representation that avoids any interdependence between patches, and b) by computing a particle-based surface representation including particle connectivity, and by updating this connectivity during particle refinement and coarsening. In the rendering stage, the surface is either rendered as a set of quadrilateral surface patches using high-quality point-based approaches, or a surface triangulation is built in turn from the given particle connectivity and the resulting triangle mesh is rendered. We perform a comparative study of the proposed techniques with respect to surface quality, visual quality and performance by visualizing streak surfaces in real flows using different rendering options.",
                "AuthorNames": "Burger, K.;Ferstl, F.;Theisel, H.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization group, Tech. Univ. Munchen, Munich, Germany|c|;;;",
                "AuthorIDs": ";37606419000;37266875400;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Burger, K.;Ferstl, F.;Theisel, H.;Westermann, R.",
                "filename": "burger_vis_09",
                "Citations": "235211;964506;4658156;398875;4658155"
            }
        },
        {
            "name": "Bobach, T.",
            "value": 42,
            "numPapers": 5,
            "cluster": "6",
            "index": 488,
            "weight": 1,
            "x": -266.08028499725765,
            "y": 709.7918146243476,
            "px": -872.5921635307753,
            "py": 1118.0628670304081,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "A tetrahedra-based stream surface algorithm",
                "PaperDOI": "10.1109/VISUAL.2001.964506",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964506",
                "firstage": "151",
                "Lastage": "158",
                "IEEEXPLOREArticleNumber": "964506",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.",
                "AuthorNames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;;;",
                "AuthorIDs": "37282574800;37728450600;37282578800;37728450100;37282068700;37267811400;37722986700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "filename": "scheuermann_vis_01",
                "Citations": "398875;235211;485145;809896;663910"
            }
        },
        {
            "name": "Mahrous, K.",
            "value": 42,
            "numPapers": 5,
            "cluster": "6",
            "index": 489,
            "weight": 1,
            "x": 120.09937161659636,
            "y": 715.8737736588066,
            "px": -135.78526060291023,
            "py": 1100.5505253194065,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "A tetrahedra-based stream surface algorithm",
                "PaperDOI": "10.1109/VISUAL.2001.964506",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964506",
                "firstage": "151",
                "Lastage": "158",
                "IEEEXPLOREArticleNumber": "964506",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.",
                "AuthorNames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;;;",
                "AuthorIDs": "37282574800;37728450600;37282578800;37728450100;37282068700;37267811400;37722986700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "filename": "scheuermann_vis_01",
                "Citations": "398875;235211;485145;809896;663910"
            }
        },
        {
            "name": "Kollmann, W.",
            "value": 74,
            "numPapers": 15,
            "cluster": "6",
            "index": 490,
            "weight": 1,
            "x": 218.65210399655194,
            "y": -318.96615056371763,
            "px": 36.988279985238314,
            "py": -770.8723880290962,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Multifield Visualization Using Local Statistical Complexity",
                "PaperDOI": "10.1109/TVCG.2007.70615",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70615",
                "firstage": "1384",
                "Lastage": "1391",
                "IEEEXPLOREArticleNumber": "4376165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.",
                "AuthorNames": "Janicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jänicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "filename": "jaenicke_vis_07",
                "Citations": "809865;1250372;4015447;809905;4015473;1250383"
            }
        },
        {
            "name": "Chi-Wing Fu",
            "value": 42,
            "numPapers": 49,
            "cluster": "0",
            "index": 491,
            "weight": 2,
            "x": 963.5867994084344,
            "y": 726.5832235791966,
            "px": 948.5948689681991,
            "py": 621.0274196778919,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "Visualizing time-series on spirals",
                "PaperDOI": "10.1109/INFVIS.2001.963273",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963273",
                "firstage": "7",
                "Lastage": "13",
                "IEEEXPLOREArticleNumber": "963273",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identication of periodic patterns.",
                "AuthorNames": "Weber, M.;Alexa, M.;Muller, W.",
                "FirstAuthorAffiliation": "Technische Universitat Darmstadt|c|;;",
                "AuthorIDs": "37734022800;37267466700;38184260700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Weber, M.;Alexa, M.;Muller, W.",
                "filename": "alexa_infovis_01",
                "Citations": "175794;885098;528685"
            }
        },
        {
            "name": "Wenger, R.",
            "value": 50,
            "numPapers": 27,
            "cluster": "6",
            "index": 492,
            "weight": 1,
            "x": 515.6681633568707,
            "y": -540.9448140110044,
            "px": 557.2885730163431,
            "py": -1023.242435838501,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Volume tracking using higher dimensional isosurfacing",
                "PaperDOI": "10.1109/VISUAL.2003.1250374",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250374",
                "firstage": "209",
                "Lastage": "216",
                "IEEEXPLOREArticleNumber": "1250374",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Tracking and visualizing local features from a time-varying volumetric data allows the user to focus on selected regions of interest, both in space and time, which can lead to a better understanding of the underlying dynamics. In this paper, we present an efficient algorithm to track time-varying isosurfaces and interval volumes using isosurfacing in higher dimensions. Instead of extracting the data features such as isosurfaces or interval volumes separately from multiple time steps and computing the spatial correspondence between those features, our algorithm extracts the correspondence directly from the higher dimensional geometry and thus can more efficiently follow the user selected local features in time. In addition, by analyzing the resulting higher dimensional geometry, it becomes easier to detect important topological events and the corresponding critical time steps for the selected features. With our algorithm, the user can interact with the underlying time-varying data more easily. The computation cost for performing time-varying volume tracking is also minimized.",
                "AuthorNames": "Guangfeng Ji;Han-Wei Shen;Wenger, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;",
                "AuthorIDs": "38202947500;37279493500;37284274100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Guangfeng Ji;Han-Wei Shen;Wenger, R.",
                "filename": "ji_vis_03",
                "Citations": "885704;745288;568103;1183774;567807;885703;480789;663886"
            }
        },
        {
            "name": "Law, A.J.",
            "value": 0,
            "numPapers": 5,
            "cluster": "14",
            "index": 493,
            "weight": 1,
            "x": 1114.0507375450707,
            "y": 757.8619133240471,
            "px": 1196.8797201685347,
            "py": 808.2457165733456,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing",
                "PaperDOI": "10.1109/TVCG.2009.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.124",
                "firstage": "1317",
                "Lastage": "1326",
                "IEEEXPLOREArticleNumber": "5290744",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",
                "AuthorNames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;",
                "AuthorIDs": "37391937200;37541336800;37271691400;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "filename": "sajadi2_vis_09",
                "Citations": "964508;1183793;885684;809883;4376163;4015470"
            }
        },
        {
            "name": "Aliaga, D.",
            "value": 28,
            "numPapers": 19,
            "cluster": "14",
            "index": 494,
            "weight": 1,
            "x": 1118.0193437220928,
            "y": 727.3729209660905,
            "px": 1199.4692902677411,
            "py": 761.9676856863929,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing",
                "PaperDOI": "10.1109/TVCG.2009.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.124",
                "firstage": "1317",
                "Lastage": "1326",
                "IEEEXPLOREArticleNumber": "5290744",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",
                "AuthorNames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;",
                "AuthorIDs": "37391937200;37541336800;37271691400;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "filename": "sajadi2_vis_09",
                "Citations": "964508;1183793;885684;809883;4376163;4015470"
            }
        },
        {
            "name": "Zhu He",
            "value": 18,
            "numPapers": 1,
            "cluster": "14",
            "index": 495,
            "weight": 1,
            "x": 676.8282802694755,
            "y": 551.3882081002993,
            "px": 520.7285072928527,
            "py": 486.4264344804475,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Achieving color uniformity across multi-projector displays",
                "PaperDOI": "10.1109/VISUAL.2000.885684",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885684",
                "firstage": "117",
                "Lastage": "124",
                "IEEEXPLOREArticleNumber": "885684",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).",
                "AuthorNames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;",
                "AuthorIDs": "38477162600;38024209800;37298881100;37300645000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "filename": "majumder_vis_00",
                "Citations": "809890"
            }
        },
        {
            "name": "Towles, H.",
            "value": 82,
            "numPapers": 8,
            "cluster": "14",
            "index": 496,
            "weight": 4,
            "x": 809.6701215131666,
            "y": 605.2547457815399,
            "px": 791.2974210658921,
            "py": 610.1659172666588,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Achieving color uniformity across multi-projector displays",
                "PaperDOI": "10.1109/VISUAL.2000.885684",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885684",
                "firstage": "117",
                "Lastage": "124",
                "IEEEXPLOREArticleNumber": "885684",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).",
                "AuthorNames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;",
                "AuthorIDs": "38477162600;38024209800;37298881100;37300645000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "filename": "majumder_vis_00",
                "Citations": "809890"
            }
        },
        {
            "name": "Welch, G.",
            "value": 62,
            "numPapers": 4,
            "cluster": "14",
            "index": 497,
            "weight": 3,
            "x": 1002.1438143364993,
            "y": 667.4177003679947,
            "px": 835.3889209786668,
            "py": 615.5128736526618,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Achieving color uniformity across multi-projector displays",
                "PaperDOI": "10.1109/VISUAL.2000.885684",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885684",
                "firstage": "117",
                "Lastage": "124",
                "IEEEXPLOREArticleNumber": "885684",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).",
                "AuthorNames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;",
                "AuthorIDs": "38477162600;38024209800;37298881100;37300645000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "filename": "majumder_vis_00",
                "Citations": "809890"
            }
        },
        {
            "name": "Huang, J.",
            "value": 87,
            "numPapers": 53,
            "cluster": "5",
            "index": 498,
            "weight": 10,
            "x": 71.39329235304328,
            "y": 217.84147208358436,
            "px": 54.320009938937474,
            "py": 199.32404796249895,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Visualizing Temporal Patterns in Large Multivariate Data using Textual Pattern Matching",
                "PaperDOI": "10.1109/TVCG.2008.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.184",
                "firstage": "1467",
                "Lastage": "1474",
                "IEEEXPLOREArticleNumber": "4658164",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.",
                "AuthorNames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "FirstAuthorAffiliation": "Univ. of Tennessee at Knoxville, Knoxville, TN|c|;;;;",
                "AuthorIDs": "37828700000;37281262900;37410066100;37672397100;37545504600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "filename": "glatter_vis_08",
                "Citations": "1250402;4376164;4015494;1372194;4376167;964519;1532792"
            }
        },
        {
            "name": "Ahrens, E.T.",
            "value": 74,
            "numPapers": 1,
            "cluster": "6",
            "index": 499,
            "weight": 2,
            "x": 130.4367001467689,
            "y": -598.6370325746816,
            "px": 481.5976350046723,
            "py": 368.2007987821565,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "firstage": "127",
                "Lastage": "134",
                "IEEEXPLOREArticleNumber": "745294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "filename": "laidlaw_vis_98",
                "Citations": "235201"
            }
        },
        {
            "name": "Kremers, D.",
            "value": 74,
            "numPapers": 2,
            "cluster": "6",
            "index": 500,
            "weight": 2,
            "x": 954.0487735824383,
            "y": 357.2802487049864,
            "px": 478.9564320670642,
            "py": 420.0795139643464,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "firstage": "127",
                "Lastage": "134",
                "IEEEXPLOREArticleNumber": "745294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "filename": "laidlaw_vis_98",
                "Citations": "235201"
            }
        },
        {
            "name": "Avalos, M.J.",
            "value": 74,
            "numPapers": 1,
            "cluster": "6",
            "index": 501,
            "weight": 2,
            "x": -513.4477842481878,
            "y": 422.77914898383875,
            "px": 455.1352867785149,
            "py": 416.95094824179756,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "firstage": "127",
                "Lastage": "134",
                "IEEEXPLOREArticleNumber": "745294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "filename": "laidlaw_vis_98",
                "Citations": "235201"
            }
        },
        {
            "name": "Jacobs, R.E.",
            "value": 74,
            "numPapers": 1,
            "cluster": "6",
            "index": 502,
            "weight": 2,
            "x": 1061.4780023598787,
            "y": -739.2681097409231,
            "px": 532.6506408869257,
            "py": 357.21634574015496,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "firstage": "127",
                "Lastage": "134",
                "IEEEXPLOREArticleNumber": "745294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "filename": "laidlaw_vis_98",
                "Citations": "235201"
            }
        },
        {
            "name": "Readhead, C.",
            "value": 74,
            "numPapers": 1,
            "cluster": "6",
            "index": 503,
            "weight": 2,
            "x": 1187.3668977341224,
            "y": 663.3416856756495,
            "px": 508.2376213251227,
            "py": 425.61753641031333,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "firstage": "127",
                "Lastage": "134",
                "IEEEXPLOREArticleNumber": "745294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "filename": "laidlaw_vis_98",
                "Citations": "235201"
            }
        },
        {
            "name": "Delmarcelle, T.",
            "value": 97,
            "numPapers": 5,
            "cluster": "6",
            "index": 504,
            "weight": 4,
            "x": -27.01867814682214,
            "y": -163.13056368239467,
            "px": 128.3894343586666,
            "py": -6.236196581315476,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "The topology of symmetric, second-order tensor fields",
                "PaperDOI": "10.1109/VISUAL.1994.346326",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346326",
                "firstage": "140",
                "Lastage": "147, C15",
                "IEEEXPLOREArticleNumber": "346326",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data. The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities-such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields. Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Poincare-Hopf theorem for vector fields",
                "AuthorNames": "Delmarcelle, T.;Hesselink, Lambertus",
                "FirstAuthorAffiliation": "Dept. of Appl. Phys., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37378372200;37274095200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Delmarcelle, T.;Hesselink, L.",
                "filename": "delmarcelle_vis_94",
                "Citations": "175773"
            }
        },
        {
            "name": "Gerber, S.",
            "value": 20,
            "numPapers": 6,
            "cluster": "7",
            "index": 505,
            "weight": 1,
            "x": -208.83069626720743,
            "y": 548.3211234753261,
            "px": -709.724434340316,
            "py": 616.4277155380572,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Visual Exploration of High Dimensional Scalar Functions",
                "PaperDOI": "10.1109/TVCG.2010.213",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.213",
                "firstage": "1271",
                "Lastage": "1280",
                "IEEEXPLOREArticleNumber": "5613467",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.",
                "AuthorNames": "Gerber, S.;Bremer, P.;Pascucci, V.;Whitaker, R.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": "37390992900;38266672800;37284312600;37267322600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gerber, S.;Bremer, P.-T.;Pascucci, V.;Whitaker, R.T.",
                "filename": "gerber_vis_10",
                "Citations": "1372235;4376171;4015464;4376172;4376169;1532839"
            }
        },
        {
            "name": "Hao, M.C.",
            "value": 61,
            "numPapers": 24,
            "cluster": "2",
            "index": 506,
            "weight": 2,
            "x": 805.9009963882719,
            "y": 448.3885209821283,
            "px": 807.2763385459718,
            "py": 431.15901509740246,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Intelligent Visual Analytics Queries",
                "PaperDOI": "10.1109/VAST.2007.4389001",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389001",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "4389001",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.",
                "AuthorNames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.",
                "FirstAuthorAffiliation": "Hewlett Packard Lab., Palo Alto|c|;;;;",
                "AuthorIDs": "37274264300;37275646700;37283138700;37563668400;37669961800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Morent, D.;Schneidewind, J.",
                "filename": "hao_vast_07",
                "Citations": "4015431;729568;146402;885086;346302"
            }
        },
        {
            "name": "Shaw, C.",
            "value": 45,
            "numPapers": 22,
            "cluster": "5",
            "index": 507,
            "weight": 1,
            "x": 773.2671670870512,
            "y": -85.43046421306806,
            "px": 1128.5371308502652,
            "py": -580.3613570718298,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Capturing and supporting the analysis process",
                "PaperDOI": "10.1109/VAST.2009.5333020",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5333020",
                "firstage": "131",
                "Lastage": "138",
                "IEEEXPLOREArticleNumber": "5333020",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual analytics tools provide powerful visual representations in order to support the sense-making process. In this process, analysts typically iterate through sequences of steps many times, varying parameters each time. Few visual analytics tools support this process well, nor do they provide support for visualizing and understanding the analysis process itself. To help analysts understand, explore, reference, and reuse their analysis process, we present a visual analytics system named CzSaw (See-Saw) that provides an editable and re-playable history navigation channel in addition to multiple visual representations of document collections and the entities within them (in a manner inspired by Jigsaw). Conventional history navigation tools range from basic undo and redo to branching timelines of user actions. In CzSaw's approach to this, first, user interactions are translated into a script language that drives the underlying scripting-driven propagation system. The latter allows analysts to edit analysis steps, and ultimately to program them. Second, on this base, we build both a history view showing progress and alternative paths, and a dependency graph showing the underlying logic of the analysis and dependency relations among the results of each step. These tools result in a visual model of the sense-making process, providing a way for analysts to visualize their analysis process, to reinterpret the problem, explore alternative paths, extract analysis patterns from existing history, and reuse them with other related analyses.",
                "AuthorNames": "Kadivar, N.;Chen, V.;Dunsmuir, D.;Lee, E.;Qian, C.;Dill, J.;Shaw, C.;Woodbury, R.",
                "FirstAuthorAffiliation": "Sch. of Interactive Arts & Technol., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;;",
                "AuthorIDs": "37681588600;38182637400;37601085600;37596074400;37595662900;38349149300;37358198200;38181028300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kadivar, N.;Chen, V.;Dunsmuir, D.;Lee, E.;Qian, C.;Dill, J.;Shaw, C.;Woodbury, R.",
                "filename": "kadivar_vast_09",
                "Citations": "1532136;4677362;4388992;4658129;4389006;4677365;1382890;4389002;4376144;4389001"
            }
        },
        {
            "name": "Keyser, J.",
            "value": 25,
            "numPapers": 11,
            "cluster": "5",
            "index": 508,
            "weight": 1,
            "x": 888.0429907964349,
            "y": 332.50629303443594,
            "px": 1319.6928674990058,
            "py": 210.46849180982878,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Interdisciplinary visualization: lessons learned at NCSA",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846",
                "firstage": "457",
                "Lastage": "457",
                "IEEEXPLOREArticleNumber": "",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "",
                "AuthorNames": "Cox, D. C.",
                "FirstAuthorAffiliation": "National Center for Supercomputing Applications",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cox, D. C.",
                "filename": "",
                "Citations": ""
            }
        },
        {
            "name": "Johansson, S.",
            "value": 55,
            "numPapers": 9,
            "cluster": "2",
            "index": 509,
            "weight": 2,
            "x": 740.6269095047373,
            "y": -342.71493624669586,
            "px": 815.1928558427682,
            "py": 343.99717584309735,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics",
                "PaperDOI": "10.1109/TVCG.2009.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.153",
                "firstage": "993",
                "Lastage": "1000",
                "IEEEXPLOREArticleNumber": "5290704",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.",
                "AuthorNames": "Johansson, S.;Johansson, J.",
                "FirstAuthorAffiliation": "Norrkoping Visualization & Interaction Studio (NVIS), Linkoping Univ., Linkoping, Sweden|c|;",
                "AuthorIDs": "37924876400;37273045500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Johansson, S.;Johansson, J.",
                "filename": "johansso_infovis_09",
                "Citations": "1532142;1249015;729568;4015421;1382891;1382892;1382893;4658134;1382895"
            }
        },
        {
            "name": "Johansson, J.",
            "value": 156,
            "numPapers": 25,
            "cluster": "2",
            "index": 510,
            "weight": 2,
            "x": 54.20984709595638,
            "y": -155.8772813402764,
            "px": 757.7776605140994,
            "py": 346.2531921444661,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Revealing structure within clustered parallel coordinates displays",
                "PaperDOI": "10.1109/INFVIS.2005.1532138",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532138",
                "firstage": "125",
                "Lastage": "132",
                "IEEEXPLOREArticleNumber": "1532138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In order to gain insight into multivariate data, complex structures must be analysed and understood. Parallel coordinates is an excellent tool for visualizing this type of data but has its limitations. This paper deals with one of its main limitations - how to visualize a large number of data items without hiding the inherent structure they constitute. We solve this problem by constructing clusters and using high precision textures to represent them. We also use transfer functions that operate on the high precision textures in order to highlight different aspects of the cluster characteristics. Providing predefined transfer functions as well as the support to draw customized transfer functions makes it possible to extract different aspects of the data. We also show how feature animation can be used as guidance when simultaneously analysing several clusters. This technique makes it possible to visually represent statistical information about clusters and thus guides the user, making the analysis process more efficient.",
                "AuthorNames": "Johansson, J.;Ljung, P.;Jern, M.;Cooper, M.",
                "FirstAuthorAffiliation": "Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden|c|;;;",
                "AuthorIDs": "37273045500;37284208400;37283245900;37268765000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Johansson, J.;Ljung, P.;Jern, M.;Cooper, M.",
                "filename": "johansso_infovis_05",
                "Citations": "146402;809866;1382894"
            }
        },
        {
            "name": "Johnson, B.",
            "value": 190,
            "numPapers": 5,
            "cluster": "3",
            "index": 511,
            "weight": 2,
            "x": 321.1863449571951,
            "y": 339.6802588561784,
            "px": 687.0068718541922,
            "py": 177.68545027840833,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "Tree-maps: a space-filling approach to the visualization of hierarchical information structures",
                "PaperDOI": "10.1109/VISUAL.1991.175815",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175815",
                "firstage": "284",
                "Lastage": "291",
                "IEEEXPLOREArticleNumber": "175815",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A method for visualizing hierarchically structured information is described. The tree-map visualization technique makes 100% use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. Tree-maps can depict both the structure and content of the hierarchy. However, the approach is best suited to hierarchies in which the content of the leaf nodes and the structure of the hierarchy are of primary importance, and the content information associated with internal nodes is largely derived from their children",
                "AuthorNames": "Johnson, B.;Shneiderman, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;",
                "AuthorIDs": "37381975300;37283016400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Johnson, B.;Shneiderman, B.",
                "filename": "johnson_vis_91",
                "Citations": ""
            }
        },
        {
            "name": "Post, F.H.",
            "value": 195,
            "numPapers": 34,
            "cluster": "6",
            "index": 512,
            "weight": 1,
            "x": 1008.9751492758082,
            "y": -545.8193299098654,
            "px": 1522.9661841863096,
            "py": -1162.0328855383902,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets",
                "PaperDOI": "10.1109/TVCG.2008.131",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.131",
                "firstage": "1436",
                "Lastage": "1451",
                "IEEEXPLOREArticleNumber": "4658160",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis'04 contest), the ionization front instability data set (Vis'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.",
                "AuthorNames": "Blaas, J.;Botha, C.P.;Post, F.H.",
                "FirstAuthorAffiliation": "Data Visualization Group, Delft Univ. of Technol., Delft|c|;;",
                "AuthorIDs": "37550793100;37373834100;37295045800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Blaas, J.;Botha, C.P.;Post, F.H.",
                "filename": "blaas_vis_08",
                "Citations": "809866;4015444;1532138;1382894;346302;885739"
            }
        },
        {
            "name": "Mansmann, F.",
            "value": 43,
            "numPapers": 15,
            "cluster": "2",
            "index": 513,
            "weight": 1,
            "x": 775.1880966167445,
            "y": 940.9167826775426,
            "px": 989.3463488446484,
            "py": 1528.4464240321342,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps",
                "PaperDOI": "10.1109/TVCG.2009.182",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.182",
                "firstage": "913",
                "Lastage": "920",
                "IEEEXPLOREArticleNumber": "5290694",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.",
                "AuthorNames": "Bak, P.;Mansmann, F.;Janetzko, H.;Keim, D.A.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;",
                "AuthorIDs": "37392085400;37392086200;37594026300;37283138700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bak, P.;Mansmann, F.;Janetzko, H.;Keim, D.A.",
                "filename": "bak_infovis_09",
                "Citations": "1382887;485140;1532144;4015426;4376136;4376143;801851;4015427"
            }
        },
        {
            "name": "Kriegel, H.-P.",
            "value": 57,
            "numPapers": 10,
            "cluster": "2",
            "index": 514,
            "weight": 3,
            "x": 1468.2284479445693,
            "y": 683.9027262040782,
            "px": 1060.5424552172824,
            "py": 529.9880801720608,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Recursive pattern: a technique for visualizing very large amounts of data",
                "PaperDOI": "10.1109/VISUAL.1995.485140",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.485140",
                "firstage": "279",
                "Lastage": "286, 463",
                "IEEEXPLOREArticleNumber": "485140",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An important goal of visualization technology is to support the exploration and analysis of very large amounts of data. In this paper, we propose a new visualization technique called a `recursive pattern', which has been developed for visualizing large amounts of multidimensional data. The technique is based on a generic recursive scheme which generalizes a wide range of pixel-oriented arrangements for displaying large data sets. By instantiating the technique with adequate data- and application-dependent parameters, the user may greatly influence the structure of the resulting visualizations. Since the technique uses one pixel for presenting each data value, the amount of data which can be displayed is only limited by the resolution of current display technology and by the limitations of human perceptibility. Beside describing the basic idea of the `recursive pattern' technique, we provide several examples of useful parameter settings for the various recursion levels. We further show that our `recursive pattern' technique is particularly advantageous for the large class of data sets which have a natural order according to one dimension (e.g. time series data). We demonstrate the usefulness of our technique by using a stock market application",
                "AuthorNames": "Keim, D.A.;Kriegel, H.-P.;Ankerst, M.",
                "FirstAuthorAffiliation": "Inst. for Comput. Sci., Munchen Univ., Germany|c|;;",
                "AuthorIDs": "37283138700;37276747000;37371609900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keim, D.A.;Kriegel, H.-P.;Ankerst, M.",
                "filename": "keim_vis_95",
                "Citations": "146402;528688;175809;146386;146387;146389"
            }
        },
        {
            "name": "Panse, C.",
            "value": 27,
            "numPapers": 10,
            "cluster": "2",
            "index": 515,
            "weight": 1,
            "x": 1772.3164357735045,
            "y": -99.56322121050903,
            "px": 2913.545116825408,
            "py": -427.11987432529946,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Efficient cartogram generation: a comparison",
                "PaperDOI": "10.1109/INFVIS.2002.1173144",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173144",
                "firstage": "33",
                "Lastage": "36",
                "IEEEXPLOREArticleNumber": "1173144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Cartograms are a well-known technique for showing geography-related statistical information, such as population demographics and epidemiological data. The basic idea is to distort a map by resizing its regions according to a statistical parameter, but in a way that keeps the map recognizable. We deal with the problem of making continuous cartograms that strictly retain the topology of the input mesh. We compare two algorithms to solve the continuous cartogram problem. The first one uses an iterative relocation of the vertices based on scanlines. The second one is based on the Gridfit technique, which uses pixel-based distortion based on a quadtree-like data structure.",
                "AuthorNames": "Keim, D.A.;North, S.C.;Panse, C.;Schneidewind, J.",
                "FirstAuthorAffiliation": "AT&T Shannon Lab., Florham Park, NJ, USA|c|;;;",
                "AuthorIDs": "37283138700;37372818600;37282557300;37669961800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Keim, D.A.;North, S.C.;Panse, C.;Schneidewind, J.",
                "filename": "keim_infovis_02",
                "Citations": "745301;745303"
            }
        },
        {
            "name": "Takahashi, S.",
            "value": 77,
            "numPapers": 14,
            "cluster": "7",
            "index": 516,
            "weight": 1,
            "x": 727.7642650221804,
            "y": -358.45138634176465,
            "px": 1022.4022893370952,
            "py": -1077.833923975445,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "A feature-driven approach to locating optimal viewpoints for volume visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532834",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532834",
                "firstage": "495",
                "Lastage": "502",
                "IEEEXPLOREArticleNumber": "1532834",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.",
                "AuthorNames": "Takahashi, S.;Fujishiro, I.;Takeshima, Y.;Nishita, T.",
                "FirstAuthorAffiliation": "Tokyo Univ., Japan|c|;;;",
                "AuthorIDs": "37280401000;37282596600;;37267968100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Takahashi, S.;Fujishiro, I.;Takeshima, Y.;Nishita, T.",
                "filename": "takahash_vis_05",
                "Citations": "480789;1372235;1183774;1532833;663875;1183785"
            }
        },
        {
            "name": "Sajadi, B.",
            "value": 8,
            "numPapers": 11,
            "cluster": "14",
            "index": 517,
            "weight": 4,
            "x": 759.3549726129928,
            "y": 618.7249720423581,
            "px": 695.9066854431671,
            "py": 577.0524062074095,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing",
                "PaperDOI": "10.1109/TVCG.2009.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.124",
                "firstage": "1317",
                "Lastage": "1326",
                "IEEEXPLOREArticleNumber": "5290744",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",
                "AuthorNames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;",
                "AuthorIDs": "37391937200;37541336800;37271691400;37408075400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "filename": "sajadi2_vis_09",
                "Citations": "964508;1183793;885684;809883;4376163;4015470"
            }
        },
        {
            "name": "Ruigang Yang",
            "value": 54,
            "numPapers": 5,
            "cluster": "14",
            "index": 518,
            "weight": 3,
            "x": 1033.1071114599476,
            "y": 670.2375120604777,
            "px": 836.5385030653496,
            "py": 617.4175773093193,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "PixelFlex: a reconfigurable multi-projector display system",
                "PaperDOI": "10.1109/VISUAL.2001.964508",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964508",
                "firstage": "167",
                "Lastage": "554",
                "IEEEXPLOREArticleNumber": "964508",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.",
                "AuthorNames": "Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;",
                "AuthorIDs": "37277874700;37601397400;37274010000;38278187600;37277811200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.",
                "filename": "yang_vis_01",
                "Citations": "885685;809890;809883;885712"
            }
        },
        {
            "name": "Brown, M.S.",
            "value": 54,
            "numPapers": 18,
            "cluster": "14",
            "index": 519,
            "weight": 6,
            "x": 889.5605552741847,
            "y": 618.6822919394937,
            "px": 818.3328714754322,
            "py": 580.2420157817895,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Hypothesis Generation in Climate Research with Interactive Visual Data Exploration",
                "PaperDOI": "10.1109/TVCG.2008.139",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.139",
                "firstage": "1579",
                "Lastage": "1586",
                "IEEEXPLOREArticleNumber": "4658178",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.",
                "AuthorNames": "Kehrer, J.;Ladstadter, F.;Muigg, P.;Doleisch, H.;Steiner, A.;Hauser, H.",
                "FirstAuthorAffiliation": "Dept. of Inf., Bergen Univ., Bergen|c|;;;;;",
                "AuthorIDs": "37546620000;;37546620600;37546620400;37884365600;37274158800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kehrer, J.;Ladstadter, F.;Muigg, P.;Doleisch, H.;Steiner, A.;Hauser, H.",
                "filename": "kehrer_vis_08",
                "Citations": "1532138;346302;1532850;4015444"
            }
        },
        {
            "name": "Hensley, J.",
            "value": 20,
            "numPapers": 4,
            "cluster": "14",
            "index": 520,
            "weight": 1,
            "x": 862.5661974233949,
            "y": 264.0187750155506,
            "px": 800.200980786404,
            "py": -2.1965849907446082,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "PixelFlex: a reconfigurable multi-projector display system",
                "PaperDOI": "10.1109/VISUAL.2001.964508",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964508",
                "firstage": "167",
                "Lastage": "554",
                "IEEEXPLOREArticleNumber": "964508",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.",
                "AuthorNames": "Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;",
                "AuthorIDs": "37277874700;37601397400;37274010000;38278187600;37277811200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.",
                "filename": "yang_vis_01",
                "Citations": "885685;809890;809883;885712"
            }
        },
        {
            "name": "Raskar, R.",
            "value": 34,
            "numPapers": 1,
            "cluster": "14",
            "index": 521,
            "weight": 1,
            "x": 1056.7041391471353,
            "y": 344.02066515249453,
            "px": 1125.0537638978763,
            "py": 137.42088436463618,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "firstage": "161",
                "Lastage": "522",
                "IEEEXPLOREArticleNumber": "809883",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "filename": "raskar_vis_99",
                "Citations": ""
            }
        },
        {
            "name": "Wei-Chao Chen",
            "value": 34,
            "numPapers": 1,
            "cluster": "14",
            "index": 522,
            "weight": 1,
            "x": 692.6463432913947,
            "y": 792.84214840804,
            "px": 533.1481436397626,
            "py": 849.0717690572029,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "firstage": "161",
                "Lastage": "522",
                "IEEEXPLOREArticleNumber": "809883",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "filename": "raskar_vis_99",
                "Citations": ""
            }
        },
        {
            "name": "Scales, B.",
            "value": 34,
            "numPapers": 1,
            "cluster": "14",
            "index": 523,
            "weight": 1,
            "x": 1191.9168778116866,
            "y": 430.0810050223769,
            "px": 1361.212006696143,
            "py": 274.58772086210695,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "firstage": "161",
                "Lastage": "522",
                "IEEEXPLOREArticleNumber": "809883",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "filename": "raskar_vis_99",
                "Citations": ""
            }
        },
        {
            "name": "Fuchs, H.",
            "value": 123,
            "numPapers": 11,
            "cluster": "14",
            "index": 524,
            "weight": 3,
            "x": 861.588349911765,
            "y": 565.9243255504833,
            "px": 870.3425767268899,
            "py": 502.3310000208334,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Enhancing transparent skin surfaces with ridge and valley lines",
                "PaperDOI": "10.1109/VISUAL.1995.480795",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480795",
                "firstage": "52",
                "Lastage": "59, 438",
                "IEEEXPLOREArticleNumber": "480795",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "There are many applications that can benefit from the simultaneous display of multiple layers of data. The objective in these cases is to render the layered surfaces in a such way that the outer structures can be seen and seen through at the same time. The paper focuses on the particular application of radiation therapy treatment planning, in which physicians need to understand the three dimensional distribution of radiation dose in the context of patient anatomy. We describe a promising technique for communicating the shape and position of the transparent skin surface while at the same time minimally occluding underlying isointensity dose surfaces and anatomical objects: adding a sparse, opaque texture comprised of a small set of carefully chosen lines. We explain the perceptual motivation for explicitly drawing ridge and valley curves on a transparent surface, describe straightforward mathematical techniques for detecting and rendering these lines, and propose a small number of reasonably effective methods for selectively emphasizing the most perceptually relevant lines in the display",
                "AuthorNames": "Interrante, V.;Fuchs, H.;Pizer, S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;",
                "AuthorIDs": "37282637800;37285537200;37284115400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Interrante, V.;Fuchs, H.;Pizer, S.",
                "filename": "interrante_vis_95",
                "Citations": ""
            }
        },
        {
            "name": "Chu, A.",
            "value": 0,
            "numPapers": 7,
            "cluster": "0",
            "index": 525,
            "weight": 1,
            "x": 841.1838171199332,
            "y": 551.9813284124093,
            "px": 828.363217823947,
            "py": 492.04590829817266,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Spiders: a new user interface for rotation and visualization of n-dimensional point sets",
                "PaperDOI": "10.1109/VISUAL.1994.346318",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346318",
                "firstage": "205",
                "Lastage": "211, C22",
                "IEEEXPLOREArticleNumber": "346318",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a new method for creating n-dimensional rotation matrices from manipulating the projections of n-dimensional data coordinate axes onto a viewing plane. A user interface for n-dimensional rotation is implemented. The interface is shown to have no rotational hysteresis",
                "AuthorNames": "Duffin, K.L.;Barrett, W.A.",
                "FirstAuthorAffiliation": "Brigham Young Univ., Provo, UT, USA|c|;",
                "AuthorIDs": "37663438100;37339053800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Duffin, K.L.;Barrett, W.A.",
                "filename": "duffin_vis_94",
                "Citations": "175794"
            }
        },
        {
            "name": "Heng, P.A.",
            "value": 34,
            "numPapers": 5,
            "cluster": "0",
            "index": 526,
            "weight": 2,
            "x": 887.6749476151571,
            "y": 681.7523531532544,
            "px": 884.0954581505505,
            "py": 653.525053842085,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "Four-dimensional views of 3D scalar fields",
                "PaperDOI": "10.1109/VISUAL.1992.235222",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235222",
                "firstage": "84",
                "Lastage": "91",
                "IEEEXPLOREArticleNumber": "235222",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalar functions of three variables, w=f(x , y, z), are common in many types of scientific and medical applications. Such 3D scalar fields can be understood as elevation maps in four dimensions, with three independent variables (x, y, z) and a fourth, dependent, variable w that corresponds to the elevations. It is shown how techniques developed originally for the display of 3-manifolds in 4D Euclidean space can be adapted to visualize 3D scalar fields in a variety of ways",
                "AuthorNames": "Hanson, A.J.;Heng, P.A.",
                "FirstAuthorAffiliation": "CERN, Geneva, Switzerland|c|;",
                "AuthorIDs": "37333439100;37388382500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hanson, A.J.;Heng, P.A.",
                "filename": "hansena_vis_92",
                "Citations": "146363;175821;146391"
            }
        },
        {
            "name": "Pheng-Ann Heng",
            "value": 3,
            "numPapers": 11,
            "cluster": "0",
            "index": 527,
            "weight": 1,
            "x": 893.4466977468752,
            "y": 836.3966701421908,
            "px": 911.2609404998892,
            "py": 874.1857456896321,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Spiders: a new user interface for rotation and visualization of n-dimensional point sets",
                "PaperDOI": "10.1109/VISUAL.1994.346318",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346318",
                "firstage": "205",
                "Lastage": "211, C22",
                "IEEEXPLOREArticleNumber": "346318",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a new method for creating n-dimensional rotation matrices from manipulating the projections of n-dimensional data coordinate axes onto a viewing plane. A user interface for n-dimensional rotation is implemented. The interface is shown to have no rotational hysteresis",
                "AuthorNames": "Duffin, K.L.;Barrett, W.A.",
                "FirstAuthorAffiliation": "Brigham Young Univ., Provo, UT, USA|c|;",
                "AuthorIDs": "37663438100;37339053800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Duffin, K.L.;Barrett, W.A.",
                "filename": "duffin_vis_94",
                "Citations": "175794"
            }
        },
        {
            "name": "Cross, R.A.",
            "value": 37,
            "numPapers": 7,
            "cluster": "0",
            "index": 528,
            "weight": 3,
            "x": 887.8798142980072,
            "y": 649.9606341168578,
            "px": 896.5555859160505,
            "py": 601.0437443801475,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Virtual reality performance for virtual geometry",
                "PaperDOI": "10.1109/VISUAL.1994.346324",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346324",
                "firstage": "156",
                "Lastage": "163, C17",
                "IEEEXPLOREArticleNumber": "346324",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe the theoretical and practical visualization issues solved in the implementation of an interactive real-time four-dimensional geometry interface for the CAVE, an immersive virtual reality environment. While our specific task is to produce a â€œvirtual geometryâ€ experience by approximating physically correct rendering of manifolds embedded in four dimensions, the general principles exploited by our approach reflect requirements common to many immersive virtual reality applications, especially those involving volume rendering. Among the issues we address are the classification of rendering tasks, the specialized hardware support required to attain interactivity, specific techniques required to render 4D objects, and interactive methods appropriate for our 4D virtual world application",
                "AuthorNames": "Cross, R.A.;Hanson, A.J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37664370800;37333439100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cross, R.A.;Hanson, A.J.",
                "filename": "cross_vis_94",
                "Citations": "346330;398869;175821;235222"
            }
        },
        {
            "name": "Varetto, U.",
            "value": 0,
            "numPapers": 14,
            "cluster": "5",
            "index": 529,
            "weight": 1,
            "x": -96.0580089338977,
            "y": 258.6442503109428,
            "px": -135.23020572231536,
            "py": 324.8984308513467,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Visual Verification and Analysis of Cluster Detection for Molecular Dynamics",
                "PaperDOI": "10.1109/TVCG.2007.70614",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70614",
                "firstage": "1624",
                "Lastage": "1631",
                "IEEEXPLOREArticleNumber": "4376195",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.",
                "AuthorNames": "Grottel, S.;Reina, G.;Vrabec, J.;Ertl, T.",
                "FirstAuthorAffiliation": "Univ. Stuttgart, Stuttgart|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Grottel, S.;Reina, G.;Vrabec, J.;Ertl, T.",
                "filename": "grottel_vis_07",
                "Citations": "1250404;1183811;4015487;1372203;4015464;1250404"
            }
        },
        {
            "name": "Yi-Jen Chiang",
            "value": 81,
            "numPapers": 17,
            "cluster": "5",
            "index": 530,
            "weight": 9,
            "x": 285.1363160163759,
            "y": 387.3164757464663,
            "px": 337.42575722798085,
            "py": 429.00238140006246,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Out-of-core isosurface extraction of time-varying fields over irregular grids",
                "PaperDOI": "10.1109/VISUAL.2003.1250375",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250375",
                "firstage": "217",
                "Lastage": "224",
                "IEEEXPLOREArticleNumber": "1250375",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we propose a novel out-of-core isosurface extraction technique for large time-varying fields over irregular grids. We employ our meta-cell technique to explore the spatial coherence of the data, and our time tree algorithm to consider the temporal coherence as well. Our one-time preprocessing phase first partitions the dataset into meta-cells that cluster spatially neighboring cells together and are stored in disk. We then build a time tree to index the meta-cells for fast isosurface extraction. The time tree takes advantage of the temporal coherence among the scalar values at different time steps, and uses BBIO trees as secondary structures, which are stored in disk and support I/O-optimal interval searches. The time tree algorithm employs a novel meta-interval collapsing scheme and the buffer technique, to take care of the temporal coherence in an I/O-efficient way. We further make the time tree cache-oblivious, so that searching on it automatically performs optimal number of block transfers between any two consecutive levels of memory hierarchy (such as between cache and main memory and between main memory and disk) simultaneously. At run-time, we perform optimal cache-oblivious searches in the time tree, together with I/O-optimal searches in the BBIO trees, to read the active meta-cells from disk and generate the queried isosurface efficiently. The experiments demonstrate the effectiveness of our new technique. In particular, compared with the query-optimal main-memory algorithm by Cignoni et al. (1997) (extended for time-varying fields) when there is not enough main memory, our technique can speed up the isosurface queries from more than 18 hours to less than 4 minutes.",
                "AuthorNames": "Yi-Jen Chiang",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Polytech. Univ., Brooklyn, NY, USA|c|",
                "AuthorIDs": "37288235400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yi-Jen Chiang",
                "filename": "chiang_vis_03",
                "Citations": "480806;745299;663895;568121;1250373;663888;745298"
            }
        },
        {
            "name": "Livnat, Y.",
            "value": 218,
            "numPapers": 29,
            "cluster": "5",
            "index": 531,
            "weight": 18,
            "x": 215.65434191342922,
            "y": 315.77151638662957,
            "px": 283.3726409129116,
            "py": 362.120335541662,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Visual correlation for situational awareness",
                "PaperDOI": "10.1109/INFVIS.2005.1532134",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532134",
                "firstage": "95",
                "Lastage": "102",
                "IEEEXPLOREArticleNumber": "1532134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel visual correlation paradigm for situational awareness (SA) and suggest its usage in a diverse set of applications that require a high level of SA. Our approach is based on a concise and scalable representation, which leads to a flexible visualization tool that is both clear and intuitive to use. Situational awareness is the continuous extraction of environmental information, its integration with previous knowledge to form a coherent mental picture, and the use of that picture in anticipating future events. In this paper we build on our previous work on visualization for network intrusion detection and show how that approach can be generalized to encompass a much broader class of SA systems. We first propose a generalization that is based on what we term, the w3 premise, namely that each event must have at least the what, when and where attributes. We also present a second generalization, which increases flexibility and facilitates complex visual correlations. Finally, we demonstrate the generality of our approaches by applying our visualization paradigm in a collection of diverse SA areas.",
                "AuthorNames": "Livnat, Y.;Agutter, J.;Shaun Moon;Foresti, S.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., USA|c|;;;",
                "AuthorIDs": "37282553200;37442679500;37553253600;37354354100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Livnat, Y.;Agutter, J.;Shaun Moon;Foresti, S.",
                "filename": "livnat_infovis_05",
                "Citations": "1250415"
            }
        },
        {
            "name": "Hermann, S.",
            "value": 25,
            "numPapers": 9,
            "cluster": "5",
            "index": 532,
            "weight": 1,
            "x": -78.83396175095885,
            "y": 677.1597014650952,
            "px": -320.087751339766,
            "py": 738.0388859596411,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "firstage": "1515",
                "Lastage": "1522",
                "IEEEXPLOREArticleNumber": "5290768",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "filename": "ropinski_vis_09",
                "Citations": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "Reich, R.",
            "value": 25,
            "numPapers": 9,
            "cluster": "5",
            "index": 533,
            "weight": 1,
            "x": 340.21637762762515,
            "y": 68.94537124355013,
            "px": 389.06894878670425,
            "py": -316.3733581077213,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "firstage": "1515",
                "Lastage": "1522",
                "IEEEXPLOREArticleNumber": "5290768",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "filename": "ropinski_vis_09",
                "Citations": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "Schafers, M.",
            "value": 25,
            "numPapers": 9,
            "cluster": "5",
            "index": 534,
            "weight": 1,
            "x": 88.6170920992993,
            "y": 979.3106167110867,
            "px": -45.567765940235695,
            "py": 1264.2893242414896,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "firstage": "1515",
                "Lastage": "1522",
                "IEEEXPLOREArticleNumber": "5290768",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "filename": "ropinski_vis_09",
                "Citations": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "Hinrichs, K.",
            "value": 57,
            "numPapers": 27,
            "cluster": "5",
            "index": 535,
            "weight": 2,
            "x": 304.0917625631254,
            "y": 528.4453886196269,
            "px": 297.32732853787,
            "py": 664.0452457160849,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2008.136",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.136",
                "firstage": "1499",
                "Lastage": "1506",
                "IEEEXPLOREArticleNumber": "4658168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.",
                "AuthorNames": "Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster|c|;;;;",
                "AuthorIDs": "37869986400;37273031400;;37295281400;37267218300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.",
                "filename": "meyerspr_vis_08",
                "Citations": "1250425;4015499;4376196;745294"
            }
        },
        {
            "name": "Ming-Yuen Chan",
            "value": 19,
            "numPapers": 31,
            "cluster": "5",
            "index": 536,
            "weight": 2,
            "x": 334.09817926084344,
            "y": 591.0759636915376,
            "px": 387.98387147079507,
            "py": 649.3722907569661,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Perception-Based Transparency Optimization for Direct Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2009.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.172",
                "firstage": "1283",
                "Lastage": "1290",
                "IEEEXPLOREArticleNumber": "5290740",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.",
                "AuthorNames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;",
                "AuthorIDs": "37401176900;37407308300;37306814700;37279188600;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "filename": "chan_vis_09",
                "Citations": "745319;885694;4658198;1250414;4376159;1372208;4658153;4015473;4658191;4015460"
            }
        },
        {
            "name": "Wai-Ho Mak",
            "value": 19,
            "numPapers": 26,
            "cluster": "5",
            "index": 537,
            "weight": 2,
            "x": 251.56727089382983,
            "y": 542.9810868566151,
            "px": 418.9839733928684,
            "py": 597.0441083333899,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Perception-Based Transparency Optimization for Direct Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2009.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.172",
                "firstage": "1283",
                "Lastage": "1290",
                "IEEEXPLOREArticleNumber": "5290740",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.",
                "AuthorNames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;",
                "AuthorIDs": "37401176900;37407308300;37306814700;37279188600;37272637300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "filename": "chan_vis_09",
                "Citations": "745319;885694;4658198;1250414;4376159;1372208;4658153;4015473;4658191;4015460"
            }
        },
        {
            "name": "Georgii, J.",
            "value": 23,
            "numPapers": 20,
            "cluster": "5",
            "index": 538,
            "weight": 2,
            "x": 246.73226410956738,
            "y": 246.45147120182713,
            "px": 27.014930991242945,
            "py": 133.8204381260791,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "A Generic and Scalable Pipeline for GPU Tetrahedral Grid Rendering",
                "PaperDOI": "10.1109/TVCG.2006.110",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.110",
                "firstage": "1345",
                "Lastage": "1352",
                "IEEEXPLOREArticleNumber": "4015501",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Recent advances in algorithms and graphics hardware have opened the possibility to render tetrahedral grids at interactive rates on commodity PCs. This paper extends on this work in that it presents a direct volume rendering method for such grids which supports both current and upcoming graphics hardware architectures, large and deformable grids, as well as different rendering options. At the core of our method is the idea to perform the sampling of tetrahedral elements along the view rays entirely in local barycentric coordinates. Then, sampling requires minimum GPU memory and texture access operations, and it maps efficiently onto a feed-forward pipeline of multiple stages performing computation and geometry construction. We propose to spawn rendered elements from one single vertex. This makes the method amenable to upcoming Direct3D 10 graphics hardware which allows to create geometry on the GPU. By only modifying the algorithm slightly it can be used to render per-pixel iso-surfaces and to perform tetrahedral cell projection. As our method neither requires any pre-processing nor an intermediate grid representation it can efficiently deal with dynamic and large 3D meshes",
                "AuthorNames": "Georgii, J.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Technische Univ. Munchen|c|;",
                "AuthorIDs": "37828702100;37444424000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Georgii, J.;Westermann, R.",
                "filename": "georgii_vis_06",
                "Citations": "1250390;663853;885683;1250384;964512;567606"
            }
        },
        {
            "name": "Lum, E.B.",
            "value": 95,
            "numPapers": 16,
            "cluster": "5",
            "index": 539,
            "weight": 2,
            "x": 368.48660703446905,
            "y": 334.93311475969244,
            "px": 5.524339684563439,
            "py": 157.5249971863836,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "A novel interface for higher-dimensional classification of volume data",
                "PaperDOI": "10.1109/VISUAL.2003.1250413",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250413",
                "firstage": "505",
                "Lastage": "512",
                "IEEEXPLOREArticleNumber": "1250413",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the traditional volume visualization paradigm, the user specifies a transfer function that assigns each scalar value to a color and opacity by defining an opacity and a color map function. The transfer function has two limitations. First, the user must define curves based on histogram and value rather than seeing and working with the volume itself. Second, the transfer function is inflexible in classifying regions of interest, where values at a voxel such as intensity and gradient are used to differentiate material, not talking into account additional properties such as texture and position. We describe an intuitive user interface for specifying the classification functions that consists of the users painting directly on sample slices of the volume. These painted regions are used to automatically define high-dimensional classification functions that can be implemented in hardware for interactive rendering. The classification of the volume is iteratively improved as the user paints samples, allowing intuitive and efficient viewing of materials of interest.",
                "AuthorNames": "Tzeng, F.-Y.;Lum, E.B.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;",
                "AuthorIDs": "37425953500;37282576300;37275869400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tzeng, F.-Y.;Lum, E.B.;Kwan-Liu Ma",
                "filename": "tzeng_vis_03",
                "Citations": "745319;964519;809932;663875;568112"
            }
        },
        {
            "name": "Miller, M.",
            "value": 111,
            "numPapers": 11,
            "cluster": "5",
            "index": 540,
            "weight": 1,
            "x": 108.35770187458667,
            "y": 493.85663498394274,
            "px": -54.746255623534545,
            "py": 491.9366065274944,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "A contract based system for large data visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532795",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532795",
                "firstage": "191",
                "Lastage": "198",
                "IEEEXPLOREArticleNumber": "1532795",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisIt is a richly featured visualization tool that is used to visualize some of the largest simulations ever run. The scale of these simulations requires that optimizations are incorporated into every operation VisIt performs. But the set of applicable optimizations that VisIt can perform is dependent on the types of operations being done. Complicating the issue, VisIt has a plugin capability that allows new, unforeseen components to be added, making it even harder to determine which optimizations can be applied. We introduce the concept of a contract to the standard data flow network design. This contract enables each component of the data flow network to modify the set of optimizations used. In addition, the contract allows for new components to be accommodated gracefully within VisIt's data flow network system.",
                "AuthorNames": "Childs, H.;Brugger, E.;Bonnell, K.;Meredith, J.;Miller, M.;Whitlock, B.;Max, N.",
                "FirstAuthorAffiliation": "California Univ., Davis, CA, USA|c|;;;;;;",
                "AuthorIDs": "37411882800;37550795800;37550791600;37346846400;37558142500;37393104100;37267387800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Childs, H.;Brugger, E.;Bonnell, K.;Meredith, J.;Miller, M.;Whitlock, B.;Max, N.",
                "filename": "childs_vis_05",
                "Citations": "567746_1;146416;480821;175794;663895"
            }
        },
        {
            "name": "Jänicke, H.",
            "value": 104,
            "numPapers": 23,
            "cluster": "6",
            "index": 541,
            "weight": 1,
            "x": -530.4281140287361,
            "y": -200.7138654679712,
            "px": -1430.5850628414867,
            "py": -525.3073639053745,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Evaluating the impact of task demands and block resolution on the effectiveness of pixel-based visualization",
                "PaperDOI": "10.1109/TVCG.2010.150",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.150",
                "firstage": "963",
                "Lastage": "972",
                "IEEEXPLOREArticleNumber": "5613433",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.",
                "AuthorNames": "Borgo, R.;Proctor, K.;Chen, M.;Janicke, H.;Murray, T.;Thornton, I.M.",
                "FirstAuthorAffiliation": "Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;",
                "AuthorIDs": "37591074800;37591072200;37280982800;37393638200;37274098800;37591073500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Borgo, R.;Proctor, K.;Chen, M.;Jänicke, H.;Murray, T.;Thornton, I.M.",
                "filename": "borgo_infovis_10",
                "Citations": "480803"
            }
        },
        {
            "name": "Knoll, A.",
            "value": 12,
            "numPapers": 18,
            "cluster": "5",
            "index": 542,
            "weight": 2,
            "x": 362.530081219233,
            "y": 436.4292425829657,
            "px": 465.32337893420333,
            "py": 585.3951172316026,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Volume Ray Casting with Peak finding and Differential Sampling",
                "PaperDOI": "10.1109/TVCG.2009.204",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.204",
                "firstage": "1571",
                "Lastage": "1578",
                "IEEEXPLOREArticleNumber": "5290775",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C0 transfer functions.",
                "AuthorNames": "Knoll, A.;Hijazi, Y.;Westerteiger, R.;Schott, M.;Hansen, C.;Hagen, H.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;",
                "AuthorIDs": "37692671900;37544121300;38108787400;38099955600;37266777200;37282578800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Knoll, A.;Hijazi, Y.;Westerteiger, R.;Schott, M.;Hansen, C.;Hagen, H.",
                "filename": "knoll_vis_09",
                "Citations": "346320;1250384;1250412;745713;4015486;885683;4015483;964490;1372230;745300"
            }
        },
        {
            "name": "Shirley, P.",
            "value": 81,
            "numPapers": 14,
            "cluster": "5",
            "index": 543,
            "weight": 2,
            "x": 667.4232862037604,
            "y": 458.3867609949209,
            "px": 386.95714526237475,
            "py": 542.0526674959355,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Interactive rendering of large unstructured grids using dynamic level-of-detail",
                "PaperDOI": "10.1109/VISUAL.2005.1532796",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532796",
                "firstage": "199",
                "Lastage": "206",
                "IEEEXPLOREArticleNumber": "1532796",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe a new dynamic level-of-detail (LOD) technique that allows real-time rendering of large tetrahedral meshes. Unlike approaches that require hierarchies of tetrahedra, our approach uses a subset of the faces that compose the mesh. No connectivity is used for these faces so our technique eliminates the need for topological information and hierarchical data structures. By operating on a simple set of triangular faces, our algorithm allows a robust and straightforward graphics hardware (GPU) implementation. Because the subset of faces processed can be constrained to arbitrary size, interactive rendering is possible for a wide range of data sets and hardware configurations.",
                "AuthorNames": "Callahan, S.P.;Comba, J.L.D.;Shirley, P.;Silva, C.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah State Univ., Logan, UT, USA|c|;;;",
                "AuthorIDs": "37426872800;37267034700;37266808400;37275249200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Callahan, S.P.;Comba, J.L.D.;Shirley, P.;Silva, C.T.",
                "filename": "callahan_vis_05",
                "Citations": "1372227;809908;745283;1372176;1250390;1183778;745329;1183767;885711"
            }
        },
        {
            "name": "Scholtz, J.",
            "value": 33,
            "numPapers": 9,
            "cluster": "5",
            "index": 544,
            "weight": 1,
            "x": 719.8709945607651,
            "y": 136.24967524234546,
            "px": 1005.3076219240104,
            "py": -142.78705985800562,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "VAST contest dataset use in education",
                "PaperDOI": "10.1109/VAST.2009.5333245",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5333245",
                "firstage": "115",
                "Lastage": "122",
                "IEEEXPLOREArticleNumber": "5333245",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The IEEE Visual Analytics Science and Technology (VAST) Symposium has held a contest each year since its inception in 2006. These events are designed to provide visual analytics researchers and developers with analytic challenges similar to those encountered by professional information analysts. The VAST contest has had an extended life outside of the symposium, however, as materials are being used in universities and other educational settings, either to help teachers of visual analytics-related classes or for student projects. We describe how we develop VAST contest datasets that results in products that can be used in different settings and review some specific examples of the adoption of the VAST contest materials in the classroom. The examples are drawn from graduate and undergraduate courses at Virginia Tech and from the Visual Analytics ldquoSummer Camprdquo run by the National Visualization and Analytics Center in 2008. We finish with a brief discussion on evaluation metrics for education.",
                "AuthorNames": "Whiting, M.A.;North, C.;Endert, A.;Scholtz, J.;Haack, J.;Varley, C.;Thomas, J.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": "37357067600;37419565900;37681759500;37268671300;37267550400;37678660700;37273308900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Whiting, M.A.;North, C.;Endert, A.;Scholtz, J.;Haack, J.;Varley, C.;Thomas, J.",
                "filename": "whiting_vast_09",
                "Citations": "4035759"
            }
        },
        {
            "name": "Grinstein, G.",
            "value": 63,
            "numPapers": 21,
            "cluster": "5",
            "index": 545,
            "weight": 1,
            "x": 98.08529690530929,
            "y": 937.9358405400591,
            "px": -124.21525749492046,
            "py": 1314.449449523385,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "DNA visual and analytic data mining",
                "PaperDOI": "10.1109/VISUAL.1997.663916",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663916",
                "firstage": "437",
                "Lastage": "441",
                "IEEEXPLOREArticleNumber": "663916",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Describes data exploration techniques designed to classify DNA sequences. Several visualization and data mining techniques were used to validate and attempt to discover new methods for distinguishing coding DNA sequences (exons) from non-coding DNA sequences (introns). The goal of the data mining was to see whether some other, possibly non-linear combination of the fundamental position-dependent DNA nucleotide frequency values could be a better predictor than the AMI (average mutual information). We tried many different classification techniques including rule-based classifiers and neural networks. We also used visualization of both the original data and the results of the data mining to help verify patterns and to understand the distinction between the different types of data and classifications. In particular, the visualization helped us develop refinements to neural network classifiers, which have accuracies as high as any known method. Finally, we discuss the interactions between visualization and data mining and suggest an integrated approach.",
                "AuthorNames": "Hoffman, P.;Grinstein, G.;Marx, K.;Grosse, I.;Stanley, E.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Perception Res., Massachusetts Univ., Lowell, MA, USA|c|;;;;",
                "AuthorIDs": "37617749600;38470495600;38318555000;37622312400;38180962800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hoffman, P.;Grinstein, G.;Marx, K.;Grosse, I.;Stanley, E.",
                "filename": "hoffman_vis_97",
                "Citations": "485139"
            }
        },
        {
            "name": "Whiting, M.",
            "value": 0,
            "numPapers": 5,
            "cluster": "5",
            "index": 546,
            "weight": 1,
            "x": 779.4980698698547,
            "y": 1076.76025771469,
            "px": 1143.347657092254,
            "py": 1598.583341482382,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Interdisciplinary visualization: lessons learned at NCSA",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846",
                "firstage": "457",
                "Lastage": "457",
                "IEEEXPLOREArticleNumber": "",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "",
                "AuthorNames": "Cox, D. C.",
                "FirstAuthorAffiliation": "National Center for Supercomputing Applications",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cox, D. C.",
                "filename": "",
                "Citations": ""
            }
        },
        {
            "name": "Gross, M.",
            "value": 149,
            "numPapers": 37,
            "cluster": "7",
            "index": 547,
            "weight": 4,
            "x": -191.0278706596219,
            "y": -281.3593536199038,
            "px": 5.465331082289232,
            "py": -24.048035597546438,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Volume rendering of smoke propagation CFD data",
                "PaperDOI": "10.1109/VISUAL.2005.1532813",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532813",
                "firstage": "335",
                "Lastage": "341",
                "IEEEXPLOREArticleNumber": "1532813",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The evacuation of buildings in the event of a fire requires careful planning of ventilation and evacuation routes during early architectural design stages. Different designs are evaluated by simulating smoke propagation using computational fluid dynamics (CFD). Visibility plays a decisive role in finding the nearest fire exit. This paper presents real-time volume rendering of transient smoke propagation conforming to standardized visibility distances. We visualize time dependent smoke particle concentration on unstructured tetrahedral meshes using a direct volume rendering approach. Due to the linear transfer function of the optical model commonly used in fire protection engineering, accurate pre-integration of diffuse color across tetrahedra can be carried out with a single 2D texture lookup. We reduce rounding errors during frame buffer blending by applying randomized dithering if high accuracy frame buffers are unavailable on the target platform. A simple absorption-based lighting model is evaluated in a preprocessing step using the same rendering approach. Back-illuminated exit signs are commonly used to indicate the escape route. As light emitting objects are visible further than reflective objects, the transfer function in front of illuminated exit signs must be adjusted with a deferred rendering pass.",
                "AuthorNames": "Staubli, O.;Sigg, C.;Peikert, R.;Gubler, D.;Gross, Markus",
                "FirstAuthorAffiliation": "Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;;",
                "AuthorIDs": "37565784300;37565783800;37282541100;37565771500;37275694700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Staubli, O.;Sigg, C.;Peikert, R.;Gubler, D.;Gross, M.",
                "filename": "staubli_vis_05",
                "Citations": "885683;1250390;398846;1372176;1250384;1250385"
            }
        },
        {
            "name": "Staadt, O.",
            "value": 65,
            "numPapers": 5,
            "cluster": "7",
            "index": 548,
            "weight": 2,
            "x": 34.33359842785749,
            "y": -169.45655151444268,
            "px": 345.3201101899049,
            "py": 305.5095476023425,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Progressive tetrahedralizations",
                "PaperDOI": "10.1109/VISUAL.1998.745329",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745329",
                "firstage": "397",
                "Lastage": "402",
                "IEEEXPLOREArticleNumber": "745329",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes some fundamental issues for robust implementations of progressively refined tetrahedralizations generated through sequences of edge collapses. We address the definition of appropriate cost functions and explain on various tests which are necessary to preserve the consistency of the mesh when collapsing edges. Although considered a special case of progressive simplicial complexes (J. Popovic and H. Hoppe, 1997), the results of our method are of high practical importance and can be used in many different applications, such as finite element meshing, scattered data interpolation, or rendering of unstructured volume data.",
                "AuthorNames": "Staadt, O.G.;Gross, M.H.",
                "FirstAuthorAffiliation": "Comput. Graphics Res. Group, Fed.. Inst. of Technol., Zurich, Switzerland|c|;",
                "AuthorIDs": "37355334600;37275694700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Staadt, O.;Gross, M.",
                "filename": "staadt_vis_98",
                "Citations": "663907;663901;663883"
            }
        },
        {
            "name": "Cignoni, P.",
            "value": 99,
            "numPapers": 27,
            "cluster": "7",
            "index": 549,
            "weight": 1,
            "x": -325.3340029728641,
            "y": 682.0754139206375,
            "px": -819.9039556791454,
            "py": 713.6364353781912,
            "node": {
                "Conference": "SciVis",
                "Year": "2010",
                "PaperTitle": "Browsing Large Image Datasets through Voronoi Diagrams",
                "PaperDOI": "10.1109/TVCG.2010.136",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.136",
                "firstage": "1261",
                "Lastage": "1270",
                "IEEEXPLOREArticleNumber": "5613466",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Conventional browsing of image collections use mechanisms such as thumbnails arranged on a regular grid or on a line, often mounted over a scrollable panel. However, this approach does not scale well with the size of the datasets (number of images). In this paper, we propose a new thumbnail-based interface to browse large collections of images. Our approach is based on weighted centroidal anisotropic Voronoi diagrams. A dynamically changing subset of images is represented by thumbnails and shown on the screen. Thumbnails are shaped like general polygons, to better cover screen space, while still reflecting the original aspect ratios or orientation of the represented images. During the browsing process, thumbnails are dynamically rearranged, reshaped and rescaled. The objective is to devote more screen space (more numerous and larger thumbnails) to the parts of the dataset closer to the current region of interest, and progressively lesser away from it, while still making the dataset visible as a whole. During the entire process, temporal coherence is always maintained. GPU implementation easily guarantees the frame rates needed for fully smooth interactivity.",
                "AuthorNames": "Brivio, P.;Tarini, M.;Cignoni, P.",
                "FirstAuthorAffiliation": "Univ. of Insubria, Varese, Italy|c|;;",
                "AuthorIDs": "37586785100;37591264000;37265783400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Brivio, P.;Tarini, M.;Cignoni, P.",
                "filename": "brivio_vis_10",
                "Citations": ""
            }
        },
        {
            "name": "Costanza, D.",
            "value": 34,
            "numPapers": 4,
            "cluster": "7",
            "index": 550,
            "weight": 1,
            "x": 420.75368800498626,
            "y": 184.4023002948529,
            "px": 505.12441221525893,
            "py": -145.89969630171527,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Simplification of tetrahedral meshes with accurate error evaluation",
                "PaperDOI": "10.1109/VISUAL.2000.885680",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885680",
                "firstage": "85",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "885680",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.",
                "AuthorNames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "FirstAuthorAffiliation": "Ist. Sci. e Tecnol. dell''Inf., CNR, Pisa, Italy|c|;;;;",
                "AuthorIDs": "37265783400;38015245400;37265786500;37333160000;37270887900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "filename": "cignoni_vis_00",
                "Citations": "745315;663907;745329;745312"
            }
        },
        {
            "name": "Montani, C.",
            "value": 93,
            "numPapers": 8,
            "cluster": "7",
            "index": 551,
            "weight": 1,
            "x": 232.4064673383932,
            "y": 128.52576542126667,
            "px": 180.74737897030846,
            "py": -243.83881717832452,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization",
                "PaperDOI": "10.1109/TVCG.2006.115",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.115",
                "firstage": "1237",
                "Lastage": "1244",
                "IEEEXPLOREArticleNumber": "4015487",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 106 atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time.",
                "AuthorNames": "Tarini, M.;Cignoni, P.;Montani, C.",
                "FirstAuthorAffiliation": "Universita dell''Insubria, Varese|c|;;",
                "AuthorIDs": "37591264000;37265783400;37265786500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tarini, M.;Cignoni, P.;Montani, C.",
                "filename": "tarini_vis_06",
                "Citations": "885694;1250394"
            }
        },
        {
            "name": "Rocchini, C.",
            "value": 45,
            "numPapers": 5,
            "cluster": "7",
            "index": 552,
            "weight": 1,
            "x": -348.00375715031424,
            "y": 675.1741474895916,
            "px": -846.9919465130909,
            "py": 706.3695889386333,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Simplification of tetrahedral meshes with accurate error evaluation",
                "PaperDOI": "10.1109/VISUAL.2000.885680",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885680",
                "firstage": "85",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "885680",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.",
                "AuthorNames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "FirstAuthorAffiliation": "Ist. Sci. e Tecnol. dell''Inf., CNR, Pisa, Italy|c|;;;;",
                "AuthorIDs": "37265783400;38015245400;37265786500;37333160000;37270887900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "filename": "cignoni_vis_00",
                "Citations": "745315;663907;745329;745312"
            }
        },
        {
            "name": "Scopigno, R.",
            "value": 89,
            "numPapers": 25,
            "cluster": "7",
            "index": 553,
            "weight": 1,
            "x": 274.1642818660311,
            "y": 130.36580073538013,
            "px": 251.7683838223674,
            "py": -240.74451492324505,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Optimal global conformal surface parameterization",
                "PaperDOI": "10.1109/VISUAL.2004.75",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.75",
                "firstage": "267",
                "Lastage": "274",
                "IEEEXPLOREArticleNumber": "1372206",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "All orientable metric surfaces are Riemann surfaces and admit global conformal parameterizations. Riemann surface structure is a fundamental structure and governs many natural physical phenomena, such as heat diffusion and electro-magnetic fields on the surface. A good parameterization is crucial for simulation and visualization. This paper provides an explicit method for finding optimal global conformal parameterizations of arbitrary surfaces. It relies on certain holomorphic differential forms and conformal mappings from differential geometry and Riemann surface theories. Algorithms are developed to modify topology, locate zero points, and determine cohomology types of differential forms. The implementation is based on a finite dimensional optimization method. The optimal parameterization is intrinsic to the geometry, preserves angular structure, and can play an important role in various applications including texture mapping, remeshing, morphing and simulation. The method is demonstrated by visualizing the Riemann surface structure of real surfaces represented as triangle meshes.",
                "AuthorNames": "Miao Jin;Yalin Wang;Shing-Tung Yau;Gu, X.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;",
                "AuthorIDs": "37279448300;37281424800;37272109300;37276603700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Miao Jin;Yalin Wang;Shing-Tung Yau;Gu, X.",
                "filename": "jin_vis_04",
                "Citations": ""
            }
        },
        {
            "name": "Gerstner, T.",
            "value": 46,
            "numPapers": 9,
            "cluster": "7",
            "index": 554,
            "weight": 2,
            "x": -10.551396003957986,
            "y": 405.62989918521515,
            "px": 382.0979433493292,
            "py": 603.5803569593821,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Topology preserving and controlled topology simplifying multiresolution isosurface extraction",
                "PaperDOI": "10.1109/VISUAL.2000.885703",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885703",
                "firstage": "259",
                "Lastage": "266",
                "IEEEXPLOREArticleNumber": "885703",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Multiresolution methods are becoming increasingly important tools for the interactive visualization of very large data sets. Multiresolution isosurface visualization allows the user to explore volume data using simplified and coarse representations of the isosurface for overview images, and finer resolution in areas of high interest or when zooming into the data. Ideally, a coarse isosurface should have the same topological structure as the original. The topological genus of the isosurface is one important property which is often neglected in multiresolution algorithms. This results in uncontrolled topological changes which can occur whenever the level-of-detail is changed. The scope of this paper is to propose an efficient technique which allows preservation of topology as well as controlled topology simplification in multiresolution isosurface extraction.",
                "AuthorNames": "Gerstner, T.;Pajarola, Renato",
                "FirstAuthorAffiliation": "Dept. of Appl. Math., Bonn Univ., Germany|c|;",
                "AuthorIDs": "38015261400;37282193800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gerstner, T.;Pajarola, Renato",
                "filename": "gerstner_vis_00",
                "Citations": "568127;663907;663909;745300;346334;663869"
            }
        },
        {
            "name": "Pajarola, Renato",
            "value": 106,
            "numPapers": 36,
            "cluster": "7",
            "index": 555,
            "weight": 3,
            "x": 94.0678680299645,
            "y": 1.7492299622467975,
            "px": 161.3938314785867,
            "py": 256.60160343373104,
            "node": {
                "Conference": "SciVis",
                "Year": "2011",
                "PaperTitle": "Extinction-Based Shading and Illumination in GPU Volume Ray-Casting",
                "PaperDOI": "10.1109/TVCG.2011.198",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.198",
                "firstage": "1795",
                "Lastage": "1802",
                "IEEEXPLOREArticleNumber": "6064942",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Direct volume rendering has become a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and color bleeding effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering is based on a very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i.e. soft directional shadows, ambient occlusion and color bleeding. We will show how this can be achieved and how it can be implemented on the GPU.",
                "AuthorNames": "Schlegel, P.;Makhinya, M.;Pajarola, Renato",
                "FirstAuthorAffiliation": "Dept. of Inf., Univ. of Zurich, Zurich, Switzerland|c|;;",
                "AuthorIDs": "38026738000;37695663200;37282193800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schlegel, P.;Makhinya, M.;Pajarola, Renato",
                "filename": "schlegel_vis_11",
                "Citations": "4376160;1183764;1250384"
            }
        },
        {
            "name": "Chandak, A.",
            "value": 0,
            "numPapers": 5,
            "cluster": "6",
            "index": 556,
            "weight": 5,
            "x": 701.1164853881501,
            "y": 186.85346347518555,
            "px": 804.3502955190773,
            "py": 282.1979004259101,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Listener-based Analysis of Surface Importance for Acoustic Metrics",
                "PaperDOI": "10.1109/TVCG.2007.70575",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70575",
                "firstage": "1680",
                "Lastage": "1687",
                "IEEEXPLOREArticleNumber": "4376202",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D50) and clarity (C50) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C50) values at listener positions throughout the room.",
                "AuthorNames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "FirstAuthorAffiliation": "IRTG Kaiserslautern, Kaiserslautern|c|;;;;",
                "AuthorIDs": "37838754300;37282727900;;37282573700;37282578800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "filename": "michel_vis_07",
                "Citations": "4015479;1532790"
            }
        },
        {
            "name": "Deines, E.",
            "value": 67,
            "numPapers": 15,
            "cluster": "6",
            "index": 557,
            "weight": 5,
            "x": 760.8628133453076,
            "y": 397.467978311042,
            "px": 849.3546199095287,
            "py": 488.05667319857633,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Visualization of intricate flow structures for vortex breakdown analysis",
                "PaperDOI": "10.1109/VISUAL.2004.113",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.113",
                "firstage": "187",
                "Lastage": "194",
                "IEEEXPLOREArticleNumber": "1372196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Vortex breakdowns and flow recirculation are essential phenomena in aeronautics where they appear as a limiting factor in the design of modern aircrafts. Because of the inherent intricacy of these features, standard flow visualization techniques typically yield cluttered depictions. The paper addresses the challenges raised by the visual exploration and validation of two CFD simulations involving vortex breakdown. To permit accurate and insightful visualization we propose a new approach that unfolds the geometry of the breakdown region by letting a plane travel through the structure along a curve. We track the continuous evolution of the associated projected vector field using the theoretical framework of parametric topology. To improve the understanding of the spatial relationship between the resulting curves and lines we use direct volume rendering and multidimensional transfer functions for the display of flow-derived scalar quantities. This enriches the visualization and provides an intuitive context for the extracted topological information. Our results offer clear, synthetic depictions that permit new insight into the structural properties of vortex breakdowns.",
                "AuthorNames": "Tricoche, X.;Garth, C.;Kindlmann, G.;Deines, E.;Scheuermann, G.;Ruetten, M.;Hansen, C.",
                "FirstAuthorAffiliation": "Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37282575100;37282573700;37282742400;37282727900;37282574800;37282728900;37266777200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tricoche, X.;Garth, C.;Kindlmann, G.;Deines, E.;Scheuermann, G.;Ruetten, M.;Hansen, C.",
                "filename": "tricoche_vis_04",
                "Citations": "964519;745296;175773;663910;809896;1250414;1250376;964489;398875;175789;346314"
            }
        },
        {
            "name": "Lauterbach, C.",
            "value": 0,
            "numPapers": 5,
            "cluster": "6",
            "index": 558,
            "weight": 5,
            "x": 836.6479599461949,
            "y": 314.6124499334043,
            "px": 881.8728019874044,
            "py": 348.0846794928973,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Listener-based Analysis of Surface Importance for Acoustic Metrics",
                "PaperDOI": "10.1109/TVCG.2007.70575",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70575",
                "firstage": "1680",
                "Lastage": "1687",
                "IEEEXPLOREArticleNumber": "4376202",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D50) and clarity (C50) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C50) values at listener positions throughout the room.",
                "AuthorNames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "FirstAuthorAffiliation": "IRTG Kaiserslautern, Kaiserslautern|c|;;;;",
                "AuthorIDs": "37838754300;37282727900;;37282573700;37282578800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "filename": "michel_vis_07",
                "Citations": "4015479;1532790"
            }
        },
        {
            "name": "Manocha, D.",
            "value": 43,
            "numPapers": 28,
            "cluster": "6",
            "index": 559,
            "weight": 7,
            "x": 838.2020804185354,
            "y": 342.56147421604044,
            "px": 860.7326743193375,
            "py": 344.314753639727,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Feature-sensitive subdivision and isosurface reconstruction",
                "PaperDOI": "10.1109/VISUAL.2003.1250360",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250360",
                "firstage": "99",
                "Lastage": "106",
                "IEEEXPLOREArticleNumber": "1250360",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present improved subdivision and isosurface reconstruction algorithms for polygonizing implicit surfaces and performing accurate geometric operations. Our improved reconstruction algorithm uses directed distance fields (Kobbelt et al., 2001) to detect multiple intersections along an edge, separates them into components and reconstructs an isosurface locally within each components using the dual contouring algorithm (Ju et al., 2002). It can reconstruct thin features without creating handles and results in improved surface extraction from volumetric data. Our subdivision algorithm takes into account sharp features that arise from intersecting surfaces or Boolean operations and generates an adaptive grid such that each voxel has at most one sharp feature. The subdivision algorithm is combined with our improved reconstruction algorithm to compute accurate polygonization of Boolean combinations or offsets of complex primitives that faithfully reconstruct the sharp features. We have applied these algorithms to polygonize complex CAD models designed using thousands of Boolean operations on curved primitives.",
                "AuthorNames": "Varadhan, G.;Shankar Krishnan;Kim, Y.J.;Manocha, D.",
                "FirstAuthorAffiliation": "North Carolina Univ., Chapel Hill, NC, USA|c|;;;",
                "AuthorIDs": "37267825100;37275776600;38185529300;37267825600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Varadhan, G.;Shankar Krishnan;Kim, Y.J.;Manocha, D.",
                "filename": "varadhan_vis_03",
                "Citations": "964518;568127"
            }
        },
        {
            "name": "Bertram, M.",
            "value": 35,
            "numPapers": 11,
            "cluster": "6",
            "index": 560,
            "weight": 3,
            "x": 1214.1828775036738,
            "y": 759.0459475463966,
            "px": 1083.9176792590474,
            "py": 579.0941655587403,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Comparative Visualization for Wave-based and Geometric Acoustics",
                "PaperDOI": "10.1109/TVCG.2006.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.125",
                "firstage": "1173",
                "Lastage": "1180",
                "IEEEXPLOREArticleNumber": "4015479",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects",
                "AuthorNames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "FirstAuthorAffiliation": "IRTG, Kaiserslautern|c|;;;;;;",
                "AuthorIDs": "37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "filename": "deines_vis_06",
                "Citations": "1532790"
            }
        },
        {
            "name": "Mohring, J.",
            "value": 33,
            "numPapers": 2,
            "cluster": "6",
            "index": 561,
            "weight": 3,
            "x": 1090.5183077906293,
            "y": 592.1399046435332,
            "px": 1102.6804676115505,
            "py": 543.962257902338,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Comparative Visualization for Wave-based and Geometric Acoustics",
                "PaperDOI": "10.1109/TVCG.2006.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.125",
                "firstage": "1173",
                "Lastage": "1180",
                "IEEEXPLOREArticleNumber": "4015479",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects",
                "AuthorNames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "FirstAuthorAffiliation": "IRTG, Kaiserslautern|c|;;;;;;",
                "AuthorIDs": "37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "filename": "deines_vis_06",
                "Citations": "1532790"
            }
        },
        {
            "name": "Jegorovs, J.",
            "value": 33,
            "numPapers": 2,
            "cluster": "6",
            "index": 562,
            "weight": 3,
            "x": 1060.5033858569543,
            "y": 574.6754124012737,
            "px": 1121.2976457161426,
            "py": 556.7689031287307,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Comparative Visualization for Wave-based and Geometric Acoustics",
                "PaperDOI": "10.1109/TVCG.2006.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.125",
                "firstage": "1173",
                "Lastage": "1180",
                "IEEEXPLOREArticleNumber": "4015479",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects",
                "AuthorNames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "FirstAuthorAffiliation": "IRTG, Kaiserslautern|c|;;;;;;",
                "AuthorIDs": "37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "filename": "deines_vis_06",
                "Citations": "1532790"
            }
        },
        {
            "name": "Joshi, A.",
            "value": 41,
            "numPapers": 19,
            "cluster": "5",
            "index": 563,
            "weight": 2,
            "x": 126.442534424475,
            "y": 192.93881057204598,
            "px": 74.77072398743266,
            "py": 89.54217235896019,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Texture-based feature tracking for effective time-varying data visualization",
                "PaperDOI": "10.1109/TVCG.2007.70599",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70599",
                "firstage": "1472",
                "Lastage": "1479",
                "IEEEXPLOREArticleNumber": "4376176",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.",
                "AuthorNames": "Caban, J.J.;Joshi, A.;Rheingans, P.",
                "FirstAuthorAffiliation": "Univ. of Maryland Baltimore County, Baltimore|c|;;",
                "AuthorIDs": ";37278517400;37282292000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Caban, J.J.;Joshi, A.;Rheingans, P.",
                "filename": "caban_vis_07",
                "Citations": "1250374;885694;745288;567807"
            }
        },
        {
            "name": "Schneider, D.",
            "value": 47,
            "numPapers": 18,
            "cluster": "6",
            "index": 564,
            "weight": 1,
            "x": 1859.4403555407127,
            "y": -1862.827390153045,
            "px": 3153.2985036087407,
            "py": -3753.54877171948,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2008.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.143",
                "firstage": "1475",
                "Lastage": "1482",
                "IEEEXPLOREArticleNumber": "4658165",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.",
                "AuthorNames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Leipzig Univ., Leipzig|c|;;;;",
                "AuthorIDs": "37869538100;37565763400;37282624500;37403333700;37282574800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "filename": "schneide_vis_08",
                "Citations": "4015446;964519;1372214;4376165;1532830;4015447;1372235;1250374;4376167;1532848;663875;1532835"
            }
        },
        {
            "name": "Globus, A.",
            "value": 121,
            "numPapers": 4,
            "cluster": "6",
            "index": 565,
            "weight": 3,
            "x": 602.242955810154,
            "y": 271.210559454277,
            "px": 558.8616517142162,
            "py": 259.18654662028445,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "A tool for visualizing the topology of three-dimensional vector fields",
                "PaperDOI": "10.1109/VISUAL.1991.175773",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175773",
                "firstage": "33",
                "Lastage": "40, 408",
                "IEEEXPLOREArticleNumber": "175773",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 3×3 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.",
                "AuthorNames": "Globus, A.;Levit, C.;Lasinski, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37377256900;37671515100;37671524000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Globus, A.;Levit, C.;Lasinski, T.",
                "filename": "globus_vis_91",
                "Citations": "146360;146359"
            }
        },
        {
            "name": "Levit, C.",
            "value": 144,
            "numPapers": 4,
            "cluster": "6",
            "index": 566,
            "weight": 2,
            "x": 1045.9866793577112,
            "y": 336.593064249036,
            "px": 511.56103105848524,
            "py": 214.12408581668143,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "A tool for visualizing the topology of three-dimensional vector fields",
                "PaperDOI": "10.1109/VISUAL.1991.175773",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175773",
                "firstage": "33",
                "Lastage": "40, 408",
                "IEEEXPLOREArticleNumber": "175773",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 3×3 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.",
                "AuthorNames": "Globus, A.;Levit, C.;Lasinski, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37377256900;37671515100;37671524000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Globus, A.;Levit, C.;Lasinski, T.",
                "filename": "globus_vis_91",
                "Citations": "146360;146359"
            }
        },
        {
            "name": "Lasinski, T.",
            "value": 84,
            "numPapers": 2,
            "cluster": "6",
            "index": 567,
            "weight": 2,
            "x": 745.5103232156825,
            "y": 800.3537995067209,
            "px": 503.3559314855346,
            "py": 242.56856246635138,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "A tool for visualizing the topology of three-dimensional vector fields",
                "PaperDOI": "10.1109/VISUAL.1991.175773",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175773",
                "firstage": "33",
                "Lastage": "40, 408",
                "IEEEXPLOREArticleNumber": "175773",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 3×3 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.",
                "AuthorNames": "Globus, A.;Levit, C.;Lasinski, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37377256900;37671515100;37671524000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Globus, A.;Levit, C.;Lasinski, T.",
                "filename": "globus_vis_91",
                "Citations": "146360;146359"
            }
        },
        {
            "name": "Ka-Kei Chung",
            "value": 11,
            "numPapers": 22,
            "cluster": "5",
            "index": 568,
            "weight": 1,
            "x": 648.3534586627754,
            "y": 621.2563989001677,
            "px": 837.0921665510527,
            "py": 666.8654108432154,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Interactive Visual Optimization and Analysis for RfiD Benchmarking",
                "PaperDOI": "10.1109/TVCG.2009.156",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.156",
                "firstage": "1335",
                "Lastage": "1342",
                "IEEEXPLOREArticleNumber": "5290746",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.",
                "AuthorNames": "Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Cheung, S.C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;",
                "AuthorIDs": "37407308300;37406959900;37272637300;37403856700;37275216500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Cheung, S.C.",
                "filename": "wu_vis_09",
                "Citations": "4658160;146402;4376143;1532141;567800;1382890"
            }
        },
        {
            "name": "Crossno, P.",
            "value": 124,
            "numPapers": 26,
            "cluster": "5",
            "index": 569,
            "weight": 2,
            "x": 518.0147804150614,
            "y": 317.5949665465476,
            "px": 504.68915972892006,
            "py": 582.3153937629426,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "firstage": "135",
                "Lastage": "142",
                "IEEEXPLOREArticleNumber": "1532788",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "filename": "bavoil_vis_05",
                "Citations": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Termeer, M.",
            "value": 38,
            "numPapers": 6,
            "cluster": "5",
            "index": 570,
            "weight": 1,
            "x": -158.7248693512049,
            "y": 676.2035195527369,
            "px": -583.2839394836857,
            "py": 811.9324365228648,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "firstage": "1632",
                "Lastage": "1639",
                "IEEEXPLOREArticleNumber": "4376196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "filename": "termeer_vis_07",
                "Citations": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Bescos, J.O.",
            "value": 43,
            "numPapers": 10,
            "cluster": "5",
            "index": 571,
            "weight": 1,
            "x": 8224.145819561498,
            "y": 8997.429674094774,
            "px": 15948.292626169961,
            "py": 17313.291649579878,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "firstage": "1632",
                "Lastage": "1639",
                "IEEEXPLOREArticleNumber": "4376196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "filename": "termeer_vis_07",
                "Citations": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Gerritsen, F.",
            "value": 45,
            "numPapers": 10,
            "cluster": "5",
            "index": 572,
            "weight": 1,
            "x": 1535.2380788742466,
            "y": 1911.8420934381927,
            "px": 2670.578478197427,
            "py": 3245.3730799628715,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "firstage": "1632",
                "Lastage": "1639",
                "IEEEXPLOREArticleNumber": "4376196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "filename": "termeer_vis_07",
                "Citations": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Hongwei Li",
            "value": 25,
            "numPapers": 25,
            "cluster": "0",
            "index": 573,
            "weight": 2,
            "x": 942.2055685214239,
            "y": 759.1874427334949,
            "px": 951.8882615663582,
            "py": 779.5139027246948,
            "node": {
                "Conference": "SciVis",
                "Year": "2007",
                "PaperTitle": "Visualizing Large-Scale Uncertainty in Astrophysical Data",
                "PaperDOI": "10.1109/TVCG.2007.70530",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70530",
                "firstage": "1640",
                "Lastage": "1647",
                "IEEEXPLOREArticleNumber": "4376197",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.",
                "AuthorNames": "Hongwei Li;Chi-Wing Fu;Yinggang Li;Hanson, A.J.",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;;",
                "AuthorIDs": "37881121400;;37835045200;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hongwei Li;Chi-Wing Fu;Yinggang Li;Hanson, A.J.",
                "filename": "li_vis_07",
                "Citations": "885679;1183769;1250404;1532807;4015476;4015458;1372187;1532853;568116;1183824;568105;1173145;1532803;1372183"
            }
        },
        {
            "name": "Thompson, D.",
            "value": 61,
            "numPapers": 24,
            "cluster": "6",
            "index": 574,
            "weight": 2,
            "x": 565.0657007143714,
            "y": 183.0049983332771,
            "px": 209.37547411427897,
            "py": 562.3712082378099,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Vortex Visualization for Practical Engineering Applications",
                "PaperDOI": "10.1109/TVCG.2006.201",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.201",
                "firstage": "957",
                "Lastage": "964",
                "IEEEXPLOREArticleNumber": "4015452",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability",
                "AuthorNames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Raghu Machiraju",
                "FirstAuthorAffiliation": "Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;",
                "AuthorIDs": ";37826582200;;37269516700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.",
                "filename": "jankunke_vis_06",
                "Citations": "663894;1183789;1532830;745296;745288;809896"
            }
        },
        {
            "name": "Glatter, M.",
            "value": 17,
            "numPapers": 15,
            "cluster": "5",
            "index": 575,
            "weight": 1,
            "x": 551.4791014023183,
            "y": 841.2244398254727,
            "px": 713.5696470568562,
            "py": 1128.4472431823879,
            "node": {
                "Conference": "SciVis",
                "Year": "2008",
                "PaperTitle": "Visualizing Temporal Patterns in Large Multivariate Data using Textual Pattern Matching",
                "PaperDOI": "10.1109/TVCG.2008.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.184",
                "firstage": "1467",
                "Lastage": "1474",
                "IEEEXPLOREArticleNumber": "4658164",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.",
                "AuthorNames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "FirstAuthorAffiliation": "Univ. of Tennessee at Knoxville, Knoxville, TN|c|;;;;",
                "AuthorIDs": "37828700000;37281262900;37410066100;37672397100;37545504600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "filename": "glatter_vis_08",
                "Citations": "1250402;4376164;4015494;1372194;4376167;964519;1532792"
            }
        },
        {
            "name": "Jianping Fan",
            "value": 28,
            "numPapers": 13,
            "cluster": "2",
            "index": 576,
            "weight": 2,
            "x": -699.2064954680126,
            "y": -68.72725860073301,
            "px": -311.9577936248849,
            "py": 135.03915413190154,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "firstage": "191",
                "Lastage": "198",
                "IEEEXPLOREArticleNumber": "4035765",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "filename": "yang_vast_06",
                "Citations": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Hangzai Luo",
            "value": 28,
            "numPapers": 13,
            "cluster": "2",
            "index": 577,
            "weight": 2,
            "x": -645.8826483028255,
            "y": -278.4560988849024,
            "px": -326.59597519948335,
            "py": 143.08673682874752,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "firstage": "191",
                "Lastage": "198",
                "IEEEXPLOREArticleNumber": "4035765",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "filename": "yang_vast_06",
                "Citations": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Wise, J.A.",
            "value": 167,
            "numPapers": 1,
            "cluster": "2",
            "index": 578,
            "weight": 4,
            "x": 749.9903064948267,
            "y": -1231.0834796640302,
            "px": 468.5479293908224,
            "py": -921.6264363630523,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "528686",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "filename": "wise_infovis_95",
                "Citations": "398863"
            }
        },
        {
            "name": "Pennock, K.",
            "value": 167,
            "numPapers": 1,
            "cluster": "2",
            "index": 579,
            "weight": 4,
            "x": 622.7602062922929,
            "y": -562.073521178888,
            "px": 362.908810223022,
            "py": -393.5761452521268,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "528686",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "filename": "wise_infovis_95",
                "Citations": "398863"
            }
        },
        {
            "name": "Lantrip, D.",
            "value": 167,
            "numPapers": 1,
            "cluster": "2",
            "index": 580,
            "weight": 4,
            "x": 303.08005312208667,
            "y": 1000.4765923766105,
            "px": 117.76094988442354,
            "py": 796.5879546233539,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "528686",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "filename": "wise_infovis_95",
                "Citations": "398863"
            }
        },
        {
            "name": "Pottier, M.",
            "value": 167,
            "numPapers": 1,
            "cluster": "2",
            "index": 581,
            "weight": 4,
            "x": 740.5643526306059,
            "y": 151.26120560209833,
            "px": 446.9531616716196,
            "py": 156.1703355234298,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "528686",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "filename": "wise_infovis_95",
                "Citations": "398863"
            }
        },
        {
            "name": "Schur, A.",
            "value": 167,
            "numPapers": 1,
            "cluster": "2",
            "index": 582,
            "weight": 4,
            "x": 4468.339532517225,
            "y": 2263.7574577669147,
            "px": 3381.4061365474968,
            "py": 1803.906635142599,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "528686",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "filename": "wise_infovis_95",
                "Citations": "398863"
            }
        },
        {
            "name": "Crow, V.",
            "value": 192,
            "numPapers": 5,
            "cluster": "2",
            "index": 583,
            "weight": 4,
            "x": 1069.6827857364456,
            "y": 883.8588930491593,
            "px": 695.1474826157407,
            "py": 707.03888932393,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "firstage": "51",
                "Lastage": "58",
                "IEEEXPLOREArticleNumber": "528686",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "filename": "wise_infovis_95",
                "Citations": "398863"
            }
        },
        {
            "name": "Chi-Chun Pan",
            "value": 24,
            "numPapers": 4,
            "cluster": "5",
            "index": 584,
            "weight": 1,
            "x": -13.233136497297355,
            "y": 325.2632879134968,
            "px": -296.97781895998656,
            "py": 207.54197591446592,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "FemaRepViz: Automatic Extraction and Geo-Temporal Visualization of FEMA National Situation Updates",
                "PaperDOI": "10.1109/VAST.2007.4388991",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4388991",
                "firstage": "11",
                "Lastage": "18",
                "IEEEXPLOREArticleNumber": "4388991",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An architecture for visualizing information extracted from text documents is proposed. In conformance with this architecture, a toolkit, FemaRepViz, has been implemented to extract and visualize temporal, geospatial, and summarized information from FEMA national update reports. Preliminary tests have shown satisfactory accuracy for FEMARepViz. A central component of the architecture is an entity extractor that extracts named entities like person names, location names, temporal references, etc. FEMARepViz is based on FactXtractor, an entity-extractor that works on text documents. The information extracted using FactXtractor is processed using GeoTagger, a geographical name disambiguation tool based on a novel clustering-based disambiguation algorithm. To extract relationships among entities, we propose a machine-learning based algorithm that uses a novel stripped dependency tree kernel. We illustrate and evaluate the usefulness of our system on the FEMA National Situation Updates. Daily reports are fetched by FEMARepViz from the FEMA website, segmented into coherent sections and each section is classified into one of several known incident types. We use concept Vista, Google maps and Google earth to visualize the events extracted from the text reports and allow the user to interactively filter the topics, locations, and time-periods of interest to create a visual analytics toolkit that is useful for rapid analysis of events reported in a large set of text documents.",
                "AuthorNames": "Chi-Chun Pan;Mitra, P.",
                "FirstAuthorAffiliation": "Pennsylvania State Univ., State College|c|;",
                "AuthorIDs": "37880213000;37286730000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chi-Chun Pan;Mitra, P.",
                "filename": "pan_vast_07",
                "Citations": ""
            }
        },
        {
            "name": "Laskowski, S.",
            "value": 0,
            "numPapers": 5,
            "cluster": "5",
            "index": 585,
            "weight": 1,
            "x": 776.854704065185,
            "y": 482.7934172632216,
            "px": 1083.9533099142786,
            "py": 489.2674827294955,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Interdisciplinary visualization: lessons learned at NCSA",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846",
                "firstage": "457",
                "Lastage": "457",
                "IEEEXPLOREArticleNumber": "",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "",
                "AuthorNames": "Cox, D. C.",
                "FirstAuthorAffiliation": "National Center for Supercomputing Applications",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cox, D. C.",
                "filename": "",
                "Citations": ""
            }
        },
        {
            "name": "Wehrend, S.",
            "value": 50,
            "numPapers": 1,
            "cluster": "3",
            "index": 586,
            "weight": 1,
            "x": -1002.0870175954374,
            "y": 841.058540154581,
            "px": -1910.1110686717766,
            "py": 1154.349138519117,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "A problem-oriented classification of visualization techniques",
                "PaperDOI": "10.1109/VISUAL.1990.146375",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146375",
                "firstage": "139",
                "Lastage": "143, 469",
                "IEEEXPLOREArticleNumber": "146375",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods",
                "AuthorNames": "Wehrend, S.;Lewis, C.",
                "FirstAuthorAffiliation": "Colorado Univ., Boulder, CO, USA|c|;",
                "AuthorIDs": "38222492800;37380191400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wehrend, S.;Lewis, C.",
                "filename": "wehrend_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Lewis, C.",
            "value": 50,
            "numPapers": 1,
            "cluster": "3",
            "index": 587,
            "weight": 1,
            "x": 818.8914986536212,
            "y": 153.87126324379727,
            "px": 1564.450067475132,
            "py": -157.0596570394413,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "A problem-oriented classification of visualization techniques",
                "PaperDOI": "10.1109/VISUAL.1990.146375",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146375",
                "firstage": "139",
                "Lastage": "143, 469",
                "IEEEXPLOREArticleNumber": "146375",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods",
                "AuthorNames": "Wehrend, S.;Lewis, C.",
                "FirstAuthorAffiliation": "Colorado Univ., Boulder, CO, USA|c|;",
                "AuthorIDs": "38222492800;37380191400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wehrend, S.;Lewis, C.",
                "filename": "wehrend_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "North, S.C.",
            "value": 100,
            "numPapers": 15,
            "cluster": "2",
            "index": 588,
            "weight": 1,
            "x": -557.5090202702675,
            "y": 1452.3322320123707,
            "px": -1552.6294152055987,
            "py": 2549.8570575267577,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats",
                "PaperDOI": "10.1109/TVCG.2007.70522",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70522",
                "firstage": "1105",
                "Lastage": "1112",
                "IEEEXPLOREArticleNumber": "4376129",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.",
                "AuthorNames": "Mansmann, F.;Keim, D.A.;North, S.C.;Rexroad, B.;Sheleheda, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz|c|;;;;",
                "AuthorIDs": "37392086200;;;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Mansmann, F.;Keim, D.A.;North, S.C.;Rexroad, B.;Sheleheda, D.",
                "filename": "mansmann_infovis_07",
                "Citations": "4035756;1173156;1382888;175815"
            }
        },
        {
            "name": "Peitgen, H.-O.",
            "value": 70,
            "numPapers": 9,
            "cluster": "5",
            "index": 589,
            "weight": 1,
            "x": -213.8007896078742,
            "y": 154.73846892757223,
            "px": -707.9019764202593,
            "py": -165.1323297646,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Visualization and interaction techniques for the exploration of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2001.964538",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964538",
                "firstage": "395",
                "Lastage": "402",
                "IEEEXPLOREArticleNumber": "964538",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.",
                "AuthorNames": "Hahn, H.K.;Preim, B.;Selle, D.;Peitgen, H.-O.",
                "FirstAuthorAffiliation": "MeVis-Center for Med. Diagnostic Syst., Bremen, Germany|c|;;;",
                "AuthorIDs": "37729702200;37424645300;37728223900;37442956900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hahn, H.K.;Preim, B.;Selle, D.;Peitgen, H.-O.",
                "filename": "hahn_vis_01",
                "Citations": "663917"
            }
        },
        {
            "name": "Eick, S.G.",
            "value": 73,
            "numPapers": 11,
            "cluster": "5",
            "index": 590,
            "weight": 1,
            "x": 4.607689969744236,
            "y": 334.46593067246863,
            "px": -276.4624370304575,
            "py": 218.08429913976101,
            "node": {
                "Conference": "SciVis",
                "Year": "1993",
                "PaperTitle": "Navigating large networks with hierarchies",
                "PaperDOI": "10.1109/VISUAL.1993.398870",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398870",
                "firstage": "204",
                "Lastage": "210",
                "IEEEXPLOREArticleNumber": "398870",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper is aimed at the exploratory visualization of networks where there is a strength or weight associated with each link, and makes use of any hierarchy present on the nodes to aid the investigation of large networks. It describes a method of placing nodes on the plane that gives meaning to their relative positions. The paper discusses how linking and interaction principles aid the user in the exploration. Two examples are given; one of electronic mail communication over eight months within a department, another concerned with changes to a large section of a computer program",
                "AuthorNames": "Eick, S.G.;Wills, G.J.",
                "FirstAuthorAffiliation": "AT&T Bell Lab., USA|c|;",
                "AuthorIDs": "37282570100;37844196100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Eick, S.G.;Wills, G.J.",
                "filename": "eick_vis_93",
                "Citations": "146369;175815"
            }
        },
        {
            "name": "Tsigas, P.",
            "value": 41,
            "numPapers": 16,
            "cluster": "2",
            "index": 591,
            "weight": 1,
            "x": 380.62837248820995,
            "y": -92.32591278691837,
            "px": 125.32240581803403,
            "py": -383.7208945505668,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data",
                "PaperDOI": "10.1109/VAST.2007.4389013",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389013",
                "firstage": "187",
                "Lastage": "194",
                "IEEEXPLOREArticleNumber": "4389013",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.",
                "AuthorNames": "Elmqvist, N.;Stasko, J.;Tsigas, P.",
                "FirstAuthorAffiliation": "Univ. Paris-Sud, Paris|c|;;",
                "AuthorIDs": "37295438200;37267736900;37295439000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Elmqvist, N.;Stasko, J.;Tsigas, P.",
                "filename": "elmqvist_vast_07",
                "Citations": "885086;146386;175815;1249026;4035757;1532139;4035764;4035743;1532136;636793;4035763;4035747;1249016;809866;146375"
            }
        },
        {
            "name": "Martin, A.R.",
            "value": 110,
            "numPapers": 3,
            "cluster": "2",
            "index": 592,
            "weight": 2,
            "x": -235.18597737987272,
            "y": -304.4976969354764,
            "px": 713.9008712856381,
            "py": 324.2484056620511,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "High Dimensional Brushing for Interactive Exploration of Multivariate Data",
                "PaperDOI": "10.1109/VISUAL.1995.485139",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.485139",
                "firstage": "271",
                "Lastage": "",
                "IEEEXPLOREArticleNumber": "485139",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Brushing is an operation found in many data visualization systems. It is a mechanism for interactively selecting subsets of the data so that they may be highlighted, deleted, or masked. Traditionally, brushes have been defined in screen space via methods such as painting and rubberband rectangles. In this paper we describe the design of N-dimensional brushes which are defined in data space rather than screen space, and show how they have been integrated into XmdvTool, a visualization package for displaying multivariate data. Depending on the data display technique in use, brushes may be specified and manipulated via direct or indirect methods, and the specification may be demand-driven or data-driven. Various brush operations such as highlighting, linking, masking, moving average, and quantitative display have been developed to apply to the selected data. In addition, we have explored several new brush concepts, such as non-discrete brush boundaries, simultaneous display of multiple brushes, and creating composite brushes via logical operators. Preliminary experimental evaluation with test subjects supports the usefulness of N-dimensional brushes in data exploration tasks.",
                "AuthorNames": "Martin, A.R.;Ward, M.O.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "38149689900;37268441700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Martin, A.R.;Ward, M.O.",
                "filename": "martin_vis_95",
                "Citations": "146386;146402;346302"
            }
        },
        {
            "name": "House, D.",
            "value": 54,
            "numPapers": 11,
            "cluster": "2",
            "index": 593,
            "weight": 1,
            "x": -288.5136988790588,
            "y": 767.6795766063655,
            "px": -1008.6880038316707,
            "py": 1216.2963279304558,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Texturing of Layered Surfaces for Optimal Viewing",
                "PaperDOI": "10.1109/TVCG.2006.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.183",
                "firstage": "1125",
                "Lastage": "1132",
                "IEEEXPLOREArticleNumber": "4015473",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a \"human in the loop\" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines",
                "AuthorNames": "Bair, A.S.;House, D.H.;Ware, C.",
                "FirstAuthorAffiliation": "Texas A&M Univ., College Station, TX|c|;;",
                "AuthorIDs": "37565577300;37284216700;37265850800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bair, A.;House, D.;Ware, C.",
                "filename": "bair_vis_06",
                "Citations": "1532782;1249022"
            }
        },
        {
            "name": "Feng Qiu",
            "value": 22,
            "numPapers": 12,
            "cluster": "5",
            "index": 594,
            "weight": 1,
            "x": -294.5705323527088,
            "y": 444.4089565851614,
            "px": -855.1185121597287,
            "py": 362.9717853520903,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "A Pipeline for Computer Aided Polyp Detection",
                "PaperDOI": "10.1109/TVCG.2006.112",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.112",
                "firstage": "861",
                "Lastage": "868",
                "IEEEXPLOREArticleNumber": "4015440",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy",
                "AuthorNames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stony Brook Univ., NY|c|;;",
                "AuthorIDs": "37277099300;37416126400;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "filename": "hong_vis_06",
                "Citations": "964540;1372236;235231;1250384"
            }
        },
        {
            "name": "Avila, R.",
            "value": 100,
            "numPapers": 14,
            "cluster": "5",
            "index": 595,
            "weight": 7,
            "x": 248.48339551097268,
            "y": 506.94442378126496,
            "px": 290.06460310003405,
            "py": 517.4251452676182,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "A haptic interaction method for volume visualization",
                "PaperDOI": "10.1109/VISUAL.1996.568108",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568108",
                "firstage": "197",
                "Lastage": "204",
                "IEEEXPLOREArticleNumber": "568108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume visualization techniques typically provide support for visual exploration of data, however additional information can be conveyed by allowing a user to see as well as feel virtual objects. We present a haptic interaction method that is suitable for both volume visualization and modeling applications. Point contact forces are computed directly from the volume data and are consistent with the isosurface and volume rendering methods, providing a strong correspondence between visual and haptic feedback. Virtual tools are simulated by applying three-dimensional filters to some properties of the data within the extent of the tool, and interactive visual feedback rates are obtained by using an accelerated ray casting method. This haptic interaction method was implemented using a PHANToM haptic interface.",
                "AuthorNames": "Avila, R.S.;Sobierajski, L.M.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;",
                "AuthorIDs": "37323905300;37378488600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Avila, R.;Sobierajski, L.",
                "filename": "avila_vis_96",
                "Citations": "480792"
            }
        },
        {
            "name": "Sobierajski, L.",
            "value": 102,
            "numPapers": 16,
            "cluster": "5",
            "index": 596,
            "weight": 7,
            "x": 232.53105738651308,
            "y": 521.5755991695546,
            "px": 277.7124032508447,
            "py": 533.0016603011301,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "A haptic interaction method for volume visualization",
                "PaperDOI": "10.1109/VISUAL.1996.568108",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568108",
                "firstage": "197",
                "Lastage": "204",
                "IEEEXPLOREArticleNumber": "568108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume visualization techniques typically provide support for visual exploration of data, however additional information can be conveyed by allowing a user to see as well as feel virtual objects. We present a haptic interaction method that is suitable for both volume visualization and modeling applications. Point contact forces are computed directly from the volume data and are consistent with the isosurface and volume rendering methods, providing a strong correspondence between visual and haptic feedback. Virtual tools are simulated by applying three-dimensional filters to some properties of the data within the extent of the tool, and interactive visual feedback rates are obtained by using an accelerated ray casting method. This haptic interaction method was implemented using a PHANToM haptic interface.",
                "AuthorNames": "Avila, R.S.;Sobierajski, L.M.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;",
                "AuthorIDs": "37323905300;37378488600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Avila, R.;Sobierajski, L.",
                "filename": "avila_vis_96",
                "Citations": "480792"
            }
        },
        {
            "name": "Jankun-Kelly, T.J.",
            "value": 84,
            "numPapers": 34,
            "cluster": "5",
            "index": 597,
            "weight": 1,
            "x": -1050.308102549648,
            "y": -313.5077818735976,
            "px": -2044.560717758415,
            "py": -730.2932452351278,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates",
                "PaperDOI": "10.1109/VAST.2009.5332586",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332586",
                "firstage": "19",
                "Lastage": "26",
                "IEEEXPLOREArticleNumber": "5332586",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system's utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis.",
                "AuthorNames": "Steed, C.A.;Swan, J.E.;Jankun-Kelly, T.J.;Fitzpatrick, P.J.",
                "FirstAuthorAffiliation": "Naval Res. Lab., Orlando, FL, USA|c|;;;",
                "AuthorIDs": "37396434400;37295140400;37399870300;37267202400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Steed, C.A.;Swan, J.E.;Jankun-Kelly, T.J.;Fitzpatrick, P.J.",
                "filename": "steed_vast_09",
                "Citations": "4376168;1532138;4035743;1382894;485139;1173157;809866;4015444"
            }
        },
        {
            "name": "Wei Qiao",
            "value": 51,
            "numPapers": 21,
            "cluster": "5",
            "index": 598,
            "weight": 2,
            "x": 329.7035288403238,
            "y": 139.5086598781003,
            "px": -55.47185133328381,
            "py": 114.40430333968516,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Projecting tetrahedra without rendering artifacts",
                "PaperDOI": "10.1109/VISUAL.2004.85",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.85",
                "firstage": "27",
                "Lastage": "34",
                "IEEEXPLOREArticleNumber": "1372176",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Hardware-accelerated direct volume rendering of unstructured volumetric meshes is often based on tetrahedral cell projection, in particular, the projected tetrahedra (PT) algorithm and its variants. Unfortunately, even implementations of the most advanced variants of the PT algorithm are very prone to rendering artifacts. In this work, we identify linear interpolation in screen coordinates as a cause for significant rendering artifacts and implement the correct perspective interpolation for the PT algorithm with programmable graphics hardware. We also demonstrate how to use features of modern graphics hardware to improve the accuracy of the coloring of individual tetrahedra and the compositing of the resulting colors, in particular, by employing a logarithmic scale for the preintegrated color lookup table, using textures with high color resolution, rendering to floating-point color buffers, and alpha dithering. Combined with a correct visibility ordering, these techniques result in the first implementation of the PT algorithm without objectionable rendering artifacts. Apart from the important improvement in rendering quality, our approach also provides a test bed for different implementations of the PT algorithm that allows us to study the particular rendering artifacts introduced by these variants.",
                "AuthorNames": "Kraus, M.;Wei Qiao;Ebert, D.S.",
                "FirstAuthorAffiliation": "Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "38367958800;37282552800;38472155300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kraus, M.;Wei Qiao;Ebert, D.S.",
                "filename": "kraus_vis_04",
                "Citations": "885683;1250390;964514;1250384"
            }
        },
        {
            "name": "Erlebacher, G.",
            "value": 74,
            "numPapers": 19,
            "cluster": "5",
            "index": 599,
            "weight": 5,
            "x": 186.8731069964995,
            "y": 260.9164952688074,
            "px": 39.80968123614187,
            "py": 224.76042507065773,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated texture advection for unsteady flow visualization",
                "PaperDOI": "10.1109/VISUAL.2000.885689",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885689",
                "firstage": "155",
                "Lastage": "162",
                "IEEEXPLOREArticleNumber": "885689",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.",
                "AuthorNames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;",
                "AuthorIDs": "37267249300;37324424400;37324426600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "filename": "jobard_vis_00",
                "Citations": "480817;745324"
            }
        },
        {
            "name": "Zhang, H.",
            "value": 0,
            "numPapers": 5,
            "cluster": "5",
            "index": 600,
            "weight": 1,
            "x": 229.0901031367836,
            "y": 50.63150528601857,
            "px": 86.7870383342129,
            "py": -285.0365906273126,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "firstage": "233",
                "Lastage": "238",
                "IEEEXPLOREArticleNumber": "745713",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "filename": "parker_vis_98",
                "Citations": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "Parker, S.",
            "value": 67,
            "numPapers": 5,
            "cluster": "5",
            "index": 601,
            "weight": 1,
            "x": 515.8587582016049,
            "y": 366.25625113340243,
            "px": 592.1138314449869,
            "py": 286.55541105433366,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "firstage": "233",
                "Lastage": "238",
                "IEEEXPLOREArticleNumber": "745713",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "filename": "parker_vis_98",
                "Citations": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "Sloan, P.-P.",
            "value": 67,
            "numPapers": 5,
            "cluster": "5",
            "index": 602,
            "weight": 1,
            "x": 301.208752566479,
            "y": 335.7769432199368,
            "px": 255.26505513218464,
            "py": 231.04905844663847,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "firstage": "233",
                "Lastage": "238",
                "IEEEXPLOREArticleNumber": "745713",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "filename": "parker_vis_98",
                "Citations": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "Shi, Q.",
            "value": 0,
            "numPapers": 11,
            "cluster": "5",
            "index": 603,
            "weight": 2,
            "x": 545.4091320203513,
            "y": 231.22513697329646,
            "px": 411.967195166872,
            "py": 563.6659978429382,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "firstage": "233",
                "Lastage": "238",
                "IEEEXPLOREArticleNumber": "745713",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "filename": "parker_vis_98",
                "Citations": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "JaJa, J.",
            "value": 9,
            "numPapers": 25,
            "cluster": "5",
            "index": 604,
            "weight": 2,
            "x": 22.15555019726178,
            "y": 693.490055100817,
            "px": 465.8286986223635,
            "py": 499.96048236716064,
            "node": {
                "Conference": "SciVis",
                "Year": "2012",
                "PaperTitle": "Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms",
                "PaperDOI": "10.1109/TVCG.2012.231",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.231",
                "firstage": "2355",
                "Lastage": "2363",
                "IEEEXPLOREArticleNumber": "6327240",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.",
                "AuthorNames": "Cheuk Yiu Ip;Varshney, A.;JaJa, J.",
                "FirstAuthorAffiliation": "Inst. for Adv. Comput. Studies, Univ. of Maryland, College Park, MD, USA|c|;;",
                "AuthorIDs": "37586231900;37282560200;37276261200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cheuk Yiu Ip;Varshney, A.;JaJa, J.",
                "filename": "ip_vis_12",
                "Citations": "5613460;5290763;809932;1532795;1250370;5613476;4658153;6064952;6064956;4015448;6064936;4376207;5290751;4015460"
            }
        },
        {
            "name": "Yoon, S.-E.",
            "value": 17,
            "numPapers": 17,
            "cluster": "7",
            "index": 605,
            "weight": 2,
            "x": 266.8013109564698,
            "y": 285.5468965296857,
            "px": -19.953414715940173,
            "py": 173.57861576712878,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Mesh Layouts for Block-Based Caches",
                "PaperDOI": "10.1109/TVCG.2006.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.162",
                "firstage": "1213",
                "Lastage": "1220",
                "IEEEXPLOREArticleNumber": "4015484",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy",
                "AuthorNames": "Yoon, S.-E.;Lindstrom, P.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;",
                "AuthorIDs": ";37269320000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yoon, S.-E.;Lindstrom, P.",
                "filename": "yoon_vis_06",
                "Citations": "1372189;1250408;964533;568125;1532800;1183794"
            }
        },
        {
            "name": "Woodring, J.",
            "value": 74,
            "numPapers": 26,
            "cluster": "0",
            "index": 606,
            "weight": 1,
            "x": 827.8095798548641,
            "y": 597.927857986741,
            "px": 816.1080837792699,
            "py": 547.7846039808221,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Information-Aware Framework for Exploring Multivariate Data Sets",
                "PaperDOI": "10.1109/TVCG.2013.133",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.133",
                "firstage": "2683",
                "Lastage": "2692",
                "IEEEXPLOREArticleNumber": "6634187",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.",
                "AuthorNames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "FirstAuthorAffiliation": "Gravity Group, Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "filename": "biswas_vis_13",
                "Citations": "5613460;5290764;146402;5613461;4015449;4658163;5613439;1382895;4658188;4658174;4389000;6064997;485139;1532833;5613459;663875;1183785"
            }
        },
        {
            "name": "Gao, J.",
            "value": 35,
            "numPapers": 34,
            "cluster": "5",
            "index": 607,
            "weight": 6,
            "x": 214.51762835286576,
            "y": 241.79545156735134,
            "px": 211.8652875242794,
            "py": 248.51375696700578,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Distributed data management for large volume visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532794",
                "firstage": "183",
                "Lastage": "189",
                "IEEEXPLOREArticleNumber": "1532794",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an \"enhanced time-space partitioning\" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.",
                "AuthorNames": "Gao, J.;Huang, J.;Johnson, C.R.;Atchley, S.",
                "FirstAuthorAffiliation": "Oak Ridge Nat. Lab., TN, USA|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gao, J.;Huang, J.;Johnson, C.R.;Atchley, S.",
                "filename": "gao_vis_05",
                "Citations": "1183758;1183757;809910;745300;1372191;1372192;809879"
            }
        },
        {
            "name": "Shareef, N.",
            "value": 29,
            "numPapers": 3,
            "cluster": "5",
            "index": 608,
            "weight": 1,
            "x": -867.5971184541821,
            "y": -894.9093928423147,
            "px": -1489.8294934897747,
            "py": -1639.8911458005425,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "FastSplats: optimized splatting on rectilinear grids",
                "PaperDOI": "10.1109/VISUAL.2000.885698",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885698",
                "firstage": "219",
                "Lastage": "226",
                "IEEEXPLOREArticleNumber": "885698",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Splatting is widely applied in many areas, including volume, point-based and image-based rendering. Improvements to splatting, such as eliminating popping and color bleeding, occasion-based acceleration, post-rendering classification and shading, have all been recently accomplished. These improvements share a common need for efficient frame-buffer accesses. We present an optimized software splatting package, using a newly designed primitive, called FastSplat, to scan-convert footprints. Our approach does not use texture mapping hardware, but supports the whole pipeline in memory. In such an integrated pipeline, we are then able to study the optimization strategies and address image quality issues. While this research is meant for a study of the inherent trade-off of splatting, our renderer, purely in software, achieves 3- to 5-fold speedups over a top-end texture hardware implementation (for opaque data sets). We further propose a method of efficient occlusion culling using a summed area table of opacity. 3D solid texturing and bump mapping capabilities are demonstrated to show the flexibility of such an integrated rendering pipeline. A detailed numerical error analysis, in addition to the performance and storage issues, is also presented. Our approach requires low storage and uses simple operations. Thus, it is easily implementable in hardware.",
                "AuthorNames": "Huang, Jian;Mueller, K.;Shareef, N.;Crawfis, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": "37367805100;37273119700;37355552900;37284273900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Huang, J.;Mueller, K.;Shareef, N.;Crawfis, R.",
                "filename": "huang_vis_00",
                "Citations": "809909;398877;809872"
            }
        },
        {
            "name": "Crawfis, R.",
            "value": 339,
            "numPapers": 65,
            "cluster": "5",
            "index": 609,
            "weight": 21,
            "x": 141.20112721346806,
            "y": 382.79858987059066,
            "px": 96.52776703761067,
            "py": 383.2483772034906,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Volumetric shadows using splatting",
                "PaperDOI": "10.1109/VISUAL.2002.1183761",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183761",
                "firstage": "85",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "1183761",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes an efficient algorithm to model the light attenuation due to a participating media with low albedo. The light attenuation is modeled using splatting volume renderer for both the viewer and the light source. During the rendering, a 2D shadow buffer attenuates the light for each pixel. When the contribution of a footprint is added to the image buffer, as seen from the eye, we add the contribution to the shadow buffer, as seen from the light source. We have generated shadows for point lights and parallel lights using this algorithm. The shadow algorithm has been extended to deal with multiple light sources and projective textured lights.",
                "AuthorNames": "Zhang, C.;Crawfis, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;",
                "AuthorIDs": "37274216600;37284273900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zhang, C.;Crawfis, R.",
                "filename": "zhang3-1_vis_02",
                "Citations": "745309;809909;885698;1183764"
            }
        },
        {
            "name": "Wang, X.",
            "value": 53,
            "numPapers": 6,
            "cluster": "6",
            "index": 610,
            "weight": 1,
            "x": -588.4864051872971,
            "y": 1601.181347738146,
            "px": -1395.2284475006747,
            "py": 2715.769727614326,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "Volume tracking",
                "PaperDOI": "10.1109/VISUAL.1996.567807",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567807",
                "firstage": "157",
                "Lastage": "164",
                "IEEEXPLOREArticleNumber": "567807",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "3D time varying datasets are difficult to visualize and analyze because of the immense amount of data involved. This is especially true when the datasets are turbulent with many evolving amorphous regions, as it is difficult to observe patterns and follow regions of interest. We present our volume based feature tracking algorithm and discuss how it can be used to help visualize and analyze large time varying datasets. We also address efficiency issues in dealing with massive time varying datasets.",
                "AuthorNames": "Silver, D.;Wang, X.",
                "FirstAuthorAffiliation": "Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;",
                "AuthorIDs": "37274132700;37367862600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Silver, D.;Wang, X.",
                "filename": "silver_vis_96",
                "Citations": "485141;480789"
            }
        },
        {
            "name": "Jiang, M.",
            "value": 40,
            "numPapers": 10,
            "cluster": "6",
            "index": 611,
            "weight": 2,
            "x": 514.2444328740013,
            "y": 31.0704479919416,
            "px": 229.75793413266334,
            "py": 598.7203707228367,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Vortex Visualization for Practical Engineering Applications",
                "PaperDOI": "10.1109/TVCG.2006.201",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.201",
                "firstage": "957",
                "Lastage": "964",
                "IEEEXPLOREArticleNumber": "4015452",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability",
                "AuthorNames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Raghu Machiraju",
                "FirstAuthorAffiliation": "Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;",
                "AuthorIDs": ";37826582200;;37269516700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.",
                "filename": "jankunke_vis_06",
                "Citations": "663894;1183789;1532830;745296;745288;809896"
            }
        },
        {
            "name": "Fanea, E.",
            "value": 14,
            "numPapers": 13,
            "cluster": "2",
            "index": 612,
            "weight": 2,
            "x": -26.066261711435388,
            "y": -110.92335365759139,
            "px": 747.1987215818274,
            "py": 351.884813979899,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "An interactive 3D integration of parallel coordinates and star glyphs",
                "PaperDOI": "10.1109/INFVIS.2005.1532141",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532141",
                "firstage": "149",
                "Lastage": "156",
                "IEEEXPLOREArticleNumber": "1532141",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Parallel coordinates are a powerful method for visualizing multidimensional data but, when applied to large data sets, they become cluttered and difficult to read. Star glyphs, on the other hand, can be used to display either the attributes of a data item or the values across all items for a single attribute. Star glyphs may readily provide a quick impression; however, since the full data set require multiple glyphs, overall readings are more difficult. We present parallel glyphs, an interactive integration of the visual representations of parallel coordinates and star glyphs that utilizes the advantages of both representations to offset the disadvantages they have separately. We discuss the role of uniform and stepped colour scales in the visual comparison of non-adjacent items and star glyphs. Parallel glyphs provide capabilities for focus-in-context exploration using two types of lenses and interactions specific to the 3D space.",
                "AuthorNames": "Fanea, E.;Carpendale, S.;Isenberg, T.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;",
                "AuthorIDs": "37550785900;37285000100;37297057400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Fanea, E.;Carpendale, S.;Isenberg, T.",
                "filename": "fanea_infovis_05",
                "Citations": "485139;1249024;1249008;1173157;1382893;1249015;1382895;1382894;809866;1173151;346302;663866;146402"
            }
        },
        {
            "name": "Telea, A.",
            "value": 124,
            "numPapers": 40,
            "cluster": "6",
            "index": 613,
            "weight": 1,
            "x": 531.9802444817198,
            "y": -146.10855457682703,
            "px": 602.924276493808,
            "py": -356.6956302394198,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Decision Exploration Lab: A Visual Analytics Solution for Decision Management",
                "PaperDOI": "10.1109/TVCG.2013.146",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.146",
                "firstage": "1972",
                "Lastage": "1981",
                "IEEEXPLOREArticleNumber": "6634184",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.",
                "AuthorNames": "Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.",
                "FirstAuthorAffiliation": "IBM France Center for Adv. Studies, Univ. of Groningen, Groningen, France|c|;;;",
                "AuthorIDs": ";;;",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.",
                "filename": "broeksema_vast_13",
                "Citations": "175815;6102463;5652398;4677361;4677363;6064996;6102457"
            }
        },
        {
            "name": "Weinstein, D.",
            "value": 125,
            "numPapers": 12,
            "cluster": "6",
            "index": 614,
            "weight": 2,
            "x": -52.18101727487833,
            "y": -618.8672362086821,
            "px": 587.0576044937634,
            "py": 517.2565985626484,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Hue-balls and lit-tensors for direct volume rendering of diffusion tensor fields",
                "PaperDOI": "10.1109/VISUAL.1999.809886",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809886",
                "firstage": "183",
                "Lastage": "524",
                "IEEEXPLOREArticleNumber": "809886",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "With the development of magnetic resonance imaging techniques for acquiring diffusion tensor data from biological tissue, visualization of tensor data has become a new research focus. The diffusion tensor describes the directional dependence of water molecules' diffusion and can be represented by a three-by-three symmetric matrix. Visualization of second-order tensor fields is difficult because the data values have many degrees of freedom. Existing visualization techniques are best at portraying the tensor's properties over a two-dimensional field, or over a small subset of locations within a three-dimensional field. A means of visualizing the global structure in measured diffusion tensor data is needed. We propose the use of direct volume rendering, with novel approaches for the tensors' coloring, lighting, and opacity assignment. Hue-balls use a two-dimensional colormap on the unit sphere to illustrate the tensor's action as a linear operator. Lit-tensors provide a lighting model for tensors which includes as special cases both lit-lines (from streamline vector visualization) and standard Phong surface lighting. Together with an opacity assignment based on a novel two-dimensional barycentric space of anisotropy, these methods are shown to produce informative renderings of measured diffusion tensor data from the human brain.",
                "AuthorNames": "Kindlmann, G.;Weinstein, D.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;",
                "AuthorIDs": "37282742400;37337510400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kindlmann, G.;Weinstein, D.",
                "filename": "kindlman_vis_99",
                "Citations": "146373;235193;567777;745294"
            }
        },
        {
            "name": "Bemis, K.",
            "value": 17,
            "numPapers": 9,
            "cluster": "5",
            "index": 615,
            "weight": 2,
            "x": 106.88227095358785,
            "y": 134.91113191928844,
            "px": -160.65646895836173,
            "py": -11.66124004873789,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Generating realistic images from hydrothermal plume data",
                "PaperDOI": "10.1109/VISUAL.2004.34",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.34",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "1372184",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Most data used in the study of seafloor hydrothermal plumes consists of sonar (acoustic) scans and sensor readings. Visual data captures only a portion of the sonar data range due to the prohibitive cost and physical infeasibility of taking sufficient lighting and video equipment to such extreme depths. However, visual images are available from research dives and from the recent IMAX movie, volcanoes of the deep sea. In this application paper, we apply existing lighting models with forward scattering and light attenuation to the 3D sonar data in order to mimic the visual images available. These generated images are compared to existing visual images. This can help the geoscientists understand the relationship between these different data modalities and elucidate some of the mechanisms used to capture the data.",
                "AuthorNames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "FirstAuthorAffiliation": "Rutgers Univ., NJ, USA|c|;;;;",
                "AuthorIDs": "37282733800;37282733100;37274132700;37410745700;37282733200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "filename": "santilli_vis_04",
                "Citations": "885737;1250383;745347"
            }
        },
        {
            "name": "Rona, P.",
            "value": 17,
            "numPapers": 9,
            "cluster": "5",
            "index": 616,
            "weight": 2,
            "x": 123.44187846298013,
            "y": 318.88917204731644,
            "px": -139.7578836520317,
            "py": -87.66751093976795,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Generating realistic images from hydrothermal plume data",
                "PaperDOI": "10.1109/VISUAL.2004.34",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.34",
                "firstage": "91",
                "Lastage": "98",
                "IEEEXPLOREArticleNumber": "1372184",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Most data used in the study of seafloor hydrothermal plumes consists of sonar (acoustic) scans and sensor readings. Visual data captures only a portion of the sonar data range due to the prohibitive cost and physical infeasibility of taking sufficient lighting and video equipment to such extreme depths. However, visual images are available from research dives and from the recent IMAX movie, volcanoes of the deep sea. In this application paper, we apply existing lighting models with forward scattering and light attenuation to the 3D sonar data in order to mimic the visual images available. These generated images are compared to existing visual images. This can help the geoscientists understand the relationship between these different data modalities and elucidate some of the mechanisms used to capture the data.",
                "AuthorNames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "FirstAuthorAffiliation": "Rutgers Univ., NJ, USA|c|;;;;",
                "AuthorIDs": "37282733800;37282733100;37274132700;37410745700;37282733200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "filename": "santilli_vis_04",
                "Citations": "885737;1250383;745347"
            }
        },
        {
            "name": "Stegmaier, S.",
            "value": 28,
            "numPapers": 21,
            "cluster": "5",
            "index": 617,
            "weight": 1,
            "x": 119.57670918029181,
            "y": -359.91053978379546,
            "px": 211.3746181910417,
            "py": -773.3451469945558,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Opening the can of worms: an exploration tool for vortical flows",
                "PaperDOI": "10.1109/VISUAL.2005.1532830",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532830",
                "firstage": "463",
                "Lastage": "470",
                "IEEEXPLOREArticleNumber": "1532830",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the λ2 method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.",
                "AuthorNames": "Stegmaier, S.;Rist, U.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37267809900;37397347800;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Stegmaier, S.;Rist, U.;Ertl, T.",
                "filename": "stegmaie_vis_05",
                "Citations": "146359;745297;346327;1372197;745288;745296"
            }
        },
        {
            "name": "Brannon, R.",
            "value": 4,
            "numPapers": 18,
            "cluster": "6",
            "index": 618,
            "weight": 2,
            "x": 783.0362500594154,
            "y": 505.9986347062655,
            "px": 679.5267450585172,
            "py": 402.443288905951,
            "node": {
                "Conference": "SciVis",
                "Year": "2005",
                "PaperTitle": "Exploring 2D tensor fields using stress nets",
                "PaperDOI": "10.1109/VISUAL.2005.1532771",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532771",
                "firstage": "11",
                "Lastage": "18",
                "IEEEXPLOREArticleNumber": "1532771",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this article we describe stress nets, a technique for exploring 2D tensor fields. Our method allows a user to examine simultaneously the tensors' eigenvectors (both major and minor) as well as scalar-valued tensor invariants. By avoiding noise-advection techniques, we are able to display both principal directions of the tensor field as well as the derived scalars without cluttering the display. We present a CPU-only implementation of stress nets as well as a hybrid CPU/GPU approach and discuss the relative strengths and weaknesses of each. Stress nets have been used as part of an investigation into crack propagation. They were used to display the directions of maximum shear in a slab of material under tension as well as the magnitude of the shear forces acting on each point. Our methods allowed users to find new features in the data that were not visible on standard plots of tensor invariants. These features disagree with commonly accepted analytical crack propagation solutions and have sparked renewed investigation. Though developed for a materials mechanics problem, our method applies equally well to any 2D tensor field having unique characteristic directions.",
                "AuthorNames": "Wilson, A.;Brannon, R.",
                "FirstAuthorAffiliation": "Sandia Nat. Labs., Albuquerque, NM, USA|c|;",
                "AuthorIDs": "37554778300;37282577100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wilson, A.;Brannon, R.",
                "filename": "wilson_vis_05",
                "Citations": "745316;235193;1183799;346326;809894;885690;398849"
            }
        },
        {
            "name": "Hastreiter, P.",
            "value": 74,
            "numPapers": 36,
            "cluster": "6",
            "index": 619,
            "weight": 1,
            "x": 605.4950401830027,
            "y": -132.89995416383832,
            "px": 711.4782163349375,
            "py": -468.6339580334654,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites",
                "PaperDOI": "10.1109/TVCG.2006.151",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.151",
                "firstage": "1181",
                "Lastage": "1188",
                "IEEEXPLOREArticleNumber": "4015480",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning",
                "AuthorNames": "Merhof, D.;Sonntag, M.;Enders, F.;Nimsky, C.;Hastreiter, P.;Greiner, G.",
                "FirstAuthorAffiliation": "Dept. of Neurosurgery, Univ. Erlangen|c|;;;;;",
                "AuthorIDs": "38266637000;37824387300;37550815500;37550816800;37373297800;37372696400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Merhof, D.;Sonntag, M.;Enders, F.;Nimsky, C.;Hastreiter, P.;Greiner, G.",
                "filename": "merhof_vis_06",
                "Citations": "1532859;1532772;1183799;1532773;1532778;567777;1532779;1372220"
            }
        },
        {
            "name": "Hui Ma",
            "value": 10,
            "numPapers": 5,
            "cluster": "0",
            "index": 620,
            "weight": 2,
            "x": 895.5840122602017,
            "y": 625.4527963210386,
            "px": 903.248173195234,
            "py": 572.1009118133978,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Space walking",
                "PaperDOI": "10.1109/VISUAL.1995.480804",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480804",
                "firstage": "126",
                "Lastage": "133, 445",
                "IEEEXPLOREArticleNumber": "480804",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Proposes an interactive method for exploring topological spaces based on the natural local geometry of the space. Examples of spaces appropriate for this visualization approach occur in abundance in mathematical visualization, surface and volume visualization problems, and scientific applications such as general relativity. Our approach is based on using a controller to choose a direction in which to ÔÇ£walkÔÇØ a manifold along a local geodesic path. The method automatically generates orientation changes that produce a maximal viewable region with each step of the walk. The proposed interaction framework has many natural properties to help the user develop a useful cognitive map of a space and is well-suited to haptic interfaces that may be incorporated into desktop virtual reality systems",
                "AuthorNames": "Hanson, A.J.;Hui Ma",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37333439100;37654495700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hanson, A.J.;Hui Ma",
                "filename": "hanson_vis_95",
                "Citations": "346324;235222"
            }
        },
        {
            "name": "Jobard, B.",
            "value": 73,
            "numPapers": 10,
            "cluster": "5",
            "index": 621,
            "weight": 3,
            "x": 297.72750712168187,
            "y": -334.703820374262,
            "px": 39.08529921810064,
            "py": -135.09412023836018,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated texture advection for unsteady flow visualization",
                "PaperDOI": "10.1109/VISUAL.2000.885689",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885689",
                "firstage": "155",
                "Lastage": "162",
                "IEEEXPLOREArticleNumber": "885689",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.",
                "AuthorNames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;",
                "AuthorIDs": "37267249300;37324424400;37324426600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "filename": "jobard_vis_00",
                "Citations": "480817;745324"
            }
        },
        {
            "name": "Hussaini, M.Y.",
            "value": 46,
            "numPapers": 6,
            "cluster": "5",
            "index": 622,
            "weight": 1,
            "x": -667.6801818928682,
            "y": -491.255742988134,
            "px": -851.1338823669669,
            "py": -797.8787802639903,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated texture advection for unsteady flow visualization",
                "PaperDOI": "10.1109/VISUAL.2000.885689",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885689",
                "firstage": "155",
                "Lastage": "162",
                "IEEEXPLOREArticleNumber": "885689",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.",
                "AuthorNames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;",
                "AuthorIDs": "37267249300;37324424400;37324426600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "filename": "jobard_vis_00",
                "Citations": "480817;745324"
            }
        },
        {
            "name": "Rottger, S.",
            "value": 80,
            "numPapers": 17,
            "cluster": "5",
            "index": 623,
            "weight": 1,
            "x": 173.04309821303164,
            "y": 373.90827031271033,
            "px": 278.570995568668,
            "py": 525.9107739258462,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated volume and isosurface rendering based on cell-projection",
                "PaperDOI": "10.1109/VISUAL.2000.885683",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885683",
                "firstage": "109",
                "Lastage": "116",
                "IEEEXPLOREArticleNumber": "885683",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.",
                "AuthorNames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37357145300;37284293000;37268023800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "filename": "roettger_vis_00",
                "Citations": "398846;346320;809887;346308;885688;346306;663853;809878;568127;480806;745300;568121;745713"
            }
        },
        {
            "name": "Kao, D.",
            "value": 106,
            "numPapers": 26,
            "cluster": "6",
            "index": 624,
            "weight": 1,
            "x": -52.967190727072094,
            "y": 259.3766514723353,
            "px": -482.40266984163975,
            "py": 175.29290164687632,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "UFLIC: a line integral convolution algorithm for visualizing unsteady flows",
                "PaperDOI": "10.1109/VISUAL.1997.663898",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663898",
                "firstage": "317",
                "Lastage": "322",
                "IEEEXPLOREArticleNumber": "663898",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper presents an algorithm, UFLIC (Unsteady Flow LIC), to visualize vector data in unsteady flow fields. Using line integral convolution (LIC) as the underlying method, a new convolution algorithm is proposed that can effectively trace the flow's global features over time. The new algorithm consists of a time-accurate value depositing scheme and a successive feedforward method. The value depositing scheme accurately models the flow advection, and the successive feedforward method maintains the coherence between animation frames. The new algorithm can produce time-accurate, highly coherent flow animations to highlight global features in unsteady flow fields. CFD scientists, for the first time, are able to visualize unsteady surface flows using the algorithm.",
                "AuthorNames": "Shen, H.-W.;Kao, D.L.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;",
                "AuthorIDs": "37366741500;37339406400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shen, H.-W.;Kao, D.",
                "filename": "shen_vis_97",
                "Citations": "480817;398848;567784"
            }
        },
        {
            "name": "Ye Zhao",
            "value": 46,
            "numPapers": 39,
            "cluster": "5",
            "index": 625,
            "weight": 2,
            "x": 226.94089556105757,
            "y": 224.25797250744714,
            "px": 293.21849207222084,
            "py": -101.1401135345091,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "SAVE: Sensor anomaly visualization engine",
                "PaperDOI": "10.1109/VAST.2011.6102458",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102458",
                "firstage": "201",
                "Lastage": "210",
                "IEEEXPLOREArticleNumber": "6102458",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.",
                "AuthorNames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "FirstAuthorAffiliation": "IBM Res., Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37543450800;37398853200;38240137400;37298955400;37588016000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Shi, L.;Qi Liao;Yuan He;Rui Li;Striegel, A.;Zhong Su",
                "filename": "shi_vast_11",
                "Citations": "5290694;5333880;1532126;1382886;5652910"
            }
        },
        {
            "name": "Wei, X.",
            "value": 33,
            "numPapers": 6,
            "cluster": "5",
            "index": 626,
            "weight": 2,
            "x": 417.98609469429573,
            "y": 86.2549895331695,
            "px": 297.5986120869543,
            "py": -121.23256046869962,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Case study: visualization of particle track data",
                "PaperDOI": "10.1109/VISUAL.2001.964552",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964552",
                "firstage": "465",
                "Lastage": "468",
                "IEEEXPLOREArticleNumber": "964552",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The Relativistic Heavy Ion Collider (RHIC) experiment at the Brookhaven National Lab is designed to study how the universe came into being. It is believed that after the Big Bang, the universe expanded and cooled, consisting of a soup of quarks, gluons, electrons and neutrinos. As the temperature lowered, electrons combined with protons and formed neutral atoms. Later, clouds of atoms contracted into stars. In this paper, we describe how techniques of volume rendering and information visualization are used to visualize the large particle track data set generated from this high energy physics experiment. The system, called TrackVis, is based on our earlier work of VolVis - Volume Visualization software. Example images of real particle collision data are shown, which are helpful to physicists in investigating the behavior of strongly interacting matter at high energy density.",
                "AuthorNames": "Wei, X.;Kaufman, A.E.;Hallman, T.J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "37279025800;37268052800;37376928400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wei, X.;Kaufman, A.;Hallman, T.J.",
                "filename": "wei_vis_01",
                "Citations": "636786;559214;346340"
            }
        },
        {
            "name": "van de Wetering, H.",
            "value": 106,
            "numPapers": 12,
            "cluster": "6",
            "index": 627,
            "weight": 1,
            "x": 360.3767423026193,
            "y": -316.76112002575985,
            "px": 307.4989733638116,
            "py": -688.4416905058266,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Composite Density Maps for Multivariate Trajectories",
                "PaperDOI": "10.1109/TVCG.2011.181",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.181",
                "firstage": "2518",
                "Lastage": "2527",
                "IEEEXPLOREArticleNumber": "6065019",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.",
                "AuthorNames": "Scheepens, R.;Willems, N.;van de Wetering, H.;Andrienko, G.;Andrienko, N.;van Wijk, J.J.",
                "FirstAuthorAffiliation": "Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;",
                "AuthorIDs": "37846960800;37846959300;37294473300;37283047100;37283047700;37267249200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Scheepens, R.;Willems, N.;van de Wetering, H.;Andrienko, G.;Andrienko, N.;van Wijk, J.J.",
                "filename": "scheepens_infovis_11",
                "Citations": "4015439;4677356;4376138;5652478;4388992;5652467;5332593"
            }
        },
        {
            "name": "Berchtold, S.",
            "value": 94,
            "numPapers": 3,
            "cluster": "2",
            "index": 628,
            "weight": 2,
            "x": -195.42065034579122,
            "y": -51.4732472976103,
            "px": 723.7804837798744,
            "py": 359.180287565743,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "firstage": "52",
                "Lastage": "60, 153",
                "IEEEXPLOREArticleNumber": "729568",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "filename": "ankerst_infovis_98",
                "Citations": "146402;346302;485140"
            }
        },
        {
            "name": "Ying-Huey Fua",
            "value": 118,
            "numPapers": 16,
            "cluster": "2",
            "index": 629,
            "weight": 3,
            "x": -85.91698316252808,
            "y": -7.340902565765369,
            "px": 258.5528420483406,
            "py": 155.40229177791497,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Hierarchical parallel coordinates for exploration of large datasets",
                "PaperDOI": "10.1109/VISUAL.1999.809866",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809866",
                "firstage": "43",
                "Lastage": "508",
                "IEEEXPLOREArticleNumber": "809866",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Our ability to accumulate large, complex (multivariate) data sets has far exceeded our ability to effectively process them in searching for patterns, anomalies and other interesting features. Conventional multivariate visualization techniques generally do not scale well with respect to the size of the data set. The focus of this paper is on the interactive visualization of large multivariate data sets based on a number of novel extensions to the parallel coordinates display technique. We develop a multi-resolution view of the data via hierarchical clustering, and use a variation of parallel coordinates to convey aggregation information for the resulting clusters. Users can then navigate the resulting structure until the desired focus region and level of detail is reached, using our suite of navigational and filtering tools. We describe the design and implementation of our hierarchical parallel coordinates system which is based on extending the XmdvTool system. Lastly, we show examples of the tools and techniques applied to large (hundreds of thousands of records) multivariate data sets.",
                "AuthorNames": "Ying-Huey Fua;Ward, M.O.;Rundensteiner, E.A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;",
                "AuthorIDs": "37445066400;37268441700;37279217900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ying-Huey Fua;Ward, M.O.;Rundensteiner, E.A.",
                "filename": "fua_vis_99",
                "Citations": "346302;801858;567800;485140;146386;146402;729557;485139"
            }
        },
        {
            "name": "Preusser, T.",
            "value": 17,
            "numPapers": 17,
            "cluster": "6",
            "index": 630,
            "weight": 1,
            "x": 860.2101075272077,
            "y": -531.4874046258859,
            "px": 1236.0767599188782,
            "py": -1127.5013271221997,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Anisotropic nonlinear diffusion in flow visualization",
                "PaperDOI": "10.1109/VISUAL.1999.809904",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809904",
                "firstage": "325",
                "Lastage": "539",
                "IEEEXPLOREArticleNumber": "809904",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.",
                "AuthorNames": "Preusser, T.;Rumpf, M.",
                "FirstAuthorAffiliation": "Inst. fur Angewandte Math., Bonn Univ., Germany|c|;",
                "AuthorIDs": "37282573000;37268036500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Preusser, T.;Rumpf, M.",
                "filename": "preusser_vis_99",
                "Citations": "398875;480817;346312;663912;567784;663898"
            }
        },
        {
            "name": "Rumpf, M.",
            "value": 24,
            "numPapers": 18,
            "cluster": "6",
            "index": 631,
            "weight": 1,
            "x": 385.7361596709259,
            "y": -298.1948508592542,
            "px": 349.4808254815753,
            "py": -652.8732548944679,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Anisotropic nonlinear diffusion in flow visualization",
                "PaperDOI": "10.1109/VISUAL.1999.809904",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809904",
                "firstage": "325",
                "Lastage": "539",
                "IEEEXPLOREArticleNumber": "809904",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.",
                "AuthorNames": "Preusser, T.;Rumpf, M.",
                "FirstAuthorAffiliation": "Inst. fur Angewandte Math., Bonn Univ., Germany|c|;",
                "AuthorIDs": "37282573000;37268036500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Preusser, T.;Rumpf, M.",
                "filename": "preusser_vis_99",
                "Citations": "398875;480817;346312;663912;567784;663898"
            }
        },
        {
            "name": "Liu Ren",
            "value": 6,
            "numPapers": 9,
            "cluster": "5",
            "index": 632,
            "weight": 2,
            "x": 669.5247088224313,
            "y": 471.95948183389083,
            "px": -106.11834843678577,
            "py": 200.93126550975393,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Hardware-accelerated adaptive EWA volume splatting",
                "PaperDOI": "10.1109/VISUAL.2004.38",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.38",
                "firstage": "67",
                "Lastage": "74",
                "IEEEXPLOREArticleNumber": "1372181",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a hardware-accelerated adaptive EWA (elliptical weighted average) volume splatting algorithm. EWA splatting combines a Gaussian reconstruction kernel with a low-pass image filter for high image quality without aliasing artifacts or excessive blurring. We introduce a novel adaptive filtering scheme to reduce the computational cost of EWA splatting. We show how this algorithm can be efficiently implemented on modern graphics processing units (GPUs). Our implementation includes interactive classification and fast lighting. To accelerate the rendering we store splat geometry and 3D volume data locally in GPU memory. We present results for several rectilinear volume datasets that demonstrate the high image quality and interactive rendering speed of our method.",
                "AuthorNames": "Wei Chen;Liu Ren;Zwicker, M.;Pfister, H.",
                "FirstAuthorAffiliation": "Zhejiang Univ., Hangzhou, China|c|;;;",
                "AuthorIDs": "37279188600;37266117500;37282240200;37275698100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wei Chen;Liu Ren;Zwicker, M.;Pfister, H.",
                "filename": "chen_vis_04",
                "Citations": "398877;663882;1250403;745309;567608;809909;480797;964490;885698"
            }
        },
        {
            "name": "Zwicker, M.",
            "value": 39,
            "numPapers": 14,
            "cluster": "5",
            "index": 633,
            "weight": 3,
            "x": -906.7589063796391,
            "y": 8.797864231597925,
            "px": -562.5269050103582,
            "py": 66.72858804100483,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "EWA volume splatting",
                "PaperDOI": "10.1109/VISUAL.2001.964490",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964490",
                "firstage": "29",
                "Lastage": "36",
                "IEEEXPLOREArticleNumber": "964490",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.",
                "AuthorNames": "Zwicker, M.;Pfister, H.;van Baar, J.;Gross, Markus",
                "FirstAuthorAffiliation": "Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;",
                "AuthorIDs": "37282240200;37275698100;37324479700;37275694700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zwicker, M.;Pfister, H.;van Baar, J.;Gross, M.",
                "filename": "zwicker_vis_01",
                "Citations": "480796;663882;745309;567608;809909"
            }
        },
        {
            "name": "Itoh, T.",
            "value": 26,
            "numPapers": 3,
            "cluster": "5",
            "index": 634,
            "weight": 2,
            "x": 212.0607941067824,
            "y": 449.1137617497289,
            "px": 489.2393526271534,
            "py": 525.7066531583281,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Isosurface generation by using extrema graphs",
                "PaperDOI": "10.1109/VISUAL.1994.346334",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346334",
                "firstage": "77",
                "Lastage": "83, C7",
                "IEEEXPLOREArticleNumber": "346334",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A high-performance algorithm for generating isosurfaces is presented. In this algorithm, extrema points in a scalar field are first extracted. A graph is then generated in which the extrema points are taken as nodes. Each arc of the graph has a list of IDs of the cells that are intersected by the arc. A boundary cell list ordered according to cells' values is also generated. The graph and the list generated in this pre-process are used as a guide in searching for seed cells. Isosurfaces are generated from seed cells that are found in arcs of the graph. In this process, isosurfaces appear to propagate themselves. The algorithm visits only cells that are intersected by an isosurface and cells whose IDs an included in cell lists. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described show the efficiency of the algorithm",
                "AuthorNames": "Itoh, T.;Koyamada, K.",
                "FirstAuthorAffiliation": "Res. Lab., IBM Japan Ltd., Tokyo, Japan|c|;",
                "AuthorIDs": "37655930100;37284304900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Itoh, T.;Koyamada, K.",
                "filename": "itoh_vis_94",
                "Citations": "235213;175780"
            }
        },
        {
            "name": "Koyamada, K.",
            "value": 28,
            "numPapers": 4,
            "cluster": "5",
            "index": 635,
            "weight": 2,
            "x": 289.5313704344431,
            "y": 361.81296398748793,
            "px": 465.52530638512155,
            "py": 566.883646537414,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Isosurface generation by using extrema graphs",
                "PaperDOI": "10.1109/VISUAL.1994.346334",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346334",
                "firstage": "77",
                "Lastage": "83, C7",
                "IEEEXPLOREArticleNumber": "346334",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A high-performance algorithm for generating isosurfaces is presented. In this algorithm, extrema points in a scalar field are first extracted. A graph is then generated in which the extrema points are taken as nodes. Each arc of the graph has a list of IDs of the cells that are intersected by the arc. A boundary cell list ordered according to cells' values is also generated. The graph and the list generated in this pre-process are used as a guide in searching for seed cells. Isosurfaces are generated from seed cells that are found in arcs of the graph. In this process, isosurfaces appear to propagate themselves. The algorithm visits only cells that are intersected by an isosurface and cells whose IDs an included in cell lists. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described show the efficiency of the algorithm",
                "AuthorNames": "Itoh, T.;Koyamada, K.",
                "FirstAuthorAffiliation": "Res. Lab., IBM Japan Ltd., Tokyo, Japan|c|;",
                "AuthorIDs": "37655930100;37284304900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Itoh, T.;Koyamada, K.",
                "filename": "itoh_vis_94",
                "Citations": "235213;175780"
            }
        },
        {
            "name": "Moran, P.J.",
            "value": 45,
            "numPapers": 32,
            "cluster": "8",
            "index": 636,
            "weight": 3,
            "x": 1259.913664045342,
            "y": 619.5352470109999,
            "px": 1351.509094547846,
            "py": 693.0836458338879,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "Interactive terascale particle visualization",
                "PaperDOI": "10.1109/VISUAL.2004.55",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.55",
                "firstage": "353",
                "Lastage": "360",
                "IEEEXPLOREArticleNumber": "1372217",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.",
                "AuthorNames": "Ellsworth, D.;Green, B.;Moran, P.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;;",
                "AuthorIDs": "37282594500;37273679700;37264891100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ellsworth, D.;Green, B.;Moran, P.J.",
                "filename": "ellswort_vis_04",
                "Citations": "1250375;745299;663888;1250420;346311;745343;480821"
            }
        },
        {
            "name": "Abram, G.",
            "value": 111,
            "numPapers": 18,
            "cluster": "8",
            "index": 637,
            "weight": 3,
            "x": 1636.8053464119082,
            "y": 121.83007871232597,
            "px": 1481.7053234716814,
            "py": 19.463987758039522,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "firstage": "115",
                "Lastage": "123",
                "IEEEXPLOREArticleNumber": "885098",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The “river” flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored “currents” flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "filename": "havre_infovis_00",
                "Citations": "528686;636789;729555"
            }
        },
        {
            "name": "Wan, M.",
            "value": 81,
            "numPapers": 15,
            "cluster": "5",
            "index": 638,
            "weight": 4,
            "x": -147.14060422319048,
            "y": 851.5303679538987,
            "px": 25.508385825490482,
            "py": 952.6689499112501,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Distance-field based skeletons for virtual navigation",
                "PaperDOI": "10.1109/VISUAL.2001.964517",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964517",
                "firstage": "239",
                "Lastage": "246",
                "IEEEXPLOREArticleNumber": "964517",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.",
                "AuthorNames": "Wan, M.;Dachille, F.;Kaufman, A.",
                "FirstAuthorAffiliation": "Boeing Co., Seattle, WA, USA|c|;;",
                "AuthorIDs": "37362958300;37374524900;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wan, M.;Dachille, F.;Kaufman, A.",
                "filename": "wan_vis_01",
                "Citations": "663915;885675"
            }
        },
        {
            "name": "Zhengrong Liang",
            "value": 33,
            "numPapers": 5,
            "cluster": "5",
            "index": 639,
            "weight": 2,
            "x": 624.494658182041,
            "y": 615.5900479012172,
            "px": 500.975009254903,
            "py": 922.4016128115763,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Volume rendering based interactive navigation within the human colon",
                "PaperDOI": "10.1109/VISUAL.1999.809914",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809914",
                "firstage": "397",
                "Lastage": "549",
                "IEEEXPLOREArticleNumber": "809914",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an interactive navigation system for virtual colonoscopy, which is based solely on high performance volume rendering. Previous colonic navigation systems have employed either a surface rendering or a Z-buffer-assisted volume rendering method that depends on the surface rendering results. Our method is a fast direct volume rendering technique that exploits distance information stored in the potential field of the camera control model, and is parallelized on a multiprocessor. Experiments have been conducted on both a simulated pipe and patients' data sets acquired with a CT scanner.",
                "AuthorNames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;",
                "AuthorIDs": "37362958300;37446853000;37268052800;37273115400;37354296000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "filename": "wan2_vis_99",
                "Citations": "809911;663915;745713;398852"
            }
        },
        {
            "name": "Wax, M.",
            "value": 33,
            "numPapers": 5,
            "cluster": "5",
            "index": 640,
            "weight": 2,
            "x": 661.5469172476954,
            "y": 587.1600827452469,
            "px": 458.4017919221003,
            "py": 930.0187477741529,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "Volume rendering based interactive navigation within the human colon",
                "PaperDOI": "10.1109/VISUAL.1999.809914",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809914",
                "firstage": "397",
                "Lastage": "549",
                "IEEEXPLOREArticleNumber": "809914",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an interactive navigation system for virtual colonoscopy, which is based solely on high performance volume rendering. Previous colonic navigation systems have employed either a surface rendering or a Z-buffer-assisted volume rendering method that depends on the surface rendering results. Our method is a fast direct volume rendering technique that exploits distance information stored in the potential field of the camera control model, and is parallelized on a multiprocessor. Experiments have been conducted on both a simulated pipe and patients' data sets acquired with a CT scanner.",
                "AuthorNames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;",
                "AuthorIDs": "37362958300;37446853000;37268052800;37273115400;37354296000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "filename": "wan2_vis_99",
                "Citations": "809911;663915;745713;398852"
            }
        },
        {
            "name": "El-Sana, J.",
            "value": 41,
            "numPapers": 20,
            "cluster": "7",
            "index": 641,
            "weight": 7,
            "x": 63.28386700080742,
            "y": 993.1468164890287,
            "px": 52.335736507938286,
            "py": 780.7678580435717,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Optimized view-dependent rendering for large polygonal datasets",
                "PaperDOI": "10.1109/VISUAL.2002.1183760",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183760",
                "firstage": "77",
                "Lastage": "84",
                "IEEEXPLOREArticleNumber": "1183760",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.",
                "AuthorNames": "El-Sana, J.;Bachmat, E.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel|c|;",
                "AuthorIDs": "37393584400;37698248900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "El-Sana, J.;Bachmat, E.",
                "filename": "elsana_vis_02",
                "Citations": "809877;663860;885724;745283;480805"
            }
        },
        {
            "name": "Salomon, B.",
            "value": 15,
            "numPapers": 11,
            "cluster": "7",
            "index": 642,
            "weight": 1,
            "x": -429.78631463415877,
            "y": 44.31226245786545,
            "px": -836.4742926852222,
            "py": 30.197355660535052,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Interactive view-dependent rendering with conservative occlusion culling in complex environments",
                "PaperDOI": "10.1109/VISUAL.2003.1250368",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250368",
                "firstage": "163",
                "Lastage": "170",
                "IEEEXPLOREArticleNumber": "1250368",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.",
                "AuthorNames": "Yoon, S.-E.;Salomon, B.;Manocha, D.",
                "FirstAuthorAffiliation": "North Carolina Univ., Chapel Hill, NC, USA|c|;;",
                "AuthorIDs": "37279394100;37271825900;37267825600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Yoon, S.-E.;Salomon, B.;Manocha, D.",
                "filename": "yoon_vis_03",
                "Citations": "1183760;964534;1183796"
            }
        },
        {
            "name": "Zhang, C.",
            "value": 6,
            "numPapers": 18,
            "cluster": "5",
            "index": 643,
            "weight": 2,
            "x": 3839.981395557481,
            "y": -524.8064524870543,
            "px": 77.12399384481549,
            "py": 174.1041629339987,
            "node": {
                "Conference": "SciVis",
                "Year": "2002",
                "PaperTitle": "Volumetric shadows using splatting",
                "PaperDOI": "10.1109/VISUAL.2002.1183761",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183761",
                "firstage": "85",
                "Lastage": "92",
                "IEEEXPLOREArticleNumber": "1183761",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes an efficient algorithm to model the light attenuation due to a participating media with low albedo. The light attenuation is modeled using splatting volume renderer for both the viewer and the light source. During the rendering, a 2D shadow buffer attenuates the light for each pixel. When the contribution of a footprint is added to the image buffer, as seen from the eye, we add the contribution to the shadow buffer, as seen from the light source. We have generated shadows for point lights and parallel lights using this algorithm. The shadow algorithm has been extended to deal with multiple light sources and projective textured lights.",
                "AuthorNames": "Zhang, C.;Crawfis, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;",
                "AuthorIDs": "37274216600;37284273900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zhang, C.;Crawfis, R.",
                "filename": "zhang3-1_vis_02",
                "Citations": "745309;809909;885698;1183764"
            }
        },
        {
            "name": "Mroz, L.",
            "value": 43,
            "numPapers": 19,
            "cluster": "5",
            "index": 644,
            "weight": 1,
            "x": 76.67892688912816,
            "y": 668.8943062876963,
            "px": -114.89253604264592,
            "py": 770.1731098119878,
            "node": {
                "Conference": "SciVis",
                "Year": "2004",
                "PaperTitle": "STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery",
                "PaperDOI": "10.1109/VISUAL.2004.98",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.98",
                "firstage": "513",
                "Lastage": "520",
                "IEEEXPLOREArticleNumber": "1372237",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Endonasal transsphenoidal pituitary surgery is a minimally invasive endoscopic procedure, applied to remove various kinds of pituitary tumors. To reduce the risk associated with this treatment, the surgeon must be skilled and well-prepared. Virtual endoscopy can be beneficial as a tool for training, preoperative planning and intraoperative support. This work introduces STEPS, a virtual endoscopy system designed to aid surgeons in getting acquainted with the endoscopic view, the handling of instruments, the transsphenoidal approach and challenges associated with the procedure. STEPS also assists experienced surgeons in planning a real endoscopic intervention by getting familiar with the individual patient anatomy, identifying landmarks, planning the approach and deciding upon the ideal target position of the actual surgical activity. Besides interactive visualization using two different first-hit ray casting techniques, the application provides navigation and perception aids and the possibility to simulate the procedure, including haptic feedback and simulation of surgical instruments.",
                "AuthorNames": "Neubauer, A.;Mroz, L.;Wolfsberger, S.;Wegenkittl, R.;Forster, M.-T.;Buhler, K.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "37270727300;37282641800;37282642600;37267822600;37282643000;37267821300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Neubauer, A.;Mroz, L.;Wolfsberger, S.;Wegenkittl, R.;Forster, M.-T.;Buhler, K.",
                "filename": "neubauer_vis_04",
                "Citations": "885732;885702;885673"
            }
        },
        {
            "name": "Kenwright, D.",
            "value": 76,
            "numPapers": 11,
            "cluster": "6",
            "index": 645,
            "weight": 1,
            "x": 1801.22145758392,
            "y": -1902.8552836137342,
            "px": 3041.5955489359903,
            "py": -3823.9149527391196,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "Vortex identification-applications in aerodynamics: a case study",
                "PaperDOI": "10.1109/VISUAL.1997.663910",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663910",
                "firstage": "413",
                "Lastage": "416",
                "IEEEXPLOREArticleNumber": "663910",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An eigenvector method for vortex identification has been applied to recent numerical and experimental studies in external flow aerodynamics. It is shown to be an effective way to extract and visualize features such as vortex cores, spiral vortex breakdowns, vortex bursting, and vortex diffusion. Several problems are reported and illustrated. These include: disjointed line segments, detecting non-vortical flow features, and vortex core displacement. Future research and applications are discussed, such as using vortex cores to guide automatic grid refinement.",
                "AuthorNames": "Kenwright, D.;Haimes, R.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;",
                "AuthorIDs": "37355295400;37282898700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kenwright, D.;Haimes, R.",
                "filename": "kenwrigh_vis_97",
                "Citations": "568137;346327;175773"
            }
        },
        {
            "name": "Kohl, J.A.",
            "value": 9,
            "numPapers": 19,
            "cluster": "5",
            "index": 646,
            "weight": 3,
            "x": 511.0121217642738,
            "y": 394.8654858542555,
            "px": 561.4818470246666,
            "py": 409.6881684112414,
            "node": {
                "Conference": "SciVis",
                "Year": "2003",
                "PaperTitle": "Visibility culling using plenoptic opacity functions for large volume visualization",
                "PaperDOI": "10.1109/VISUAL.2003.1250391",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250391",
                "firstage": "341",
                "Lastage": "348",
                "IEEEXPLOREArticleNumber": "1250391",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visibility culling has the potential to accelerate large data visualization in significant ways. Unfortunately, existing algorithms do not scale well when parallelized, and require full re-computation whenever the opacity transfer function is modified. To address these issues, we have designed a Plenoptic Opacity Function (POF) scheme to encode the view-dependent opacity of a volume block. POFs are computed off-line during a pre-processing stage, only once for each block. We show that using POFs is (i) an efficient, conservative and effective way to encode the opacity variations of a volume block for a range of views, (ii) flexible for re-use by a family of opacity transfer functions without the need for additional off-line processing, and (iii) highly scalable for use in massively parallel implementations. Our results confirm the efficacy of POFs for visibility culling in large-scale parallel volume rendering; we can interactively render the Visible Woman dataset using software ray-casting on 32 processors, with interactive modification of the opacity transfer function on-the-fly.",
                "AuthorNames": "Gao, J.;Huang, J.;Han-Wei Shen;Kohl, J.A.",
                "FirstAuthorAffiliation": "Ohio State Univ., USA|c|;;;",
                "AuthorIDs": "37279695300;37281262900;37279493500;37430506600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gao, J.;Huang, J.;Han-Wei Shen;Kohl, J.A.",
                "filename": "gao_vis_03",
                "Citations": "1183757;1183784;745713;964519;745300;964515;885698"
            }
        },
        {
            "name": "Banks, D.C.",
            "value": 125,
            "numPapers": 25,
            "cluster": "6",
            "index": 647,
            "weight": 1,
            "x": 976.974554136545,
            "y": -457.9380476543205,
            "px": 1503.9792095889493,
            "py": -1104.8529848509545,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "Multi-frequency noise for LIC",
                "PaperDOI": "10.1109/VISUAL.1996.567784",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567784",
                "firstage": "121",
                "Lastage": "126",
                "IEEEXPLOREArticleNumber": "567784",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a way to visualize a flow field using Line Integral Convolution (LIC) with a multi frequency noise texture. A broad range of feature sizes can enhance a user's perception of the magnitudes and direction of the flow. In addition, the multiple scales of feature size help a user clarify the motion of the flow in an animation.",
                "AuthorNames": "Ming-Hoe Kiu;Banks, D.C.",
                "FirstAuthorAffiliation": "Dept. of Electr. Eng., Mississippi State Univ., MS, USA|c|;",
                "AuthorIDs": "37612321600;37356983700",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ming-Hoe Kiu;Banks, D.C.",
                "filename": "kiu_vis_96",
                "Citations": "346313"
            }
        },
        {
            "name": "Singer, B.A.",
            "value": 45,
            "numPapers": 1,
            "cluster": "6",
            "index": 648,
            "weight": 1,
            "x": 332.4245634847882,
            "y": 565.9663664369941,
            "px": 325.0834466303254,
            "py": 701.593429735307,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Vortex tubes in turbulent flows: identification, representation, reconstruction",
                "PaperDOI": "10.1109/VISUAL.1994.346327",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346327",
                "firstage": "132",
                "Lastage": "139, C14",
                "IEEEXPLOREArticleNumber": "346327",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new algorithm for identifying vortices in complex flows is presented. The scheme uses both the vorticity and pressure fields. A skeleton line along the center of a vortex is produced by a two-step predictor-corrector scheme. The technique uses the vector field to move in the direction of the skeleton line and the scalar field to correct the location in the plane perpendicular to the skeleton line. With an economical description of the vortex tube's cross-section, the skeleton compresses the representation of the flow by a factor of 4000 or more. We show how the reconstructed geometry of vortex tubes can be enhanced to help visualize helical motion",
                "AuthorNames": "Banks, D.C.;Singer, B.A.",
                "FirstAuthorAffiliation": "Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;",
                "AuthorIDs": "37356983700;37651784800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Banks, D.C.;Singer, B.A.",
                "filename": "banks_vis_94",
                "Citations": "175773"
            }
        },
        {
            "name": "Garland, M.",
            "value": 88,
            "numPapers": 35,
            "cluster": "7",
            "index": 649,
            "weight": 1,
            "x": 297.1481479594809,
            "y": 1693.6259414247693,
            "px": 335.039607058725,
            "py": 2531.0596473050964,
            "node": {
                "Conference": "SciVis",
                "Year": "2006",
                "PaperTitle": "Interactive Point-Based Rendering of Higher-Order Tetrahedral Data",
                "PaperDOI": "10.1109/TVCG.2006.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.154",
                "firstage": "1229",
                "Lastage": "1236",
                "IEEEXPLOREArticleNumber": "4015486",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates",
                "AuthorNames": "Zhou, Y.;Garland, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Illinois Univ., Urbana, IL|c|;",
                "AuthorIDs": "37273640900;37272036400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Zhou, Y.;Garland, M.",
                "filename": "zhou_vis_06",
                "Citations": "1250406;1532796;1532776;1532809;1250404;1183757;1183771;1372224;1250390;809867;1372181;1250384;885683;1183778;1532808;1250389;480790;1372226;1532801"
            }
        },
        {
            "name": "Shaffer, E.",
            "value": 34,
            "numPapers": 7,
            "cluster": "7",
            "index": 650,
            "weight": 1,
            "x": -517.294184009761,
            "y": 1615.1506996848955,
            "px": -1121.4302537098602,
            "py": 2394.956856508541,
            "node": {
                "Conference": "SciVis",
                "Year": "2001",
                "PaperTitle": "Efficient Adaptive Simplification of Massive Meshes",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=601690&CFID=417306019&CFTOKEN=83091695",
                "firstage": "127",
                "Lastage": "134",
                "IEEEXPLOREArticleNumber": "964541_08",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The growing availability of massive polygonal models, and the inability of most existing visualization tools to work with such data, has created a pressing need for memory efficient methods capable of simplifying very large meshes. In this paper, we present a method for performing adaptive simplification of polygonal meshes that are too large to fit in-core.Our algorithm performs two passes over an input mesh. In the first pass, the model is quantized using a uniform grid, and surface information is accumulated in the form of quadrics and dual quadrics. This sampling is then used to construct a BSP-Tree in which the partitioning planes are determined by the dual quadrics. In the final pass, the original vertices are clustered using the BSP-Tree, yielding an adaptive approximation of the original mesh. The BSP-Tree describes a natural simplification hierarchy, making it possible to generate a progressive transmission and construct level-of-detail representations. In this way, the algorithm provides some of the features associated with more expensive edge contraction methods while maintaining greater computational efficiency. In addition to performing adaptive simplification, our algorithm exhibits output-sensitive memory requirements and allows fine control over the size of the simplified mesh.",
                "AuthorNames": "Shaffer, E.;Garland, M.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "x",
                "Dedupedauthornames": "Shaffer, E.;Garland, M.",
                "filename": "shaffer_vis_01",
                "Citations": "964502;745282;745314"
            }
        },
        {
            "name": "Rogowitz, B.",
            "value": 119,
            "numPapers": 9,
            "cluster": "8",
            "index": 651,
            "weight": 1,
            "x": 221.25178517104817,
            "y": -39.46377604213873,
            "px": -166.52039681938825,
            "py": -322.1996438574443,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Perceptual Organization in User-Generated Graph Layouts",
                "PaperDOI": "10.1109/TVCG.2008.155",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.155",
                "firstage": "1333",
                "Lastage": "1339",
                "IEEEXPLOREArticleNumber": "4658147",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.",
                "AuthorNames": "van Ham, F.;Rogowitz, B.",
                "FirstAuthorAffiliation": "IBM Res., Cambridge|c|;",
                "AuthorIDs": "37882135400;37332114400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "van Ham, F.;Rogowitz, B.",
                "filename": "vanham_infovis_08",
                "Citations": "1382886;4376131"
            }
        },
        {
            "name": "Treinish, L.A.",
            "value": 158,
            "numPapers": 29,
            "cluster": "8",
            "index": 652,
            "weight": 7,
            "x": 1345.6577116058156,
            "y": 491.3827903269702,
            "px": 1363.2404398863716,
            "py": 127.74586241573729,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "A rule-based tool for assisting colormap selection",
                "PaperDOI": "10.1109/VISUAL.1995.480803",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480803",
                "firstage": "118",
                "Lastage": "125, 444",
                "IEEEXPLOREArticleNumber": "480803",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper presents an interactive approach for guiding the user's select of colormaps in visualization. PRAVDAColor, implemented as a module in the IBM Visualization Data Explorer, provides the user a selection of appropriate colormaps given the data type and spatial frequency, the user's task, and properties of the human perceptual system",
                "AuthorNames": "Bergman, L.D.;Rogowitz, B.;Treinish, L.A.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;",
                "AuthorIDs": "37271768100;37332114400;37372175500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Bergman, L.D.;Rogowitz, B.;Treinish, L.A.",
                "filename": "bergman_vis_95",
                "Citations": "480821;398874"
            }
        },
        {
            "name": "Uselton, S.",
            "value": 24,
            "numPapers": 12,
            "cluster": "5",
            "index": 653,
            "weight": 1,
            "x": 853.2331002185207,
            "y": 294.27786326893,
            "px": 1254.42541646072,
            "py": 142.99414785264867,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Interdisciplinary visualization: lessons learned at NCSA",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846",
                "firstage": "457",
                "Lastage": "457",
                "IEEEXPLOREArticleNumber": "",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "",
                "AuthorNames": "Cox, D. C.",
                "FirstAuthorAffiliation": "National Center for Supercomputing Applications",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cox, D. C.",
                "filename": "",
                "Citations": ""
            }
        },
        {
            "name": "Angel, E.",
            "value": 30,
            "numPapers": 5,
            "cluster": "5",
            "index": 654,
            "weight": 1,
            "x": 655.0803222818937,
            "y": 176.55821334590453,
            "px": 777.1170373146283,
            "py": -151.09736095776447,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "Isosurface extraction using particle systems",
                "PaperDOI": "10.1109/VISUAL.1997.663930",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663930",
                "firstage": "495",
                "Lastage": "498",
                "IEEEXPLOREArticleNumber": "663930",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.",
                "AuthorNames": "Crossno, P.;Angel, E.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., New Mexico Univ., Albuquerque, NM, USA|c|;",
                "AuthorIDs": "37282576500;37284249400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Crossno, P.;Angel, E.",
                "filename": "crossno_vis_97",
                "Citations": "398880"
            }
        },
        {
            "name": "Gatti, R.",
            "value": 25,
            "numPapers": 1,
            "cluster": "7",
            "index": 655,
            "weight": 1,
            "x": -849.1484513878396,
            "y": 1305.8742334028436,
            "px": -1587.4443257615694,
            "py": 2160.2978987592014,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Fast multiresolution surface meshing",
                "PaperDOI": "10.1109/VISUAL.1995.480805",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480805",
                "firstage": "135",
                "Lastage": "142, 446",
                "IEEEXPLOREArticleNumber": "480805",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Presents a new method for adaptive surface meshing and triangulation which controls the local level-of-detail of the surface approximation by local spectral estimates. These estimates are determined by a wavelet representation of the surface data. The basic idea is to decompose the initial data set by means of an orthogonal or semi-orthogonal tensor product wavelet transform (WT) and to analyze the resulting coefficients. In surface regions where the partial energy of the resulting coefficients is low, the polygonal approximation of the surface can be performed with larger triangles without losing too much fine-grain detail. However, since the localization of the WT is bound by the Heisenberg principle, the meshing method has to be controlled by the detail signals rather than directly by the coefficients. The dyadic scaling of the WT stimulated us to build a hierarchical meshing algorithm which transforms the initially regular data grid into a quadtree representation by rejection of unimportant mesh vertices. The optimum triangulation of the resulting quadtree cells is carried out by selection from a look-up table. The tree grows recursively, as controlled by the detail signals, which are computed from a modified inverse WT. In order to control the local level-of-detail, we introduce a new class of wavelet space filters acting as ÔÇ£magnifying glassesÔÇØ on the data",
                "AuthorNames": "Gross, M.H.;Gatti, R.;Staadt, O.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;",
                "AuthorIDs": "37275694700;37355330500;37355334600",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gross, M.;Gatti, R.;Staadt, O.",
                "filename": "gross_vis_95",
                "Citations": "346333"
            }
        },
        {
            "name": "Gershon, N.",
            "value": 26,
            "numPapers": 8,
            "cluster": "5",
            "index": 656,
            "weight": 1,
            "x": -302.81296210637646,
            "y": -680.8615871192511,
            "px": -923.3320399946608,
            "py": -1760.0453373629664,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "Visualization of fuzzy data using generalized animation",
                "PaperDOI": "10.1109/VISUAL.1992.235199",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235199",
                "firstage": "268",
                "Lastage": "273",
                "IEEEXPLOREArticleNumber": "235199",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Methods are presented for the visualization of fuzzy data based on the sensitivity of the human visual system to motion and dynamic changes, and the ease of which electronic display devices can change their display. The methods include taking an otherwise static image and displaying in an animation loop either its segmented components or a series of blurred versions of the whole image. This approach was applied to sea-surface temperature data and was found to be effective in showing fuzzy details embedded in the data, and in drawing the viewer's attention. This approach and these methods could play a significant role in the display of browse products for massive data and information systems",
                "AuthorNames": "Gershon, N.D.",
                "FirstAuthorAffiliation": "Mitre Corp., McLean, VA, USA|c|",
                "AuthorIDs": "37352200300",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gershon, N.",
                "filename": "gershon_vis_92",
                "Citations": ""
            }
        },
        {
            "name": "Jurrus, E.",
            "value": 47,
            "numPapers": 11,
            "cluster": "2",
            "index": 657,
            "weight": 1,
            "x": -803.3235485814891,
            "y": 369.1332659570323,
            "px": -1281.9595859394992,
            "py": 598.9250862523814,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "firstage": "105",
                "Lastage": "111",
                "IEEEXPLOREArticleNumber": "885097",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as AÔåÆBÔåÆCÔåÆD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "filename": "wong_infovis_00",
                "Citations": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Beddow, J.",
            "value": 27,
            "numPapers": 1,
            "cluster": "2",
            "index": 658,
            "weight": 1,
            "x": -1107.7180099662614,
            "y": 1341.7428114081172,
            "px": -2623.302590699709,
            "py": 2341.8882373219776,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Shape coding of multidimensional data on a microcomputer display",
                "PaperDOI": "10.1109/VISUAL.1990.146387",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146387",
                "firstage": "238",
                "Lastage": "246, 478",
                "IEEEXPLOREArticleNumber": "146387",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The author presents a simple and flexible method of sharp coding for higher dimensional data sets that allows the database operator or the scientist quick access to promising patterns within and among records or samples. The example used is a 13-parameter set of solar wind, magnetosphere, and ground observation data collected hourly for 21 days in 1976. The software system is a prototype developed to demonstrate the glyph approach to depicting higher-dimensional data sets. The experiment was to depict all parameters simultaneously, to see if any global or local patterns emerged. This experiment proves that much more complex data can be presented for visual pattern extraction than standard methods allow",
                "AuthorNames": "Beddow, J.",
                "FirstAuthorAffiliation": "Microsimulations Res., Minneapolis, MN|c|",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Beddow, J.",
                "filename": "beddow_vis_90",
                "Citations": ""
            }
        },
        {
            "name": "Wilhelms, J.",
            "value": 32,
            "numPapers": 6,
            "cluster": "5",
            "index": 659,
            "weight": 1,
            "x": -614.2821201366344,
            "y": 235.53965465817674,
            "px": -1138.5627731614873,
            "py": 308.6423840745342,
            "node": {
                "Conference": "SciVis",
                "Year": "1993",
                "PaperTitle": "Rapid exploration of curvilinear grids using direct volume rendering (Extended Abstract)",
                "PaperDOI": "10.1109/VISUAL.1993.398853",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398853",
                "firstage": "70",
                "Lastage": "77",
                "IEEEXPLOREArticleNumber": "398853",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Fast techniques for direct volume rendering over curvilinear grids (common to computational fluid dynamics and finite element analysis) are developed. Three new projection methods that use polygon-rendering hardware for speed are presented and compared with each other and with previous methods for tetrahedral grids and rectilinear grids. A simplified algorithm for visibility ordering, based on a combination of breadth-first and depth-first searches, is described. A new multi-pass blending method is described that reduces visual artifacts that are introduced by linear interpolation in hardware where exponential interpolation is needed. Visualization tools that permit rapid data banding and cycling through transfer functions, as well as region restriction, are described",
                "AuthorNames": "Van Gelder, A.;Wilhelms, J.",
                "FirstAuthorAffiliation": "Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37352962400;37828154400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Van Gelder, A.;Wilhelms, J.",
                "filename": "gelder_vis_93",
                "Citations": "235204;235228"
            }
        },
        {
            "name": "Van Gelder, A.",
            "value": 32,
            "numPapers": 6,
            "cluster": "5",
            "index": 660,
            "weight": 1,
            "x": -193.88822433165848,
            "y": 195.02419163753956,
            "px": -296.20587089657994,
            "py": 224.82305796057315,
            "node": {
                "Conference": "SciVis",
                "Year": "1993",
                "PaperTitle": "Rapid exploration of curvilinear grids using direct volume rendering (Extended Abstract)",
                "PaperDOI": "10.1109/VISUAL.1993.398853",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398853",
                "firstage": "70",
                "Lastage": "77",
                "IEEEXPLOREArticleNumber": "398853",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Fast techniques for direct volume rendering over curvilinear grids (common to computational fluid dynamics and finite element analysis) are developed. Three new projection methods that use polygon-rendering hardware for speed are presented and compared with each other and with previous methods for tetrahedral grids and rectilinear grids. A simplified algorithm for visibility ordering, based on a combination of breadth-first and depth-first searches, is described. A new multi-pass blending method is described that reduces visual artifacts that are introduced by linear interpolation in hardware where exponential interpolation is needed. Visualization tools that permit rapid data banding and cycling through transfer functions, as well as region restriction, are described",
                "AuthorNames": "Van Gelder, A.;Wilhelms, J.",
                "FirstAuthorAffiliation": "Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37352962400;37828154400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Van Gelder, A.;Wilhelms, J.",
                "filename": "gelder_vis_93",
                "Citations": "235204;235228"
            }
        },
        {
            "name": "Lichan Hong",
            "value": 80,
            "numPapers": 22,
            "cluster": "5",
            "index": 661,
            "weight": 2,
            "x": 579.3600288638557,
            "y": 330.23090379528827,
            "px": 400.1591571307097,
            "py": 592.9264294774262,
            "node": {
                "Conference": "SciVis",
                "Year": "1998",
                "PaperTitle": "Accelerated ray-casting for curvilinear volumes",
                "PaperDOI": "10.1109/VISUAL.1998.745310",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745310",
                "firstage": "247",
                "Lastage": "253",
                "IEEEXPLOREArticleNumber": "745310",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an efficient and robust ray-casting algorithm for directly rendering a curvilinear volume of arbitrarily-shaped cells. We designed the algorithm to alleviate the consumption of CPU power and memory space. By incorporating the essence of the projection paradigm into the ray-casting process, we have successfully accelerated the ray traversal through the grid and data interpolations at sample points. Our algorithm also overcomes the conventional limitation requiring the cells to be convex. Application of this algorithm to several commonly-used curvilinear data sets has produced a favorable performance when compared with recently reported algorithms.",
                "AuthorNames": "Lichan Hong;Kaufman, A.",
                "FirstAuthorAffiliation": "Lucent Technol., AT&T Bell Labs., Naperville, IL, USA|c|;",
                "AuthorIDs": "37347459100;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lichan Hong;Kaufman, A.",
                "filename": "hong_vis_98",
                "Citations": "398853;235228;567606"
            }
        },
        {
            "name": "Dong, F.",
            "value": 0,
            "numPapers": 7,
            "cluster": "5",
            "index": 662,
            "weight": 1,
            "x": -378.50739531408334,
            "y": -66.23195365295976,
            "px": -625.4781741675554,
            "py": -260.24969836270657,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "An anti-aliasing technique for splatting",
                "PaperDOI": "10.1109/VISUAL.1997.663882",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663882",
                "firstage": "197",
                "Lastage": "204",
                "IEEEXPLOREArticleNumber": "663882",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Splatting is a popular direct volume rendering algorithm. However, the algorithm does not correctly render cases where the volume sampling rate is higher than the image sampling rate (e.g. more than one voxel maps into a pixel). This situation arises with orthographic projections of high-resolution volumes, as well as with perspective projections of volumes of any resolution. The result is potentially severe spatial and temporal aliasing artifacts. Some volume ray-casting algorithms avoid these artifacts by employing reconstruction kernels which vary in width as the rays diverge. Unlike ray-casting algorithms, existing splatting algorithms do not have an equivalent mechanism for avoiding these artifacts. The authors propose such a mechanism, which delivers high-quality splatted images and has the potential for a very efficient hardware implementation.",
                "AuthorNames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "FirstAuthorAffiliation": "Adv. Comput. Center for the Arts & Design, Ohio State Univ., Columbus, OH, USA|c|;;;;;",
                "AuthorIDs": "37295140400;37273119700;38341221100;;37284273900;38335291800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "filename": "swan_vis_97",
                "Citations": "567608;398877;346331;480792;398852"
            }
        },
        {
            "name": "Krokos, M.",
            "value": 0,
            "numPapers": 7,
            "cluster": "5",
            "index": 663,
            "weight": 1,
            "x": -227.70671630634905,
            "y": -379.10936846376626,
            "px": -369.858941133156,
            "py": -845.4436033947982,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "An anti-aliasing technique for splatting",
                "PaperDOI": "10.1109/VISUAL.1997.663882",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663882",
                "firstage": "197",
                "Lastage": "204",
                "IEEEXPLOREArticleNumber": "663882",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Splatting is a popular direct volume rendering algorithm. However, the algorithm does not correctly render cases where the volume sampling rate is higher than the image sampling rate (e.g. more than one voxel maps into a pixel). This situation arises with orthographic projections of high-resolution volumes, as well as with perspective projections of volumes of any resolution. The result is potentially severe spatial and temporal aliasing artifacts. Some volume ray-casting algorithms avoid these artifacts by employing reconstruction kernels which vary in width as the rays diverge. Unlike ray-casting algorithms, existing splatting algorithms do not have an equivalent mechanism for avoiding these artifacts. The authors propose such a mechanism, which delivers high-quality splatted images and has the potential for a very efficient hardware implementation.",
                "AuthorNames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "FirstAuthorAffiliation": "Adv. Comput. Center for the Arts & Design, Ohio State Univ., Columbus, OH, USA|c|;;;;;",
                "AuthorIDs": "37295140400;37273119700;38341221100;;37284273900;38335291800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "filename": "swan_vis_97",
                "Citations": "567608;398877;346331;480792;398852"
            }
        },
        {
            "name": "Taosong He",
            "value": 84,
            "numPapers": 12,
            "cluster": "5",
            "index": 664,
            "weight": 5,
            "x": 521.6185631893266,
            "y": 681.5669451933707,
            "px": 533.5957606352223,
            "py": 689.3264835058153,
            "node": {
                "Conference": "SciVis",
                "Year": "1997",
                "PaperTitle": "Integrated volume compression and visualization",
                "PaperDOI": "10.1109/VISUAL.1997.663900",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663900",
                "firstage": "329",
                "Lastage": "336",
                "IEEEXPLOREArticleNumber": "663900",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volumetric data sets require enormous storage capacity even at moderate resolution levels. The excessive storage demands not only stress the capacity of the underlying storage and communications systems, but also seriously limit the speed of volume rendering due to data movement and manipulation. A novel volumetric data visualization scheme is proposed and implemented in this work that renders 2D images directly from compressed 3D data sets. The novelty of this algorithm is that rendering is performed on the compressed representation of the volumetric data without pre-decompression. As a result, the overheads associated with both data movement and rendering processing are significantly reduced. The proposed algorithm generalizes previously proposed whole-volume frequency-domain rendering schemes by first dividing the 3D data set into subcubes, transforming each subcube to a frequency-domain representation, and applying the Fourier projection theorem to produce the projected 2D images according to given viewing angles. Compared to the whole-volume approach, the subcube-based scheme not only achieves higher compression efficiency by exploiting local coherency, but also improves the quality of resultant rendering images because it approximates the occlusion effect on a subcube by subcube basis.",
                "AuthorNames": "Tzi-cker Chiueh;Chuan-Kai Yang;Taosong He;Pfister, H.;Kaufman, A.",
                "FirstAuthorAffiliation": "Center for Visual Comput., State Univ. of New York, Stony Brook, NY, USA|c|;;;;",
                "AuthorIDs": "37273336700;37615351500;37350343500;37275698100;37268052800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Tzi-cker Chiueh;Chuan-Kai Yang;Taosong He;Pfister, H.;Kaufman, A.",
                "filename": "chiueh_vis_97",
                "Citations": "398845"
            }
        },
        {
            "name": "Wang, S.",
            "value": 73,
            "numPapers": 8,
            "cluster": "5",
            "index": 665,
            "weight": 3,
            "x": 122.99504681422336,
            "y": 306.3806064753274,
            "px": 271.3019854665417,
            "py": 455.8130011162388,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "VolVis: a diversified volume visualization system",
                "PaperDOI": "10.1109/VISUAL.1994.346340",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346340",
                "firstage": "31",
                "Lastage": "38, C3",
                "IEEEXPLOREArticleNumber": "346340",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VolVis is a diversified, easy to use, extensible, high performance, and portable volume visualization system for scientists and engineers as well as for visualization developers and researchers. VolVis accepts as input 3D scalar volumetric data as well as 3D volume-sampled and classical geometric models. Interaction with the data is controlled by a variety of 3D input devices in an input device-independent environment. VolVis output includes navigation preview, static images, and animation sequences. A variety of volume rendering algorithms are supported ranging from fast rough approximations, to compression-domain rendering, to accurate volumetric ray tracing and radiosity, and irregular grid rendering",
                "AuthorNames": "Avila, R.;Taosong He;Lichan Hong;Kaufman, A.;Pfister, H.;Silva, C.;Sobierajski, L.;Wang, S.",
                "FirstAuthorAffiliation": "Howard Hughes Med. Inst., State Univ. of New York, Stony Brook, NY, USA|c|;;;;;;;",
                "AuthorIDs": "37323905300;37350343500;37652123600;37268052800;37275698100;38183059100;37378488600;37351033000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Avila, R.;Taosong He;Lichan Hong;Kaufman, A.;Pfister, H.;Silva, C.T.;Sobierajski, L.;Wang, S.",
                "filename": "avila_vis_94",
                "Citations": "235231;398862;398854;146391"
            }
        },
        {
            "name": "Chi, E.H.",
            "value": 86,
            "numPapers": 16,
            "cluster": "13",
            "index": 666,
            "weight": 2,
            "x": 1156.581368616781,
            "y": 77.39725202397982,
            "px": 1117.880967148755,
            "py": 48.095096208951766,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "A taxonomy of visualization techniques using the data state reference model",
                "PaperDOI": "10.1109/INFVIS.2000.885092",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885092",
                "firstage": "69",
                "Lastage": "75",
                "IEEEXPLOREArticleNumber": "885092",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly",
                "AuthorNames": "Chi, Ed H.",
                "FirstAuthorAffiliation": "Xerox Palo Alto Res. Center, CA, USA|c|",
                "AuthorIDs": "37448030800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chi, E.H.",
                "filename": "chi_infovis_00",
                "Citations": "636761;636792;729560"
            }
        },
        {
            "name": "Riedl, J.",
            "value": 98,
            "numPapers": 17,
            "cluster": "13",
            "index": 667,
            "weight": 7,
            "x": 1097.4402730835948,
            "y": 348.55909408405535,
            "px": 1084.5907716377958,
            "py": 234.47440177807312,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "A spreadsheet approach to information visualization",
                "PaperDOI": "10.1109/INFVIS.1997.636761",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636761",
                "firstage": "17",
                "Lastage": "24",
                "IEEEXPLOREArticleNumber": "636761",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.",
                "AuthorNames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "filename": "chi_infovis_97",
                "Citations": "567796;567746_1;528690;480794;398859"
            }
        },
        {
            "name": "Becker, B.",
            "value": 69,
            "numPapers": 23,
            "cluster": "2",
            "index": 668,
            "weight": 4,
            "x": -143.0211527420742,
            "y": 231.22628994811026,
            "px": -320.453750985102,
            "py": 102.01140957824843,
            "node": {
                "Conference": "SciVis",
                "Year": "1993",
                "PaperTitle": "Flow volumes for interactive vector field visualization",
                "PaperDOI": "10.1109/VISUAL.1993.398846",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398846",
                "firstage": "19",
                "Lastage": "24",
                "IEEEXPLOREArticleNumber": "398846",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Flow volumes are the volumetric equivalent of stream lines. They provide more information about the vector field being visualized than do stream lines or ribbons. Presented is an efficient method for producing flow volumes, composed of transparently rendered tetrahedra, for use in an interactive system. The problems of rendering, subdivision, sorting, composing artifacts, and user interaction are dealt with. Efficiency comes from rendering only the volume of the smoke, and using hardware texturing and compositing",
                "AuthorNames": "Max, N.;Becker, B.;Crawfis, R.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;;",
                "AuthorIDs": "37267387800;37363099200;37284273900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Max, N.;Becker, B.;Crawfis, R.",
                "filename": "max_vis_93",
                "Citations": "235210;235211"
            }
        },
        {
            "name": "Lodha, S.K.",
            "value": 81,
            "numPapers": 19,
            "cluster": "6",
            "index": 669,
            "weight": 2,
            "x": 786.7252257925846,
            "y": 599.2996414093944,
            "px": 822.8038637122428,
            "py": 618.382355092652,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "UFLOW: visualizing uncertainty in fluid flow",
                "PaperDOI": "10.1109/VISUAL.1996.568116",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568116",
                "firstage": "249",
                "Lastage": "254",
                "IEEEXPLOREArticleNumber": "568116",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.",
                "AuthorNames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;;",
                "AuthorIDs": "37298532100;37267352000;38242145300;37351416000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "filename": "lodha2_vis_96",
                "Citations": "235199;568105;485141;346315"
            }
        },
        {
            "name": "Wernert, E.A.",
            "value": 17,
            "numPapers": 4,
            "cluster": "0",
            "index": 670,
            "weight": 1,
            "x": 955.1606488515495,
            "y": 627.283402821708,
            "px": 979.2798344466441,
            "py": 582.7521348451432,
            "node": {
                "Conference": "SciVis",
                "Year": "1999",
                "PaperTitle": "A framework for assisted exploration with collaboration",
                "PaperDOI": "10.1109/VISUAL.1999.809893",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809893",
                "firstage": "241",
                "Lastage": "529",
                "IEEEXPLOREArticleNumber": "809893",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We approach the problem of exploring a virtual space by exploiting positional and camera-model constraints on navigation to provide extra assistance that focuses the user's explorational wanderings on the task objectives. Our specific design incorporates not only task-based constraints on the viewer's location, gaze, and viewing parameters, but also a personal \"glide\" that serves two important functions: keeping the user oriented in the navigation space, and \"pointing\" to interesting subject areas as they are approached. The guide's cues may be ignored by continuing in motion, but if the user stops, the gaze shifts automatically toward whatever the guide was interested in. This design has the serendipitous feature that it automatically incorporates a nested collaborative paradigm simply by allowing any given viewer to be seen as the \"guide\" of one or more viewers following behind; the leading automated guide (we tend to select a guide dog for this avatar) can remind the leading live human guide of interesting sites to point out, while each real human collaborator down the chain has some choices about whether to follow the local leader's hints. We have chosen VRML as our initial development medium primarily because of its portability, and we have implemented a variety of natural modes for leading and collaborating, including ways for collaborators to attach to and detach from a particular leader.",
                "AuthorNames": "Wernert, E.A.;Hanson, A.J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37371964800;37333439100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Wernert, E.A.;Hanson, A.J.",
                "filename": "wernert_vis_99",
                "Citations": "745326;663876"
            }
        },
        {
            "name": "Sheehan, R.E.",
            "value": 68,
            "numPapers": 10,
            "cluster": "6",
            "index": 671,
            "weight": 1,
            "x": 683.3420102392824,
            "y": 713.6653633803815,
            "px": 811.5676040905388,
            "py": 959.8426998199067,
            "node": {
                "Conference": "SciVis",
                "Year": "1996",
                "PaperTitle": "UFLOW: visualizing uncertainty in fluid flow",
                "PaperDOI": "10.1109/VISUAL.1996.568116",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568116",
                "firstage": "249",
                "Lastage": "254",
                "IEEEXPLOREArticleNumber": "568116",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.",
                "AuthorNames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;;",
                "AuthorIDs": "37298532100;37267352000;38242145300;37351416000",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "filename": "lodha2_vis_96",
                "Citations": "235199;568105;485141;346315"
            }
        },
        {
            "name": "Ed Huai-Hsin Chi",
            "value": 74,
            "numPapers": 13,
            "cluster": "13",
            "index": 672,
            "weight": 2,
            "x": 1151.5969604997324,
            "y": 248.18173469040747,
            "px": 1147.6132725044963,
            "py": 254.6756618398707,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "A spreadsheet approach to information visualization",
                "PaperDOI": "10.1109/INFVIS.1997.636761",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636761",
                "firstage": "17",
                "Lastage": "24",
                "IEEEXPLOREArticleNumber": "636761",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.",
                "AuthorNames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "filename": "chi_infovis_97",
                "Citations": "567796;567746_1;528690;480794;398859"
            }
        },
        {
            "name": "Barry, P.",
            "value": 49,
            "numPapers": 9,
            "cluster": "13",
            "index": 673,
            "weight": 2,
            "x": 1131.331404079433,
            "y": 237.2595743367681,
            "px": 1077.0857509675745,
            "py": 192.73613582759504,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "A spreadsheet approach to information visualization",
                "PaperDOI": "10.1109/INFVIS.1997.636761",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636761",
                "firstage": "17",
                "Lastage": "24",
                "IEEEXPLOREArticleNumber": "636761",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.",
                "AuthorNames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "filename": "chi_infovis_97",
                "Citations": "567796;567746_1;528690;480794;398859"
            }
        },
        {
            "name": "Shoop, E.",
            "value": 24,
            "numPapers": 4,
            "cluster": "13",
            "index": 674,
            "weight": 1,
            "x": 1138.5939419994615,
            "y": 300.9897727916623,
            "px": 1095.541556322775,
            "py": 308.26944523130464,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Visualization of biological sequence similarity search results",
                "PaperDOI": "10.1109/VISUAL.1995.480794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480794",
                "firstage": "44",
                "Lastage": "51, 437",
                "IEEEXPLOREArticleNumber": "480794",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Biological sequence similarity analysis presents visualization challenges, primarily because of the massive amounts of discrete, multi dimensional data. Genomic data generated by molecular biologists is analyzed by algorithms that search for similarity to known sequences in large genomic databases. The output from these algorithms can be several thousand pages of text, and is difficult to analyze because of its length and complexity. We developed and implemented a novel graphical representation for sequence similarity search results, which visually reveals features that are difficult to find in textual reports. The method opens new possibilities in the interpretation of this discrete, multidimensional data by enabling interactive investigation of the graphical representation",
                "AuthorNames": "Chi, E.H.-H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;;;",
                "AuthorIDs": "38256270000;38285364900;37660278300;37564789400;37660264900;38475865200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chi, E.H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "filename": "chi_vis_95",
                "Citations": "398883"
            }
        },
        {
            "name": "Carlis, J.V.",
            "value": 24,
            "numPapers": 4,
            "cluster": "13",
            "index": 675,
            "weight": 1,
            "x": 1226.8880529909582,
            "y": 161.43925227786795,
            "px": 1240.9661029029826,
            "py": 105.24526569895757,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Visualization of biological sequence similarity search results",
                "PaperDOI": "10.1109/VISUAL.1995.480794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480794",
                "firstage": "44",
                "Lastage": "51, 437",
                "IEEEXPLOREArticleNumber": "480794",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Biological sequence similarity analysis presents visualization challenges, primarily because of the massive amounts of discrete, multi dimensional data. Genomic data generated by molecular biologists is analyzed by algorithms that search for similarity to known sequences in large genomic databases. The output from these algorithms can be several thousand pages of text, and is difficult to analyze because of its length and complexity. We developed and implemented a novel graphical representation for sequence similarity search results, which visually reveals features that are difficult to find in textual reports. The method opens new possibilities in the interpretation of this discrete, multidimensional data by enabling interactive investigation of the graphical representation",
                "AuthorNames": "Chi, E.H.-H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;;;",
                "AuthorIDs": "38256270000;38285364900;37660278300;37564789400;37660264900;38475865200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chi, E.H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "filename": "chi_vis_95",
                "Citations": "398883"
            }
        },
        {
            "name": "Retzel, E.",
            "value": 24,
            "numPapers": 4,
            "cluster": "13",
            "index": 676,
            "weight": 1,
            "x": 1034.8919114564624,
            "y": 483.5275596136508,
            "px": 957.5243616322915,
            "py": 563.7301459664674,
            "node": {
                "Conference": "SciVis",
                "Year": "1995",
                "PaperTitle": "Visualization of biological sequence similarity search results",
                "PaperDOI": "10.1109/VISUAL.1995.480794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480794",
                "firstage": "44",
                "Lastage": "51, 437",
                "IEEEXPLOREArticleNumber": "480794",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Biological sequence similarity analysis presents visualization challenges, primarily because of the massive amounts of discrete, multi dimensional data. Genomic data generated by molecular biologists is analyzed by algorithms that search for similarity to known sequences in large genomic databases. The output from these algorithms can be several thousand pages of text, and is difficult to analyze because of its length and complexity. We developed and implemented a novel graphical representation for sequence similarity search results, which visually reveals features that are difficult to find in textual reports. The method opens new possibilities in the interpretation of this discrete, multidimensional data by enabling interactive investigation of the graphical representation",
                "AuthorNames": "Chi, E.H.-H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;;;",
                "AuthorIDs": "38256270000;38285364900;37660278300;37564789400;37660264900;38475865200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Chi, E.H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "filename": "chi_vis_95",
                "Citations": "398883"
            }
        },
        {
            "name": "Smith, S.",
            "value": 29,
            "numPapers": 11,
            "cluster": "5",
            "index": 677,
            "weight": 1,
            "x": 779.7778217817195,
            "y": 1553.6157032623935,
            "px": 1163.7419650042973,
            "py": 2543.6638665630794,
            "node": {
                "Conference": "SciVis",
                "Year": "2009",
                "PaperTitle": "Sampling and Visualizing Creases with Scale-Space Particles",
                "PaperDOI": "10.1109/TVCG.2009.177",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.177",
                "firstage": "1415",
                "Lastage": "1424",
                "IEEEXPLOREArticleNumber": "5290756",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "T",
                "Abstract": "Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.",
                "AuthorNames": "Kindlmann, G.L.;Estepar, R.S.J.;Smith, S.M.;Westin, C.-F.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of Chicago, Chicago, IL, USA|c|;;;",
                "AuthorIDs": "37282742400;37829931900;38183671700;37294318400",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Kindlmann, G.;Estepar, R.S.J.;Smith, S.;Westin, C.-F.",
                "filename": "kindlman_vis_09",
                "Citations": "4658173;398880;4376205;4658184;663930;4658166;809896"
            }
        },
        {
            "name": "Volpe, C.R.",
            "value": 62,
            "numPapers": 8,
            "cluster": "14",
            "index": 678,
            "weight": 2,
            "x": 826.9790227640668,
            "y": 425.9602072104969,
            "px": 833.2996101763675,
            "py": 393.54303398458416,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "The stream polygon-a technique for 3D vector field visualization",
                "PaperDOI": "10.1109/VISUAL.1991.175789",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175789",
                "firstage": "126",
                "Lastage": "132, 417",
                "IEEEXPLOREArticleNumber": "175789",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A method is presented for the visualization of 3D vector fields. The stream polygon, which is a regular, n-sided polygon, oriented normal to the local vector, can present local deformations due to rigid body rotation and both normal and shear strain. The effect of translation and scalar functions can be represented by sweeping the stream polygon along the streamline, and by appropriately varying the radius and shading the surface of the resulting streamtube. A mathematical foundation for the stream is developed, and examples with application to velocity field visualization are provided.",
                "AuthorNames": "Schroeder, W.J.;Volpe, C.R.;Lorensen, W.E.",
                "FirstAuthorAffiliation": "General Electric Corp. Res. & Dev., Schenectady, NY, USA|c|;;",
                "AuthorIDs": "37282730100;37378427600;37378427200",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schroeder, W.J.;Volpe, C.R.;Lorensen, W.F.",
                "filename": "schroederw_vis_91",
                "Citations": ""
            }
        },
        {
            "name": "Lorensen, W.F.",
            "value": 139,
            "numPapers": 13,
            "cluster": "14",
            "index": 679,
            "weight": 3,
            "x": 845.3908410811537,
            "y": 466.23214177817704,
            "px": 835.2855958609869,
            "py": 442.1909011712316,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Implicit modeling of swept surfaces and volumes",
                "PaperDOI": "10.1109/VISUAL.1994.346339",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346339",
                "firstage": "40",
                "Lastage": "45, C4",
                "IEEEXPLOREArticleNumber": "346339",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning",
                "AuthorNames": "Schroeder, W.J.;Lorensen, W.F.;Linthicum, S.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;",
                "AuthorIDs": "37282730100;37378427200;37659236800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schroeder, W.J.;Lorensen, W.F.;Linthicum, S.",
                "filename": "schroeder_vis_94",
                "Citations": ""
            }
        },
        {
            "name": "Hai Tao",
            "value": 29,
            "numPapers": 1,
            "cluster": "5",
            "index": 680,
            "weight": 1,
            "x": 223.10209907065968,
            "y": 501.78803867839764,
            "px": 322.82022340235034,
            "py": 714.1637831128367,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Progressive transmission of scientific data using biorthogonal wavelet transform",
                "PaperDOI": "10.1109/VISUAL.1994.346332",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346332",
                "firstage": "93",
                "Lastage": "99, C9",
                "IEEEXPLOREArticleNumber": "346332",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An important issue in scientific visualization systems is the management of data sets. Most data sets in scientific visualization, whether created by measurement or simulation, are usually voluminous. The goal of data management is to reduce the storage space and the access time of these data sets to speed up the visualization process. A new progressive transmission scheme using spline biorthogonal wavelet bases is proposed in this paper. By exploiting the properties of this set of wavelet bases, a fast algorithm involving only additions and subtractions is developed. Due to the multiresolutional nature of the wavelet transform, this scheme is compatible with hierarchical-structured rendering algorithms. The formula for reconstructing the functional values in a continuous volume space is given in a simple polynomial form. Lossless compression is possible, even when using floating-point numbers. This algorithm has been applied to data from a global ocean model. The lossless compression ratio is about 1.5:1. With a compression ratio of 50:1, the reconstructed data is still of good quality. Several other wavelet bases are compared with the spline biorthogonal wavelet bases. Finally the reconstructed data is visualized using various algorithms and the results are demonstrated",
                "AuthorNames": "Hai Tao;Moorhead, R.J.",
                "FirstAuthorAffiliation": "NSF Eng. Res. Center for Comput. Field Simulation, Mississippi Univ., MS, USA|c|;",
                "AuthorIDs": "37652845200;37282559500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Hai Tao;Moorhead, R.J.",
                "filename": "tao_vis_94",
                "Citations": "398845"
            }
        },
        {
            "name": "Schroeder, W.J.",
            "value": 168,
            "numPapers": 26,
            "cluster": "14",
            "index": 681,
            "weight": 1,
            "x": 898.8928510182859,
            "y": 550.5877231471425,
            "px": 927.4326169449992,
            "py": 543.2872858257083,
            "node": {
                "Conference": "SciVis",
                "Year": "1994",
                "PaperTitle": "Implicit modeling of swept surfaces and volumes",
                "PaperDOI": "10.1109/VISUAL.1994.346339",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346339",
                "firstage": "40",
                "Lastage": "45, C4",
                "IEEEXPLOREArticleNumber": "346339",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning",
                "AuthorNames": "Schroeder, W.J.;Lorensen, W.F.;Linthicum, S.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;",
                "AuthorIDs": "37282730100;37378427200;37659236800",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Schroeder, W.J.;Lorensen, W.F.;Linthicum, S.",
                "filename": "schroeder_vis_94",
                "Citations": ""
            }
        },
        {
            "name": "Lucas, B.",
            "value": 100,
            "numPapers": 7,
            "cluster": "8",
            "index": 682,
            "weight": 2,
            "x": 1203.3968255643201,
            "y": -294.3905978944177,
            "px": 1380.2985267037886,
            "py": -203.72801804485098,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "firstage": "107",
                "Lastage": "114",
                "IEEEXPLOREArticleNumber": "235219",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "filename": "lucas1_vis_92",
                "Citations": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Collins, N.",
            "value": 87,
            "numPapers": 5,
            "cluster": "8",
            "index": 683,
            "weight": 1,
            "x": 1849.5775115122462,
            "y": -528.8754339826377,
            "px": 2190.527807004164,
            "py": -687.5879986032841,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "firstage": "107",
                "Lastage": "114",
                "IEEEXPLOREArticleNumber": "235219",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "filename": "lucas1_vis_92",
                "Citations": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Epstein, D.A.",
            "value": 51,
            "numPapers": 4,
            "cluster": "8",
            "index": 684,
            "weight": 1,
            "x": 1338.9670728952815,
            "y": 296.6289992878328,
            "px": 1333.2320183152433,
            "py": 665.4300322989619,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "firstage": "107",
                "Lastage": "114",
                "IEEEXPLOREArticleNumber": "235219",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "filename": "lucas1_vis_92",
                "Citations": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Gresh, D.L.",
            "value": 94,
            "numPapers": 14,
            "cluster": "8",
            "index": 685,
            "weight": 1,
            "x": 1861.0767283188889,
            "y": -455.43616482126845,
            "px": 2206.2866011768338,
            "py": -571.8596376505916,
            "node": {
                "Conference": "SciVis",
                "Year": "2000",
                "PaperTitle": "WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data",
                "PaperDOI": "10.1109/VISUAL.2000.885739",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885739",
                "firstage": "489",
                "Lastage": "492",
                "IEEEXPLOREArticleNumber": "885739",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "WEAVE (Workbench Environment for Analysis and Visual Exploration) is an environment for creating interactive visualization applications. WEAVE differs from previous systems in that it provides transparent linking between custom 3D visualizations and multidimensional statistical representations, and provides interactive color brushing between all visualizations. The authors demonstrate how WEAVE can be used to rapidly prototype a biomedical application, weaving together simulation data, measurement data, and 3D anatomical data concerning the propagation of excitation in the heart. These linked statistical and custom three-dimensional visualizations of the heart can allow scientists to more effectively study the correspondence of structure and behavior.",
                "AuthorNames": "Gresh, D.L.;Rogowitz, B.E.;Winslow, R.L.;Scollan, D.F.;Yung, C.K.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;",
                "AuthorIDs": "37378534100;37332114400;37330343000;37443860200;38021754100",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Gresh, D.L.;Rogowtiz, B.;Winslow, R.L.;Scollan, D.F.;Yung, C.K.",
                "filename": "gresh_vis_00",
                "Citations": "235219;809894;528688;175794;559210"
            }
        },
        {
            "name": "McAuliffe, K.P.",
            "value": 51,
            "numPapers": 4,
            "cluster": "8",
            "index": 686,
            "weight": 1,
            "x": 903.537607680631,
            "y": 308.63550223262297,
            "px": 620.7076852646948,
            "py": 673.666920161328,
            "node": {
                "Conference": "SciVis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "firstage": "107",
                "Lastage": "114",
                "IEEEXPLOREArticleNumber": "235219",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "filename": "lucas1_vis_92",
                "Citations": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Elvins, T.T.",
            "value": 14,
            "numPapers": 8,
            "cluster": "14",
            "index": 687,
            "weight": 1,
            "x": 896.1441581147966,
            "y": 478.38701334017566,
            "px": 874.740093655044,
            "py": 450.6989924393001,
            "node": {
                "Conference": "SciVis",
                "Year": "1991",
                "PaperTitle": "Image handling in a multi-vendor environment",
                "PaperDOI": "10.1109/VISUAL.1991.175814",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175814",
                "firstage": "276",
                "Lastage": "283",
                "IEEEXPLOREArticleNumber": "175814",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Software developed to deal with differing image file formats, mismatched byte order and word sizes, and confusing hardcopy device interfaces is described. The SDSC Image Tool suite provides a simple, extensible, and portable mechanism for the support of a variety of common image formats so that tool-writers can concentrate on the task in hand, rather than on the quirks of a particular image file format. Users of such tools are able to work with images generated from a variety of sources, without being restricted to an arbitrary standard format. The SDSC Visualization Printing suite creates a unified view of hardcopy devices",
                "AuthorNames": "Nadeau, David R.;Elvins, T.T.;Bailey, M.J.",
                "FirstAuthorAffiliation": "San Diego Supercomput. Center, CA, USA|c|;;",
                "AuthorIDs": "37374054100;37389499500;37280473500",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Nadeau, David R.;Elvins, T.T.;Bailey, M.",
                "filename": "nadeau_vis_91",
                "Citations": "175807"
            }
        },
        {
            "name": "Nadeau, David R.",
            "value": 14,
            "numPapers": 7,
            "cluster": "14",
            "index": 688,
            "weight": 1,
            "x": 971.684133048849,
            "y": 516.4255552058603,
            "px": 980.0394201325696,
            "py": 489.17662706399636,
            "node": {
                "Conference": "SciVis",
                "Year": "1990",
                "PaperTitle": "Interdisciplinary visualization: lessons learned at NCSA",
                "PaperDOI": "",
                "Link": "http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846",
                "firstage": "457",
                "Lastage": "457",
                "IEEEXPLOREArticleNumber": "",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperTTVCGjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "",
                "AuthorNames": "Cox, D. C.",
                "FirstAuthorAffiliation": "National Center for Supercomputing Applications",
                "AuthorIDs": "",
                "IEEEXploreNumberGuessed": "",
                "Dedupedauthornames": "Cox, D. C.",
                "filename": "",
                "Citations": ""
            }
        }
    ]
}