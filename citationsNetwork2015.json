{
    "links": [
        {
            "source": 0,
            "target": 1
        },
        {
            "source": 0,
            "target": 2
        },
        {
            "source": 0,
            "target": 3
        },
        {
            "source": 4,
            "target": 5
        },
        {
            "source": 4,
            "target": 6
        },
        {
            "source": 4,
            "target": 2
        },
        {
            "source": 4,
            "target": 7
        },
        {
            "source": 4,
            "target": 3
        },
        {
            "source": 8,
            "target": 9
        },
        {
            "source": 8,
            "target": 10
        },
        {
            "source": 8,
            "target": 11
        },
        {
            "source": 8,
            "target": 12
        },
        {
            "source": 13,
            "target": 14
        },
        {
            "source": 13,
            "target": 15
        },
        {
            "source": 13,
            "target": 16
        },
        {
            "source": 13,
            "target": 12
        },
        {
            "source": 17,
            "target": 12
        },
        {
            "source": 13,
            "target": 18
        },
        {
            "source": 13,
            "target": 19
        },
        {
            "source": 17,
            "target": 18
        },
        {
            "source": 20,
            "target": 21
        },
        {
            "source": 20,
            "target": 22
        },
        {
            "source": 23,
            "target": 1
        },
        {
            "source": 24,
            "target": 25
        },
        {
            "source": 24,
            "target": 26
        },
        {
            "source": 27,
            "target": 26
        },
        {
            "source": 28,
            "target": 12
        },
        {
            "source": 29,
            "target": 12
        },
        {
            "source": 24,
            "target": 12
        },
        {
            "source": 30,
            "target": 31
        },
        {
            "source": 27,
            "target": 32
        },
        {
            "source": 27,
            "target": 33
        },
        {
            "source": 27,
            "target": 34
        },
        {
            "source": 27,
            "target": 31
        },
        {
            "source": 27,
            "target": 35
        },
        {
            "source": 24,
            "target": 36
        },
        {
            "source": 37,
            "target": 38
        },
        {
            "source": 39,
            "target": 37
        },
        {
            "source": 39,
            "target": 38
        },
        {
            "source": 38,
            "target": 37
        },
        {
            "source": 37,
            "target": 40
        },
        {
            "source": 37,
            "target": 41
        },
        {
            "source": 37,
            "target": 42
        },
        {
            "source": 37,
            "target": 43
        },
        {
            "source": 37,
            "target": 9
        },
        {
            "source": 38,
            "target": 9
        },
        {
            "source": 43,
            "target": 9
        },
        {
            "source": 37,
            "target": 2
        },
        {
            "source": 44,
            "target": 6
        },
        {
            "source": 45,
            "target": 46
        },
        {
            "source": 47,
            "target": 46
        },
        {
            "source": 47,
            "target": 6
        },
        {
            "source": 44,
            "target": 3
        },
        {
            "source": 45,
            "target": 3
        },
        {
            "source": 47,
            "target": 3
        },
        {
            "source": 48,
            "target": 49
        },
        {
            "source": 50,
            "target": 6
        },
        {
            "source": 51,
            "target": 6
        },
        {
            "source": 52,
            "target": 6
        },
        {
            "source": 51,
            "target": 52
        },
        {
            "source": 53,
            "target": 52
        },
        {
            "source": 54,
            "target": 52
        },
        {
            "source": 52,
            "target": 51
        },
        {
            "source": 52,
            "target": 55
        },
        {
            "source": 52,
            "target": 27
        },
        {
            "source": 52,
            "target": 44
        },
        {
            "source": 52,
            "target": 56
        },
        {
            "source": 52,
            "target": 57
        },
        {
            "source": 51,
            "target": 58
        },
        {
            "source": 52,
            "target": 58
        },
        {
            "source": 51,
            "target": 59
        },
        {
            "source": 52,
            "target": 59
        },
        {
            "source": 60,
            "target": 11
        },
        {
            "source": 60,
            "target": 12
        },
        {
            "source": 11,
            "target": 12
        },
        {
            "source": 60,
            "target": 61
        },
        {
            "source": 60,
            "target": 62
        },
        {
            "source": 11,
            "target": 61
        },
        {
            "source": 11,
            "target": 62
        },
        {
            "source": 11,
            "target": 63
        },
        {
            "source": 15,
            "target": 12
        },
        {
            "source": 64,
            "target": 65
        },
        {
            "source": 66,
            "target": 21
        },
        {
            "source": 15,
            "target": 21
        },
        {
            "source": 67,
            "target": 21
        },
        {
            "source": 68,
            "target": 21
        },
        {
            "source": 64,
            "target": 21
        },
        {
            "source": 69,
            "target": 70
        },
        {
            "source": 69,
            "target": 71
        },
        {
            "source": 72,
            "target": 70
        },
        {
            "source": 72,
            "target": 71
        },
        {
            "source": 73,
            "target": 70
        },
        {
            "source": 73,
            "target": 71
        },
        {
            "source": 58,
            "target": 70
        },
        {
            "source": 58,
            "target": 71
        },
        {
            "source": 58,
            "target": 59
        },
        {
            "source": 58,
            "target": 52
        },
        {
            "source": 74,
            "target": 6
        },
        {
            "source": 75,
            "target": 6
        },
        {
            "source": 76,
            "target": 6
        },
        {
            "source": 6,
            "target": 77
        },
        {
            "source": 6,
            "target": 3
        },
        {
            "source": 6,
            "target": 19
        },
        {
            "source": 6,
            "target": 18
        },
        {
            "source": 6,
            "target": 78
        },
        {
            "source": 6,
            "target": 79
        },
        {
            "source": 80,
            "target": 71
        },
        {
            "source": 80,
            "target": 70
        },
        {
            "source": 81,
            "target": 71
        },
        {
            "source": 81,
            "target": 70
        },
        {
            "source": 82,
            "target": 71
        },
        {
            "source": 82,
            "target": 70
        },
        {
            "source": 2,
            "target": 6
        },
        {
            "source": 2,
            "target": 71
        },
        {
            "source": 83,
            "target": 2
        },
        {
            "source": 84,
            "target": 71
        },
        {
            "source": 83,
            "target": 71
        },
        {
            "source": 85,
            "target": 12
        },
        {
            "source": 85,
            "target": 36
        },
        {
            "source": 86,
            "target": 3
        },
        {
            "source": 86,
            "target": 87
        },
        {
            "source": 86,
            "target": 83
        },
        {
            "source": 86,
            "target": 2
        },
        {
            "source": 27,
            "target": 52
        },
        {
            "source": 31,
            "target": 52
        },
        {
            "source": 30,
            "target": 27
        },
        {
            "source": 31,
            "target": 27
        },
        {
            "source": 86,
            "target": 88
        },
        {
            "source": 86,
            "target": 89
        },
        {
            "source": 86,
            "target": 70
        },
        {
            "source": 36,
            "target": 6
        },
        {
            "source": 90,
            "target": 55
        },
        {
            "source": 91,
            "target": 55
        },
        {
            "source": 92,
            "target": 55
        },
        {
            "source": 90,
            "target": 91
        },
        {
            "source": 90,
            "target": 93
        },
        {
            "source": 55,
            "target": 91
        },
        {
            "source": 55,
            "target": 93
        },
        {
            "source": 91,
            "target": 93
        },
        {
            "source": 92,
            "target": 91
        },
        {
            "source": 92,
            "target": 93
        },
        {
            "source": 55,
            "target": 6
        },
        {
            "source": 55,
            "target": 7
        },
        {
            "source": 91,
            "target": 6
        },
        {
            "source": 91,
            "target": 7
        },
        {
            "source": 55,
            "target": 59
        },
        {
            "source": 55,
            "target": 92
        },
        {
            "source": 55,
            "target": 94
        },
        {
            "source": 55,
            "target": 5
        },
        {
            "source": 91,
            "target": 92
        },
        {
            "source": 91,
            "target": 94
        },
        {
            "source": 91,
            "target": 5
        },
        {
            "source": 92,
            "target": 94
        },
        {
            "source": 92,
            "target": 5
        },
        {
            "source": 58,
            "target": 55
        },
        {
            "source": 58,
            "target": 95
        },
        {
            "source": 6,
            "target": 71
        },
        {
            "source": 79,
            "target": 18
        },
        {
            "source": 79,
            "target": 19
        },
        {
            "source": 96,
            "target": 3
        },
        {
            "source": 96,
            "target": 52
        },
        {
            "source": 96,
            "target": 97
        },
        {
            "source": 96,
            "target": 98
        },
        {
            "source": 96,
            "target": 99
        },
        {
            "source": 100,
            "target": 101
        },
        {
            "source": 102,
            "target": 103
        },
        {
            "source": 104,
            "target": 103
        },
        {
            "source": 104,
            "target": 105
        },
        {
            "source": 101,
            "target": 106
        },
        {
            "source": 101,
            "target": 107
        },
        {
            "source": 101,
            "target": 108
        },
        {
            "source": 101,
            "target": 109
        },
        {
            "source": 110,
            "target": 106
        },
        {
            "source": 110,
            "target": 101
        },
        {
            "source": 101,
            "target": 111
        },
        {
            "source": 101,
            "target": 112
        },
        {
            "source": 101,
            "target": 5
        },
        {
            "source": 101,
            "target": 113
        },
        {
            "source": 114,
            "target": 115
        },
        {
            "source": 114,
            "target": 116
        },
        {
            "source": 117,
            "target": 115
        },
        {
            "source": 114,
            "target": 118
        },
        {
            "source": 114,
            "target": 119
        },
        {
            "source": 117,
            "target": 118
        },
        {
            "source": 120,
            "target": 121
        },
        {
            "source": 120,
            "target": 122
        },
        {
            "source": 120,
            "target": 123
        },
        {
            "source": 120,
            "target": 124
        },
        {
            "source": 120,
            "target": 21
        },
        {
            "source": 120,
            "target": 22
        },
        {
            "source": 1,
            "target": 2
        },
        {
            "source": 125,
            "target": 65
        },
        {
            "source": 125,
            "target": 1
        },
        {
            "source": 126,
            "target": 65
        },
        {
            "source": 126,
            "target": 1
        },
        {
            "source": 1,
            "target": 65
        },
        {
            "source": 65,
            "target": 1
        },
        {
            "source": 1,
            "target": 127
        },
        {
            "source": 65,
            "target": 127
        },
        {
            "source": 65,
            "target": 113
        },
        {
            "source": 128,
            "target": 129
        },
        {
            "source": 128,
            "target": 130
        },
        {
            "source": 128,
            "target": 131
        },
        {
            "source": 128,
            "target": 65
        },
        {
            "source": 132,
            "target": 128
        },
        {
            "source": 133,
            "target": 128
        },
        {
            "source": 128,
            "target": 134
        },
        {
            "source": 128,
            "target": 135
        },
        {
            "source": 128,
            "target": 136
        },
        {
            "source": 128,
            "target": 64
        },
        {
            "source": 128,
            "target": 11
        },
        {
            "source": 137,
            "target": 138
        },
        {
            "source": 139,
            "target": 138
        },
        {
            "source": 105,
            "target": 26
        },
        {
            "source": 140,
            "target": 27
        },
        {
            "source": 140,
            "target": 95
        },
        {
            "source": 140,
            "target": 141
        },
        {
            "source": 140,
            "target": 99
        },
        {
            "source": 140,
            "target": 142
        },
        {
            "source": 140,
            "target": 143
        },
        {
            "source": 140,
            "target": 144
        },
        {
            "source": 140,
            "target": 11
        },
        {
            "source": 140,
            "target": 145
        },
        {
            "source": 120,
            "target": 146
        },
        {
            "source": 120,
            "target": 147
        },
        {
            "source": 120,
            "target": 148
        },
        {
            "source": 120,
            "target": 149
        },
        {
            "source": 150,
            "target": 120
        },
        {
            "source": 120,
            "target": 151
        },
        {
            "source": 120,
            "target": 152
        },
        {
            "source": 120,
            "target": 112
        },
        {
            "source": 120,
            "target": 153
        },
        {
            "source": 120,
            "target": 154
        },
        {
            "source": 155,
            "target": 26
        },
        {
            "source": 156,
            "target": 112
        },
        {
            "source": 156,
            "target": 11
        },
        {
            "source": 123,
            "target": 157
        },
        {
            "source": 123,
            "target": 140
        },
        {
            "source": 158,
            "target": 159
        },
        {
            "source": 158,
            "target": 116
        },
        {
            "source": 160,
            "target": 116
        },
        {
            "source": 159,
            "target": 116
        },
        {
            "source": 26,
            "target": 116
        },
        {
            "source": 116,
            "target": 159
        },
        {
            "source": 160,
            "target": 3
        },
        {
            "source": 26,
            "target": 3
        },
        {
            "source": 100,
            "target": 140
        },
        {
            "source": 100,
            "target": 144
        },
        {
            "source": 100,
            "target": 96
        },
        {
            "source": 161,
            "target": 101
        },
        {
            "source": 64,
            "target": 101
        },
        {
            "source": 162,
            "target": 123
        },
        {
            "source": 162,
            "target": 105
        },
        {
            "source": 162,
            "target": 163
        },
        {
            "source": 164,
            "target": 116
        },
        {
            "source": 165,
            "target": 105
        },
        {
            "source": 166,
            "target": 105
        },
        {
            "source": 164,
            "target": 167
        },
        {
            "source": 164,
            "target": 105
        },
        {
            "source": 164,
            "target": 168
        },
        {
            "source": 169,
            "target": 105
        },
        {
            "source": 170,
            "target": 105
        },
        {
            "source": 171,
            "target": 105
        },
        {
            "source": 172,
            "target": 105
        },
        {
            "source": 172,
            "target": 164
        },
        {
            "source": 164,
            "target": 173
        },
        {
            "source": 164,
            "target": 123
        },
        {
            "source": 174,
            "target": 175
        },
        {
            "source": 174,
            "target": 176
        },
        {
            "source": 119,
            "target": 112
        },
        {
            "source": 177,
            "target": 119
        },
        {
            "source": 119,
            "target": 178
        },
        {
            "source": 119,
            "target": 179
        },
        {
            "source": 101,
            "target": 180
        },
        {
            "source": 101,
            "target": 27
        },
        {
            "source": 180,
            "target": 181
        },
        {
            "source": 180,
            "target": 182
        },
        {
            "source": 180,
            "target": 27
        },
        {
            "source": 183,
            "target": 149
        },
        {
            "source": 149,
            "target": 112
        },
        {
            "source": 183,
            "target": 120
        },
        {
            "source": 149,
            "target": 120
        },
        {
            "source": 145,
            "target": 123
        },
        {
            "source": 184,
            "target": 123
        },
        {
            "source": 145,
            "target": 11
        },
        {
            "source": 184,
            "target": 11
        },
        {
            "source": 184,
            "target": 145
        },
        {
            "source": 145,
            "target": 124
        },
        {
            "source": 145,
            "target": 163
        },
        {
            "source": 145,
            "target": 162
        },
        {
            "source": 184,
            "target": 185
        },
        {
            "source": 184,
            "target": 124
        },
        {
            "source": 184,
            "target": 163
        },
        {
            "source": 184,
            "target": 162
        },
        {
            "source": 186,
            "target": 181
        },
        {
            "source": 186,
            "target": 187
        },
        {
            "source": 186,
            "target": 188
        },
        {
            "source": 186,
            "target": 27
        },
        {
            "source": 186,
            "target": 180
        },
        {
            "source": 181,
            "target": 186
        },
        {
            "source": 181,
            "target": 187
        },
        {
            "source": 181,
            "target": 188
        },
        {
            "source": 181,
            "target": 27
        },
        {
            "source": 181,
            "target": 180
        },
        {
            "source": 189,
            "target": 181
        },
        {
            "source": 189,
            "target": 187
        },
        {
            "source": 189,
            "target": 188
        },
        {
            "source": 189,
            "target": 27
        },
        {
            "source": 189,
            "target": 180
        },
        {
            "source": 187,
            "target": 186
        },
        {
            "source": 187,
            "target": 181
        },
        {
            "source": 187,
            "target": 188
        },
        {
            "source": 187,
            "target": 27
        },
        {
            "source": 187,
            "target": 180
        },
        {
            "source": 188,
            "target": 186
        },
        {
            "source": 188,
            "target": 181
        },
        {
            "source": 188,
            "target": 187
        },
        {
            "source": 188,
            "target": 27
        },
        {
            "source": 188,
            "target": 180
        },
        {
            "source": 27,
            "target": 186
        },
        {
            "source": 27,
            "target": 181
        },
        {
            "source": 27,
            "target": 187
        },
        {
            "source": 27,
            "target": 188
        },
        {
            "source": 27,
            "target": 180
        },
        {
            "source": 180,
            "target": 187
        },
        {
            "source": 180,
            "target": 188
        },
        {
            "source": 27,
            "target": 190
        },
        {
            "source": 27,
            "target": 191
        },
        {
            "source": 27,
            "target": 192
        },
        {
            "source": 27,
            "target": 193
        },
        {
            "source": 27,
            "target": 194
        },
        {
            "source": 180,
            "target": 195
        },
        {
            "source": 180,
            "target": 196
        },
        {
            "source": 180,
            "target": 193
        },
        {
            "source": 186,
            "target": 101
        },
        {
            "source": 186,
            "target": 197
        },
        {
            "source": 181,
            "target": 101
        },
        {
            "source": 181,
            "target": 197
        },
        {
            "source": 187,
            "target": 101
        },
        {
            "source": 187,
            "target": 197
        },
        {
            "source": 188,
            "target": 101
        },
        {
            "source": 188,
            "target": 197
        },
        {
            "source": 27,
            "target": 101
        },
        {
            "source": 27,
            "target": 197
        },
        {
            "source": 180,
            "target": 198
        },
        {
            "source": 180,
            "target": 101
        },
        {
            "source": 180,
            "target": 197
        },
        {
            "source": 181,
            "target": 182
        },
        {
            "source": 187,
            "target": 182
        },
        {
            "source": 188,
            "target": 182
        },
        {
            "source": 27,
            "target": 182
        },
        {
            "source": 180,
            "target": 105
        },
        {
            "source": 27,
            "target": 3
        },
        {
            "source": 64,
            "target": 129
        },
        {
            "source": 64,
            "target": 130
        },
        {
            "source": 64,
            "target": 131
        },
        {
            "source": 161,
            "target": 128
        },
        {
            "source": 64,
            "target": 128
        },
        {
            "source": 161,
            "target": 64
        },
        {
            "source": 64,
            "target": 135
        },
        {
            "source": 64,
            "target": 199
        },
        {
            "source": 64,
            "target": 67
        },
        {
            "source": 64,
            "target": 200
        },
        {
            "source": 64,
            "target": 201
        },
        {
            "source": 128,
            "target": 199
        },
        {
            "source": 128,
            "target": 67
        },
        {
            "source": 128,
            "target": 200
        },
        {
            "source": 128,
            "target": 101
        },
        {
            "source": 128,
            "target": 201
        },
        {
            "source": 65,
            "target": 101
        },
        {
            "source": 64,
            "target": 106
        },
        {
            "source": 202,
            "target": 108
        },
        {
            "source": 202,
            "target": 101
        },
        {
            "source": 203,
            "target": 204
        },
        {
            "source": 203,
            "target": 108
        },
        {
            "source": 203,
            "target": 205
        },
        {
            "source": 203,
            "target": 101
        },
        {
            "source": 203,
            "target": 27
        },
        {
            "source": 203,
            "target": 128
        },
        {
            "source": 202,
            "target": 203
        },
        {
            "source": 203,
            "target": 206
        },
        {
            "source": 203,
            "target": 207
        },
        {
            "source": 208,
            "target": 11
        },
        {
            "source": 209,
            "target": 11
        },
        {
            "source": 208,
            "target": 113
        },
        {
            "source": 11,
            "target": 113
        },
        {
            "source": 208,
            "target": 142
        },
        {
            "source": 208,
            "target": 143
        },
        {
            "source": 11,
            "target": 142
        },
        {
            "source": 11,
            "target": 143
        },
        {
            "source": 208,
            "target": 210
        },
        {
            "source": 208,
            "target": 184
        },
        {
            "source": 11,
            "target": 210
        },
        {
            "source": 11,
            "target": 184
        },
        {
            "source": 11,
            "target": 145
        },
        {
            "source": 211,
            "target": 36
        },
        {
            "source": 138,
            "target": 36
        },
        {
            "source": 211,
            "target": 212
        },
        {
            "source": 138,
            "target": 163
        },
        {
            "source": 138,
            "target": 212
        },
        {
            "source": 211,
            "target": 185
        },
        {
            "source": 138,
            "target": 185
        },
        {
            "source": 213,
            "target": 214
        },
        {
            "source": 213,
            "target": 215
        },
        {
            "source": 216,
            "target": 214
        },
        {
            "source": 216,
            "target": 215
        },
        {
            "source": 8,
            "target": 214
        },
        {
            "source": 8,
            "target": 215
        },
        {
            "source": 217,
            "target": 214
        },
        {
            "source": 217,
            "target": 215
        },
        {
            "source": 8,
            "target": 194
        },
        {
            "source": 8,
            "target": 191
        },
        {
            "source": 8,
            "target": 193
        },
        {
            "source": 8,
            "target": 3
        },
        {
            "source": 8,
            "target": 218
        },
        {
            "source": 8,
            "target": 219
        },
        {
            "source": 8,
            "target": 220
        },
        {
            "source": 8,
            "target": 101
        },
        {
            "source": 221,
            "target": 175
        },
        {
            "source": 193,
            "target": 175
        },
        {
            "source": 221,
            "target": 105
        },
        {
            "source": 193,
            "target": 105
        },
        {
            "source": 222,
            "target": 5
        },
        {
            "source": 193,
            "target": 5
        },
        {
            "source": 193,
            "target": 164
        },
        {
            "source": 221,
            "target": 223
        },
        {
            "source": 193,
            "target": 223
        },
        {
            "source": 120,
            "target": 101
        },
        {
            "source": 224,
            "target": 214
        },
        {
            "source": 224,
            "target": 215
        },
        {
            "source": 225,
            "target": 214
        },
        {
            "source": 225,
            "target": 215
        },
        {
            "source": 225,
            "target": 5
        },
        {
            "source": 226,
            "target": 100
        },
        {
            "source": 227,
            "target": 100
        },
        {
            "source": 228,
            "target": 100
        },
        {
            "source": 229,
            "target": 3
        },
        {
            "source": 230,
            "target": 3
        },
        {
            "source": 50,
            "target": 3
        },
        {
            "source": 229,
            "target": 6
        },
        {
            "source": 230,
            "target": 6
        },
        {
            "source": 96,
            "target": 6
        },
        {
            "source": 50,
            "target": 46
        },
        {
            "source": 231,
            "target": 232
        },
        {
            "source": 231,
            "target": 8
        },
        {
            "source": 232,
            "target": 233
        },
        {
            "source": 232,
            "target": 234
        },
        {
            "source": 232,
            "target": 235
        },
        {
            "source": 232,
            "target": 236
        },
        {
            "source": 232,
            "target": 8
        },
        {
            "source": 237,
            "target": 232
        },
        {
            "source": 238,
            "target": 232
        },
        {
            "source": 239,
            "target": 232
        },
        {
            "source": 240,
            "target": 232
        },
        {
            "source": 232,
            "target": 112
        },
        {
            "source": 232,
            "target": 241
        },
        {
            "source": 232,
            "target": 239
        },
        {
            "source": 232,
            "target": 242
        },
        {
            "source": 232,
            "target": 243
        },
        {
            "source": 232,
            "target": 244
        },
        {
            "source": 231,
            "target": 245
        },
        {
            "source": 231,
            "target": 246
        },
        {
            "source": 231,
            "target": 247
        },
        {
            "source": 232,
            "target": 245
        },
        {
            "source": 232,
            "target": 246
        },
        {
            "source": 232,
            "target": 247
        },
        {
            "source": 237,
            "target": 245
        },
        {
            "source": 238,
            "target": 245
        },
        {
            "source": 239,
            "target": 245
        },
        {
            "source": 240,
            "target": 245
        },
        {
            "source": 232,
            "target": 231
        },
        {
            "source": 231,
            "target": 248
        },
        {
            "source": 232,
            "target": 248
        },
        {
            "source": 232,
            "target": 249
        },
        {
            "source": 231,
            "target": 250
        },
        {
            "source": 231,
            "target": 251
        },
        {
            "source": 232,
            "target": 250
        },
        {
            "source": 232,
            "target": 251
        },
        {
            "source": 232,
            "target": 252
        },
        {
            "source": 253,
            "target": 252
        },
        {
            "source": 254,
            "target": 252
        },
        {
            "source": 255,
            "target": 252
        },
        {
            "source": 254,
            "target": 256
        },
        {
            "source": 253,
            "target": 2
        },
        {
            "source": 254,
            "target": 2
        },
        {
            "source": 255,
            "target": 2
        },
        {
            "source": 253,
            "target": 31
        },
        {
            "source": 253,
            "target": 34
        },
        {
            "source": 257,
            "target": 31
        },
        {
            "source": 257,
            "target": 34
        },
        {
            "source": 254,
            "target": 31
        },
        {
            "source": 254,
            "target": 34
        },
        {
            "source": 255,
            "target": 31
        },
        {
            "source": 255,
            "target": 34
        },
        {
            "source": 254,
            "target": 45
        },
        {
            "source": 254,
            "target": 258
        },
        {
            "source": 254,
            "target": 3
        },
        {
            "source": 253,
            "target": 259
        },
        {
            "source": 253,
            "target": 35
        },
        {
            "source": 257,
            "target": 35
        },
        {
            "source": 254,
            "target": 259
        },
        {
            "source": 254,
            "target": 35
        },
        {
            "source": 255,
            "target": 259
        },
        {
            "source": 255,
            "target": 35
        },
        {
            "source": 256,
            "target": 3
        },
        {
            "source": 256,
            "target": 260
        },
        {
            "source": 256,
            "target": 261
        },
        {
            "source": 256,
            "target": 262
        },
        {
            "source": 256,
            "target": 48
        },
        {
            "source": 256,
            "target": 254
        },
        {
            "source": 25,
            "target": 116
        },
        {
            "source": 160,
            "target": 71
        },
        {
            "source": 263,
            "target": 71
        },
        {
            "source": 25,
            "target": 71
        },
        {
            "source": 25,
            "target": 70
        },
        {
            "source": 25,
            "target": 232
        },
        {
            "source": 25,
            "target": 8
        },
        {
            "source": 25,
            "target": 264
        },
        {
            "source": 25,
            "target": 265
        },
        {
            "source": 25,
            "target": 266
        },
        {
            "source": 25,
            "target": 160
        },
        {
            "source": 25,
            "target": 267
        },
        {
            "source": 25,
            "target": 26
        },
        {
            "source": 192,
            "target": 6
        },
        {
            "source": 192,
            "target": 191
        },
        {
            "source": 192,
            "target": 193
        },
        {
            "source": 268,
            "target": 101
        },
        {
            "source": 138,
            "target": 101
        },
        {
            "source": 268,
            "target": 198
        },
        {
            "source": 138,
            "target": 198
        },
        {
            "source": 138,
            "target": 112
        },
        {
            "source": 138,
            "target": 140
        },
        {
            "source": 269,
            "target": 270
        },
        {
            "source": 264,
            "target": 232
        },
        {
            "source": 269,
            "target": 232
        },
        {
            "source": 265,
            "target": 232
        },
        {
            "source": 266,
            "target": 248
        },
        {
            "source": 266,
            "target": 232
        },
        {
            "source": 264,
            "target": 265
        },
        {
            "source": 264,
            "target": 48
        },
        {
            "source": 264,
            "target": 266
        },
        {
            "source": 265,
            "target": 264
        },
        {
            "source": 265,
            "target": 48
        },
        {
            "source": 265,
            "target": 266
        },
        {
            "source": 266,
            "target": 264
        },
        {
            "source": 266,
            "target": 265
        },
        {
            "source": 266,
            "target": 48
        },
        {
            "source": 271,
            "target": 272
        },
        {
            "source": 271,
            "target": 273
        },
        {
            "source": 274,
            "target": 272
        },
        {
            "source": 274,
            "target": 273
        },
        {
            "source": 274,
            "target": 264
        },
        {
            "source": 274,
            "target": 265
        },
        {
            "source": 274,
            "target": 266
        },
        {
            "source": 274,
            "target": 12
        },
        {
            "source": 274,
            "target": 232
        },
        {
            "source": 274,
            "target": 36
        },
        {
            "source": 274,
            "target": 275
        },
        {
            "source": 254,
            "target": 276
        },
        {
            "source": 8,
            "target": 277
        },
        {
            "source": 8,
            "target": 71
        },
        {
            "source": 8,
            "target": 278
        },
        {
            "source": 8,
            "target": 279
        },
        {
            "source": 8,
            "target": 280
        },
        {
            "source": 8,
            "target": 281
        },
        {
            "source": 8,
            "target": 282
        },
        {
            "source": 8,
            "target": 283
        },
        {
            "source": 8,
            "target": 284
        },
        {
            "source": 112,
            "target": 285
        },
        {
            "source": 112,
            "target": 286
        },
        {
            "source": 112,
            "target": 99
        },
        {
            "source": 220,
            "target": 214
        },
        {
            "source": 220,
            "target": 215
        },
        {
            "source": 220,
            "target": 287
        },
        {
            "source": 288,
            "target": 214
        },
        {
            "source": 288,
            "target": 215
        },
        {
            "source": 288,
            "target": 287
        },
        {
            "source": 289,
            "target": 214
        },
        {
            "source": 289,
            "target": 215
        },
        {
            "source": 220,
            "target": 12
        },
        {
            "source": 288,
            "target": 12
        },
        {
            "source": 220,
            "target": 77
        },
        {
            "source": 220,
            "target": 6
        },
        {
            "source": 220,
            "target": 8
        },
        {
            "source": 288,
            "target": 8
        },
        {
            "source": 289,
            "target": 8
        },
        {
            "source": 220,
            "target": 219
        },
        {
            "source": 123,
            "target": 26
        },
        {
            "source": 123,
            "target": 273
        },
        {
            "source": 290,
            "target": 291
        },
        {
            "source": 290,
            "target": 292
        },
        {
            "source": 290,
            "target": 293
        },
        {
            "source": 290,
            "target": 5
        },
        {
            "source": 291,
            "target": 292
        },
        {
            "source": 291,
            "target": 293
        },
        {
            "source": 291,
            "target": 5
        },
        {
            "source": 292,
            "target": 291
        },
        {
            "source": 292,
            "target": 293
        },
        {
            "source": 292,
            "target": 5
        },
        {
            "source": 293,
            "target": 291
        },
        {
            "source": 293,
            "target": 292
        },
        {
            "source": 293,
            "target": 5
        },
        {
            "source": 5,
            "target": 291
        },
        {
            "source": 5,
            "target": 292
        },
        {
            "source": 5,
            "target": 293
        },
        {
            "source": 291,
            "target": 101
        },
        {
            "source": 292,
            "target": 101
        },
        {
            "source": 5,
            "target": 294
        },
        {
            "source": 5,
            "target": 295
        },
        {
            "source": 5,
            "target": 101
        },
        {
            "source": 270,
            "target": 269
        },
        {
            "source": 296,
            "target": 101
        },
        {
            "source": 101,
            "target": 6
        },
        {
            "source": 296,
            "target": 6
        },
        {
            "source": 101,
            "target": 198
        },
        {
            "source": 101,
            "target": 99
        },
        {
            "source": 296,
            "target": 198
        },
        {
            "source": 296,
            "target": 99
        },
        {
            "source": 101,
            "target": 31
        },
        {
            "source": 101,
            "target": 34
        },
        {
            "source": 296,
            "target": 218
        },
        {
            "source": 101,
            "target": 297
        },
        {
            "source": 296,
            "target": 59
        },
        {
            "source": 215,
            "target": 36
        },
        {
            "source": 214,
            "target": 36
        },
        {
            "source": 215,
            "target": 214
        },
        {
            "source": 214,
            "target": 215
        },
        {
            "source": 298,
            "target": 24
        },
        {
            "source": 4,
            "target": 232
        },
        {
            "source": 4,
            "target": 299
        },
        {
            "source": 4,
            "target": 87
        },
        {
            "source": 4,
            "target": 36
        },
        {
            "source": 4,
            "target": 71
        },
        {
            "source": 300,
            "target": 52
        },
        {
            "source": 300,
            "target": 3
        },
        {
            "source": 36,
            "target": 5
        },
        {
            "source": 301,
            "target": 36
        },
        {
            "source": 302,
            "target": 55
        },
        {
            "source": 303,
            "target": 55
        },
        {
            "source": 304,
            "target": 55
        },
        {
            "source": 219,
            "target": 87
        },
        {
            "source": 305,
            "target": 6
        },
        {
            "source": 305,
            "target": 87
        },
        {
            "source": 306,
            "target": 87
        },
        {
            "source": 305,
            "target": 307
        },
        {
            "source": 233,
            "target": 232
        },
        {
            "source": 233,
            "target": 8
        },
        {
            "source": 84,
            "target": 232
        },
        {
            "source": 84,
            "target": 8
        },
        {
            "source": 234,
            "target": 233
        },
        {
            "source": 234,
            "target": 232
        },
        {
            "source": 234,
            "target": 8
        },
        {
            "source": 84,
            "target": 112
        },
        {
            "source": 12,
            "target": 308
        },
        {
            "source": 12,
            "target": 309
        },
        {
            "source": 12,
            "target": 310
        },
        {
            "source": 12,
            "target": 311
        },
        {
            "source": 12,
            "target": 312
        },
        {
            "source": 12,
            "target": 21
        },
        {
            "source": 12,
            "target": 313
        },
        {
            "source": 12,
            "target": 63
        },
        {
            "source": 314,
            "target": 308
        },
        {
            "source": 314,
            "target": 315
        },
        {
            "source": 29,
            "target": 316
        },
        {
            "source": 12,
            "target": 317
        },
        {
            "source": 318,
            "target": 52
        },
        {
            "source": 51,
            "target": 264
        },
        {
            "source": 51,
            "target": 265
        },
        {
            "source": 51,
            "target": 266
        },
        {
            "source": 52,
            "target": 264
        },
        {
            "source": 52,
            "target": 265
        },
        {
            "source": 52,
            "target": 266
        },
        {
            "source": 52,
            "target": 319
        },
        {
            "source": 51,
            "target": 45
        },
        {
            "source": 51,
            "target": 3
        },
        {
            "source": 52,
            "target": 45
        },
        {
            "source": 52,
            "target": 3
        },
        {
            "source": 281,
            "target": 112
        },
        {
            "source": 281,
            "target": 87
        },
        {
            "source": 281,
            "target": 320
        },
        {
            "source": 321,
            "target": 214
        },
        {
            "source": 321,
            "target": 215
        },
        {
            "source": 193,
            "target": 214
        },
        {
            "source": 193,
            "target": 215
        },
        {
            "source": 193,
            "target": 321
        },
        {
            "source": 193,
            "target": 222
        },
        {
            "source": 193,
            "target": 194
        },
        {
            "source": 193,
            "target": 191
        },
        {
            "source": 193,
            "target": 220
        },
        {
            "source": 26,
            "target": 266
        },
        {
            "source": 25,
            "target": 258
        },
        {
            "source": 25,
            "target": 3
        },
        {
            "source": 26,
            "target": 258
        },
        {
            "source": 26,
            "target": 25
        },
        {
            "source": 25,
            "target": 48
        },
        {
            "source": 26,
            "target": 264
        },
        {
            "source": 26,
            "target": 48
        },
        {
            "source": 266,
            "target": 281
        },
        {
            "source": 266,
            "target": 242
        },
        {
            "source": 266,
            "target": 244
        },
        {
            "source": 266,
            "target": 278
        },
        {
            "source": 266,
            "target": 279
        },
        {
            "source": 266,
            "target": 280
        },
        {
            "source": 266,
            "target": 12
        },
        {
            "source": 266,
            "target": 3
        },
        {
            "source": 116,
            "target": 322
        },
        {
            "source": 116,
            "target": 26
        },
        {
            "source": 25,
            "target": 46
        },
        {
            "source": 25,
            "target": 323
        },
        {
            "source": 191,
            "target": 321
        },
        {
            "source": 191,
            "target": 193
        },
        {
            "source": 191,
            "target": 194
        },
        {
            "source": 315,
            "target": 193
        },
        {
            "source": 2,
            "target": 1
        },
        {
            "source": 2,
            "target": 324
        },
        {
            "source": 140,
            "target": 36
        },
        {
            "source": 140,
            "target": 96
        },
        {
            "source": 192,
            "target": 18
        },
        {
            "source": 93,
            "target": 91
        },
        {
            "source": 93,
            "target": 55
        },
        {
            "source": 93,
            "target": 266
        },
        {
            "source": 93,
            "target": 48
        },
        {
            "source": 91,
            "target": 78
        },
        {
            "source": 93,
            "target": 78
        },
        {
            "source": 55,
            "target": 78
        },
        {
            "source": 91,
            "target": 3
        },
        {
            "source": 93,
            "target": 7
        },
        {
            "source": 93,
            "target": 3
        },
        {
            "source": 55,
            "target": 3
        },
        {
            "source": 175,
            "target": 105
        },
        {
            "source": 163,
            "target": 105
        },
        {
            "source": 116,
            "target": 325
        },
        {
            "source": 86,
            "target": 6
        },
        {
            "source": 86,
            "target": 71
        },
        {
            "source": 0,
            "target": 86
        },
        {
            "source": 86,
            "target": 93
        },
        {
            "source": 86,
            "target": 326
        },
        {
            "source": 86,
            "target": 327
        },
        {
            "source": 86,
            "target": 328
        },
        {
            "source": 252,
            "target": 86
        },
        {
            "source": 252,
            "target": 329
        },
        {
            "source": 252,
            "target": 3
        },
        {
            "source": 252,
            "target": 6
        },
        {
            "source": 330,
            "target": 31
        },
        {
            "source": 330,
            "target": 34
        },
        {
            "source": 330,
            "target": 35
        },
        {
            "source": 331,
            "target": 31
        },
        {
            "source": 331,
            "target": 34
        },
        {
            "source": 331,
            "target": 35
        },
        {
            "source": 31,
            "target": 34
        },
        {
            "source": 31,
            "target": 259
        },
        {
            "source": 31,
            "target": 35
        },
        {
            "source": 27,
            "target": 259
        },
        {
            "source": 34,
            "target": 31
        },
        {
            "source": 34,
            "target": 259
        },
        {
            "source": 34,
            "target": 35
        },
        {
            "source": 34,
            "target": 332
        },
        {
            "source": 31,
            "target": 87
        },
        {
            "source": 31,
            "target": 333
        },
        {
            "source": 34,
            "target": 87
        },
        {
            "source": 34,
            "target": 333
        },
        {
            "source": 31,
            "target": 252
        },
        {
            "source": 31,
            "target": 86
        },
        {
            "source": 27,
            "target": 252
        },
        {
            "source": 34,
            "target": 252
        },
        {
            "source": 34,
            "target": 86
        },
        {
            "source": 2,
            "target": 334
        },
        {
            "source": 1,
            "target": 6
        },
        {
            "source": 1,
            "target": 334
        },
        {
            "source": 2,
            "target": 77
        },
        {
            "source": 2,
            "target": 86
        },
        {
            "source": 1,
            "target": 86
        },
        {
            "source": 335,
            "target": 6
        },
        {
            "source": 336,
            "target": 6
        },
        {
            "source": 337,
            "target": 6
        },
        {
            "source": 338,
            "target": 6
        },
        {
            "source": 339,
            "target": 6
        },
        {
            "source": 3,
            "target": 6
        },
        {
            "source": 3,
            "target": 19
        },
        {
            "source": 340,
            "target": 6
        },
        {
            "source": 3,
            "target": 305
        },
        {
            "source": 3,
            "target": 77
        },
        {
            "source": 3,
            "target": 2
        },
        {
            "source": 3,
            "target": 46
        },
        {
            "source": 3,
            "target": 308
        },
        {
            "source": 335,
            "target": 87
        },
        {
            "source": 3,
            "target": 87
        },
        {
            "source": 3,
            "target": 9
        },
        {
            "source": 248,
            "target": 232
        },
        {
            "source": 232,
            "target": 341
        },
        {
            "source": 342,
            "target": 232
        },
        {
            "source": 343,
            "target": 232
        },
        {
            "source": 232,
            "target": 52
        },
        {
            "source": 248,
            "target": 242
        },
        {
            "source": 232,
            "target": 84
        },
        {
            "source": 232,
            "target": 344
        },
        {
            "source": 232,
            "target": 345
        },
        {
            "source": 232,
            "target": 346
        },
        {
            "source": 232,
            "target": 347
        },
        {
            "source": 232,
            "target": 348
        },
        {
            "source": 232,
            "target": 299
        },
        {
            "source": 232,
            "target": 264
        },
        {
            "source": 232,
            "target": 349
        },
        {
            "source": 232,
            "target": 265
        },
        {
            "source": 232,
            "target": 350
        },
        {
            "source": 232,
            "target": 266
        },
        {
            "source": 232,
            "target": 87
        },
        {
            "source": 220,
            "target": 193
        },
        {
            "source": 220,
            "target": 49
        },
        {
            "source": 220,
            "target": 86
        },
        {
            "source": 6,
            "target": 334
        },
        {
            "source": 6,
            "target": 7
        },
        {
            "source": 351,
            "target": 55
        },
        {
            "source": 93,
            "target": 52
        },
        {
            "source": 55,
            "target": 52
        },
        {
            "source": 93,
            "target": 6
        },
        {
            "source": 93,
            "target": 57
        },
        {
            "source": 55,
            "target": 57
        },
        {
            "source": 36,
            "target": 87
        },
        {
            "source": 36,
            "target": 4
        },
        {
            "source": 36,
            "target": 2
        },
        {
            "source": 36,
            "target": 9
        },
        {
            "source": 3,
            "target": 5
        },
        {
            "source": 85,
            "target": 352
        },
        {
            "source": 52,
            "target": 327
        },
        {
            "source": 353,
            "target": 19
        },
        {
            "source": 353,
            "target": 18
        },
        {
            "source": 354,
            "target": 86
        },
        {
            "source": 355,
            "target": 86
        },
        {
            "source": 353,
            "target": 86
        },
        {
            "source": 353,
            "target": 6
        },
        {
            "source": 353,
            "target": 79
        },
        {
            "source": 2,
            "target": 356
        },
        {
            "source": 83,
            "target": 86
        },
        {
            "source": 83,
            "target": 1
        },
        {
            "source": 281,
            "target": 3
        },
        {
            "source": 46,
            "target": 3
        },
        {
            "source": 1,
            "target": 324
        },
        {
            "source": 324,
            "target": 2
        },
        {
            "source": 357,
            "target": 21
        },
        {
            "source": 357,
            "target": 22
        },
        {
            "source": 83,
            "target": 6
        },
        {
            "source": 358,
            "target": 6
        },
        {
            "source": 27,
            "target": 6
        },
        {
            "source": 59,
            "target": 3
        },
        {
            "source": 198,
            "target": 3
        },
        {
            "source": 296,
            "target": 3
        },
        {
            "source": 99,
            "target": 3
        },
        {
            "source": 198,
            "target": 5
        },
        {
            "source": 296,
            "target": 291
        },
        {
            "source": 296,
            "target": 5
        },
        {
            "source": 59,
            "target": 101
        },
        {
            "source": 297,
            "target": 101
        },
        {
            "source": 198,
            "target": 101
        },
        {
            "source": 99,
            "target": 101
        },
        {
            "source": 59,
            "target": 58
        },
        {
            "source": 59,
            "target": 52
        },
        {
            "source": 297,
            "target": 52
        },
        {
            "source": 198,
            "target": 52
        },
        {
            "source": 296,
            "target": 52
        },
        {
            "source": 99,
            "target": 52
        },
        {
            "source": 59,
            "target": 99
        },
        {
            "source": 297,
            "target": 99
        },
        {
            "source": 198,
            "target": 99
        },
        {
            "source": 59,
            "target": 36
        },
        {
            "source": 296,
            "target": 36
        },
        {
            "source": 99,
            "target": 36
        },
        {
            "source": 296,
            "target": 359
        },
        {
            "source": 296,
            "target": 21
        },
        {
            "source": 296,
            "target": 22
        },
        {
            "source": 59,
            "target": 27
        },
        {
            "source": 99,
            "target": 27
        },
        {
            "source": 59,
            "target": 327
        },
        {
            "source": 99,
            "target": 360
        },
        {
            "source": 59,
            "target": 361
        },
        {
            "source": 59,
            "target": 12
        },
        {
            "source": 59,
            "target": 296
        },
        {
            "source": 198,
            "target": 192
        },
        {
            "source": 198,
            "target": 193
        },
        {
            "source": 99,
            "target": 193
        },
        {
            "source": 198,
            "target": 273
        },
        {
            "source": 71,
            "target": 70
        },
        {
            "source": 71,
            "target": 9
        },
        {
            "source": 71,
            "target": 362
        },
        {
            "source": 71,
            "target": 363
        },
        {
            "source": 364,
            "target": 101
        },
        {
            "source": 365,
            "target": 101
        },
        {
            "source": 366,
            "target": 101
        },
        {
            "source": 367,
            "target": 101
        },
        {
            "source": 128,
            "target": 108
        },
        {
            "source": 368,
            "target": 101
        },
        {
            "source": 156,
            "target": 120
        },
        {
            "source": 220,
            "target": 120
        },
        {
            "source": 207,
            "target": 27
        },
        {
            "source": 207,
            "target": 369
        },
        {
            "source": 119,
            "target": 369
        },
        {
            "source": 119,
            "target": 207
        },
        {
            "source": 370,
            "target": 174
        },
        {
            "source": 370,
            "target": 105
        },
        {
            "source": 371,
            "target": 174
        },
        {
            "source": 371,
            "target": 105
        },
        {
            "source": 370,
            "target": 175
        },
        {
            "source": 370,
            "target": 163
        },
        {
            "source": 371,
            "target": 175
        },
        {
            "source": 371,
            "target": 163
        },
        {
            "source": 128,
            "target": 138
        },
        {
            "source": 105,
            "target": 113
        },
        {
            "source": 174,
            "target": 163
        },
        {
            "source": 174,
            "target": 105
        },
        {
            "source": 372,
            "target": 174
        },
        {
            "source": 372,
            "target": 105
        },
        {
            "source": 105,
            "target": 174
        },
        {
            "source": 105,
            "target": 175
        },
        {
            "source": 105,
            "target": 163
        },
        {
            "source": 105,
            "target": 103
        },
        {
            "source": 105,
            "target": 176
        },
        {
            "source": 105,
            "target": 373
        },
        {
            "source": 105,
            "target": 374
        },
        {
            "source": 105,
            "target": 375
        },
        {
            "source": 105,
            "target": 376
        },
        {
            "source": 105,
            "target": 377
        },
        {
            "source": 378,
            "target": 95
        },
        {
            "source": 95,
            "target": 146
        },
        {
            "source": 185,
            "target": 105
        },
        {
            "source": 185,
            "target": 379
        },
        {
            "source": 185,
            "target": 123
        },
        {
            "source": 185,
            "target": 162
        },
        {
            "source": 185,
            "target": 163
        },
        {
            "source": 380,
            "target": 105
        },
        {
            "source": 145,
            "target": 379
        },
        {
            "source": 184,
            "target": 379
        },
        {
            "source": 104,
            "target": 381
        },
        {
            "source": 104,
            "target": 175
        },
        {
            "source": 104,
            "target": 112
        },
        {
            "source": 104,
            "target": 174
        },
        {
            "source": 156,
            "target": 198
        },
        {
            "source": 220,
            "target": 198
        },
        {
            "source": 112,
            "target": 120
        },
        {
            "source": 26,
            "target": 120
        },
        {
            "source": 26,
            "target": 382
        },
        {
            "source": 112,
            "target": 203
        },
        {
            "source": 26,
            "target": 203
        },
        {
            "source": 113,
            "target": 26
        },
        {
            "source": 115,
            "target": 112
        },
        {
            "source": 116,
            "target": 112
        },
        {
            "source": 115,
            "target": 119
        },
        {
            "source": 115,
            "target": 118
        },
        {
            "source": 116,
            "target": 119
        },
        {
            "source": 116,
            "target": 118
        },
        {
            "source": 114,
            "target": 207
        },
        {
            "source": 116,
            "target": 369
        },
        {
            "source": 116,
            "target": 207
        },
        {
            "source": 116,
            "target": 273
        },
        {
            "source": 138,
            "target": 120
        },
        {
            "source": 383,
            "target": 223
        },
        {
            "source": 223,
            "target": 164
        },
        {
            "source": 180,
            "target": 384
        },
        {
            "source": 180,
            "target": 163
        },
        {
            "source": 180,
            "target": 212
        },
        {
            "source": 385,
            "target": 101
        },
        {
            "source": 112,
            "target": 153
        },
        {
            "source": 152,
            "target": 120
        },
        {
            "source": 191,
            "target": 214
        },
        {
            "source": 191,
            "target": 215
        },
        {
            "source": 191,
            "target": 192
        },
        {
            "source": 193,
            "target": 192
        },
        {
            "source": 193,
            "target": 273
        },
        {
            "source": 193,
            "target": 26
        },
        {
            "source": 198,
            "target": 207
        },
        {
            "source": 101,
            "target": 386
        },
        {
            "source": 101,
            "target": 207
        },
        {
            "source": 180,
            "target": 207
        },
        {
            "source": 101,
            "target": 191
        },
        {
            "source": 101,
            "target": 192
        },
        {
            "source": 101,
            "target": 193
        },
        {
            "source": 387,
            "target": 112
        },
        {
            "source": 388,
            "target": 112
        },
        {
            "source": 389,
            "target": 112
        },
        {
            "source": 390,
            "target": 112
        },
        {
            "source": 390,
            "target": 140
        },
        {
            "source": 391,
            "target": 392
        },
        {
            "source": 392,
            "target": 393
        },
        {
            "source": 391,
            "target": 393
        },
        {
            "source": 27,
            "target": 207
        },
        {
            "source": 394,
            "target": 395
        },
        {
            "source": 394,
            "target": 206
        },
        {
            "source": 395,
            "target": 396
        },
        {
            "source": 395,
            "target": 397
        },
        {
            "source": 395,
            "target": 206
        },
        {
            "source": 398,
            "target": 232
        },
        {
            "source": 398,
            "target": 8
        },
        {
            "source": 252,
            "target": 232
        },
        {
            "source": 252,
            "target": 8
        },
        {
            "source": 233,
            "target": 12
        },
        {
            "source": 254,
            "target": 399
        },
        {
            "source": 254,
            "target": 400
        },
        {
            "source": 254,
            "target": 401
        },
        {
            "source": 254,
            "target": 402
        },
        {
            "source": 112,
            "target": 3
        },
        {
            "source": 112,
            "target": 111
        },
        {
            "source": 403,
            "target": 8
        },
        {
            "source": 404,
            "target": 8
        },
        {
            "source": 405,
            "target": 120
        },
        {
            "source": 272,
            "target": 12
        },
        {
            "source": 352,
            "target": 12
        },
        {
            "source": 273,
            "target": 12
        },
        {
            "source": 273,
            "target": 352
        },
        {
            "source": 273,
            "target": 6
        },
        {
            "source": 406,
            "target": 46
        },
        {
            "source": 406,
            "target": 3
        },
        {
            "source": 352,
            "target": 3
        },
        {
            "source": 273,
            "target": 46
        },
        {
            "source": 273,
            "target": 3
        },
        {
            "source": 406,
            "target": 36
        },
        {
            "source": 406,
            "target": 275
        },
        {
            "source": 273,
            "target": 36
        },
        {
            "source": 273,
            "target": 275
        },
        {
            "source": 193,
            "target": 2
        },
        {
            "source": 8,
            "target": 248
        },
        {
            "source": 8,
            "target": 232
        },
        {
            "source": 8,
            "target": 242
        },
        {
            "source": 8,
            "target": 84
        },
        {
            "source": 8,
            "target": 344
        },
        {
            "source": 8,
            "target": 345
        },
        {
            "source": 8,
            "target": 346
        },
        {
            "source": 101,
            "target": 146
        },
        {
            "source": 8,
            "target": 198
        },
        {
            "source": 8,
            "target": 317
        },
        {
            "source": 8,
            "target": 407
        },
        {
            "source": 8,
            "target": 7
        },
        {
            "source": 8,
            "target": 408
        },
        {
            "source": 8,
            "target": 49
        },
        {
            "source": 403,
            "target": 3
        },
        {
            "source": 35,
            "target": 252
        },
        {
            "source": 34,
            "target": 52
        },
        {
            "source": 27,
            "target": 58
        },
        {
            "source": 101,
            "target": 35
        },
        {
            "source": 101,
            "target": 291
        },
        {
            "source": 101,
            "target": 292
        },
        {
            "source": 268,
            "target": 5
        },
        {
            "source": 101,
            "target": 36
        },
        {
            "source": 101,
            "target": 409
        },
        {
            "source": 101,
            "target": 21
        },
        {
            "source": 299,
            "target": 348
        },
        {
            "source": 299,
            "target": 12
        },
        {
            "source": 299,
            "target": 410
        },
        {
            "source": 299,
            "target": 411
        },
        {
            "source": 299,
            "target": 412
        },
        {
            "source": 299,
            "target": 87
        },
        {
            "source": 4,
            "target": 55
        },
        {
            "source": 4,
            "target": 46
        },
        {
            "source": 4,
            "target": 52
        },
        {
            "source": 413,
            "target": 232
        },
        {
            "source": 245,
            "target": 239
        },
        {
            "source": 245,
            "target": 232
        },
        {
            "source": 245,
            "target": 242
        },
        {
            "source": 246,
            "target": 232
        },
        {
            "source": 246,
            "target": 242
        },
        {
            "source": 247,
            "target": 232
        },
        {
            "source": 247,
            "target": 242
        },
        {
            "source": 404,
            "target": 232
        },
        {
            "source": 413,
            "target": 8
        },
        {
            "source": 245,
            "target": 8
        },
        {
            "source": 246,
            "target": 8
        },
        {
            "source": 247,
            "target": 8
        },
        {
            "source": 245,
            "target": 71
        },
        {
            "source": 232,
            "target": 277
        },
        {
            "source": 232,
            "target": 71
        },
        {
            "source": 245,
            "target": 248
        },
        {
            "source": 245,
            "target": 84
        },
        {
            "source": 245,
            "target": 344
        },
        {
            "source": 245,
            "target": 345
        },
        {
            "source": 245,
            "target": 346
        },
        {
            "source": 246,
            "target": 248
        },
        {
            "source": 246,
            "target": 84
        },
        {
            "source": 247,
            "target": 248
        },
        {
            "source": 247,
            "target": 84
        },
        {
            "source": 245,
            "target": 250
        },
        {
            "source": 245,
            "target": 403
        },
        {
            "source": 232,
            "target": 403
        },
        {
            "source": 245,
            "target": 231
        },
        {
            "source": 246,
            "target": 245
        },
        {
            "source": 247,
            "target": 245
        },
        {
            "source": 245,
            "target": 251
        },
        {
            "source": 245,
            "target": 246
        },
        {
            "source": 245,
            "target": 247
        },
        {
            "source": 12,
            "target": 3
        },
        {
            "source": 48,
            "target": 314
        },
        {
            "source": 193,
            "target": 52
        },
        {
            "source": 357,
            "target": 281
        },
        {
            "source": 357,
            "target": 12
        },
        {
            "source": 26,
            "target": 267
        },
        {
            "source": 26,
            "target": 273
        },
        {
            "source": 274,
            "target": 6
        },
        {
            "source": 26,
            "target": 265
        },
        {
            "source": 274,
            "target": 414
        },
        {
            "source": 274,
            "target": 3
        },
        {
            "source": 12,
            "target": 36
        },
        {
            "source": 29,
            "target": 46
        },
        {
            "source": 29,
            "target": 3
        },
        {
            "source": 317,
            "target": 3
        },
        {
            "source": 29,
            "target": 258
        },
        {
            "source": 84,
            "target": 242
        },
        {
            "source": 8,
            "target": 241
        },
        {
            "source": 8,
            "target": 239
        },
        {
            "source": 8,
            "target": 243
        },
        {
            "source": 8,
            "target": 244
        },
        {
            "source": 232,
            "target": 70
        },
        {
            "source": 232,
            "target": 415
        },
        {
            "source": 8,
            "target": 70
        },
        {
            "source": 8,
            "target": 415
        },
        {
            "source": 245,
            "target": 112
        },
        {
            "source": 8,
            "target": 112
        },
        {
            "source": 84,
            "target": 86
        },
        {
            "source": 245,
            "target": 86
        },
        {
            "source": 232,
            "target": 329
        },
        {
            "source": 232,
            "target": 416
        },
        {
            "source": 232,
            "target": 417
        },
        {
            "source": 232,
            "target": 86
        },
        {
            "source": 249,
            "target": 86
        },
        {
            "source": 8,
            "target": 329
        },
        {
            "source": 8,
            "target": 416
        },
        {
            "source": 8,
            "target": 417
        },
        {
            "source": 8,
            "target": 86
        },
        {
            "source": 418,
            "target": 254
        },
        {
            "source": 402,
            "target": 254
        },
        {
            "source": 254,
            "target": 412
        },
        {
            "source": 254,
            "target": 46
        },
        {
            "source": 254,
            "target": 323
        },
        {
            "source": 419,
            "target": 296
        },
        {
            "source": 420,
            "target": 232
        },
        {
            "source": 420,
            "target": 8
        },
        {
            "source": 421,
            "target": 232
        },
        {
            "source": 421,
            "target": 8
        },
        {
            "source": 420,
            "target": 245
        },
        {
            "source": 421,
            "target": 245
        },
        {
            "source": 232,
            "target": 12
        },
        {
            "source": 244,
            "target": 232
        },
        {
            "source": 273,
            "target": 274
        },
        {
            "source": 273,
            "target": 272
        },
        {
            "source": 305,
            "target": 2
        },
        {
            "source": 294,
            "target": 291
        },
        {
            "source": 294,
            "target": 5
        },
        {
            "source": 294,
            "target": 101
        },
        {
            "source": 422,
            "target": 101
        },
        {
            "source": 294,
            "target": 295
        },
        {
            "source": 294,
            "target": 423
        },
        {
            "source": 294,
            "target": 424
        },
        {
            "source": 294,
            "target": 425
        },
        {
            "source": 422,
            "target": 294
        },
        {
            "source": 422,
            "target": 295
        },
        {
            "source": 422,
            "target": 423
        },
        {
            "source": 422,
            "target": 424
        },
        {
            "source": 422,
            "target": 425
        },
        {
            "source": 101,
            "target": 294
        },
        {
            "source": 101,
            "target": 295
        },
        {
            "source": 101,
            "target": 423
        },
        {
            "source": 101,
            "target": 424
        },
        {
            "source": 101,
            "target": 425
        },
        {
            "source": 327,
            "target": 276
        },
        {
            "source": 327,
            "target": 45
        },
        {
            "source": 327,
            "target": 3
        },
        {
            "source": 327,
            "target": 299
        },
        {
            "source": 327,
            "target": 6
        },
        {
            "source": 327,
            "target": 334
        },
        {
            "source": 327,
            "target": 281
        },
        {
            "source": 426,
            "target": 232
        },
        {
            "source": 426,
            "target": 8
        },
        {
            "source": 427,
            "target": 232
        },
        {
            "source": 427,
            "target": 8
        },
        {
            "source": 428,
            "target": 232
        },
        {
            "source": 428,
            "target": 8
        },
        {
            "source": 429,
            "target": 232
        },
        {
            "source": 429,
            "target": 8
        },
        {
            "source": 426,
            "target": 245
        },
        {
            "source": 427,
            "target": 245
        },
        {
            "source": 428,
            "target": 245
        },
        {
            "source": 429,
            "target": 245
        },
        {
            "source": 430,
            "target": 3
        },
        {
            "source": 348,
            "target": 87
        },
        {
            "source": 431,
            "target": 87
        },
        {
            "source": 403,
            "target": 112
        },
        {
            "source": 281,
            "target": 266
        },
        {
            "source": 432,
            "target": 3
        },
        {
            "source": 26,
            "target": 46
        },
        {
            "source": 26,
            "target": 323
        },
        {
            "source": 273,
            "target": 101
        },
        {
            "source": 265,
            "target": 3
        },
        {
            "source": 273,
            "target": 5
        },
        {
            "source": 403,
            "target": 12
        },
        {
            "source": 112,
            "target": 138
        },
        {
            "source": 403,
            "target": 111
        },
        {
            "source": 112,
            "target": 433
        },
        {
            "source": 112,
            "target": 8
        },
        {
            "source": 434,
            "target": 5
        },
        {
            "source": 291,
            "target": 185
        },
        {
            "source": 5,
            "target": 185
        },
        {
            "source": 5,
            "target": 162
        },
        {
            "source": 435,
            "target": 214
        },
        {
            "source": 435,
            "target": 215
        },
        {
            "source": 436,
            "target": 214
        },
        {
            "source": 436,
            "target": 215
        },
        {
            "source": 437,
            "target": 214
        },
        {
            "source": 437,
            "target": 215
        },
        {
            "source": 438,
            "target": 214
        },
        {
            "source": 438,
            "target": 215
        },
        {
            "source": 220,
            "target": 116
        },
        {
            "source": 5,
            "target": 146
        },
        {
            "source": 5,
            "target": 26
        },
        {
            "source": 439,
            "target": 440
        },
        {
            "source": 439,
            "target": 441
        },
        {
            "source": 439,
            "target": 5
        },
        {
            "source": 5,
            "target": 441
        },
        {
            "source": 441,
            "target": 439
        },
        {
            "source": 441,
            "target": 440
        },
        {
            "source": 441,
            "target": 5
        },
        {
            "source": 5,
            "target": 36
        },
        {
            "source": 101,
            "target": 442
        },
        {
            "source": 443,
            "target": 101
        },
        {
            "source": 101,
            "target": 352
        },
        {
            "source": 198,
            "target": 352
        },
        {
            "source": 322,
            "target": 70
        },
        {
            "source": 322,
            "target": 71
        },
        {
            "source": 322,
            "target": 9
        },
        {
            "source": 49,
            "target": 70
        },
        {
            "source": 49,
            "target": 71
        },
        {
            "source": 408,
            "target": 71
        },
        {
            "source": 408,
            "target": 9
        },
        {
            "source": 408,
            "target": 363
        },
        {
            "source": 49,
            "target": 19
        },
        {
            "source": 408,
            "target": 19
        },
        {
            "source": 444,
            "target": 6
        },
        {
            "source": 322,
            "target": 6
        },
        {
            "source": 49,
            "target": 6
        },
        {
            "source": 408,
            "target": 6
        },
        {
            "source": 445,
            "target": 6
        },
        {
            "source": 52,
            "target": 446
        },
        {
            "source": 52,
            "target": 447
        },
        {
            "source": 52,
            "target": 7
        },
        {
            "source": 52,
            "target": 307
        },
        {
            "source": 52,
            "target": 334
        },
        {
            "source": 83,
            "target": 3
        },
        {
            "source": 332,
            "target": 2
        },
        {
            "source": 332,
            "target": 307
        },
        {
            "source": 332,
            "target": 448
        },
        {
            "source": 332,
            "target": 449
        },
        {
            "source": 220,
            "target": 281
        },
        {
            "source": 220,
            "target": 21
        },
        {
            "source": 220,
            "target": 22
        },
        {
            "source": 450,
            "target": 21
        },
        {
            "source": 450,
            "target": 22
        },
        {
            "source": 288,
            "target": 21
        },
        {
            "source": 288,
            "target": 22
        },
        {
            "source": 451,
            "target": 21
        },
        {
            "source": 451,
            "target": 22
        },
        {
            "source": 220,
            "target": 308
        },
        {
            "source": 220,
            "target": 309
        },
        {
            "source": 220,
            "target": 410
        },
        {
            "source": 220,
            "target": 452
        },
        {
            "source": 327,
            "target": 52
        },
        {
            "source": 35,
            "target": 31
        },
        {
            "source": 35,
            "target": 34
        },
        {
            "source": 332,
            "target": 8
        },
        {
            "source": 332,
            "target": 453
        },
        {
            "source": 2,
            "target": 332
        },
        {
            "source": 1,
            "target": 52
        },
        {
            "source": 454,
            "target": 18
        },
        {
            "source": 439,
            "target": 2
        },
        {
            "source": 440,
            "target": 2
        },
        {
            "source": 441,
            "target": 2
        },
        {
            "source": 440,
            "target": 5
        },
        {
            "source": 5,
            "target": 442
        },
        {
            "source": 49,
            "target": 1
        },
        {
            "source": 49,
            "target": 86
        },
        {
            "source": 2,
            "target": 3
        },
        {
            "source": 251,
            "target": 84
        },
        {
            "source": 251,
            "target": 248
        },
        {
            "source": 251,
            "target": 232
        },
        {
            "source": 251,
            "target": 8
        },
        {
            "source": 232,
            "target": 7
        },
        {
            "source": 232,
            "target": 455
        },
        {
            "source": 87,
            "target": 6
        },
        {
            "source": 116,
            "target": 36
        },
        {
            "source": 27,
            "target": 99
        },
        {
            "source": 112,
            "target": 101
        },
        {
            "source": 112,
            "target": 456
        },
        {
            "source": 112,
            "target": 457
        },
        {
            "source": 99,
            "target": 140
        },
        {
            "source": 97,
            "target": 52
        },
        {
            "source": 59,
            "target": 55
        },
        {
            "source": 99,
            "target": 314
        },
        {
            "source": 458,
            "target": 212
        },
        {
            "source": 379,
            "target": 185
        },
        {
            "source": 379,
            "target": 212
        },
        {
            "source": 458,
            "target": 379
        },
        {
            "source": 379,
            "target": 142
        },
        {
            "source": 379,
            "target": 162
        },
        {
            "source": 115,
            "target": 101
        },
        {
            "source": 114,
            "target": 459
        },
        {
            "source": 116,
            "target": 459
        },
        {
            "source": 116,
            "target": 164
        },
        {
            "source": 116,
            "target": 16
        },
        {
            "source": 223,
            "target": 175
        },
        {
            "source": 223,
            "target": 105
        },
        {
            "source": 120,
            "target": 193
        },
        {
            "source": 120,
            "target": 36
        },
        {
            "source": 120,
            "target": 460
        },
        {
            "source": 212,
            "target": 461
        },
        {
            "source": 212,
            "target": 286
        },
        {
            "source": 206,
            "target": 101
        },
        {
            "source": 462,
            "target": 203
        },
        {
            "source": 206,
            "target": 203
        },
        {
            "source": 203,
            "target": 463
        },
        {
            "source": 464,
            "target": 185
        },
        {
            "source": 464,
            "target": 379
        },
        {
            "source": 464,
            "target": 162
        },
        {
            "source": 212,
            "target": 185
        },
        {
            "source": 212,
            "target": 379
        },
        {
            "source": 212,
            "target": 162
        },
        {
            "source": 27,
            "target": 95
        },
        {
            "source": 95,
            "target": 369
        },
        {
            "source": 95,
            "target": 141
        },
        {
            "source": 95,
            "target": 207
        },
        {
            "source": 383,
            "target": 105
        },
        {
            "source": 465,
            "target": 120
        },
        {
            "source": 465,
            "target": 149
        },
        {
            "source": 175,
            "target": 174
        },
        {
            "source": 175,
            "target": 223
        },
        {
            "source": 175,
            "target": 163
        },
        {
            "source": 466,
            "target": 112
        },
        {
            "source": 297,
            "target": 112
        },
        {
            "source": 101,
            "target": 369
        },
        {
            "source": 101,
            "target": 141
        },
        {
            "source": 134,
            "target": 135
        },
        {
            "source": 134,
            "target": 199
        },
        {
            "source": 134,
            "target": 67
        },
        {
            "source": 134,
            "target": 200
        },
        {
            "source": 134,
            "target": 101
        },
        {
            "source": 134,
            "target": 201
        },
        {
            "source": 134,
            "target": 64
        },
        {
            "source": 11,
            "target": 185
        },
        {
            "source": 11,
            "target": 163
        },
        {
            "source": 11,
            "target": 162
        },
        {
            "source": 11,
            "target": 212
        },
        {
            "source": 467,
            "target": 468
        },
        {
            "source": 467,
            "target": 469
        },
        {
            "source": 443,
            "target": 107
        },
        {
            "source": 470,
            "target": 101
        },
        {
            "source": 470,
            "target": 107
        },
        {
            "source": 471,
            "target": 101
        },
        {
            "source": 471,
            "target": 107
        },
        {
            "source": 472,
            "target": 101
        },
        {
            "source": 472,
            "target": 107
        },
        {
            "source": 473,
            "target": 101
        },
        {
            "source": 473,
            "target": 107
        },
        {
            "source": 474,
            "target": 101
        },
        {
            "source": 474,
            "target": 107
        },
        {
            "source": 101,
            "target": 475
        },
        {
            "source": 101,
            "target": 476
        },
        {
            "source": 101,
            "target": 477
        },
        {
            "source": 101,
            "target": 473
        },
        {
            "source": 101,
            "target": 478
        },
        {
            "source": 198,
            "target": 473
        },
        {
            "source": 198,
            "target": 478
        },
        {
            "source": 198,
            "target": 107
        },
        {
            "source": 470,
            "target": 106
        },
        {
            "source": 470,
            "target": 108
        },
        {
            "source": 471,
            "target": 106
        },
        {
            "source": 471,
            "target": 108
        },
        {
            "source": 472,
            "target": 106
        },
        {
            "source": 472,
            "target": 108
        },
        {
            "source": 473,
            "target": 106
        },
        {
            "source": 473,
            "target": 108
        },
        {
            "source": 198,
            "target": 106
        },
        {
            "source": 198,
            "target": 108
        },
        {
            "source": 101,
            "target": 110
        },
        {
            "source": 101,
            "target": 479
        },
        {
            "source": 101,
            "target": 480
        },
        {
            "source": 198,
            "target": 110
        },
        {
            "source": 198,
            "target": 479
        },
        {
            "source": 198,
            "target": 480
        },
        {
            "source": 198,
            "target": 112
        },
        {
            "source": 473,
            "target": 109
        },
        {
            "source": 101,
            "target": 481
        },
        {
            "source": 482,
            "target": 6
        },
        {
            "source": 264,
            "target": 242
        },
        {
            "source": 264,
            "target": 244
        },
        {
            "source": 265,
            "target": 242
        },
        {
            "source": 265,
            "target": 244
        },
        {
            "source": 252,
            "target": 87
        },
        {
            "source": 140,
            "target": 146
        },
        {
            "source": 140,
            "target": 113
        },
        {
            "source": 26,
            "target": 36
        },
        {
            "source": 267,
            "target": 3
        },
        {
            "source": 215,
            "target": 483
        },
        {
            "source": 215,
            "target": 484
        },
        {
            "source": 214,
            "target": 483
        },
        {
            "source": 214,
            "target": 484
        },
        {
            "source": 485,
            "target": 254
        },
        {
            "source": 485,
            "target": 258
        },
        {
            "source": 485,
            "target": 3
        },
        {
            "source": 486,
            "target": 6
        },
        {
            "source": 487,
            "target": 6
        },
        {
            "source": 440,
            "target": 6
        },
        {
            "source": 439,
            "target": 6
        },
        {
            "source": 441,
            "target": 6
        },
        {
            "source": 488,
            "target": 352
        },
        {
            "source": 489,
            "target": 352
        },
        {
            "source": 490,
            "target": 352
        },
        {
            "source": 491,
            "target": 352
        },
        {
            "source": 352,
            "target": 492
        },
        {
            "source": 101,
            "target": 493
        },
        {
            "source": 78,
            "target": 2
        },
        {
            "source": 78,
            "target": 46
        },
        {
            "source": 78,
            "target": 3
        },
        {
            "source": 78,
            "target": 258
        },
        {
            "source": 78,
            "target": 323
        },
        {
            "source": 250,
            "target": 232
        },
        {
            "source": 250,
            "target": 242
        },
        {
            "source": 250,
            "target": 8
        },
        {
            "source": 250,
            "target": 86
        },
        {
            "source": 8,
            "target": 36
        },
        {
            "source": 494,
            "target": 214
        },
        {
            "source": 494,
            "target": 215
        },
        {
            "source": 320,
            "target": 214
        },
        {
            "source": 320,
            "target": 215
        },
        {
            "source": 220,
            "target": 112
        },
        {
            "source": 49,
            "target": 3
        },
        {
            "source": 1,
            "target": 3
        },
        {
            "source": 322,
            "target": 3
        },
        {
            "source": 322,
            "target": 1
        },
        {
            "source": 322,
            "target": 86
        },
        {
            "source": 86,
            "target": 1
        },
        {
            "source": 322,
            "target": 2
        },
        {
            "source": 495,
            "target": 2
        },
        {
            "source": 496,
            "target": 2
        },
        {
            "source": 112,
            "target": 71
        },
        {
            "source": 58,
            "target": 27
        },
        {
            "source": 65,
            "target": 21
        },
        {
            "source": 65,
            "target": 22
        },
        {
            "source": 2,
            "target": 21
        },
        {
            "source": 218,
            "target": 2
        },
        {
            "source": 329,
            "target": 252
        },
        {
            "source": 329,
            "target": 71
        },
        {
            "source": 322,
            "target": 252
        },
        {
            "source": 248,
            "target": 71
        },
        {
            "source": 84,
            "target": 12
        },
        {
            "source": 248,
            "target": 12
        },
        {
            "source": 250,
            "target": 12
        },
        {
            "source": 248,
            "target": 86
        },
        {
            "source": 52,
            "target": 356
        },
        {
            "source": 52,
            "target": 2
        },
        {
            "source": 497,
            "target": 52
        },
        {
            "source": 498,
            "target": 52
        },
        {
            "source": 92,
            "target": 21
        },
        {
            "source": 94,
            "target": 21
        },
        {
            "source": 5,
            "target": 21
        },
        {
            "source": 5,
            "target": 123
        },
        {
            "source": 94,
            "target": 5
        },
        {
            "source": 5,
            "target": 22
        },
        {
            "source": 93,
            "target": 334
        },
        {
            "source": 3,
            "target": 7
        },
        {
            "source": 272,
            "target": 412
        },
        {
            "source": 273,
            "target": 412
        },
        {
            "source": 273,
            "target": 493
        },
        {
            "source": 272,
            "target": 273
        },
        {
            "source": 272,
            "target": 146
        },
        {
            "source": 273,
            "target": 146
        },
        {
            "source": 4,
            "target": 12
        },
        {
            "source": 219,
            "target": 112
        },
        {
            "source": 214,
            "target": 499
        },
        {
            "source": 214,
            "target": 500
        },
        {
            "source": 214,
            "target": 111
        },
        {
            "source": 214,
            "target": 112
        },
        {
            "source": 215,
            "target": 499
        },
        {
            "source": 215,
            "target": 500
        },
        {
            "source": 215,
            "target": 111
        },
        {
            "source": 215,
            "target": 112
        },
        {
            "source": 352,
            "target": 273
        },
        {
            "source": 112,
            "target": 5
        },
        {
            "source": 245,
            "target": 111
        },
        {
            "source": 146,
            "target": 493
        },
        {
            "source": 233,
            "target": 70
        },
        {
            "source": 233,
            "target": 71
        },
        {
            "source": 234,
            "target": 70
        },
        {
            "source": 234,
            "target": 71
        },
        {
            "source": 78,
            "target": 18
        },
        {
            "source": 78,
            "target": 21
        },
        {
            "source": 48,
            "target": 266
        },
        {
            "source": 48,
            "target": 281
        },
        {
            "source": 3,
            "target": 254
        },
        {
            "source": 3,
            "target": 45
        },
        {
            "source": 45,
            "target": 258
        },
        {
            "source": 3,
            "target": 258
        },
        {
            "source": 3,
            "target": 323
        },
        {
            "source": 501,
            "target": 315
        },
        {
            "source": 315,
            "target": 502
        },
        {
            "source": 501,
            "target": 503
        },
        {
            "source": 315,
            "target": 503
        },
        {
            "source": 501,
            "target": 193
        },
        {
            "source": 504,
            "target": 12
        },
        {
            "source": 264,
            "target": 6
        },
        {
            "source": 264,
            "target": 3
        },
        {
            "source": 266,
            "target": 46
        },
        {
            "source": 244,
            "target": 3
        },
        {
            "source": 505,
            "target": 101
        },
        {
            "source": 478,
            "target": 101
        },
        {
            "source": 478,
            "target": 106
        },
        {
            "source": 101,
            "target": 506
        },
        {
            "source": 478,
            "target": 107
        },
        {
            "source": 478,
            "target": 108
        },
        {
            "source": 478,
            "target": 109
        },
        {
            "source": 101,
            "target": 203
        },
        {
            "source": 12,
            "target": 507
        },
        {
            "source": 12,
            "target": 13
        },
        {
            "source": 12,
            "target": 508
        },
        {
            "source": 361,
            "target": 21
        },
        {
            "source": 361,
            "target": 22
        },
        {
            "source": 12,
            "target": 22
        },
        {
            "source": 12,
            "target": 87
        },
        {
            "source": 78,
            "target": 6
        },
        {
            "source": 314,
            "target": 99
        },
        {
            "source": 314,
            "target": 509
        },
        {
            "source": 314,
            "target": 510
        },
        {
            "source": 511,
            "target": 26
        },
        {
            "source": 512,
            "target": 26
        },
        {
            "source": 513,
            "target": 26
        },
        {
            "source": 123,
            "target": 142
        },
        {
            "source": 123,
            "target": 143
        },
        {
            "source": 514,
            "target": 105
        },
        {
            "source": 135,
            "target": 101
        },
        {
            "source": 135,
            "target": 64
        },
        {
            "source": 515,
            "target": 112
        },
        {
            "source": 179,
            "target": 112
        },
        {
            "source": 175,
            "target": 113
        },
        {
            "source": 175,
            "target": 103
        },
        {
            "source": 175,
            "target": 176
        },
        {
            "source": 175,
            "target": 375
        },
        {
            "source": 175,
            "target": 376
        },
        {
            "source": 175,
            "target": 377
        },
        {
            "source": 212,
            "target": 516
        },
        {
            "source": 212,
            "target": 184
        },
        {
            "source": 212,
            "target": 11
        },
        {
            "source": 212,
            "target": 145
        },
        {
            "source": 464,
            "target": 212
        },
        {
            "source": 212,
            "target": 163
        },
        {
            "source": 212,
            "target": 517
        },
        {
            "source": 212,
            "target": 518
        },
        {
            "source": 212,
            "target": 123
        },
        {
            "source": 212,
            "target": 138
        },
        {
            "source": 519,
            "target": 520
        },
        {
            "source": 378,
            "target": 520
        },
        {
            "source": 521,
            "target": 96
        },
        {
            "source": 522,
            "target": 96
        },
        {
            "source": 521,
            "target": 523
        },
        {
            "source": 522,
            "target": 523
        },
        {
            "source": 521,
            "target": 493
        },
        {
            "source": 522,
            "target": 493
        },
        {
            "source": 112,
            "target": 369
        },
        {
            "source": 112,
            "target": 207
        },
        {
            "source": 105,
            "target": 164
        },
        {
            "source": 105,
            "target": 524
        },
        {
            "source": 105,
            "target": 525
        },
        {
            "source": 105,
            "target": 104
        },
        {
            "source": 390,
            "target": 352
        },
        {
            "source": 526,
            "target": 245
        },
        {
            "source": 526,
            "target": 8
        },
        {
            "source": 527,
            "target": 245
        },
        {
            "source": 527,
            "target": 8
        },
        {
            "source": 314,
            "target": 245
        },
        {
            "source": 314,
            "target": 8
        },
        {
            "source": 526,
            "target": 314
        },
        {
            "source": 527,
            "target": 314
        },
        {
            "source": 180,
            "target": 155
        },
        {
            "source": 180,
            "target": 138
        },
        {
            "source": 424,
            "target": 294
        },
        {
            "source": 424,
            "target": 295
        },
        {
            "source": 424,
            "target": 101
        },
        {
            "source": 295,
            "target": 294
        },
        {
            "source": 295,
            "target": 101
        },
        {
            "source": 424,
            "target": 142
        },
        {
            "source": 295,
            "target": 142
        },
        {
            "source": 123,
            "target": 207
        },
        {
            "source": 442,
            "target": 5
        },
        {
            "source": 180,
            "target": 112
        },
        {
            "source": 180,
            "target": 5
        },
        {
            "source": 423,
            "target": 294
        },
        {
            "source": 423,
            "target": 295
        },
        {
            "source": 423,
            "target": 424
        },
        {
            "source": 423,
            "target": 425
        },
        {
            "source": 423,
            "target": 101
        },
        {
            "source": 101,
            "target": 273
        },
        {
            "source": 528,
            "target": 314
        },
        {
            "source": 529,
            "target": 123
        },
        {
            "source": 379,
            "target": 123
        },
        {
            "source": 379,
            "target": 11
        },
        {
            "source": 379,
            "target": 145
        },
        {
            "source": 379,
            "target": 140
        },
        {
            "source": 138,
            "target": 530
        },
        {
            "source": 138,
            "target": 531
        },
        {
            "source": 532,
            "target": 155
        },
        {
            "source": 532,
            "target": 138
        },
        {
            "source": 138,
            "target": 155
        },
        {
            "source": 138,
            "target": 533
        },
        {
            "source": 138,
            "target": 534
        },
        {
            "source": 163,
            "target": 123
        },
        {
            "source": 162,
            "target": 185
        },
        {
            "source": 116,
            "target": 140
        },
        {
            "source": 26,
            "target": 175
        },
        {
            "source": 26,
            "target": 105
        },
        {
            "source": 162,
            "target": 212
        },
        {
            "source": 115,
            "target": 142
        },
        {
            "source": 173,
            "target": 120
        },
        {
            "source": 2,
            "target": 9
        },
        {
            "source": 535,
            "target": 308
        },
        {
            "source": 535,
            "target": 309
        },
        {
            "source": 536,
            "target": 5
        },
        {
            "source": 77,
            "target": 6
        },
        {
            "source": 537,
            "target": 6
        },
        {
            "source": 77,
            "target": 334
        },
        {
            "source": 77,
            "target": 71
        },
        {
            "source": 6,
            "target": 2
        },
        {
            "source": 538,
            "target": 2
        },
        {
            "source": 539,
            "target": 2
        },
        {
            "source": 8,
            "target": 308
        },
        {
            "source": 8,
            "target": 309
        },
        {
            "source": 299,
            "target": 71
        },
        {
            "source": 540,
            "target": 71
        },
        {
            "source": 8,
            "target": 21
        },
        {
            "source": 8,
            "target": 22
        },
        {
            "source": 541,
            "target": 542
        },
        {
            "source": 541,
            "target": 543
        },
        {
            "source": 544,
            "target": 502
        },
        {
            "source": 545,
            "target": 332
        },
        {
            "source": 502,
            "target": 503
        },
        {
            "source": 361,
            "target": 12
        },
        {
            "source": 12,
            "target": 546
        },
        {
            "source": 14,
            "target": 507
        },
        {
            "source": 14,
            "target": 13
        },
        {
            "source": 14,
            "target": 508
        },
        {
            "source": 16,
            "target": 507
        },
        {
            "source": 16,
            "target": 13
        },
        {
            "source": 16,
            "target": 508
        },
        {
            "source": 14,
            "target": 15
        },
        {
            "source": 14,
            "target": 11
        },
        {
            "source": 14,
            "target": 16
        },
        {
            "source": 16,
            "target": 14
        },
        {
            "source": 16,
            "target": 15
        },
        {
            "source": 16,
            "target": 11
        },
        {
            "source": 14,
            "target": 63
        },
        {
            "source": 14,
            "target": 12
        },
        {
            "source": 16,
            "target": 63
        },
        {
            "source": 16,
            "target": 12
        },
        {
            "source": 242,
            "target": 70
        },
        {
            "source": 242,
            "target": 71
        },
        {
            "source": 344,
            "target": 71
        },
        {
            "source": 345,
            "target": 71
        },
        {
            "source": 346,
            "target": 71
        },
        {
            "source": 264,
            "target": 535
        },
        {
            "source": 547,
            "target": 266
        },
        {
            "source": 266,
            "target": 548
        },
        {
            "source": 266,
            "target": 535
        },
        {
            "source": 266,
            "target": 50
        },
        {
            "source": 273,
            "target": 112
        },
        {
            "source": 36,
            "target": 549
        },
        {
            "source": 36,
            "target": 550
        },
        {
            "source": 48,
            "target": 535
        },
        {
            "source": 48,
            "target": 3
        },
        {
            "source": 46,
            "target": 87
        },
        {
            "source": 46,
            "target": 258
        },
        {
            "source": 46,
            "target": 323
        },
        {
            "source": 2,
            "target": 307
        },
        {
            "source": 2,
            "target": 449
        },
        {
            "source": 15,
            "target": 63
        },
        {
            "source": 21,
            "target": 281
        },
        {
            "source": 22,
            "target": 281
        },
        {
            "source": 21,
            "target": 22
        },
        {
            "source": 22,
            "target": 21
        },
        {
            "source": 281,
            "target": 71
        },
        {
            "source": 281,
            "target": 9
        },
        {
            "source": 8,
            "target": 111
        },
        {
            "source": 316,
            "target": 3
        },
        {
            "source": 316,
            "target": 46
        },
        {
            "source": 316,
            "target": 266
        },
        {
            "source": 273,
            "target": 99
        },
        {
            "source": 551,
            "target": 105
        },
        {
            "source": 162,
            "target": 140
        },
        {
            "source": 175,
            "target": 164
        },
        {
            "source": 175,
            "target": 123
        },
        {
            "source": 105,
            "target": 123
        },
        {
            "source": 552,
            "target": 123
        },
        {
            "source": 163,
            "target": 164
        },
        {
            "source": 403,
            "target": 314
        },
        {
            "source": 403,
            "target": 99
        },
        {
            "source": 553,
            "target": 554
        },
        {
            "source": 553,
            "target": 461
        },
        {
            "source": 555,
            "target": 554
        },
        {
            "source": 555,
            "target": 461
        },
        {
            "source": 556,
            "target": 554
        },
        {
            "source": 556,
            "target": 461
        },
        {
            "source": 557,
            "target": 554
        },
        {
            "source": 557,
            "target": 461
        },
        {
            "source": 558,
            "target": 554
        },
        {
            "source": 558,
            "target": 461
        },
        {
            "source": 536,
            "target": 554
        },
        {
            "source": 536,
            "target": 461
        },
        {
            "source": 559,
            "target": 554
        },
        {
            "source": 559,
            "target": 461
        },
        {
            "source": 536,
            "target": 36
        },
        {
            "source": 536,
            "target": 123
        },
        {
            "source": 553,
            "target": 162
        },
        {
            "source": 536,
            "target": 162
        },
        {
            "source": 110,
            "target": 120
        },
        {
            "source": 479,
            "target": 120
        },
        {
            "source": 480,
            "target": 120
        },
        {
            "source": 105,
            "target": 514
        },
        {
            "source": 175,
            "target": 524
        },
        {
            "source": 175,
            "target": 525
        },
        {
            "source": 105,
            "target": 167
        },
        {
            "source": 105,
            "target": 168
        },
        {
            "source": 60,
            "target": 116
        },
        {
            "source": 11,
            "target": 116
        },
        {
            "source": 116,
            "target": 461
        },
        {
            "source": 101,
            "target": 560
        },
        {
            "source": 101,
            "target": 138
        },
        {
            "source": 67,
            "target": 101
        },
        {
            "source": 101,
            "target": 64
        },
        {
            "source": 67,
            "target": 106
        },
        {
            "source": 561,
            "target": 196
        },
        {
            "source": 561,
            "target": 193
        },
        {
            "source": 442,
            "target": 196
        },
        {
            "source": 442,
            "target": 193
        },
        {
            "source": 561,
            "target": 195
        },
        {
            "source": 561,
            "target": 442
        },
        {
            "source": 561,
            "target": 5
        },
        {
            "source": 442,
            "target": 561
        },
        {
            "source": 561,
            "target": 562
        },
        {
            "source": 561,
            "target": 459
        },
        {
            "source": 561,
            "target": 26
        },
        {
            "source": 180,
            "target": 459
        },
        {
            "source": 180,
            "target": 26
        },
        {
            "source": 442,
            "target": 562
        },
        {
            "source": 442,
            "target": 459
        },
        {
            "source": 442,
            "target": 26
        },
        {
            "source": 101,
            "target": 26
        },
        {
            "source": 442,
            "target": 185
        },
        {
            "source": 442,
            "target": 534
        },
        {
            "source": 128,
            "target": 563
        },
        {
            "source": 314,
            "target": 101
        },
        {
            "source": 314,
            "target": 203
        },
        {
            "source": 314,
            "target": 155
        },
        {
            "source": 314,
            "target": 138
        },
        {
            "source": 564,
            "target": 101
        },
        {
            "source": 425,
            "target": 101
        },
        {
            "source": 295,
            "target": 5
        },
        {
            "source": 424,
            "target": 5
        },
        {
            "source": 294,
            "target": 78
        },
        {
            "source": 423,
            "target": 78
        },
        {
            "source": 295,
            "target": 78
        },
        {
            "source": 424,
            "target": 78
        },
        {
            "source": 425,
            "target": 78
        },
        {
            "source": 101,
            "target": 78
        },
        {
            "source": 101,
            "target": 148
        },
        {
            "source": 467,
            "target": 565
        },
        {
            "source": 467,
            "target": 99
        },
        {
            "source": 467,
            "target": 314
        },
        {
            "source": 467,
            "target": 566
        },
        {
            "source": 467,
            "target": 360
        },
        {
            "source": 467,
            "target": 101
        },
        {
            "source": 5,
            "target": 142
        },
        {
            "source": 5,
            "target": 108
        },
        {
            "source": 104,
            "target": 163
        },
        {
            "source": 175,
            "target": 514
        },
        {
            "source": 175,
            "target": 162
        },
        {
            "source": 111,
            "target": 174
        },
        {
            "source": 111,
            "target": 105
        },
        {
            "source": 111,
            "target": 175
        },
        {
            "source": 175,
            "target": 11
        },
        {
            "source": 175,
            "target": 184
        },
        {
            "source": 175,
            "target": 145
        },
        {
            "source": 111,
            "target": 95
        },
        {
            "source": 567,
            "target": 21
        },
        {
            "source": 113,
            "target": 36
        },
        {
            "source": 113,
            "target": 409
        },
        {
            "source": 99,
            "target": 112
        },
        {
            "source": 113,
            "target": 112
        },
        {
            "source": 113,
            "target": 379
        },
        {
            "source": 113,
            "target": 123
        },
        {
            "source": 113,
            "target": 142
        },
        {
            "source": 379,
            "target": 184
        },
        {
            "source": 379,
            "target": 113
        },
        {
            "source": 185,
            "target": 11
        },
        {
            "source": 185,
            "target": 184
        },
        {
            "source": 185,
            "target": 113
        },
        {
            "source": 185,
            "target": 145
        },
        {
            "source": 568,
            "target": 113
        },
        {
            "source": 568,
            "target": 379
        },
        {
            "source": 568,
            "target": 123
        },
        {
            "source": 379,
            "target": 569
        },
        {
            "source": 379,
            "target": 157
        },
        {
            "source": 198,
            "target": 120
        },
        {
            "source": 101,
            "target": 120
        },
        {
            "source": 570,
            "target": 379
        },
        {
            "source": 570,
            "target": 123
        },
        {
            "source": 571,
            "target": 379
        },
        {
            "source": 571,
            "target": 123
        },
        {
            "source": 572,
            "target": 379
        },
        {
            "source": 572,
            "target": 123
        },
        {
            "source": 573,
            "target": 379
        },
        {
            "source": 573,
            "target": 123
        },
        {
            "source": 570,
            "target": 11
        },
        {
            "source": 571,
            "target": 11
        },
        {
            "source": 572,
            "target": 11
        },
        {
            "source": 573,
            "target": 11
        },
        {
            "source": 570,
            "target": 185
        },
        {
            "source": 571,
            "target": 185
        },
        {
            "source": 572,
            "target": 185
        },
        {
            "source": 573,
            "target": 185
        },
        {
            "source": 220,
            "target": 101
        },
        {
            "source": 220,
            "target": 5
        },
        {
            "source": 417,
            "target": 71
        },
        {
            "source": 6,
            "target": 9
        },
        {
            "source": 540,
            "target": 70
        },
        {
            "source": 299,
            "target": 70
        },
        {
            "source": 232,
            "target": 410
        },
        {
            "source": 8,
            "target": 410
        },
        {
            "source": 326,
            "target": 3
        },
        {
            "source": 328,
            "target": 3
        },
        {
            "source": 327,
            "target": 79
        },
        {
            "source": 327,
            "target": 19
        },
        {
            "source": 3,
            "target": 535
        },
        {
            "source": 239,
            "target": 70
        },
        {
            "source": 239,
            "target": 71
        },
        {
            "source": 249,
            "target": 21
        },
        {
            "source": 249,
            "target": 22
        },
        {
            "source": 281,
            "target": 12
        },
        {
            "source": 52,
            "target": 503
        },
        {
            "source": 111,
            "target": 112
        },
        {
            "source": 112,
            "target": 22
        },
        {
            "source": 112,
            "target": 21
        },
        {
            "source": 78,
            "target": 79
        },
        {
            "source": 78,
            "target": 19
        },
        {
            "source": 123,
            "target": 105
        },
        {
            "source": 241,
            "target": 70
        },
        {
            "source": 241,
            "target": 71
        },
        {
            "source": 243,
            "target": 70
        },
        {
            "source": 243,
            "target": 71
        },
        {
            "source": 244,
            "target": 70
        },
        {
            "source": 244,
            "target": 71
        },
        {
            "source": 574,
            "target": 575
        },
        {
            "source": 574,
            "target": 576
        },
        {
            "source": 576,
            "target": 575
        },
        {
            "source": 576,
            "target": 577
        },
        {
            "source": 576,
            "target": 578
        },
        {
            "source": 576,
            "target": 579
        },
        {
            "source": 576,
            "target": 580
        },
        {
            "source": 576,
            "target": 581
        },
        {
            "source": 576,
            "target": 582
        },
        {
            "source": 352,
            "target": 101
        },
        {
            "source": 164,
            "target": 207
        },
        {
            "source": 164,
            "target": 583
        },
        {
            "source": 116,
            "target": 584
        },
        {
            "source": 99,
            "target": 141
        },
        {
            "source": 99,
            "target": 95
        },
        {
            "source": 99,
            "target": 585
        },
        {
            "source": 586,
            "target": 587
        },
        {
            "source": 586,
            "target": 26
        },
        {
            "source": 138,
            "target": 587
        },
        {
            "source": 138,
            "target": 26
        },
        {
            "source": 138,
            "target": 207
        },
        {
            "source": 99,
            "target": 369
        },
        {
            "source": 99,
            "target": 207
        },
        {
            "source": 185,
            "target": 517
        },
        {
            "source": 185,
            "target": 212
        },
        {
            "source": 185,
            "target": 138
        },
        {
            "source": 99,
            "target": 468
        },
        {
            "source": 99,
            "target": 469
        },
        {
            "source": 99,
            "target": 588
        },
        {
            "source": 173,
            "target": 185
        },
        {
            "source": 173,
            "target": 212
        },
        {
            "source": 123,
            "target": 185
        },
        {
            "source": 123,
            "target": 212
        },
        {
            "source": 173,
            "target": 379
        },
        {
            "source": 123,
            "target": 379
        },
        {
            "source": 173,
            "target": 123
        },
        {
            "source": 123,
            "target": 162
        },
        {
            "source": 563,
            "target": 101
        },
        {
            "source": 173,
            "target": 207
        },
        {
            "source": 173,
            "target": 11
        },
        {
            "source": 173,
            "target": 145
        },
        {
            "source": 123,
            "target": 11
        },
        {
            "source": 123,
            "target": 184
        },
        {
            "source": 123,
            "target": 113
        },
        {
            "source": 123,
            "target": 145
        },
        {
            "source": 138,
            "target": 382
        },
        {
            "source": 534,
            "target": 112
        },
        {
            "source": 534,
            "target": 138
        },
        {
            "source": 532,
            "target": 185
        },
        {
            "source": 532,
            "target": 212
        },
        {
            "source": 11,
            "target": 517
        },
        {
            "source": 211,
            "target": 379
        },
        {
            "source": 532,
            "target": 379
        },
        {
            "source": 11,
            "target": 379
        },
        {
            "source": 11,
            "target": 123
        },
        {
            "source": 138,
            "target": 379
        },
        {
            "source": 11,
            "target": 518
        },
        {
            "source": 11,
            "target": 589
        },
        {
            "source": 11,
            "target": 590
        },
        {
            "source": 11,
            "target": 124
        },
        {
            "source": 138,
            "target": 162
        },
        {
            "source": 11,
            "target": 36
        },
        {
            "source": 193,
            "target": 148
        },
        {
            "source": 193,
            "target": 163
        },
        {
            "source": 591,
            "target": 393
        },
        {
            "source": 185,
            "target": 140
        },
        {
            "source": 163,
            "target": 212
        },
        {
            "source": 162,
            "target": 379
        },
        {
            "source": 185,
            "target": 518
        },
        {
            "source": 162,
            "target": 518
        },
        {
            "source": 185,
            "target": 36
        },
        {
            "source": 162,
            "target": 36
        },
        {
            "source": 212,
            "target": 36
        },
        {
            "source": 151,
            "target": 583
        },
        {
            "source": 592,
            "target": 576
        },
        {
            "source": 593,
            "target": 576
        },
        {
            "source": 576,
            "target": 594
        },
        {
            "source": 576,
            "target": 595
        },
        {
            "source": 576,
            "target": 596
        },
        {
            "source": 597,
            "target": 369
        },
        {
            "source": 597,
            "target": 207
        },
        {
            "source": 184,
            "target": 113
        },
        {
            "source": 184,
            "target": 142
        },
        {
            "source": 184,
            "target": 212
        },
        {
            "source": 184,
            "target": 143
        },
        {
            "source": 184,
            "target": 518
        },
        {
            "source": 140,
            "target": 378
        },
        {
            "source": 140,
            "target": 598
        },
        {
            "source": 140,
            "target": 599
        },
        {
            "source": 140,
            "target": 600
        },
        {
            "source": 140,
            "target": 601
        },
        {
            "source": 140,
            "target": 602
        },
        {
            "source": 140,
            "target": 603
        },
        {
            "source": 140,
            "target": 157
        },
        {
            "source": 140,
            "target": 461
        },
        {
            "source": 314,
            "target": 588
        },
        {
            "source": 314,
            "target": 360
        },
        {
            "source": 314,
            "target": 468
        },
        {
            "source": 314,
            "target": 469
        },
        {
            "source": 604,
            "target": 105
        },
        {
            "source": 95,
            "target": 105
        },
        {
            "source": 111,
            "target": 101
        },
        {
            "source": 111,
            "target": 203
        },
        {
            "source": 112,
            "target": 27
        },
        {
            "source": 111,
            "target": 207
        },
        {
            "source": 9,
            "target": 87
        },
        {
            "source": 9,
            "target": 36
        },
        {
            "source": 605,
            "target": 21
        },
        {
            "source": 605,
            "target": 22
        },
        {
            "source": 9,
            "target": 71
        },
        {
            "source": 70,
            "target": 71
        },
        {
            "source": 3,
            "target": 606
        },
        {
            "source": 607,
            "target": 36
        },
        {
            "source": 608,
            "target": 12
        },
        {
            "source": 12,
            "target": 609
        },
        {
            "source": 63,
            "target": 12
        },
        {
            "source": 299,
            "target": 3
        },
        {
            "source": 21,
            "target": 308
        },
        {
            "source": 21,
            "target": 309
        },
        {
            "source": 22,
            "target": 308
        },
        {
            "source": 22,
            "target": 309
        },
        {
            "source": 325,
            "target": 5
        },
        {
            "source": 101,
            "target": 140
        },
        {
            "source": 101,
            "target": 155
        },
        {
            "source": 456,
            "target": 105
        },
        {
            "source": 610,
            "target": 611
        },
        {
            "source": 610,
            "target": 595
        },
        {
            "source": 610,
            "target": 612
        },
        {
            "source": 576,
            "target": 611
        },
        {
            "source": 576,
            "target": 299
        },
        {
            "source": 576,
            "target": 613
        },
        {
            "source": 576,
            "target": 612
        },
        {
            "source": 610,
            "target": 576
        },
        {
            "source": 576,
            "target": 614
        },
        {
            "source": 576,
            "target": 615
        },
        {
            "source": 576,
            "target": 616
        },
        {
            "source": 576,
            "target": 617
        },
        {
            "source": 116,
            "target": 5
        },
        {
            "source": 111,
            "target": 352
        },
        {
            "source": 111,
            "target": 106
        },
        {
            "source": 534,
            "target": 26
        },
        {
            "source": 618,
            "target": 393
        },
        {
            "source": 393,
            "target": 619
        },
        {
            "source": 620,
            "target": 393
        },
        {
            "source": 393,
            "target": 621
        },
        {
            "source": 622,
            "target": 273
        },
        {
            "source": 623,
            "target": 193
        },
        {
            "source": 623,
            "target": 624
        },
        {
            "source": 623,
            "target": 207
        },
        {
            "source": 623,
            "target": 120
        },
        {
            "source": 174,
            "target": 164
        },
        {
            "source": 174,
            "target": 524
        },
        {
            "source": 174,
            "target": 525
        },
        {
            "source": 118,
            "target": 106
        },
        {
            "source": 118,
            "target": 101
        },
        {
            "source": 625,
            "target": 106
        },
        {
            "source": 626,
            "target": 106
        },
        {
            "source": 627,
            "target": 106
        },
        {
            "source": 628,
            "target": 106
        },
        {
            "source": 628,
            "target": 101
        },
        {
            "source": 403,
            "target": 273
        },
        {
            "source": 403,
            "target": 140
        },
        {
            "source": 629,
            "target": 198
        },
        {
            "source": 629,
            "target": 101
        },
        {
            "source": 245,
            "target": 198
        },
        {
            "source": 245,
            "target": 101
        },
        {
            "source": 630,
            "target": 198
        },
        {
            "source": 630,
            "target": 101
        },
        {
            "source": 142,
            "target": 143
        },
        {
            "source": 142,
            "target": 113
        },
        {
            "source": 144,
            "target": 378
        },
        {
            "source": 631,
            "target": 138
        },
        {
            "source": 273,
            "target": 140
        },
        {
            "source": 273,
            "target": 207
        },
        {
            "source": 111,
            "target": 140
        },
        {
            "source": 112,
            "target": 140
        },
        {
            "source": 112,
            "target": 95
        },
        {
            "source": 111,
            "target": 632
        },
        {
            "source": 112,
            "target": 632
        },
        {
            "source": 193,
            "target": 633
        },
        {
            "source": 122,
            "target": 123
        },
        {
            "source": 123,
            "target": 583
        },
        {
            "source": 120,
            "target": 207
        },
        {
            "source": 273,
            "target": 153
        },
        {
            "source": 207,
            "target": 138
        },
        {
            "source": 139,
            "target": 207
        },
        {
            "source": 162,
            "target": 207
        },
        {
            "source": 139,
            "target": 624
        },
        {
            "source": 207,
            "target": 634
        },
        {
            "source": 207,
            "target": 624
        },
        {
            "source": 207,
            "target": 26
        },
        {
            "source": 207,
            "target": 193
        },
        {
            "source": 44,
            "target": 254
        },
        {
            "source": 7,
            "target": 449
        },
        {
            "source": 244,
            "target": 446
        },
        {
            "source": 19,
            "target": 18
        },
        {
            "source": 334,
            "target": 19
        },
        {
            "source": 334,
            "target": 18
        },
        {
            "source": 356,
            "target": 2
        },
        {
            "source": 5,
            "target": 308
        },
        {
            "source": 5,
            "target": 309
        },
        {
            "source": 4,
            "target": 21
        },
        {
            "source": 83,
            "target": 21
        },
        {
            "source": 4,
            "target": 22
        },
        {
            "source": 314,
            "target": 21
        },
        {
            "source": 281,
            "target": 310
        },
        {
            "source": 281,
            "target": 311
        },
        {
            "source": 281,
            "target": 21
        },
        {
            "source": 281,
            "target": 22
        },
        {
            "source": 635,
            "target": 266
        },
        {
            "source": 266,
            "target": 636
        },
        {
            "source": 266,
            "target": 637
        },
        {
            "source": 266,
            "target": 21
        },
        {
            "source": 266,
            "target": 638
        },
        {
            "source": 266,
            "target": 412
        },
        {
            "source": 266,
            "target": 639
        },
        {
            "source": 266,
            "target": 640
        },
        {
            "source": 266,
            "target": 641
        },
        {
            "source": 266,
            "target": 642
        },
        {
            "source": 266,
            "target": 643
        },
        {
            "source": 163,
            "target": 174
        },
        {
            "source": 163,
            "target": 644
        },
        {
            "source": 105,
            "target": 645
        },
        {
            "source": 105,
            "target": 644
        },
        {
            "source": 174,
            "target": 646
        },
        {
            "source": 174,
            "target": 647
        },
        {
            "source": 174,
            "target": 648
        },
        {
            "source": 174,
            "target": 649
        },
        {
            "source": 174,
            "target": 650
        },
        {
            "source": 163,
            "target": 651
        },
        {
            "source": 163,
            "target": 652
        },
        {
            "source": 105,
            "target": 651
        },
        {
            "source": 105,
            "target": 652
        },
        {
            "source": 653,
            "target": 654
        },
        {
            "source": 653,
            "target": 162
        },
        {
            "source": 655,
            "target": 654
        },
        {
            "source": 655,
            "target": 162
        },
        {
            "source": 656,
            "target": 654
        },
        {
            "source": 656,
            "target": 162
        },
        {
            "source": 653,
            "target": 657
        },
        {
            "source": 653,
            "target": 658
        },
        {
            "source": 653,
            "target": 659
        },
        {
            "source": 655,
            "target": 657
        },
        {
            "source": 655,
            "target": 658
        },
        {
            "source": 655,
            "target": 659
        },
        {
            "source": 656,
            "target": 657
        },
        {
            "source": 656,
            "target": 658
        },
        {
            "source": 656,
            "target": 659
        },
        {
            "source": 155,
            "target": 273
        },
        {
            "source": 155,
            "target": 146
        },
        {
            "source": 155,
            "target": 207
        },
        {
            "source": 138,
            "target": 273
        },
        {
            "source": 138,
            "target": 146
        },
        {
            "source": 155,
            "target": 101
        },
        {
            "source": 192,
            "target": 583
        },
        {
            "source": 193,
            "target": 583
        },
        {
            "source": 660,
            "target": 273
        },
        {
            "source": 660,
            "target": 146
        },
        {
            "source": 379,
            "target": 36
        },
        {
            "source": 379,
            "target": 583
        },
        {
            "source": 212,
            "target": 583
        },
        {
            "source": 5,
            "target": 536
        },
        {
            "source": 5,
            "target": 534
        },
        {
            "source": 661,
            "target": 123
        },
        {
            "source": 123,
            "target": 167
        },
        {
            "source": 123,
            "target": 168
        },
        {
            "source": 379,
            "target": 143
        },
        {
            "source": 379,
            "target": 662
        },
        {
            "source": 379,
            "target": 663
        },
        {
            "source": 379,
            "target": 664
        },
        {
            "source": 665,
            "target": 198
        },
        {
            "source": 193,
            "target": 207
        },
        {
            "source": 111,
            "target": 273
        },
        {
            "source": 111,
            "target": 146
        },
        {
            "source": 146,
            "target": 112
        },
        {
            "source": 101,
            "target": 147
        },
        {
            "source": 196,
            "target": 193
        },
        {
            "source": 193,
            "target": 120
        },
        {
            "source": 193,
            "target": 190
        },
        {
            "source": 666,
            "target": 101
        },
        {
            "source": 667,
            "target": 101
        },
        {
            "source": 668,
            "target": 101
        },
        {
            "source": 64,
            "target": 107
        },
        {
            "source": 64,
            "target": 108
        },
        {
            "source": 669,
            "target": 393
        },
        {
            "source": 669,
            "target": 16
        },
        {
            "source": 591,
            "target": 16
        },
        {
            "source": 393,
            "target": 16
        },
        {
            "source": 393,
            "target": 207
        },
        {
            "source": 670,
            "target": 142
        },
        {
            "source": 585,
            "target": 142
        },
        {
            "source": 597,
            "target": 120
        },
        {
            "source": 671,
            "target": 207
        },
        {
            "source": 317,
            "target": 21
        },
        {
            "source": 317,
            "target": 22
        },
        {
            "source": 407,
            "target": 21
        },
        {
            "source": 407,
            "target": 22
        },
        {
            "source": 3,
            "target": 672
        },
        {
            "source": 3,
            "target": 673
        },
        {
            "source": 3,
            "target": 21
        },
        {
            "source": 674,
            "target": 12
        },
        {
            "source": 637,
            "target": 412
        },
        {
            "source": 636,
            "target": 412
        },
        {
            "source": 281,
            "target": 412
        },
        {
            "source": 281,
            "target": 638
        },
        {
            "source": 281,
            "target": 639
        },
        {
            "source": 281,
            "target": 640
        },
        {
            "source": 281,
            "target": 641
        },
        {
            "source": 281,
            "target": 642
        },
        {
            "source": 281,
            "target": 643
        },
        {
            "source": 675,
            "target": 21
        },
        {
            "source": 676,
            "target": 12
        },
        {
            "source": 677,
            "target": 12
        },
        {
            "source": 281,
            "target": 36
        },
        {
            "source": 314,
            "target": 207
        },
        {
            "source": 163,
            "target": 583
        },
        {
            "source": 210,
            "target": 142
        },
        {
            "source": 210,
            "target": 143
        },
        {
            "source": 113,
            "target": 143
        },
        {
            "source": 113,
            "target": 11
        },
        {
            "source": 113,
            "target": 184
        },
        {
            "source": 113,
            "target": 145
        },
        {
            "source": 185,
            "target": 654
        },
        {
            "source": 379,
            "target": 207
        },
        {
            "source": 162,
            "target": 654
        },
        {
            "source": 198,
            "target": 141
        },
        {
            "source": 101,
            "target": 128
        },
        {
            "source": 101,
            "target": 678
        },
        {
            "source": 153,
            "target": 101
        },
        {
            "source": 153,
            "target": 273
        },
        {
            "source": 153,
            "target": 146
        },
        {
            "source": 153,
            "target": 207
        },
        {
            "source": 153,
            "target": 106
        },
        {
            "source": 153,
            "target": 203
        },
        {
            "source": 203,
            "target": 155
        },
        {
            "source": 203,
            "target": 138
        },
        {
            "source": 162,
            "target": 583
        },
        {
            "source": 106,
            "target": 101
        },
        {
            "source": 575,
            "target": 611
        },
        {
            "source": 575,
            "target": 595
        },
        {
            "source": 575,
            "target": 612
        },
        {
            "source": 575,
            "target": 582
        },
        {
            "source": 575,
            "target": 596
        },
        {
            "source": 5,
            "target": 138
        },
        {
            "source": 146,
            "target": 273
        },
        {
            "source": 11,
            "target": 157
        },
        {
            "source": 145,
            "target": 157
        },
        {
            "source": 21,
            "target": 679
        },
        {
            "source": 22,
            "target": 679
        },
        {
            "source": 12,
            "target": 680
        },
        {
            "source": 36,
            "target": 606
        },
        {
            "source": 410,
            "target": 411
        },
        {
            "source": 410,
            "target": 412
        },
        {
            "source": 411,
            "target": 410
        },
        {
            "source": 411,
            "target": 412
        },
        {
            "source": 412,
            "target": 410
        },
        {
            "source": 412,
            "target": 411
        },
        {
            "source": 21,
            "target": 12
        },
        {
            "source": 21,
            "target": 310
        },
        {
            "source": 21,
            "target": 311
        },
        {
            "source": 631,
            "target": 26
        },
        {
            "source": 681,
            "target": 203
        },
        {
            "source": 203,
            "target": 682
        },
        {
            "source": 203,
            "target": 683
        },
        {
            "source": 273,
            "target": 459
        },
        {
            "source": 273,
            "target": 26
        },
        {
            "source": 534,
            "target": 273
        },
        {
            "source": 534,
            "target": 207
        },
        {
            "source": 684,
            "target": 112
        },
        {
            "source": 120,
            "target": 140
        },
        {
            "source": 120,
            "target": 393
        },
        {
            "source": 193,
            "target": 624
        },
        {
            "source": 685,
            "target": 26
        },
        {
            "source": 273,
            "target": 686
        },
        {
            "source": 685,
            "target": 459
        },
        {
            "source": 687,
            "target": 624
        },
        {
            "source": 203,
            "target": 688
        },
        {
            "source": 203,
            "target": 634
        },
        {
            "source": 203,
            "target": 624
        },
        {
            "source": 203,
            "target": 689
        },
        {
            "source": 690,
            "target": 624
        },
        {
            "source": 690,
            "target": 207
        },
        {
            "source": 691,
            "target": 624
        },
        {
            "source": 691,
            "target": 207
        },
        {
            "source": 690,
            "target": 120
        },
        {
            "source": 691,
            "target": 120
        },
        {
            "source": 120,
            "target": 530
        },
        {
            "source": 120,
            "target": 531
        },
        {
            "source": 692,
            "target": 104
        },
        {
            "source": 104,
            "target": 390
        },
        {
            "source": 121,
            "target": 393
        },
        {
            "source": 145,
            "target": 36
        },
        {
            "source": 196,
            "target": 459
        },
        {
            "source": 196,
            "target": 26
        },
        {
            "source": 193,
            "target": 459
        },
        {
            "source": 693,
            "target": 597
        },
        {
            "source": 597,
            "target": 112
        },
        {
            "source": 693,
            "target": 120
        },
        {
            "source": 693,
            "target": 112
        },
        {
            "source": 597,
            "target": 624
        },
        {
            "source": 693,
            "target": 207
        },
        {
            "source": 693,
            "target": 624
        },
        {
            "source": 597,
            "target": 314
        },
        {
            "source": 597,
            "target": 694
        },
        {
            "source": 597,
            "target": 147
        },
        {
            "source": 375,
            "target": 123
        },
        {
            "source": 409,
            "target": 560
        },
        {
            "source": 142,
            "target": 153
        },
        {
            "source": 142,
            "target": 154
        },
        {
            "source": 695,
            "target": 143
        },
        {
            "source": 695,
            "target": 142
        },
        {
            "source": 670,
            "target": 143
        },
        {
            "source": 585,
            "target": 143
        },
        {
            "source": 696,
            "target": 21
        },
        {
            "source": 86,
            "target": 21
        },
        {
            "source": 696,
            "target": 22
        },
        {
            "source": 86,
            "target": 22
        },
        {
            "source": 697,
            "target": 36
        },
        {
            "source": 279,
            "target": 412
        },
        {
            "source": 554,
            "target": 157
        },
        {
            "source": 461,
            "target": 157
        },
        {
            "source": 554,
            "target": 603
        },
        {
            "source": 461,
            "target": 603
        },
        {
            "source": 461,
            "target": 162
        },
        {
            "source": 554,
            "target": 96
        },
        {
            "source": 461,
            "target": 96
        },
        {
            "source": 461,
            "target": 598
        },
        {
            "source": 461,
            "target": 599
        },
        {
            "source": 461,
            "target": 600
        },
        {
            "source": 461,
            "target": 601
        },
        {
            "source": 461,
            "target": 602
        },
        {
            "source": 554,
            "target": 140
        },
        {
            "source": 554,
            "target": 698
        },
        {
            "source": 461,
            "target": 140
        },
        {
            "source": 461,
            "target": 698
        },
        {
            "source": 153,
            "target": 699
        },
        {
            "source": 153,
            "target": 700
        },
        {
            "source": 382,
            "target": 207
        },
        {
            "source": 693,
            "target": 530
        },
        {
            "source": 693,
            "target": 531
        },
        {
            "source": 597,
            "target": 530
        },
        {
            "source": 597,
            "target": 531
        },
        {
            "source": 382,
            "target": 120
        },
        {
            "source": 273,
            "target": 96
        },
        {
            "source": 26,
            "target": 207
        },
        {
            "source": 26,
            "target": 588
        },
        {
            "source": 26,
            "target": 138
        },
        {
            "source": 701,
            "target": 26
        },
        {
            "source": 702,
            "target": 603
        },
        {
            "source": 702,
            "target": 157
        },
        {
            "source": 184,
            "target": 560
        },
        {
            "source": 11,
            "target": 560
        },
        {
            "source": 113,
            "target": 560
        },
        {
            "source": 145,
            "target": 560
        },
        {
            "source": 113,
            "target": 162
        },
        {
            "source": 145,
            "target": 113
        },
        {
            "source": 703,
            "target": 140
        },
        {
            "source": 142,
            "target": 493
        },
        {
            "source": 393,
            "target": 704
        },
        {
            "source": 116,
            "target": 686
        },
        {
            "source": 26,
            "target": 686
        },
        {
            "source": 116,
            "target": 705
        },
        {
            "source": 686,
            "target": 705
        },
        {
            "source": 686,
            "target": 706
        },
        {
            "source": 26,
            "target": 705
        },
        {
            "source": 203,
            "target": 193
        },
        {
            "source": 459,
            "target": 707
        },
        {
            "source": 459,
            "target": 26
        },
        {
            "source": 708,
            "target": 461
        },
        {
            "source": 461,
            "target": 36
        },
        {
            "source": 652,
            "target": 104
        },
        {
            "source": 104,
            "target": 623
        },
        {
            "source": 104,
            "target": 193
        },
        {
            "source": 203,
            "target": 542
        },
        {
            "source": 203,
            "target": 543
        },
        {
            "source": 709,
            "target": 710
        },
        {
            "source": 709,
            "target": 203
        },
        {
            "source": 203,
            "target": 710
        },
        {
            "source": 36,
            "target": 320
        },
        {
            "source": 554,
            "target": 461
        },
        {
            "source": 193,
            "target": 623
        },
        {
            "source": 534,
            "target": 123
        },
        {
            "source": 185,
            "target": 142
        },
        {
            "source": 162,
            "target": 142
        },
        {
            "source": 644,
            "target": 147
        },
        {
            "source": 21,
            "target": 410
        },
        {
            "source": 22,
            "target": 410
        },
        {
            "source": 21,
            "target": 312
        },
        {
            "source": 21,
            "target": 313
        },
        {
            "source": 22,
            "target": 312
        },
        {
            "source": 22,
            "target": 313
        },
        {
            "source": 21,
            "target": 711
        },
        {
            "source": 22,
            "target": 311
        },
        {
            "source": 22,
            "target": 711
        },
        {
            "source": 22,
            "target": 12
        },
        {
            "source": 21,
            "target": 712
        },
        {
            "source": 22,
            "target": 712
        },
        {
            "source": 713,
            "target": 503
        },
        {
            "source": 103,
            "target": 203
        },
        {
            "source": 203,
            "target": 147
        },
        {
            "source": 203,
            "target": 148
        },
        {
            "source": 314,
            "target": 147
        },
        {
            "source": 314,
            "target": 148
        },
        {
            "source": 382,
            "target": 36
        },
        {
            "source": 378,
            "target": 96
        },
        {
            "source": 203,
            "target": 588
        },
        {
            "source": 583,
            "target": 163
        },
        {
            "source": 714,
            "target": 36
        },
        {
            "source": 715,
            "target": 36
        },
        {
            "source": 699,
            "target": 153
        },
        {
            "source": 700,
            "target": 153
        },
        {
            "source": 403,
            "target": 147
        },
        {
            "source": 716,
            "target": 147
        },
        {
            "source": 717,
            "target": 147
        },
        {
            "source": 27,
            "target": 147
        },
        {
            "source": 716,
            "target": 314
        },
        {
            "source": 717,
            "target": 314
        },
        {
            "source": 717,
            "target": 99
        },
        {
            "source": 717,
            "target": 588
        },
        {
            "source": 27,
            "target": 314
        },
        {
            "source": 27,
            "target": 588
        },
        {
            "source": 624,
            "target": 207
        },
        {
            "source": 624,
            "target": 120
        },
        {
            "source": 624,
            "target": 382
        },
        {
            "source": 624,
            "target": 718
        },
        {
            "source": 624,
            "target": 719
        },
        {
            "source": 533,
            "target": 623
        },
        {
            "source": 720,
            "target": 623
        },
        {
            "source": 720,
            "target": 533
        },
        {
            "source": 720,
            "target": 721
        },
        {
            "source": 203,
            "target": 722
        },
        {
            "source": 203,
            "target": 723
        },
        {
            "source": 203,
            "target": 724
        },
        {
            "source": 107,
            "target": 106
        },
        {
            "source": 107,
            "target": 108
        },
        {
            "source": 107,
            "target": 481
        },
        {
            "source": 107,
            "target": 109
        },
        {
            "source": 107,
            "target": 101
        },
        {
            "source": 551,
            "target": 461
        },
        {
            "source": 162,
            "target": 560
        },
        {
            "source": 459,
            "target": 138
        },
        {
            "source": 692,
            "target": 725
        },
        {
            "source": 726,
            "target": 725
        },
        {
            "source": 656,
            "target": 725
        },
        {
            "source": 656,
            "target": 193
        },
        {
            "source": 727,
            "target": 147
        },
        {
            "source": 147,
            "target": 148
        },
        {
            "source": 727,
            "target": 314
        },
        {
            "source": 147,
            "target": 314
        },
        {
            "source": 147,
            "target": 99
        },
        {
            "source": 728,
            "target": 101
        },
        {
            "source": 108,
            "target": 101
        },
        {
            "source": 728,
            "target": 203
        },
        {
            "source": 108,
            "target": 722
        },
        {
            "source": 108,
            "target": 203
        },
        {
            "source": 461,
            "target": 560
        },
        {
            "source": 123,
            "target": 569
        },
        {
            "source": 123,
            "target": 662
        },
        {
            "source": 123,
            "target": 663
        },
        {
            "source": 123,
            "target": 664
        },
        {
            "source": 123,
            "target": 729
        },
        {
            "source": 120,
            "target": 382
        },
        {
            "source": 730,
            "target": 120
        },
        {
            "source": 120,
            "target": 624
        },
        {
            "source": 730,
            "target": 624
        },
        {
            "source": 730,
            "target": 207
        },
        {
            "source": 142,
            "target": 731
        },
        {
            "source": 142,
            "target": 732
        },
        {
            "source": 410,
            "target": 452
        },
        {
            "source": 410,
            "target": 638
        },
        {
            "source": 410,
            "target": 639
        },
        {
            "source": 410,
            "target": 640
        },
        {
            "source": 410,
            "target": 641
        },
        {
            "source": 410,
            "target": 642
        },
        {
            "source": 410,
            "target": 643
        },
        {
            "source": 455,
            "target": 412
        },
        {
            "source": 412,
            "target": 638
        },
        {
            "source": 412,
            "target": 639
        },
        {
            "source": 412,
            "target": 640
        },
        {
            "source": 412,
            "target": 641
        },
        {
            "source": 412,
            "target": 642
        },
        {
            "source": 412,
            "target": 643
        },
        {
            "source": 106,
            "target": 107
        },
        {
            "source": 106,
            "target": 108
        },
        {
            "source": 106,
            "target": 109
        },
        {
            "source": 108,
            "target": 106
        },
        {
            "source": 108,
            "target": 107
        },
        {
            "source": 108,
            "target": 109
        },
        {
            "source": 314,
            "target": 682
        },
        {
            "source": 314,
            "target": 683
        },
        {
            "source": 26,
            "target": 147
        },
        {
            "source": 623,
            "target": 382
        },
        {
            "source": 120,
            "target": 623
        },
        {
            "source": 120,
            "target": 733
        },
        {
            "source": 734,
            "target": 104
        },
        {
            "source": 735,
            "target": 104
        },
        {
            "source": 523,
            "target": 736
        },
        {
            "source": 523,
            "target": 737
        },
        {
            "source": 737,
            "target": 721
        },
        {
            "source": 190,
            "target": 738
        },
        {
            "source": 725,
            "target": 390
        },
        {
            "source": 725,
            "target": 644
        },
        {
            "source": 725,
            "target": 739
        },
        {
            "source": 725,
            "target": 645
        },
        {
            "source": 542,
            "target": 543
        },
        {
            "source": 740,
            "target": 412
        },
        {
            "source": 12,
            "target": 741
        },
        {
            "source": 147,
            "target": 588
        },
        {
            "source": 193,
            "target": 203
        },
        {
            "source": 203,
            "target": 742
        },
        {
            "source": 203,
            "target": 743
        },
        {
            "source": 203,
            "target": 744
        },
        {
            "source": 162,
            "target": 662
        },
        {
            "source": 722,
            "target": 203
        },
        {
            "source": 722,
            "target": 724
        },
        {
            "source": 722,
            "target": 723
        },
        {
            "source": 612,
            "target": 596
        },
        {
            "source": 612,
            "target": 595
        },
        {
            "source": 612,
            "target": 617
        },
        {
            "source": 27,
            "target": 203
        },
        {
            "source": 26,
            "target": 745
        },
        {
            "source": 26,
            "target": 746
        },
        {
            "source": 99,
            "target": 147
        },
        {
            "source": 747,
            "target": 314
        },
        {
            "source": 748,
            "target": 314
        },
        {
            "source": 749,
            "target": 750
        },
        {
            "source": 410,
            "target": 751
        },
        {
            "source": 412,
            "target": 751
        },
        {
            "source": 382,
            "target": 147
        },
        {
            "source": 382,
            "target": 148
        },
        {
            "source": 26,
            "target": 148
        },
        {
            "source": 26,
            "target": 624
        },
        {
            "source": 752,
            "target": 162
        },
        {
            "source": 712,
            "target": 21
        },
        {
            "source": 753,
            "target": 393
        },
        {
            "source": 207,
            "target": 120
        },
        {
            "source": 207,
            "target": 382
        },
        {
            "source": 207,
            "target": 718
        },
        {
            "source": 207,
            "target": 719
        },
        {
            "source": 461,
            "target": 752
        },
        {
            "source": 461,
            "target": 754
        },
        {
            "source": 755,
            "target": 750
        },
        {
            "source": 755,
            "target": 756
        },
        {
            "source": 750,
            "target": 749
        },
        {
            "source": 750,
            "target": 757
        },
        {
            "source": 750,
            "target": 758
        },
        {
            "source": 750,
            "target": 759
        },
        {
            "source": 750,
            "target": 756
        },
        {
            "source": 729,
            "target": 663
        },
        {
            "source": 751,
            "target": 147
        },
        {
            "source": 751,
            "target": 148
        },
        {
            "source": 760,
            "target": 761
        },
        {
            "source": 452,
            "target": 410
        },
        {
            "source": 742,
            "target": 682
        },
        {
            "source": 742,
            "target": 683
        },
        {
            "source": 742,
            "target": 203
        },
        {
            "source": 742,
            "target": 744
        },
        {
            "source": 410,
            "target": 21
        },
        {
            "source": 452,
            "target": 21
        },
        {
            "source": 286,
            "target": 762
        },
        {
            "source": 682,
            "target": 683
        },
        {
            "source": 683,
            "target": 682
        },
        {
            "source": 761,
            "target": 763
        },
        {
            "source": 761,
            "target": 760
        },
        {
            "source": 193,
            "target": 682
        },
        {
            "source": 193,
            "target": 683
        },
        {
            "source": 683,
            "target": 203
        },
        {
            "source": 682,
            "target": 203
        },
        {
            "source": 721,
            "target": 764
        },
        {
            "source": 737,
            "target": 764
        },
        {
            "source": 737,
            "target": 765
        },
        {
            "source": 737,
            "target": 766
        },
        {
            "source": 737,
            "target": 767
        },
        {
            "source": 737,
            "target": 768
        },
        {
            "source": 743,
            "target": 203
        },
        {
            "source": 704,
            "target": 393
        },
        {
            "source": 148,
            "target": 147
        },
        {
            "source": 621,
            "target": 393
        },
        {
            "source": 621,
            "target": 619
        },
        {
            "source": 744,
            "target": 203
        },
        {
            "source": 769,
            "target": 770
        }
    ],
    "nodes": [
        {
            "name": "Jansen, Y.",
            "value": 26,
            "numPapers": 31,
            "cluster": "0",
            "index": 0,
            "weight": 4,
            "x": 430.96463012550885,
            "y": 505.3004778937526,
            "px": 325.8030920735774,
            "py": 577.1730278012407,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications",
                "PaperDOI": "10.1109/TVCG.2012.251",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.251",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.",
                "AuthorNames": "Bezerianos, A.;Isenberg, P.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37413699200;37591317800",
                "Dedupedauthornames": "Bezerianos, A.;Isenberg, P.",
                "References": "10.1109/TVCG.2011.160;10.1109/TVCG.2006.184",
                "AuthorKeywords": "Information visualization, perception, wall-displays",
                "IEEEXPLOREArticleNumberdeprecated": "6327257",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065014;4015437"
            }
        },
        {
            "name": "Isenberg, P.",
            "value": 207,
            "numPapers": 86,
            "cluster": "0",
            "index": 1,
            "weight": 19,
            "x": 643.8080727683024,
            "y": 297.6142277716201,
            "px": 660.6213233298611,
            "py": 299.4179101038982,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications",
                "PaperDOI": "10.1109/TVCG.2012.251",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.251",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.",
                "AuthorNames": "Bezerianos, A.;Isenberg, P.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37413699200;37591317800",
                "Dedupedauthornames": "Bezerianos, A.;Isenberg, P.",
                "References": "10.1109/TVCG.2011.160;10.1109/TVCG.2006.184",
                "AuthorKeywords": "Information visualization, perception, wall-displays",
                "IEEEXPLOREArticleNumberdeprecated": "6327257",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065014;4015437"
            }
        },
        {
            "name": "Fekete, J.",
            "value": 617,
            "numPapers": 105,
            "cluster": "0",
            "index": 2,
            "weight": 42,
            "x": 568.9937025006151,
            "y": 203.64585525679803,
            "px": 532.6851897261572,
            "py": 219.90923522104458,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty",
                "PaperDOI": "10.1109/TVCG.2012.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.220",
                "Firstpage": "2769",
                "Lastpage": "2778",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.",
                "AuthorNames": "Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA, Sophia Antipolis, France|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.",
                "References": "10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1992.235199;10.1109/TVCG.2007.70530;10.1109/TVCG.2009.114;10.1109/VAST.2009.5332611;10.1109/VAST.2006.261424;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70589;10.1109/VISUAL.2000.885679",
                "AuthorKeywords": "Uncertainty visualization, qualitative evaluation, quantitative evaluation, perception",
                "IEEEXPLOREArticleNumberdeprecated": "6327283",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532853;235199;4376197;5290731;5332611;4035764;6327281;4376132;885679"
            }
        },
        {
            "name": "Stasko, J.",
            "value": 1106,
            "numPapers": 135,
            "cluster": "0",
            "index": 3,
            "weight": 80,
            "x": 678.2691252308817,
            "y": 147.48395115575485,
            "px": 656.0062756077303,
            "py": 149.480718795996,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Casual Information Visualization: Depictions of Data in Everyday Life",
                "PaperDOI": "10.1109/TVCG.2007.70541",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70541",
                "Firstpage": "1145",
                "Lastpage": "1152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.",
                "AuthorNames": "Pousman, Z.;Stasko, J.T.;Mateas, M.",
                "FirstAuthorAffiliation": "Georgia Inst.of Technol, Atlanta|c|;;",
                "AuthorIDs": "37945316800;37267736900;37329261300",
                "Dedupedauthornames": "Pousman, Z.;Stasko, J.;Mateas, M.",
                "References": "10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.8;10.1109/INFVIS.2003.1249031;10.1109/INFVIS.2004.59;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Casual information visualization, ambient infovis, social infovis, editorial, design, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4376134",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532126;1382897;1249031;1382903;146375"
            }
        },
        {
            "name": "Elmqvist, N.",
            "value": 251,
            "numPapers": 123,
            "cluster": "0",
            "index": 4,
            "weight": 17,
            "x": 711.7076239837115,
            "y": 257.9341026227899,
            "px": 705.2437087029772,
            "py": 267.70881452708653,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Hauser, H.",
            "value": 733,
            "numPapers": 173,
            "cluster": "5",
            "index": 5,
            "weight": 57,
            "x": 732.780436779209,
            "y": 54.426829092182516,
            "px": 739.6523022041147,
            "py": 102.92955992618384,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Radial Sets: Interactive Visual Analysis of Large Overlapping Sets",
                "PaperDOI": "10.1109/TVCG.2013.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.184",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.",
                "AuthorNames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "References": "10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157",
                "AuthorKeywords": "Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability",
                "IEEEXPLOREArticleNumberdeprecated": "6634104",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015417;5290706;4658148;6064991;1382886;5613447;6327291;1173157"
            }
        },
        {
            "name": "Heer, J.",
            "value": 856,
            "numPapers": 117,
            "cluster": "0",
            "index": 6,
            "weight": 66,
            "x": 572.2044183790013,
            "y": 99.89578454652107,
            "px": 547.4342360994747,
            "py": 105.50240826555523,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Narrative Visualization: Telling Stories with Data",
                "PaperDOI": "10.1109/TVCG.2010.179",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.179",
                "Firstpage": "1139",
                "Lastpage": "1148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data visualization is regularly promoted for its ability to reveal stories within data, yet these data stories differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.",
                "AuthorNames": "Segel, E.;Heer, J.",
                "FirstAuthorAffiliation": "Stanford Univ., Stanford, CA, USA|c|;",
                "AuthorIDs": "37590964100;37550791300",
                "Dedupedauthornames": "Segel, E.;Heer, J.",
                "References": "10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Narrative visualization, storytelling, design methods, case study, journalism, social data analysis",
                "IEEEXPLOREArticleNumberdeprecated": "5613452",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376131;4376146;4658129;4388992"
            }
        },
        {
            "name": "Robertson, G.",
            "value": 290,
            "numPapers": 17,
            "cluster": "0",
            "index": 7,
            "weight": 10,
            "x": 846.6189821389679,
            "y": 175.67570447159295,
            "px": 819.9077565404393,
            "py": 238.25829512544198,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Animated Transitions in Statistical Data Graphics",
                "PaperDOI": "10.1109/TVCG.2007.70539",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70539",
                "Firstpage": "1240",
                "Lastpage": "1247",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in DynaVis, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.",
                "AuthorNames": "Heer, J.;Robertson, G.G.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley|c|;",
                "AuthorIDs": "37550791300;37448060300",
                "Dedupedauthornames": "Heer, J.;Robertson, G.",
                "References": "10.1109/INFVIS.1999.801854;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173148",
                "AuthorKeywords": "Statistical data graphics, animation, transitions, information visualization, design, experiment",
                "IEEEXPLOREArticleNumberdeprecated": "4376146",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801854;963279;1173148"
            }
        },
        {
            "name": "Huamin Qu",
            "value": 595,
            "numPapers": 258,
            "cluster": "1",
            "index": 8,
            "weight": 84,
            "x": 580.1363272203125,
            "y": 441.2605729721425,
            "px": 579.16479480572,
            "py": 442.4911367159237,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "ASK-graphView: a large scale graph visualization system",
                "PaperDOI": "10.1109/TVCG.2006.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.120",
                "Firstpage": "669",
                "Lastpage": "676",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling",
                "AuthorNames": "Abello, J.;van Ham, F.;Neeraj Krishnan",
                "FirstAuthorAffiliation": "Rutgers Univ., New Brunswick, NJ|c|;;",
                "AuthorIDs": ";;37823691100",
                "Dedupedauthornames": "Abello, J.;van Ham, F.;Neeraj Krishnan",
                "References": "10.1109/INFVIS.2004.46;10.1109/INFVIS.2005.1532127;10.1109/INFVIS.2004.66;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2004.43",
                "AuthorKeywords": "Information visualization, graph visualization, graph clustering",
                "IEEEXPLOREArticleNumberdeprecated": "4015416",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382907;1532127;1382906;636718;1382909"
            }
        },
        {
            "name": "van Ham, F.",
            "value": 452,
            "numPapers": 32,
            "cluster": "0",
            "index": 9,
            "weight": 15,
            "x": 805.2858039419035,
            "y": 242.5016269044312,
            "px": 775.769614079812,
            "py": 296.85819458191526,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "ASK-graphView: a large scale graph visualization system",
                "PaperDOI": "10.1109/TVCG.2006.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.120",
                "Firstpage": "669",
                "Lastpage": "676",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling",
                "AuthorNames": "Abello, J.;van Ham, F.;Neeraj Krishnan",
                "FirstAuthorAffiliation": "Rutgers Univ., New Brunswick, NJ|c|;;",
                "AuthorIDs": ";;37823691100",
                "Dedupedauthornames": "Abello, J.;van Ham, F.;Neeraj Krishnan",
                "References": "10.1109/INFVIS.2004.46;10.1109/INFVIS.2005.1532127;10.1109/INFVIS.2004.66;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2004.43",
                "AuthorKeywords": "Information visualization, graph visualization, graph clustering",
                "IEEEXPLOREArticleNumberdeprecated": "4015416",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382907;1532127;1382906;636718;1382909"
            }
        },
        {
            "name": "Holten, D.",
            "value": 167,
            "numPapers": 15,
            "cluster": "1",
            "index": 10,
            "weight": 1,
            "x": 1846.0528422631814,
            "y": 80.85747664685442,
            "px": 1693.595690058751,
            "py": 119.85502683158626,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data",
                "PaperDOI": "10.1109/TVCG.2006.147",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.147",
                "Firstpage": "741",
                "Lastpage": "748",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations",
                "AuthorNames": "Holten, D.",
                "FirstAuthorAffiliation": "Technische Univ. Eindhoven|c|",
                "AuthorIDs": "37827881300",
                "Dedupedauthornames": "Holten, D.",
                "References": "10.1109/INFVIS.2004.1;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2003.1249030;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2002.1173152",
                "AuthorKeywords": "Network visualization, edge bundling, edge aggregation, edge concentration, curves, graph visualization, tree visualization, node-link diagrams, hierarchies, treemaps",
                "IEEEXPLOREArticleNumberdeprecated": "4015425",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382886;1249008;1532150;1249030;1532129;636718;1173152"
            }
        },
        {
            "name": "Theisel, H.",
            "value": 434,
            "numPapers": 144,
            "cluster": "3",
            "index": 11,
            "weight": 47,
            "x": 299.1802261131872,
            "y": 506.6456131915391,
            "px": 304.81076186772935,
            "py": 497.65053277079005,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Improving the visual analysis of high-dimensional datasets using quality measures",
                "PaperDOI": "10.1109/VAST.2010.5652433",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652433",
                "Firstpage": "19",
                "Lastpage": "26",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;",
                "AuthorIDs": "37603943800;37546817000;37601992200;37266875400;37273816400",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652433",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;1532142;663916;4035766;5332628;4658161"
            }
        },
        {
            "name": "Keim, D.A.",
            "value": 673,
            "numPapers": 163,
            "cluster": "5",
            "index": 12,
            "weight": 59,
            "x": 854.0791328296975,
            "y": 259.3306829701882,
            "px": 864.6309833474326,
            "py": 285.22497306925806,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "Anand, A.",
            "value": 121,
            "numPapers": 38,
            "cluster": "5",
            "index": 13,
            "weight": 9,
            "x": 1021.5105652939402,
            "y": -8.394516929349583,
            "px": 990.1451230564858,
            "py": -5.347724763547362,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Four Experiments on the Perception of Bar Charts",
                "PaperDOI": "10.1109/TVCG.2014.2346320",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346320",
                "Firstpage": "2152",
                "Lastpage": "2160",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland & McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland & McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts.",
                "AuthorNames": "Talbot, J.;Setlur, V.;Anand, A.",
                "FirstAuthorAffiliation": "Tableau Res., USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Talbot, J.;Setlur, V.;Anand, A.",
                "References": "10.1109/TVCG.2012.237",
                "AuthorKeywords": "Graphical perception, bar charts",
                "IEEEXPLOREArticleNumberdeprecated": "6876021",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327278"
            }
        },
        {
            "name": "Albuquerque, G.",
            "value": 85,
            "numPapers": 24,
            "cluster": "5",
            "index": 14,
            "weight": 10,
            "x": 650.0261561957954,
            "y": 265.45306787164196,
            "px": 656.2004766105207,
            "py": 189.13707395548641,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Improving the visual analysis of high-dimensional datasets using quality measures",
                "PaperDOI": "10.1109/VAST.2010.5652433",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652433",
                "Firstpage": "19",
                "Lastpage": "26",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;",
                "AuthorIDs": "37603943800;37546817000;37601992200;37266875400;37273816400",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652433",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;1532142;663916;4035766;5332628;4658161"
            }
        },
        {
            "name": "Eisemann, M.",
            "value": 82,
            "numPapers": 36,
            "cluster": "5",
            "index": 15,
            "weight": 6,
            "x": 742.7733256830401,
            "y": 43.80593554084305,
            "px": 787.1598367038688,
            "py": 78.19203343727533,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Improving the visual analysis of high-dimensional datasets using quality measures",
                "PaperDOI": "10.1109/VAST.2010.5652433",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652433",
                "Firstpage": "19",
                "Lastpage": "26",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;",
                "AuthorIDs": "37603943800;37546817000;37601992200;37266875400;37273816400",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652433",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;1532142;663916;4035766;5332628;4658161"
            }
        },
        {
            "name": "Magnor, M.",
            "value": 139,
            "numPapers": 29,
            "cluster": "5",
            "index": 16,
            "weight": 14,
            "x": 598.0588227784532,
            "y": -29.68543614413197,
            "px": 657.5195474091853,
            "py": 32.78196869500049,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Improving the visual analysis of high-dimensional datasets using quality measures",
                "PaperDOI": "10.1109/VAST.2010.5652433",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652433",
                "Firstpage": "19",
                "Lastpage": "26",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;",
                "AuthorIDs": "37603943800;37546817000;37601992200;37266875400;37273816400",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652433",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;1532142;663916;4035766;5332628;4658161"
            }
        },
        {
            "name": "Talbot, J.",
            "value": 76,
            "numPapers": 23,
            "cluster": "0",
            "index": 17,
            "weight": 2,
            "x": 1563.5557151364706,
            "y": -893.4912505211071,
            "px": 1392.2592807455246,
            "py": -735.3257853773913,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Four Experiments on the Perception of Bar Charts",
                "PaperDOI": "10.1109/TVCG.2014.2346320",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346320",
                "Firstpage": "2152",
                "Lastpage": "2160",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland & McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland & McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts.",
                "AuthorNames": "Talbot, J.;Setlur, V.;Anand, A.",
                "FirstAuthorAffiliation": "Tableau Res., USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Talbot, J.;Setlur, V.;Anand, A.",
                "References": "10.1109/TVCG.2012.237",
                "AuthorKeywords": "Graphical perception, bar charts",
                "IEEEXPLOREArticleNumberdeprecated": "6876021",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327278"
            }
        },
        {
            "name": "Hanrahan, P.",
            "value": 467,
            "numPapers": 20,
            "cluster": "0",
            "index": 18,
            "weight": 10,
            "x": 822.4840059434007,
            "y": -0.5418332866813333,
            "px": 852.4541674627143,
            "py": 4.223604514939676,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Show Me: Automatic Presentation for Visual Analysis",
                "PaperDOI": "10.1109/TVCG.2007.70594",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70594",
                "Firstpage": "1137",
                "Lastpage": "1144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.",
                "AuthorNames": "Mackinlay, J.;Hanrahan, P.;Stolte, C.",
                "FirstAuthorAffiliation": "Tableau Software, Seattle|c|;;",
                "AuthorIDs": "37372036700;37349803800;37442008700",
                "Dedupedauthornames": "Mackinlay, J.;Hanrahan, P.;Stolte, C.",
                "References": "10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Automatic presentation, visual analysis, graphic design, best practices, data visualization, small multiples",
                "IEEEXPLOREArticleNumberdeprecated": "4376133",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086"
            }
        },
        {
            "name": "Stolte, C.",
            "value": 357,
            "numPapers": 17,
            "cluster": "0",
            "index": 19,
            "weight": 11,
            "x": 993.0767561062187,
            "y": 102.01816719045067,
            "px": 924.8033833847954,
            "py": 112.6565474750171,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Show Me: Automatic Presentation for Visual Analysis",
                "PaperDOI": "10.1109/TVCG.2007.70594",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70594",
                "Firstpage": "1137",
                "Lastpage": "1144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.",
                "AuthorNames": "Mackinlay, J.;Hanrahan, P.;Stolte, C.",
                "FirstAuthorAffiliation": "Tableau Software, Seattle|c|;;",
                "AuthorIDs": "37372036700;37349803800;37442008700",
                "Dedupedauthornames": "Mackinlay, J.;Hanrahan, P.;Stolte, C.",
                "References": "10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Automatic presentation, visual analysis, graphic design, best practices, data visualization, small multiples",
                "IEEEXPLOREArticleNumberdeprecated": "4376133",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086"
            }
        },
        {
            "name": "Johansson, J.",
            "value": 183,
            "numPapers": 36,
            "cluster": "5",
            "index": 20,
            "weight": 2,
            "x": 1226.9203332541058,
            "y": 496.98321618678057,
            "px": 1271.5572101666794,
            "py": 500.07890576111316,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics",
                "PaperDOI": "10.1109/TVCG.2009.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.153",
                "Firstpage": "993",
                "Lastpage": "1000",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.",
                "AuthorNames": "Johansson, S.;Johansson, J.",
                "FirstAuthorAffiliation": "Norrkoping Visualization & Interaction Studio (NVIS), Linkoping Univ., Linkoping, Sweden|c|;",
                "AuthorIDs": "37924876400;37273045500",
                "Dedupedauthornames": "Johansson, S.;Johansson, J.",
                "References": "10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.161;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2008.138;10.1109/INFVIS.2004.15",
                "AuthorKeywords": "dimensionality reduction, interactivity, quality metrics, variable ordering",
                "IEEEXPLOREArticleNumberdeprecated": "5290704",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532142;1249015;729568;4015421;1382891;1382892;1382893;4658134;1382895"
            }
        },
        {
            "name": "Ward, M.O.",
            "value": 806,
            "numPapers": 96,
            "cluster": "5",
            "index": 21,
            "weight": 55,
            "x": 915.4544434923226,
            "y": 216.59638135155458,
            "px": 921.4329262958252,
            "py": 262.581982511283,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Measuring Data Abstraction Quality in Multiresolution Visualizations",
                "PaperDOI": "10.1109/TVCG.2006.161",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.161",
                "Firstpage": "709",
                "Lastpage": "716",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",
                "AuthorNames": "Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Yang, J.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA|c|;;;",
                "AuthorIDs": "37841616400;37268441700;37279217900;37292632600",
                "Dedupedauthornames": "Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Jing Yang",
                "References": "10.1109/INFVIS.2004.19;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2004.15;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2000.885088",
                "AuthorKeywords": "Metrics, Clustering, Sampling, Multiresolution Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015421",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382900;1532819;1382895;485139;885088"
            }
        },
        {
            "name": "Rundensteiner, E.A.",
            "value": 444,
            "numPapers": 80,
            "cluster": "5",
            "index": 22,
            "weight": 35,
            "x": 985.5545810778652,
            "y": 244.31046430922342,
            "px": 985.6620863133264,
            "py": 274.8764720148224,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Measuring Data Abstraction Quality in Multiresolution Visualizations",
                "PaperDOI": "10.1109/TVCG.2006.161",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.161",
                "Firstpage": "709",
                "Lastpage": "716",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",
                "AuthorNames": "Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Yang, J.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA|c|;;;",
                "AuthorIDs": "37841616400;37268441700;37279217900;37292632600",
                "Dedupedauthornames": "Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Jing Yang",
                "References": "10.1109/INFVIS.2004.19;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2004.15;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2000.885088",
                "AuthorKeywords": "Metrics, Clustering, Sampling, Multiresolution Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015421",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382900;1532819;1382895;485139;885088"
            }
        },
        {
            "name": "Forsell, C.",
            "value": 19,
            "numPapers": 25,
            "cluster": "0",
            "index": 23,
            "weight": 1,
            "x": 1532.6315075412124,
            "y": 1304.3071324432487,
            "px": 1401.730892334474,
            "py": 1166.7900922796803,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees",
                "PaperDOI": "10.1109/TVCG.2014.2346626",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346626",
                "Firstpage": "1693",
                "Lastpage": "1702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.",
                "AuthorNames": "Beham, M.;Herzner, W.;Groller, M.E.;Kehrer, J.",
                "FirstAuthorAffiliation": "Austrian Inst. of Technol., Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Beham, M.;Herzner, W.;Groller, E.;Kehrer, J.",
                "References": "10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581",
                "AuthorKeywords": "Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6875958",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634138;6634107;5613440;5290748;1532856;5613488;4015425;398859;809866;4376186"
            }
        },
        {
            "name": "Schreck, T.",
            "value": 177,
            "numPapers": 61,
            "cluster": "5",
            "index": 24,
            "weight": 5,
            "x": 1660.9454719594148,
            "y": 1440.6122177898862,
            "px": 1638.572646324234,
            "py": 1380.6117353123814,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Koch, S.",
            "value": 110,
            "numPapers": 82,
            "cluster": "0",
            "index": 25,
            "weight": 18,
            "x": 538.4623765177811,
            "y": 164.4540126227979,
            "px": 517.2485068782897,
            "py": 179.61265787461528,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Ertl, T.",
            "value": 652,
            "numPapers": 207,
            "cluster": "2",
            "index": 26,
            "weight": 55,
            "x": 246.949917845281,
            "y": 225.47901056545578,
            "px": 251.9894290841381,
            "py": 222.35175609621,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Pfister, H.",
            "value": 463,
            "numPapers": 176,
            "cluster": "2",
            "index": 27,
            "weight": 49,
            "x": 251.56806728524958,
            "y": 77.36806838068796,
            "px": 246.95046980743973,
            "py": 74.05808531230508,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "What Makes a Visualization Memorable?",
                "PaperDOI": "10.1109/TVCG.2013.234",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.234",
                "Firstpage": "2306",
                "Lastpage": "2315",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.",
                "AuthorNames": "Borkin, M.A.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.",
                "FirstAuthorAffiliation": "Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Borkin, M.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.",
                "References": "10.1109/TVCG.2012.221;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/TVCG.2012.245;10.1109/TVCG.2011.175",
                "AuthorKeywords": "Visualization taxonomy, information visualization, memorability",
                "IEEEXPLOREArticleNumberdeprecated": "6634103",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327280;1382903;6327282;6327253;6064986"
            }
        },
        {
            "name": "Oelke, D.",
            "value": 114,
            "numPapers": 12,
            "cluster": "5",
            "index": 28,
            "weight": 1,
            "x": 1098.77192023251,
            "y": -365.9038322982467,
            "px": 1079.248353615005,
            "py": -281.0591466240875,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Bum Chul Kwon",
            "value": 67,
            "numPapers": 77,
            "cluster": "0",
            "index": 29,
            "weight": 5,
            "x": 1066.3537824386713,
            "y": -360.8393153611439,
            "px": 1134.1958559307714,
            "py": -441.65780961967585,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Strobelt, H.",
            "value": 60,
            "numPapers": 41,
            "cluster": "2",
            "index": 30,
            "weight": 2,
            "x": -1505.275773416431,
            "y": 258.90878828027127,
            "px": -1406.0571168931758,
            "py": 258.89473750228433,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "UpSet: Visualization of Intersecting Sets",
                "PaperDOI": "10.1109/TVCG.2014.2346248",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346248",
                "Firstpage": "1983",
                "Lastpage": "1992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.",
                "AuthorNames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "FirstAuthorAffiliation": "Hendrik Strobelt & Hanspeter Pfister, Harvard Univ., Cambridge, MA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183",
                "AuthorKeywords": "Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data",
                "IEEEXPLOREArticleNumberdeprecated": "6876017",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;6634104;6064991;5613447;5290706;6064996;6064990"
            }
        },
        {
            "name": "Lex, A.",
            "value": 186,
            "numPapers": 65,
            "cluster": "0",
            "index": 31,
            "weight": 20,
            "x": 480.18297322148146,
            "y": 274.0342207393111,
            "px": 472.19231721449347,
            "py": 268.8250651915518,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "UpSet: Visualization of Intersecting Sets",
                "PaperDOI": "10.1109/TVCG.2014.2346248",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346248",
                "Firstpage": "1983",
                "Lastpage": "1992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.",
                "AuthorNames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "FirstAuthorAffiliation": "Hendrik Strobelt & Hanspeter Pfister, Harvard Univ., Cambridge, MA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183",
                "AuthorKeywords": "Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data",
                "IEEEXPLOREArticleNumberdeprecated": "6876017",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;6634104;6064991;5613447;5290706;6064996;6064990"
            }
        },
        {
            "name": "Steinberger, M.",
            "value": 74,
            "numPapers": 15,
            "cluster": "2",
            "index": 32,
            "weight": 1,
            "x": -589.4851364128853,
            "y": 2250.8989156588377,
            "px": -538.3987359513544,
            "py": 2059.6516699195313,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Context-Preserving Visual Links",
                "PaperDOI": "10.1109/TVCG.2011.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.183",
                "Firstpage": "2249",
                "Lastpage": "2258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.",
                "AuthorNames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "38017759700;37844773200;37403918900;37395933400;37297103800",
                "Dedupedauthornames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "References": "10.1109/TVCG.2010.138;10.1109/INFVIS.2001.963286;10.1109/TVCG.2006.147;10.1109/TVCG.2009.122;10.1109/VISUAL.1995.485139;10.1109/TVCG.2010.174;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521",
                "AuthorKeywords": "Visual links, highlighting, connectedness, routing, image-based, saliency",
                "IEEEXPLOREArticleNumberdeprecated": "6064990",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613440;963286;4015425;5290706;485139;5613438;4015424;4376140"
            }
        },
        {
            "name": "Waldner, M.",
            "value": 59,
            "numPapers": 14,
            "cluster": "2",
            "index": 33,
            "weight": 1,
            "x": 269.5898387030922,
            "y": -1060.1136740723905,
            "px": 236.57026728355993,
            "py": -915.8737501678372,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Context-Preserving Visual Links",
                "PaperDOI": "10.1109/TVCG.2011.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.183",
                "Firstpage": "2249",
                "Lastpage": "2258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.",
                "AuthorNames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "38017759700;37844773200;37403918900;37395933400;37297103800",
                "Dedupedauthornames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "References": "10.1109/TVCG.2010.138;10.1109/INFVIS.2001.963286;10.1109/TVCG.2006.147;10.1109/TVCG.2009.122;10.1109/VISUAL.1995.485139;10.1109/TVCG.2010.174;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521",
                "AuthorKeywords": "Visual links, highlighting, connectedness, routing, image-based, saliency",
                "IEEEXPLOREArticleNumberdeprecated": "6064990",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613440;963286;4015425;5290706;485139;5613438;4015424;4376140"
            }
        },
        {
            "name": "Streit, M.",
            "value": 179,
            "numPapers": 72,
            "cluster": "0",
            "index": 34,
            "weight": 19,
            "x": 602.3471176723917,
            "y": 141.0255494303491,
            "px": 570.4776501712572,
            "py": 141.05234354107372,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Context-Preserving Visual Links",
                "PaperDOI": "10.1109/TVCG.2011.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.183",
                "Firstpage": "2249",
                "Lastpage": "2258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.",
                "AuthorNames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "38017759700;37844773200;37403918900;37395933400;37297103800",
                "Dedupedauthornames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "References": "10.1109/TVCG.2010.138;10.1109/INFVIS.2001.963286;10.1109/TVCG.2006.147;10.1109/TVCG.2009.122;10.1109/VISUAL.1995.485139;10.1109/TVCG.2010.174;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521",
                "AuthorKeywords": "Visual links, highlighting, connectedness, routing, image-based, saliency",
                "IEEEXPLOREArticleNumberdeprecated": "6064990",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613440;963286;4015425;5290706;485139;5613438;4015424;4376140"
            }
        },
        {
            "name": "Schmalstieg, D.",
            "value": 156,
            "numPapers": 45,
            "cluster": "0",
            "index": 35,
            "weight": 13,
            "x": 304.5142629538447,
            "y": 181.39794821428302,
            "px": 340.03383577688726,
            "py": 226.5086236633267,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Context-Preserving Visual Links",
                "PaperDOI": "10.1109/TVCG.2011.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.183",
                "Firstpage": "2249",
                "Lastpage": "2258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.",
                "AuthorNames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "38017759700;37844773200;37403918900;37395933400;37297103800",
                "Dedupedauthornames": "Steinberger, M.;Waldner, M.;Streit, M.;Lex, A.;Schmalstieg, D.",
                "References": "10.1109/TVCG.2010.138;10.1109/INFVIS.2001.963286;10.1109/TVCG.2006.147;10.1109/TVCG.2009.122;10.1109/VISUAL.1995.485139;10.1109/TVCG.2010.174;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521",
                "AuthorKeywords": "Visual links, highlighting, connectedness, routing, image-based, saliency",
                "IEEEXPLOREArticleNumberdeprecated": "6064990",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613440;963286;4015425;5290706;485139;5613438;4015424;4376140"
            }
        },
        {
            "name": "van Wijk, J.J.",
            "value": 869,
            "numPapers": 133,
            "cluster": "3",
            "index": 36,
            "weight": 48,
            "x": 356.92673333653715,
            "y": 409.34142141696816,
            "px": 368.9445972425288,
            "py": 419.6616876901978,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Flexible Linked Axes for Multivariate Data Visualization",
                "PaperDOI": "10.1109/TVCG.2011.201",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.201",
                "Firstpage": "2310",
                "Lastpage": "2316",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.",
                "AuthorNames": "Claessen, J.H.T.;van Wijk, J.J.",
                "FirstAuthorAffiliation": "Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;",
                "AuthorIDs": "38016239600;37267249200",
                "Dedupedauthornames": "Claessen, J.H.T.;van Wijk, J.J.",
                "References": "10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2006.138;10.1109/TVCG.2010.205;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70521;10.1109/VISUAL.1991.175790;10.1109/TVCG.2008.153",
                "AuthorKeywords": "Multivariate data, visualization, scatterplot, Parallel Coordinates Plot",
                "IEEEXPLOREArticleNumberdeprecated": "6064997",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532142;1532136;1173157;4015422;5613448;4015444;4376140;175790;4658123"
            }
        },
        {
            "name": "Dwyer, T.",
            "value": 92,
            "numPapers": 41,
            "cluster": "0",
            "index": 37,
            "weight": 9,
            "x": 1052.056500639747,
            "y": 220.0745887184498,
            "px": 992.6528888813929,
            "py": 359.55193292510893,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "Untangling Euler Diagrams",
                "PaperDOI": "10.1109/TVCG.2010.210",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.210",
                "Firstpage": "1090",
                "Lastpage": "1099",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.",
                "AuthorNames": "Riche, N.H.;Dwyer, T.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37590950700;38359965100",
                "Dedupedauthornames": "Riche, N.H.;Dwyer, T.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2008.141;10.1109/TVCG.2009.122;10.1109/TVCG.2006.156;10.1109/TVCG.2006.120;10.1109/TVCG.2008.130;10.1109/TVCG.2006.166;10.1109/VISUAL.1993.398863;10.1109/TVCG.2008.153",
                "AuthorKeywords": "Information Visualization, Euler diagrams, Set Visualization, Graph Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5613447",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;4376154;1532126;4658145;5290706;4015435;4015416;4658142;4015424;398863;4658123"
            }
        },
        {
            "name": "Marriott, K.",
            "value": 66,
            "numPapers": 31,
            "cluster": "0",
            "index": 38,
            "weight": 4,
            "x": 1170.8294594586675,
            "y": -81.71148560069778,
            "px": 919.5516684869592,
            "py": 9.416105292266515,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Memorability of Visual Features in Network Diagrams",
                "PaperDOI": "10.1109/TVCG.2012.245",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.245",
                "Firstpage": "2477",
                "Lastpage": "2485",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.",
                "AuthorNames": "Marriott, K.;Purchase, H.;Wybrow, M.;Goncu, C.",
                "FirstAuthorAffiliation": "Monash Univ., Melbourne, VIC, Australia|c|;;;",
                "AuthorIDs": "37354163600;37329672500;37867777700;38490359600",
                "Dedupedauthornames": "Marriott, K.;Purchase, H.;Wybrow, M.;Goncu, C.",
                "References": "10.1109/TVCG.2008.155;10.1109/TVCG.2009.109",
                "AuthorKeywords": "Network diagrams, graph layout, perceptual theories, visual features, diagram recall, experiment",
                "IEEEXPLOREArticleNumberdeprecated": "6327253",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658147;5290700"
            }
        },
        {
            "name": "Kieffer, S.",
            "value": 6,
            "numPapers": 16,
            "cluster": "0",
            "index": 39,
            "weight": 2,
            "x": 1883.552681477233,
            "y": -2545.376433615246,
            "px": 1700.2692491771027,
            "py": -2535.6401808511646,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context",
                "PaperDOI": "10.1109/TVCG.2008.117",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.117",
                "Firstpage": "1253",
                "Lastpage": "1260",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.",
                "AuthorNames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC|c|;;;",
                "AuthorIDs": "37869962900;37349490300;37869963200;37587984100",
                "Dedupedauthornames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "References": "10.1109/INFVIS.2005.1532151;10.1109/TVCG.2006.156;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Graph layout, systems biology visualization, small multiples, design study",
                "IEEEXPLOREArticleNumberdeprecated": "4658137",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532151;4015435;4015424"
            }
        },
        {
            "name": "Buring, T.",
            "value": 38,
            "numPapers": 1,
            "cluster": "0",
            "index": 40,
            "weight": 1,
            "x": 1050.7129558766646,
            "y": 2136.0403788586927,
            "px": 820.4363077063814,
            "py": 1921.3236426725164,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs",
                "PaperDOI": "10.1109/TVCG.2006.156",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.156",
                "Firstpage": "821",
                "Lastpage": "828",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style",
                "AuthorNames": "Buring, T.;Gerken, J.;Reiterer, H.",
                "FirstAuthorAffiliation": "Konstanz Univ.|c|;;",
                "AuthorIDs": "37326161000;37414256700;37354163600",
                "Dedupedauthornames": "Buring, T.;Gerken, J.;Reiterer, H.",
                "References": "10.1109/INFVIS.2005.1532130",
                "AuthorKeywords": "Graph drawing, constraints, stress majorization, force directed algorithms,multidimensional scaling",
                "IEEEXPLOREArticleNumberdeprecated": "4015435",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532130"
            }
        },
        {
            "name": "Gerken, J.",
            "value": 38,
            "numPapers": 1,
            "cluster": "0",
            "index": 41,
            "weight": 1,
            "x": 698.7326105354534,
            "y": -927.6636119086402,
            "px": 508.4221894298464,
            "py": -767.611864885667,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs",
                "PaperDOI": "10.1109/TVCG.2006.156",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.156",
                "Firstpage": "821",
                "Lastpage": "828",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style",
                "AuthorNames": "Buring, T.;Gerken, J.;Reiterer, H.",
                "FirstAuthorAffiliation": "Konstanz Univ.|c|;;",
                "AuthorIDs": "37326161000;37414256700;37354163600",
                "Dedupedauthornames": "Buring, T.;Gerken, J.;Reiterer, H.",
                "References": "10.1109/INFVIS.2005.1532130",
                "AuthorKeywords": "Graph drawing, constraints, stress majorization, force directed algorithms,multidimensional scaling",
                "IEEEXPLOREArticleNumberdeprecated": "4015435",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532130"
            }
        },
        {
            "name": "Reiterer, H.",
            "value": 38,
            "numPapers": 1,
            "cluster": "0",
            "index": 42,
            "weight": 1,
            "x": 777.2161348631446,
            "y": 2071.384831943667,
            "px": 579.1538094175047,
            "py": 1862.7507560613662,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs",
                "PaperDOI": "10.1109/TVCG.2006.156",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.156",
                "Firstpage": "821",
                "Lastpage": "828",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style",
                "AuthorNames": "Buring, T.;Gerken, J.;Reiterer, H.",
                "FirstAuthorAffiliation": "Konstanz Univ.|c|;;",
                "AuthorIDs": "37326161000;37414256700;37354163600",
                "Dedupedauthornames": "Buring, T.;Gerken, J.;Reiterer, H.",
                "References": "10.1109/INFVIS.2005.1532130",
                "AuthorKeywords": "Graph drawing, constraints, stress majorization, force directed algorithms,multidimensional scaling",
                "IEEEXPLOREArticleNumberdeprecated": "4015435",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532130"
            }
        },
        {
            "name": "Wybrow, M.",
            "value": 51,
            "numPapers": 20,
            "cluster": "0",
            "index": 43,
            "weight": 2,
            "x": 1685.1597887771757,
            "y": -69.45299938129034,
            "px": 1555.1398076049309,
            "py": -96.95382433624236,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Memorability of Visual Features in Network Diagrams",
                "PaperDOI": "10.1109/TVCG.2012.245",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.245",
                "Firstpage": "2477",
                "Lastpage": "2485",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.",
                "AuthorNames": "Marriott, K.;Purchase, H.;Wybrow, M.;Goncu, C.",
                "FirstAuthorAffiliation": "Monash Univ., Melbourne, VIC, Australia|c|;;;",
                "AuthorIDs": "37354163600;37329672500;37867777700;38490359600",
                "Dedupedauthornames": "Marriott, K.;Purchase, H.;Wybrow, M.;Goncu, C.",
                "References": "10.1109/TVCG.2008.155;10.1109/TVCG.2009.109",
                "AuthorKeywords": "Network diagrams, graph layout, perceptual theories, visual features, diagram recall, experiment",
                "IEEEXPLOREArticleNumberdeprecated": "6327253",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658147;5290700"
            }
        },
        {
            "name": "Lam, H.",
            "value": 85,
            "numPapers": 34,
            "cluster": "0",
            "index": 44,
            "weight": 4,
            "x": 768.5748578227798,
            "y": 237.1139831418043,
            "px": 805.6956411225028,
            "py": 268.3207647042592,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "What Makes a Visualization Memorable?",
                "PaperDOI": "10.1109/TVCG.2013.234",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.234",
                "Firstpage": "2306",
                "Lastpage": "2315",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.",
                "AuthorNames": "Borkin, M.A.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.",
                "FirstAuthorAffiliation": "Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Borkin, M.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.",
                "References": "10.1109/TVCG.2012.221;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/TVCG.2012.245;10.1109/TVCG.2011.175",
                "AuthorKeywords": "Visualization taxonomy, information visualization, memorability",
                "IEEEXPLOREArticleNumberdeprecated": "6634103",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327280;1382903;6327282;6327253;6064986"
            }
        },
        {
            "name": "Youn-ah Kang",
            "value": 196,
            "numPapers": 34,
            "cluster": "0",
            "index": 45,
            "weight": 8,
            "x": 661.9071947691214,
            "y": -12.15048073170764,
            "px": 636.8208655411531,
            "py": 5.538290253163809,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "What Makes a Visualization Memorable?",
                "PaperDOI": "10.1109/TVCG.2013.234",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.234",
                "Firstpage": "2306",
                "Lastpage": "2315",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.",
                "AuthorNames": "Borkin, M.A.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.",
                "FirstAuthorAffiliation": "Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Borkin, M.;Vo, A.A.;Bylinskii, Z.;Isola, P.;Sunkavalli, S.;Oliva, A.;Pfister, H.",
                "References": "10.1109/TVCG.2012.221;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/TVCG.2012.245;10.1109/TVCG.2011.175",
                "AuthorKeywords": "Visualization taxonomy, information visualization, memorability",
                "IEEEXPLOREArticleNumberdeprecated": "6634103",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327280;1382903;6327282;6327253;6064986"
            }
        },
        {
            "name": "Zhicheng Liu",
            "value": 383,
            "numPapers": 38,
            "cluster": "0",
            "index": 46,
            "weight": 18,
            "x": 822.2751181900085,
            "y": 176.93690261438556,
            "px": 767.9827567118855,
            "py": 176.8215909395391,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "The Effects of Interactive Latency on Exploratory Visual Analysis",
                "PaperDOI": "10.1109/TVCG.2014.2346452",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346452",
                "Firstpage": "2122",
                "Lastpage": "2131",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.",
                "AuthorNames": "Zhicheng Liu;Heer, J.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Zhicheng Liu;Heer, J.",
                "References": "10.1109/TVCG.2010.177",
                "AuthorKeywords": "Interaction, latency, exploratory analysis, interactive visualization, scalability, user performance, verbal analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6876022",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613437"
            }
        },
        {
            "name": "Ji Soo Yi",
            "value": 176,
            "numPapers": 67,
            "cluster": "0",
            "index": 47,
            "weight": 3,
            "x": 1174.4858250076018,
            "y": 188.84840225924938,
            "px": 1339.3120083764532,
            "py": 225.9200259688549,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making",
                "PaperDOI": "10.1109/TVCG.2012.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.215",
                "Firstpage": "2421",
                "Lastpage": "2430",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.",
                "AuthorNames": "Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Upatising, B.;Ji Soo Yi",
                "FirstAuthorAffiliation": "Sch. ofIndustrial Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;",
                "AuthorIDs": "38489894700;38489279100;37399307600;38489813800;38238292000",
                "Dedupedauthornames": "Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Upatising, B.;Ji Soo Yi",
                "References": "10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.193;10.1109/VAST.2008.4677363;10.1109/TVCG.2010.149;10.1109/TVCG.2011.183;10.1109/VAST.2009.5333920",
                "AuthorKeywords": "Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision",
                "IEEEXPLOREArticleNumberdeprecated": "6327247",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;6065011;4677363;5613432;6064990;5333920"
            }
        },
        {
            "name": "Chang, R.",
            "value": 308,
            "numPapers": 74,
            "cluster": "0",
            "index": 48,
            "weight": 13,
            "x": 656.877840002325,
            "y": 378.43958188610327,
            "px": 595.4891418882331,
            "py": 391.7175207699004,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Helping users recall their reasoning process",
                "PaperDOI": "10.1109/VAST.2010.5653598",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5653598",
                "Firstpage": "187",
                "Lastpage": "194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The final product of an analyst's investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.",
                "AuthorNames": "Lipford, H.R.;Stukes, F.;Wenwen Dou;Hawkins, M.E.;Chang, R.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": "37601288800;37601289000;37606064200;37601287300;37592409400",
                "Dedupedauthornames": "Lipford, H.R.;Stukes, F.;Wenwen Dou;Hawkins, M.E.;Chang, R.",
                "References": "10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/VAST.2008.4677365;10.1109/VAST.2008.4677360;10.1109/VAST.2007.4389009",
                "AuthorKeywords": "Visual analytics, visualization, reasoning process ",
                "IEEEXPLOREArticleNumberdeprecated": "5653598",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658129;4388992;4677365;4677360;4389009"
            }
        },
        {
            "name": "Bongshin Lee",
            "value": 272,
            "numPapers": 53,
            "cluster": "0",
            "index": 49,
            "weight": 10,
            "x": 747.4396167302583,
            "y": 191.20650134816978,
            "px": 766.3943322801967,
            "py": 201.47720339991193,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "A Comparison of User-Generated and Automatic Graph Layouts",
                "PaperDOI": "10.1109/TVCG.2009.109",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.109",
                "Firstpage": "961",
                "Lastpage": "968",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.",
                "AuthorNames": "Dwyer, T.;Bongshin Lee;Fisher, D.;Quinn, K.I.;Isenberg, P.;Robertson, G.;North, C.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": "37326161000;37293389400;37542391000;38108819900;37591317800;37448060300;37419565900",
                "Dedupedauthornames": "Dwyer, T.;Bongshin Lee;Fisher, D.;Quinn, K.I.;Isenberg, P.;Robertson, G.;North, C.",
                "References": "10.1109/TVCG.2008.155",
                "AuthorKeywords": "Graph layout, network layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics",
                "IEEEXPLOREArticleNumberdeprecated": "5290700",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658147"
            }
        },
        {
            "name": "Ziemkiewicz, C.",
            "value": 94,
            "numPapers": 44,
            "cluster": "0",
            "index": 50,
            "weight": 4,
            "x": 521.2085209426477,
            "y": 152.54991483347442,
            "px": 401.696212966059,
            "py": 85.11096900751625,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "The Shaping of Information by Visual Metaphors",
                "PaperDOI": "10.1109/TVCG.2008.171",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.171",
                "Firstpage": "1269",
                "Lastpage": "1276",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.",
                "AuthorNames": "Ziemkiewicz, C.;Kosara, R.",
                "FirstAuthorAffiliation": "UNC, Charlotte, NC|c|;",
                "AuthorIDs": "37548028800;37282563400",
                "Dedupedauthornames": "Ziemkiewicz, C.;Kosara, R.",
                "References": "10.1109/INFVIS.2004.70;10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2004.64;10.1109/INFVIS.2001.963290",
                "AuthorKeywords": "Cognition, visualization theory, metaphors, hierarchies, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658138",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382885;1173153;1382905;963290"
            }
        },
        {
            "name": "Brehmer, M.",
            "value": 57,
            "numPapers": 67,
            "cluster": "0",
            "index": 51,
            "weight": 10,
            "x": 565.353834777431,
            "y": 286.77516551241814,
            "px": 508.77697830559987,
            "py": 317.44437702537414,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "Firstpage": "2301",
                "Lastpage": "2309",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Information visualization, user interfaces, toolkits, 2D graphics",
                "IEEEXPLOREArticleNumberdeprecated": "6064996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Munzner, T.",
            "value": 706,
            "numPapers": 178,
            "cluster": "0",
            "index": 52,
            "weight": 49,
            "x": 653.946179317264,
            "y": 296.40633072180015,
            "px": 628.3618262226903,
            "py": 318.5363757544986,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context",
                "PaperDOI": "10.1109/TVCG.2008.117",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.117",
                "Firstpage": "1253",
                "Lastpage": "1260",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.",
                "AuthorNames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC|c|;;;",
                "AuthorIDs": "37869962900;37349490300;37869963200;37587984100",
                "Dedupedauthornames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "References": "10.1109/INFVIS.2005.1532151;10.1109/TVCG.2006.156;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Graph layout, systems biology visualization, small multiples, design study",
                "IEEEXPLOREArticleNumberdeprecated": "4658137",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532151;4015435;4015424"
            }
        },
        {
            "name": "Ng, J.",
            "value": 0,
            "numPapers": 15,
            "cluster": "0",
            "index": 53,
            "weight": 1,
            "x": 833.7662358206387,
            "y": -1384.024945687843,
            "px": 788.940987162004,
            "py": -1238.2514376329486,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "Firstpage": "2301",
                "Lastpage": "2309",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Information visualization, user interfaces, toolkits, 2D graphics",
                "IEEEXPLOREArticleNumberdeprecated": "6064996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Tate, K.",
            "value": 0,
            "numPapers": 15,
            "cluster": "0",
            "index": 54,
            "weight": 1,
            "x": 845.1608133939599,
            "y": -1410.4107476744002,
            "px": 800.1144591139087,
            "py": -1260.6963060373903,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "Firstpage": "2301",
                "Lastpage": "2309",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Information visualization, user interfaces, toolkits, 2D graphics",
                "IEEEXPLOREArticleNumberdeprecated": "6064996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Dykes, J.",
            "value": 308,
            "numPapers": 99,
            "cluster": "0",
            "index": 55,
            "weight": 24,
            "x": 648.3598449898457,
            "y": 285.39824758181487,
            "px": 618.6368839655082,
            "py": 288.404516769112,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Exploring Uncertainty in Geodemographics with Interactive Graphics",
                "PaperDOI": "10.1109/TVCG.2011.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.197",
                "Firstpage": "2545",
                "Lastpage": "2554",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.",
                "AuthorNames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37590960700;37605079900;37399045100",
                "Dedupedauthornames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "References": "10.1109/INFVIS.1996.559216;10.1109/TVCG.2010.191;10.1109/TVCG.2007.70574;10.1109/TVCG.2010.186;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.165;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12",
                "AuthorKeywords": "Geodemographics, OAC, classification, cartography, uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "6065022",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559216;5613425;4376137;5613436;809866;4658149;4015427;4376144;1382904"
            }
        },
        {
            "name": "Kincaid, R.",
            "value": 80,
            "numPapers": 11,
            "cluster": "0",
            "index": 56,
            "weight": 1,
            "x": 880.4775210478823,
            "y": 1729.6720070850595,
            "px": 831.7104779909922,
            "py": 1552.723032457707,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context",
                "PaperDOI": "10.1109/TVCG.2008.117",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.117",
                "Firstpage": "1253",
                "Lastpage": "1260",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.",
                "AuthorNames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC|c|;;;",
                "AuthorIDs": "37869962900;37349490300;37869963200;37587984100",
                "Dedupedauthornames": "Barsky, A.;Munzner, T.;Gardy, J.;Kincaid, R.",
                "References": "10.1109/INFVIS.2005.1532151;10.1109/TVCG.2006.156;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Graph layout, systems biology visualization, small multiples, design study",
                "IEEEXPLOREArticleNumberdeprecated": "4658137",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532151;4015435;4015424"
            }
        },
        {
            "name": "Lloyd, D.",
            "value": 52,
            "numPapers": 2,
            "cluster": "0",
            "index": 57,
            "weight": 3,
            "x": 531.4340785578738,
            "y": 707.9940952237351,
            "px": 480.36563651422625,
            "py": 797.1386624123852,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study",
                "PaperDOI": "10.1109/TVCG.2011.209",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.209",
                "Firstpage": "2498",
                "Lastpage": "2507",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.",
                "AuthorNames": "Lloyd, D.;Dykes, J.",
                "FirstAuthorAffiliation": "giCentre, City Univ. London, London, UK|c|;",
                "AuthorIDs": "38030446400;37605079900",
                "Dedupedauthornames": "Lloyd, D.;Dykes, J.",
                "References": "10.1109/TVCG.2010.191;10.1109/TVCG.2009.174",
                "AuthorKeywords": "Evaluation, geovisualization, context of use, requirements, field study, prototypes, sketching, design",
                "IEEEXPLOREArticleNumberdeprecated": "6065017",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613425;5290720"
            }
        },
        {
            "name": "Meyer, M.",
            "value": 239,
            "numPapers": 67,
            "cluster": "0",
            "index": 58,
            "weight": 11,
            "x": 555.4277856203105,
            "y": 122.35638665007814,
            "px": 515.8703002276952,
            "py": 77.88335823364231,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Design Activity Framework for Visualization Design",
                "PaperDOI": "10.1109/TVCG.2014.2346331",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346331",
                "Firstpage": "2191",
                "Lastpage": "2200",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research.",
                "AuthorNames": "McKenna, S.;Mazur, D.;Agutter, J.;Meyer, M.",
                "FirstAuthorAffiliation": "Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "McKenna, S.;Mazur, D.;Agutter, J.;Meyer, M.",
                "References": "10.1109/TVCG.2012.213;10.1109/TVCG.2011.209;10.1109/TVCG.2009.111;10.1109/TVCG.2013.126;10.1109/TVCG.2013.145",
                "AuthorKeywords": "Design, frameworks, process, cybersecurity, nested model, decisions, models, evaluation, visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6876000",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327248;6065017;5290695;6634108;6634166"
            }
        },
        {
            "name": "Sedlmair, M.",
            "value": 236,
            "numPapers": 112,
            "cluster": "0",
            "index": 59,
            "weight": 17,
            "x": 778.817999793558,
            "y": 177.91787230990056,
            "px": 749.8482038416372,
            "py": 127.83504431415238,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "Firstpage": "2818",
                "Lastpage": "2827",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "References": "10.1109/TVCG.2009.121;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.143;10.1109/TVCG.2011.224;10.1109/TVCG.2010.199;10.1109/TVCG.2010.223;10.1109/TVCG.2012.213;10.1109/TVCG.2010.134;10.1109/TVCG.2009.194;10.1109/TVCG.2011.174;10.1109/TVCG.2009.111;10.1109/TVCG.2011.206;10.1109/TVCG.2012.234;10.1109/TVCG.2012.292;10.1109/TVCG.2008.128;10.1109/TVCG.2009.167;10.1109/TVCG.2012.223",
                "AuthorKeywords": "Evaluation, validation, systematic review, visualization, scientific visualization, information visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634108",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Lehmann, D.J.",
            "value": 46,
            "numPapers": 32,
            "cluster": "3",
            "index": 60,
            "weight": 5,
            "x": 1102.3632636255659,
            "y": 544.5520062843657,
            "px": 1025.06632515917,
            "py": 685.1969437519928,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Improving the visual analysis of high-dimensional datasets using quality measures",
                "PaperDOI": "10.1109/VAST.2010.5652433",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652433",
                "Firstpage": "19",
                "Lastpage": "26",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.",
                "AuthorNames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "FirstAuthorAffiliation": "Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;",
                "AuthorIDs": "37603943800;37546817000;37601992200;37266875400;37273816400",
                "Dedupedauthornames": "Albuquerque, G.;Eisemann, M.;Lehmann, D.J.;Theisel, H.;Magnor, M.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652433",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;1532142;663916;4035766;5332628;4658161"
            }
        },
        {
            "name": "Grinstein, G.",
            "value": 75,
            "numPapers": 11,
            "cluster": "3",
            "index": 61,
            "weight": 2,
            "x": -95.71051908615401,
            "y": -295.3637947827455,
            "px": -265.23055777551446,
            "py": -349.21227674996703,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "DNA visual and analytic data mining",
                "PaperDOI": "10.1109/VISUAL.1997.663916",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663916",
                "Firstpage": "437",
                "Lastpage": "441",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Describes data exploration techniques designed to classify DNA sequences. Several visualization and data mining techniques were used to validate and attempt to discover new methods for distinguishing coding DNA sequences (exons) from non-coding DNA sequences (introns). The goal of the data mining was to see whether some other, possibly non-linear combination of the fundamental position-dependent DNA nucleotide frequency values could be a better predictor than the AMI (average mutual information). We tried many different classification techniques including rule-based classifiers and neural networks. We also used visualization of both the original data and the results of the data mining to help verify patterns and to understand the distinction between the different types of data and classifications. In particular, the visualization helped us develop refinements to neural network classifiers, which have accuracies as high as any known method. Finally, we discuss the interactions between visualization and data mining and suggest an integrated approach.",
                "AuthorNames": "Hoffman, P.;Grinstein, G.;Marx, K.;Grosse, I.;Stanley, E.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Perception Res., Massachusetts Univ., Lowell, MA, USA|c|;;;;",
                "AuthorIDs": "37617749600;38470495600;38318555000;37622312400;38180962800",
                "Dedupedauthornames": "Hoffman, P.;Grinstein, G.;Marx, K.;Grosse, I.;Stanley, E.",
                "References": "10.1109/VISUAL.1995.485139",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "663916",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "485139"
            }
        },
        {
            "name": "Marx, K.",
            "value": 50,
            "numPapers": 4,
            "cluster": "3",
            "index": 62,
            "weight": 2,
            "x": 2093.4788023265187,
            "y": -792.8002952967848,
            "px": 2028.6426507687934,
            "py": -879.4445164339743,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "DNA visual and analytic data mining",
                "PaperDOI": "10.1109/VISUAL.1997.663916",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663916",
                "Firstpage": "437",
                "Lastpage": "441",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Describes data exploration techniques designed to classify DNA sequences. Several visualization and data mining techniques were used to validate and attempt to discover new methods for distinguishing coding DNA sequences (exons) from non-coding DNA sequences (introns). The goal of the data mining was to see whether some other, possibly non-linear combination of the fundamental position-dependent DNA nucleotide frequency values could be a better predictor than the AMI (average mutual information). We tried many different classification techniques including rule-based classifiers and neural networks. We also used visualization of both the original data and the results of the data mining to help verify patterns and to understand the distinction between the different types of data and classifications. In particular, the visualization helped us develop refinements to neural network classifiers, which have accuracies as high as any known method. Finally, we discuss the interactions between visualization and data mining and suggest an integrated approach.",
                "AuthorNames": "Hoffman, P.;Grinstein, G.;Marx, K.;Grosse, I.;Stanley, E.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Perception Res., Massachusetts Univ., Lowell, MA, USA|c|;;;;",
                "AuthorIDs": "37617749600;38470495600;38318555000;37622312400;38180962800",
                "Dedupedauthornames": "Hoffman, P.;Grinstein, G.;Marx, K.;Grosse, I.;Stanley, E.",
                "References": "10.1109/VISUAL.1995.485139",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "663916",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "485139"
            }
        },
        {
            "name": "Schneidewind, J.",
            "value": 128,
            "numPapers": 19,
            "cluster": "5",
            "index": 63,
            "weight": 6,
            "x": 901.5035301453377,
            "y": 125.81611623444184,
            "px": 849.7217756083752,
            "py": 203.73570527574321,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Combining automated analysis and visualization techniques for effective exploration of high-dimensional data",
                "PaperDOI": "10.1109/VAST.2009.5332628",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332628",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.",
                "AuthorNames": "Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;",
                "AuthorIDs": "37590724000;37603943800;37546817000;37669961800;37266875400;37273816400;37283138700",
                "Dedupedauthornames": "Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.A.",
                "References": "10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249017;10.1109/VISUAL.1994.346302;10.1109/VAST.2006.261423",
                "AuthorKeywords": "\n",
                "IEEEXPLOREArticleNumberdeprecated": "5332628",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532142;729568;1249017;346302;4035766"
            }
        },
        {
            "name": "Vilanova, A.",
            "value": 162,
            "numPapers": 75,
            "cluster": "6",
            "index": 64,
            "weight": 20,
            "x": 933.6587138961671,
            "y": 544.2476216197882,
            "px": 944.1150594390464,
            "py": 551.5597640954358,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "Isenberg, T.",
            "value": 174,
            "numPapers": 76,
            "cluster": "5",
            "index": 65,
            "weight": 11,
            "x": 989.7451285122404,
            "y": 260.3748272684943,
            "px": 1014.5825443808387,
            "py": 278.357350551864,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty",
                "PaperDOI": "10.1109/TVCG.2012.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.220",
                "Firstpage": "2769",
                "Lastpage": "2778",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.",
                "AuthorNames": "Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA, Sophia Antipolis, France|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Boukhelifa, N.;Bezerianos, A.;Isenberg, T.;Fekete, J.",
                "References": "10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1992.235199;10.1109/TVCG.2007.70530;10.1109/TVCG.2009.114;10.1109/VAST.2009.5332611;10.1109/VAST.2006.261424;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70589;10.1109/VISUAL.2000.885679",
                "AuthorKeywords": "Uncertainty visualization, qualitative evaluation, quantitative evaluation, perception",
                "IEEEXPLOREArticleNumberdeprecated": "6327283",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532853;235199;4376197;5290731;5332611;4035764;6327281;4376132;885679"
            }
        },
        {
            "name": "Raidou, R.G.",
            "value": 0,
            "numPapers": 19,
            "cluster": "5",
            "index": 66,
            "weight": 1,
            "x": 1184.2427907476695,
            "y": 321.4128253744156,
            "px": 1226.4599249597218,
            "py": 307.49631342179424,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "Breeuwer, M.",
            "value": 83,
            "numPapers": 37,
            "cluster": "6",
            "index": 67,
            "weight": 6,
            "x": 906.8558754955051,
            "y": 482.29683328230084,
            "px": 918.8677752226683,
            "py": 485.63496254166,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "Eisemann, E.",
            "value": 4,
            "numPapers": 25,
            "cluster": "5",
            "index": 68,
            "weight": 1,
            "x": 1476.875106861229,
            "y": 267.5296762223405,
            "px": 1464.0986974030236,
            "py": 255.9264891039264,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "McCurdy, N.",
            "value": 0,
            "numPapers": 13,
            "cluster": "1",
            "index": 69,
            "weight": 2,
            "x": 709.5418818344612,
            "y": 578.7211607186887,
            "px": 717.6932960860019,
            "py": 560.7072697113408,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Viegas, F.B.",
            "value": 398,
            "numPapers": 18,
            "cluster": "1",
            "index": 70,
            "weight": 24,
            "x": 776.0821020884391,
            "y": 528.2914961778375,
            "px": 757.9146318387619,
            "py": 506.86967199918956,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Parallel Tag Clouds to explore and analyze faceted text corpora",
                "PaperDOI": "10.1109/VAST.2009.5333443",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5333443",
                "Firstpage": "91",
                "Lastpage": "98",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Do court cases differ from place to place? What kind of picture do we get by looking at a country's collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.",
                "AuthorNames": "Collins, C.;Viegas, F.B.;Wattenberg, M.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto, ON, Canada|c|;;",
                "AuthorIDs": "37669874100;37681355300;37550759700",
                "Dedupedauthornames": "Collins, C.;Viegas, F.B.;Wattenberg, M.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.175;10.1109/TVCG.2008.172;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Text visualization, corpus visualization, information retrieval, text mining, tag clouds",
                "IEEEXPLOREArticleNumberdeprecated": "5333443",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;4376132;4658131;4658133;4389006;4015424"
            }
        },
        {
            "name": "Wattenberg, M.",
            "value": 704,
            "numPapers": 32,
            "cluster": "1",
            "index": 71,
            "weight": 46,
            "x": 798.0929342961364,
            "y": 477.3039357670325,
            "px": 770.9691621715671,
            "py": 469.6975528099065,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Baby names, visualization, and social data analysis",
                "PaperDOI": "10.1109/INFVIS.2005.1532122",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532122",
                "Firstpage": "1",
                "Lastpage": "7",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The Name Voyager, a Web based visualization of historical trends in baby naming, has proven remarkably popular. This paper discusses the interaction techniques it uses for smooth visual exploration of thousands of time series. We also describe design decisions behind the application and lessons learned in creating an application that makes do-it-yourself data mining popular. The prime lesson, it is hypothesized, is that an information visualization tool may be fruitfully viewed not as a tool but as part of an online social environment. In other words, to design a successful exploratory data analysis tool, one good strategy is to create a system that enables \"social\" data analysis",
                "AuthorNames": "Wattenberg, M.",
                "FirstAuthorAffiliation": "IBM Res., White Plains, NY|c|",
                "AuthorIDs": "37550759700",
                "Dedupedauthornames": "Wattenberg, M.",
                "References": "10.1109/INFVIS.2004.8;10.1109/INFVIS.2000.885098",
                "AuthorKeywords": "Design Study, Time-Varying Data Visualization, Human-Computer Interaction",
                "IEEEXPLOREArticleNumberdeprecated": "1532122",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382897;885098"
            }
        },
        {
            "name": "Lein, J.",
            "value": 0,
            "numPapers": 13,
            "cluster": "1",
            "index": 72,
            "weight": 2,
            "x": 683.2907209622339,
            "y": 515.2301434718652,
            "px": 689.3795824187674,
            "py": 512.2930978184683,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Coles, K.",
            "value": 0,
            "numPapers": 13,
            "cluster": "1",
            "index": 73,
            "weight": 2,
            "x": 1162.6314857766436,
            "y": 539.5102934282378,
            "px": 1171.7561708209569,
            "py": 534.5797745977227,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Satyanarayan, A.",
            "value": 0,
            "numPapers": 12,
            "cluster": "0",
            "index": 74,
            "weight": 1,
            "x": -1700.9947825345664,
            "y": -106.37973933258223,
            "px": -1490.2807416060539,
            "py": -60.854683079314505,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "An extended data-flow architecture for data analysis and visualization",
                "PaperDOI": "10.1109/VISUAL.1995.480821",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480821",
                "Firstpage": "263",
                "Lastpage": "270, 461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure data-flow. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer",
                "AuthorNames": "Abram, G.;Treinish, L.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;",
                "AuthorIDs": "37378534500;37372175500",
                "Dedupedauthornames": "Abram, G.;Treinish, L.A.",
                "References": "10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480821",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346305;398860;175818;235219"
            }
        },
        {
            "name": "Russell, R.",
            "value": 0,
            "numPapers": 12,
            "cluster": "0",
            "index": 75,
            "weight": 1,
            "x": 538.4319220817122,
            "y": -456.56305402612526,
            "px": 536.5520092688732,
            "py": -354.84442615994095,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "An extended data-flow architecture for data analysis and visualization",
                "PaperDOI": "10.1109/VISUAL.1995.480821",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480821",
                "Firstpage": "263",
                "Lastpage": "270, 461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure data-flow. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer",
                "AuthorNames": "Abram, G.;Treinish, L.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;",
                "AuthorIDs": "37378534500;37372175500",
                "Dedupedauthornames": "Abram, G.;Treinish, L.A.",
                "References": "10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480821",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346305;398860;175818;235219"
            }
        },
        {
            "name": "Hoffswell, J.",
            "value": 0,
            "numPapers": 12,
            "cluster": "0",
            "index": 76,
            "weight": 1,
            "x": 1338.1040541900848,
            "y": 1510.6087603091075,
            "px": 1252.799265894745,
            "py": 1388.8886573622458,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "An extended data-flow architecture for data analysis and visualization",
                "PaperDOI": "10.1109/VISUAL.1995.480821",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480821",
                "Firstpage": "263",
                "Lastpage": "270, 461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure data-flow. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer",
                "AuthorNames": "Abram, G.;Treinish, L.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;",
                "AuthorIDs": "37378534500;37372175500",
                "Dedupedauthornames": "Abram, G.;Treinish, L.A.",
                "References": "10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480821",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346305;398860;175818;235219"
            }
        },
        {
            "name": "Bostock, M.",
            "value": 265,
            "numPapers": 31,
            "cluster": "0",
            "index": 77,
            "weight": 7,
            "x": 685.694311857361,
            "y": 249.8361530649427,
            "px": 670.9126234942005,
            "py": 197.56968370230996,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "Firstpage": "2301",
                "Lastpage": "2309",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Information visualization, user interfaces, toolkits, 2D graphics",
                "IEEEXPLOREArticleNumberdeprecated": "6064996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Weaver, C.",
            "value": 203,
            "numPapers": 64,
            "cluster": "0",
            "index": 78,
            "weight": 20,
            "x": 861.1522716068987,
            "y": 19.121737165557274,
            "px": 852.6604883884144,
            "py": 4.891931397548897,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Building Highly-Coordinated Visualizations in Improvise",
                "PaperDOI": "10.1109/INFVIS.2004.12",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.12",
                "Firstpage": "159",
                "Lastpage": "166",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration",
                "AuthorNames": "Weaver, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Wisconsin Univ., Madison, WI|c|",
                "AuthorIDs": "37564883300",
                "Dedupedauthornames": "Weaver, C.",
                "References": "10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "coordinated queries, coordination, exploratory visualization, multiple views, visual abstraction language",
                "IEEEXPLOREArticleNumberdeprecated": "1382904",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173141;885086"
            }
        },
        {
            "name": "Mackinlay, J.",
            "value": 227,
            "numPapers": 22,
            "cluster": "0",
            "index": 79,
            "weight": 6,
            "x": 845.8678712050246,
            "y": 131.09925437110488,
            "px": 827.3625045901787,
            "py": 43.984358264018454,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Show Me: Automatic Presentation for Visual Analysis",
                "PaperDOI": "10.1109/TVCG.2007.70594",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70594",
                "Firstpage": "1137",
                "Lastpage": "1144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.",
                "AuthorNames": "Mackinlay, J.;Hanrahan, P.;Stolte, C.",
                "FirstAuthorAffiliation": "Tableau Software, Seattle|c|;;",
                "AuthorIDs": "37372036700;37349803800;37442008700",
                "Dedupedauthornames": "Mackinlay, J.;Hanrahan, P.;Stolte, C.",
                "References": "10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Automatic presentation, visual analysis, graphic design, best practices, data visualization, small multiples",
                "IEEEXPLOREArticleNumberdeprecated": "4376133",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086"
            }
        },
        {
            "name": "Hinrichs, U.",
            "value": 16,
            "numPapers": 17,
            "cluster": "1",
            "index": 80,
            "weight": 2,
            "x": 771.500433483538,
            "y": 579.5422231002556,
            "px": 772.4106443232835,
            "py": 558.0543184610646,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning",
                "PaperDOI": "10.1109/TVCG.2012.272",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.272",
                "Firstpage": "2789",
                "Lastpage": "2798",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.",
                "AuthorNames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37884160900;38490270400;38490599200;38489620500;38490437100;38490180100",
                "Dedupedauthornames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "References": "10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541",
                "AuthorKeywords": "Informal science education, collaborative learning, large tree visualizations, multi-touch interaction",
                "IEEEXPLOREArticleNumberdeprecated": "6327285",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963285;636718;5290695;4376146;1173153;4658128;1173148;4376134"
            }
        },
        {
            "name": "Forlini, S.",
            "value": 0,
            "numPapers": 12,
            "cluster": "1",
            "index": 81,
            "weight": 2,
            "x": 754.9564565472391,
            "y": 551.7934530226014,
            "px": 752.0507980875739,
            "py": 539.0098446502957,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning",
                "PaperDOI": "10.1109/TVCG.2012.272",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.272",
                "Firstpage": "2789",
                "Lastpage": "2798",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.",
                "AuthorNames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37884160900;38490270400;38490599200;38489620500;38490437100;38490180100",
                "Dedupedauthornames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "References": "10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541",
                "AuthorKeywords": "Informal science education, collaborative learning, large tree visualizations, multi-touch interaction",
                "IEEEXPLOREArticleNumberdeprecated": "6327285",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963285;636718;5290695;4376146;1173153;4658128;1173148;4376134"
            }
        },
        {
            "name": "Moynihan, B.",
            "value": 0,
            "numPapers": 12,
            "cluster": "1",
            "index": 82,
            "weight": 2,
            "x": 743.3751232474491,
            "y": 549.0689020884028,
            "px": 741.6091525200784,
            "py": 543.9405098867381,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning",
                "PaperDOI": "10.1109/TVCG.2012.272",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.272",
                "Firstpage": "2789",
                "Lastpage": "2798",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.",
                "AuthorNames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37884160900;38490270400;38490599200;38489620500;38490437100;38490180100",
                "Dedupedauthornames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "References": "10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541",
                "AuthorKeywords": "Informal science education, collaborative learning, large tree visualizations, multi-touch interaction",
                "IEEEXPLOREArticleNumberdeprecated": "6327285",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963285;636718;5290695;4376146;1173153;4658128;1173148;4376134"
            }
        },
        {
            "name": "Dragicevic, P.",
            "value": 182,
            "numPapers": 55,
            "cluster": "0",
            "index": 83,
            "weight": 8,
            "x": 728.3610561594086,
            "y": 243.83499457604873,
            "px": 855.2440700072046,
            "py": 259.5745230036756,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "An Interaction Model for Visualizations Beyond The Desktop",
                "PaperDOI": "10.1109/TVCG.2013.134",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.134",
                "Firstpage": "2396",
                "Lastpage": "2405",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.",
                "AuthorNames": "Jansen, Y.;Dragicevic, P.",
                "FirstAuthorAffiliation": "Inria & Univ. Paris Sud, Paris, France|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Jansen, Y.;Dragicevic, P.",
                "References": "10.1109/TVCG.2010.177;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2006.178;10.1109/TVCG.2009.162;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Information visualization, interaction model, notational system, physical visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634126",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613437;1532781;4376131;1532136;6327257;4376144;6327275;4015439;5290713;1249008;729560;146375"
            }
        },
        {
            "name": "Conglei Shi",
            "value": 136,
            "numPapers": 52,
            "cluster": "1",
            "index": 84,
            "weight": 13,
            "x": 721.8967038343142,
            "y": 498.0766714962135,
            "px": 714.2850834442311,
            "py": 482.4393170169401,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Jones, M.W.",
            "value": 27,
            "numPapers": 32,
            "cluster": "9",
            "index": 85,
            "weight": 3,
            "x": 652.2042276270996,
            "y": -756.1993655814633,
            "px": 816.3983096217632,
            "py": -748.2024838954005,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Smooth Graphs for Visual Exploration of Higher-Order State Transitions",
                "PaperDOI": "10.1109/TVCG.2009.181",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.181",
                "Firstpage": "969",
                "Lastpage": "976",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.",
                "AuthorNames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.",
                "FirstAuthorAffiliation": "Visualization Group, Delft Univ. of Technol., Delft, Netherlands|c|;;;;;",
                "AuthorIDs": "37550793100;37373834100;38110391600;37335785800;37267247900;37295045800",
                "Dedupedauthornames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.W.;Laramee, R.S.;Post, F.H.",
                "References": "10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.155;10.1109/TVCG.2008.135;10.1109/TVCG.2006.192;10.1109/INFVIS.2001.963281;10.1109/INFVIS.2001.963281;10.1109/TVCG.2006.147",
                "AuthorKeywords": "State transitions, Graph drawing, Time series, Biological data",
                "IEEEXPLOREArticleNumberdeprecated": "5290701",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528685;4658147;4658140;4015418;963281;963281;4015425"
            }
        },
        {
            "name": "Carpendale, S.",
            "value": 516,
            "numPapers": 109,
            "cluster": "1",
            "index": 86,
            "weight": 36,
            "x": 725.3557599196866,
            "y": 485.67084326965823,
            "px": 726.3487674493228,
            "py": 488.954176940435,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations",
                "PaperDOI": "10.1109/TVCG.2009.122",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.122",
                "Firstpage": "1009",
                "Lastpage": "1016",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.",
                "AuthorNames": "Collins, C.;Penn, G.;Carpendale, S.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto, ON, Canada|c|;;",
                "AuthorIDs": "37669874100;37830217600;37285000100",
                "Dedupedauthornames": "Collins, C.;Penn, G.;Carpendale, S.",
                "References": "10.1109/TVCG.2006.122;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.130;10.1109/TVCG.2008.144;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.153",
                "AuthorKeywords": "clustering, spatial layout, graph visualization, tree visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5290706",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015419;1532150;4658142;4658148;1532126;4376140;4658123"
            }
        },
        {
            "name": "Shneiderman, B.",
            "value": 565,
            "numPapers": 35,
            "cluster": "0",
            "index": 87,
            "weight": 20,
            "x": 852.799649979831,
            "y": 402.7967600906213,
            "px": 816.2650198087772,
            "py": 391.4799515283878,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories",
                "PaperDOI": "10.1109/VAST.2006.261421",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261421",
                "Firstpage": "167",
                "Lastpage": "174",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)",
                "AuthorNames": "Fails, J.A.;Karlson, A.;Shahamat, L.;Shneiderman, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Maryland Univ.|c|;;;",
                "AuthorIDs": "37830130000;38266509300;37565888100;",
                "Dedupedauthornames": "Fails, J.A.;Karlson, A.;Shahamat, L.;Shneiderman, B.",
                "References": "10.1109/INFVIS.2001.963273",
                "AuthorKeywords": "Temporal query, information visualization, user\ninterface",
                "IEEEXPLOREArticleNumberdeprecated": "4035762",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963273"
            }
        },
        {
            "name": "Pousman, Z.",
            "value": 90,
            "numPapers": 5,
            "cluster": "1",
            "index": 88,
            "weight": 1,
            "x": 1259.7458058616749,
            "y": 576.9601764229496,
            "px": 1135.2857239574237,
            "py": 558.5590184802651,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Casual Information Visualization: Depictions of Data in Everyday Life",
                "PaperDOI": "10.1109/TVCG.2007.70541",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70541",
                "Firstpage": "1145",
                "Lastpage": "1152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.",
                "AuthorNames": "Pousman, Z.;Stasko, J.T.;Mateas, M.",
                "FirstAuthorAffiliation": "Georgia Inst.of Technol, Atlanta|c|;;",
                "AuthorIDs": "37945316800;37267736900;37329261300",
                "Dedupedauthornames": "Pousman, Z.;Stasko, J.;Mateas, M.",
                "References": "10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.8;10.1109/INFVIS.2003.1249031;10.1109/INFVIS.2004.59;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Casual information visualization, ambient infovis, social infovis, editorial, design, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4376134",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532126;1382897;1249031;1382903;146375"
            }
        },
        {
            "name": "Mateas, M.",
            "value": 90,
            "numPapers": 5,
            "cluster": "1",
            "index": 89,
            "weight": 1,
            "x": 2573.88638287762,
            "y": 786.5030718980736,
            "px": 2337.9701078637436,
            "py": 749.9151046961357,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Casual Information Visualization: Depictions of Data in Everyday Life",
                "PaperDOI": "10.1109/TVCG.2007.70541",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70541",
                "Firstpage": "1145",
                "Lastpage": "1152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.",
                "AuthorNames": "Pousman, Z.;Stasko, J.T.;Mateas, M.",
                "FirstAuthorAffiliation": "Georgia Inst.of Technol, Atlanta|c|;;",
                "AuthorIDs": "37945316800;37267736900;37329261300",
                "Dedupedauthornames": "Pousman, Z.;Stasko, J.;Mateas, M.",
                "References": "10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.8;10.1109/INFVIS.2003.1249031;10.1109/INFVIS.2004.59;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Casual information visualization, ambient infovis, social infovis, editorial, design, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4376134",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532126;1382897;1249031;1382903;146375"
            }
        },
        {
            "name": "Goodwin, S.",
            "value": 15,
            "numPapers": 17,
            "cluster": "0",
            "index": 90,
            "weight": 3,
            "x": 1177.840637846702,
            "y": 711.231683470992,
            "px": 1254.4872974263983,
            "py": 802.6999571276465,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Creative User-Centered Visualization Design for Energy Analysts and Modelers",
                "PaperDOI": "10.1109/TVCG.2013.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.145",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.",
                "AuthorNames": "Goodwin, S.;Dykes, J.;Jones, S.;Dillingham, I.;Dove, G.;Duffy, A.;Kachkaev, A.;Slingsby, A.;Wood, J.",
                "FirstAuthorAffiliation": "giCentre, City Univ. London, London, UK|c|;;;;;;;;",
                "AuthorIDs": ";;;;;;;;",
                "Dedupedauthornames": "Goodwin, S.;Dykes, J.;Jones, S.;Dillingham, I.;Dove, G.;Duffy, A.;Kachkaev, A.;Slingsby, A.;Wood, J.",
                "References": "10.1109/TVCG.2010.191;10.1109/TVCG.2012.213;10.1109/TVCG.2011.196;10.1109/TVCG.2007.70539;10.1109/INFVIS.1999.801851;10.1109/TVCG.2011.209",
                "AuthorKeywords": "Creativity techniques, user-centered design, data visualization, smart home, energy consumption",
                "IEEEXPLOREArticleNumberdeprecated": "6634166",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613425;6327248;6065016;4376146;801851;6065017"
            }
        },
        {
            "name": "Slingsby, A.",
            "value": 210,
            "numPapers": 82,
            "cluster": "0",
            "index": 91,
            "weight": 13,
            "x": 648.8260999121958,
            "y": 310.6446549821764,
            "px": 660.2290458548329,
            "py": 318.08784275250486,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Exploring Uncertainty in Geodemographics with Interactive Graphics",
                "PaperDOI": "10.1109/TVCG.2011.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.197",
                "Firstpage": "2545",
                "Lastpage": "2554",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.",
                "AuthorNames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37590960700;37605079900;37399045100",
                "Dedupedauthornames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "References": "10.1109/INFVIS.1996.559216;10.1109/TVCG.2010.191;10.1109/TVCG.2007.70574;10.1109/TVCG.2010.186;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.165;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12",
                "AuthorKeywords": "Geodemographics, OAC, classification, cartography, uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "6065022",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559216;5613425;4376137;5613436;809866;4658149;4015427;4376144;1382904"
            }
        },
        {
            "name": "Turkay, C.",
            "value": 61,
            "numPapers": 45,
            "cluster": "5",
            "index": 92,
            "weight": 8,
            "x": 1155.5614381491962,
            "y": 303.86723554314204,
            "px": 1158.323626158546,
            "py": 341.42896867402857,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis",
                "PaperDOI": "10.1109/TVCG.2007.70558",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70558",
                "Firstpage": "1161",
                "Lastpage": "1168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through gw-choropleth maps, multivariate gw-boxplots, gw-shading and scalograms. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The geowigs proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in gw-shading. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.",
                "AuthorNames": "Dykes, J.;Brunsdon, C.",
                "FirstAuthorAffiliation": "City Univ., London|c|;",
                "AuthorIDs": "37605079900;37945380100",
                "Dedupedauthornames": "Dykes, J.;Brunsdon, C.",
                "References": "",
                "AuthorKeywords": "Geographical weighting, exploratory data analysis, scale, multivariate, directional, interaction, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "4376135",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Wood, J.",
            "value": 283,
            "numPapers": 98,
            "cluster": "0",
            "index": 93,
            "weight": 16,
            "x": 752.1689913739606,
            "y": 363.5504340423818,
            "px": 713.5265872838032,
            "py": 395.37379848880374,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Exploring Uncertainty in Geodemographics with Interactive Graphics",
                "PaperDOI": "10.1109/TVCG.2011.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.197",
                "Firstpage": "2545",
                "Lastpage": "2554",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.",
                "AuthorNames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37590960700;37605079900;37399045100",
                "Dedupedauthornames": "Slingsby, A.;Dykes, J.;Wood, J.",
                "References": "10.1109/INFVIS.1996.559216;10.1109/TVCG.2010.191;10.1109/TVCG.2007.70574;10.1109/TVCG.2010.186;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.165;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12",
                "AuthorKeywords": "Geodemographics, OAC, classification, cartography, uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "6065022",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559216;5613425;4376137;5613436;809866;4658149;4015427;4376144;1382904"
            }
        },
        {
            "name": "Lundervold, A.",
            "value": 38,
            "numPapers": 24,
            "cluster": "5",
            "index": 94,
            "weight": 5,
            "x": 1149.4739872244797,
            "y": 207.38661694101245,
            "px": 1144.2456464402826,
            "py": 244.78203048286264,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2012.256",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.256",
                "Firstpage": "2621",
                "Lastpage": "2630",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.",
                "AuthorNames": "Turkay, C.;Lundervold, A.;Lundervold, A.J.;Hauser, H.",
                "FirstAuthorAffiliation": "Dept. of Inf., Univ. of Bergen, Bergen, Norway|c|;;;",
                "AuthorIDs": "37567685600;37373564100;38489275800;37274158800",
                "Dedupedauthornames": "Turkay, C.;Lundervold, A.;Lundervold, A.;Hauser, H.",
                "References": "10.1109/TVCG.2009.199;10.1109/INFVIS.2005.1532142;10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2011.178;10.1109/TVCG.2007.70569;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153",
                "AuthorKeywords": "Interactive visual analysis, high-dimensional data analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6327268",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290745;1532142;6102449;885086;346302;4658163;6065027;4376166;809866;1382891;1382892;5290704"
            }
        },
        {
            "name": "Whitaker, R.T.",
            "value": 256,
            "numPapers": 47,
            "cluster": "2",
            "index": 95,
            "weight": 12,
            "x": 241.1785632576983,
            "y": 205.69490694499004,
            "px": 237.16034453383827,
            "py": 181.65823237325316,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles",
                "PaperDOI": "10.1109/TVCG.2013.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.143",
                "Firstpage": "2713",
                "Lastpage": "2722",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.",
                "AuthorNames": "Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Whitaker, R.T.;Mirzargar, M.;Kirby, R.M.",
                "References": "10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.181",
                "AuthorKeywords": "Uncertainty visualization, boxplots, band depth, ensemble visualization, order statistics",
                "IEEEXPLOREArticleNumberdeprecated": "6634129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183769;568105;1532807;5613483"
            }
        },
        {
            "name": "Laidlaw, D.H.",
            "value": 278,
            "numPapers": 79,
            "cluster": "3",
            "index": 96,
            "weight": 14,
            "x": -38.31778064654425,
            "y": 583.23650397536,
            "px": -88.07825410032632,
            "py": 701.8225134234739,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Visualizing Multivalued Data from 2D Incompressible Flows Using Concepts from Painting",
                "PaperDOI": "10.1109/VISUAL.1999.809905",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809905",
                "Firstpage": "333",
                "Lastpage": "540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a new visualization method for 2D flows which allows us to combine multiple data values in an image for simultaneous viewing. We utilize concepts from oil painting, art and design as introduced in (Laidlaw et al., 1998) to examine problems within fluid mechanics. We use a combination of discrete and continuous visual elements arranged in multiple layers to visually represent the data. The representations are inspired by the brush strokes artists apply in layers to create an oil painting. We display commonly visualized quantities such as velocity and vorticity together with three additional mathematically derived quantities: the rate of strain tensor, and the turbulent charge and turbulent current. We describe the motivation for simultaneously examining these quantities and use the motivation to guide our choice of visual representation for each particular quantity. We present visualizations of three flow examples and observations concerning some of the physical relationships made apparent by the simultaneous display technique that we employed.",
                "AuthorNames": "Kirby, R.M.;Marmanis, H.;Laidlaw, D.H.",
                "FirstAuthorAffiliation": "Div. of Appl. Math., Brown Univ., Providence, RI, USA|c|;;",
                "AuthorIDs": "37275716100;37442720100;37275712600",
                "Dedupedauthornames": "Kirby, R.M.;Marmanis, H.;Laidlaw, D.H.",
                "References": "10.1109/VISUAL.1998.745294",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809905",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745294"
            }
        },
        {
            "name": "Jian Chen",
            "value": 79,
            "numPapers": 47,
            "cluster": "3",
            "index": 97,
            "weight": 2,
            "x": -1162.1745298366777,
            "y": 1596.289331858579,
            "px": -963.6074759528974,
            "py": 1418.2418091970333,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "A Systematic Review on the Practice of Evaluating Visualization",
                "PaperDOI": "10.1109/TVCG.2013.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.126",
                "Firstpage": "2818",
                "Lastpage": "2827",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
                "AuthorNames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "FirstAuthorAffiliation": "INRIA, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Isenberg, T.;Isenberg, P.;Jian Chen;Sedlmair, M.;Moller, T.",
                "References": "10.1109/TVCG.2009.121;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.143;10.1109/TVCG.2011.224;10.1109/TVCG.2010.199;10.1109/TVCG.2010.223;10.1109/TVCG.2012.213;10.1109/TVCG.2010.134;10.1109/TVCG.2009.194;10.1109/TVCG.2011.174;10.1109/TVCG.2009.111;10.1109/TVCG.2011.206;10.1109/TVCG.2012.234;10.1109/TVCG.2012.292;10.1109/TVCG.2008.128;10.1109/TVCG.2009.167;10.1109/TVCG.2012.223",
                "AuthorKeywords": "Evaluation, validation, systematic review, visualization, scientific visualization, information visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634108",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290766;1532781;4015488;6064940;5613502;5613487;6327248;5613480;5290733;6065005;5290695;6064943;6327215;6327228;4658185;5290692;6327216"
            }
        },
        {
            "name": "Forsberg, A.",
            "value": 61,
            "numPapers": 5,
            "cluster": "3",
            "index": 98,
            "weight": 1,
            "x": -1638.0613900144388,
            "y": 745.6019848609317,
            "px": -1347.8909938635795,
            "py": 634.1225685042068,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Comparing 3D Vector field Visualization Methods: A User Study",
                "PaperDOI": "10.1109/TVCG.2009.126",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.126",
                "Firstpage": "1219",
                "Lastpage": "1226",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In a user study comparing four visualization methods for three-dimensional vector data, participants used visualizations from each method to perform five simple but representative tasks: 1) determining whether a given point was a critical point, 2) determining the type of a critical point, 3) determining whether an integral curve would advect through two points, 4) determining whether swirling movement is present at a point, and 5) determining whether the vector field is moving faster at one point than another. The visualization methods were line and tube representations of integral curves with both monoscopic and stereoscopic viewing. While participants reported a preference for stereo lines, quantitative results showed performance among the tasks varied by method. Users performed all tasks better with methods that: 1) gave a clear representation with no perceived occlusion, 2) clearly visualized curve speed and direction information, and 3) provided fewer rich 3D cues (e.g., shading, polygonal arrows, overlap cues, and surface textures). These results provide quantitative support for anecdotal evidence on visualization methods. The tasks and testing framework also give a basis for comparing other visualization methods, for creating more effective methods, and for defining additional tasks to explore further the tradeoffs among the methods.",
                "AuthorNames": "Forsberg, A.;Jian Chen;Laidlaw, D.H.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Brown Univ., RI, USA|c|;;",
                "AuthorIDs": "37612088000;38107662400;37275712600",
                "Dedupedauthornames": "Forsberg, A.;Jian Chen;Laidlaw, D.H.",
                "References": "10.1109/VISUAL.1996.567777;10.1109/VISUAL.2005.1532831;10.1109/VISUAL.2004.59;10.1109/VISUAL.2005.1532772",
                "AuthorKeywords": "3D vector fields, visualization, user study, tubes, lines, stereoscopic and monoscopic viewing",
                "IEEEXPLOREArticleNumberdeprecated": "5290732",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567777;1532831;1372179;1532772"
            }
        },
        {
            "name": "Moller, T.",
            "value": 475,
            "numPapers": 134,
            "cluster": "2",
            "index": 99,
            "weight": 34,
            "x": 254.95266293886183,
            "y": 135.8533964780187,
            "px": 253.48328339740533,
            "py": 134.36120124947584,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Rethinking Visualization: A High-Level Taxonomy",
                "PaperDOI": "10.1109/INFVIS.2004.59",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.59",
                "Firstpage": "151",
                "Lastpage": "158",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present the novel high-level visualization taxonomy. Our taxonomy classifies visualization algorithms rather than data. Algorithms are categorized based on the assumptions they make about the data being visualized; we call this set of assumptions the design model. Because our taxonomy is based on design models, it is more flexible than existing taxonomies and considers the user's conceptual model, emphasizing the human aspect of visualization. Design models are classified according to whether they are discrete or continuous and by how much the algorithm designer chooses display attributes such as spatialization, timing, colour, and transparency. This novel approach provides an alternative view of the visualization field that helps explain how traditional divisions (e.g., information and scientific visualization) relates and overlap, and that may inspire research ideas in hybrid visualization areas",
                "AuthorNames": "Tory, M.;Moller, T.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC|c|;",
                "AuthorIDs": "37275861300;37275858700",
                "Dedupedauthornames": "Tory, M.;Moller, T.",
                "References": "10.1109/VISUAL.1990.146375;10.1109/INFVIS.2000.885092;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1999.801856",
                "AuthorKeywords": "visualization, taxonomy, classification, design model, user model, conceptual model",
                "IEEEXPLOREArticleNumberdeprecated": "1382903",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146375;885092;636792;801856"
            }
        },
        {
            "name": "Schultz, T.",
            "value": 80,
            "numPapers": 56,
            "cluster": "3",
            "index": 100,
            "weight": 7,
            "x": -391.36589727558993,
            "y": 863.2585563793552,
            "px": -528.5199744504691,
            "py": 860.1363495886363,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Exploded Views for Volume Data",
                "PaperDOI": "10.1109/TVCG.2006.140",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.140",
                "Firstpage": "1077",
                "Lastpage": "1084",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second",
                "AuthorNames": "Bruckner, S.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;",
                "AuthorIDs": "37265895700;37284271200",
                "Dedupedauthornames": "Bruckner, S.;Groller, E.",
                "References": "10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2005.1532783;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250384;10.1109/INFVIS.1996.559215;10.1109/VISUAL.2004.104;10.1109/VISUAL.2005.1532817",
                "AuthorKeywords": "Illustrative visualization, exploded views, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "4015467",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250400;1532783;1532856;1532807;1250384;559215;1372221;1532817"
            }
        },
        {
            "name": "Groller, E.",
            "value": 1115,
            "numPapers": 295,
            "cluster": "2",
            "index": 101,
            "weight": 136,
            "x": 286.36196304366825,
            "y": 231.00939606362422,
            "px": 274.42656000257807,
            "py": 220.004625512262,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees",
                "PaperDOI": "10.1109/TVCG.2014.2346626",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346626",
                "Firstpage": "1693",
                "Lastpage": "1702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.",
                "AuthorNames": "Beham, M.;Herzner, W.;Groller, M.E.;Kehrer, J.",
                "FirstAuthorAffiliation": "Austrian Inst. of Technol., Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Beham, M.;Herzner, W.;Groller, E.;Kehrer, J.",
                "References": "10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581",
                "AuthorKeywords": "Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6875958",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634138;6634107;5613440;5290748;1532856;5613488;4015425;398859;809866;4376186"
            }
        },
        {
            "name": "Weiss, K.",
            "value": 2,
            "numPapers": 11,
            "cluster": "3",
            "index": 102,
            "weight": 1,
            "x": 267.77819122659787,
            "y": 668.3094615819671,
            "px": 257.03369931148995,
            "py": 679.9970615537051,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Direct Interval Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2010.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.145",
                "Firstpage": "1505",
                "Lastpage": "1514",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",
                "AuthorNames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "FirstAuthorAffiliation": "VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;;",
                "AuthorIDs": "37393968500;37268045000;37282624500",
                "Dedupedauthornames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "References": "10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.85;10.1109/VISUAL.1995.480789;10.1109/VISUAL.2002.1183762;10.1109/TVCG.2009.149;10.1109/TVCG.2006.113;10.1109/TVCG.2008.186;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532808;10.1109/TVCG.2008.160;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.204;10.1109/VISUAL.1995.480807",
                "AuthorKeywords": "Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",
                "IEEEXPLOREArticleNumberdeprecated": "5613492",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745713;663886;1372176;480789;1183762;5290780;4015502;4658152;885683;1532808;4658188;1250384;5290775;480807"
            }
        },
        {
            "name": "Duchaineau, M.",
            "value": 119,
            "numPapers": 36,
            "cluster": "3",
            "index": 103,
            "weight": 5,
            "x": 219.0011042245614,
            "y": 638.4709235810528,
            "px": 227.03684549301178,
            "py": 641.715158908234,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "ROAMing terrain: Real-time Optimally Adapting Meshes",
                "PaperDOI": "10.1109/VISUAL.1997.663860",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663860",
                "Firstpage": "81",
                "Lastpage": "88",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Terrain visualization is a difficult problem for applications requiring accurate images of large datasets at high frame rates, such as flight simulation and ground-based aircraft testing using synthetic sensor simulation. On current graphics hardware, the problem is to maintain dynamic, view-dependent triangle meshes and texture maps that produce good images at the required frame rate. We present an algorithm for constructing triangle meshes that optimizes flexible view-dependent error metrics, produces guaranteed error bounds, achieves specified triangle counts directly and uses frame-to-frame coherence to operate at high frame rates for thousands of triangles per frame. Our method, dubbed Real-time Optimally Adapting Meshes (ROAM), uses two priority queues to drive split and merge operations that maintain continuous triangulations built from pre-processed bintree triangles. We introduce two additional performance optimizations: incremental triangle stripping and priority-computation deferral lists. ROAM's execution time is proportional to the number of triangle changes per frame, which is typically a few percent of the output mesh size; hence ROAM's performance is insensitive to the resolution and extent of the input terrain. Dynamic terrain and simple vertex morphing are supported.",
                "AuthorNames": "Duchaineau, M.;Wolinsky, M.;Sigeti, D.E.;Miller, M.C.;Aldrich, C.;Mineev-Weinstein, M.B.",
                "FirstAuthorAffiliation": "Los Alamos Nat. Lab., NM, USA|c|;;;;;",
                "AuthorIDs": "37267813100;37443252200;37443253500;;37608683600;37612202100",
                "Dedupedauthornames": "Duchaineau, M.;Wolinsky, M.;Sigeti, D.E.;Miller, M.;Aldrich, C.;Mineev-Weinstein, M.B.",
                "References": "10.1109/VISUAL.1996.567600;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1996.568125;10.1109/VISUAL.1995.480813;10.1109/VISUAL.1995.480805",
                "AuthorKeywords": "triangle bintree, view-dependent mesh, frame-to-frame coherence, greedy algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "663860",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567600;568126;568125;480813;480805"
            }
        },
        {
            "name": "Lindstrom, P.",
            "value": 144,
            "numPapers": 87,
            "cluster": "3",
            "index": 104,
            "weight": 15,
            "x": 220.78530029716939,
            "y": 581.3603078973192,
            "px": 228.67705827722926,
            "py": 570.7229864389334,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Direct Interval Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2010.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.145",
                "Firstpage": "1505",
                "Lastpage": "1514",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",
                "AuthorNames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "FirstAuthorAffiliation": "VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;;",
                "AuthorIDs": "37393968500;37268045000;37282624500",
                "Dedupedauthornames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "References": "10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.85;10.1109/VISUAL.1995.480789;10.1109/VISUAL.2002.1183762;10.1109/TVCG.2009.149;10.1109/TVCG.2006.113;10.1109/TVCG.2008.186;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532808;10.1109/TVCG.2008.160;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.204;10.1109/VISUAL.1995.480807",
                "AuthorKeywords": "Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",
                "IEEEXPLOREArticleNumberdeprecated": "5613492",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745713;663886;1372176;480789;1183762;5290780;4015502;4658152;885683;1532808;4658188;1250384;5290775;480807"
            }
        },
        {
            "name": "Pascucci, V.",
            "value": 524,
            "numPapers": 136,
            "cluster": "3",
            "index": 105,
            "weight": 54,
            "x": 268.71564692137423,
            "y": 567.9644156799089,
            "px": 278.64629165940033,
            "py": 561.9596380235156,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Interactive view-dependent rendering of large isosurfaces",
                "PaperDOI": "10.1109/VISUAL.2002.1183810",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183810",
                "Firstpage": "475",
                "Lastpage": "482",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an algorithm for interactively extracting and rendering isosurfaces of large volume datasets in a view-dependent fashion. A recursive tetrahedral mesh refinement scheme, based on longest edge bisection, is used to hierarchically decompose the data into a multiresolution structure. This data structure allows fast extraction of arbitrary isosurfaces to within user specified view-dependent error bounds. A data layout scheme based on hierarchical space filling curves provides access to the data in a cache coherent manner that follows the data access pattern indicated by the mesh refinement.",
                "AuthorNames": "Gregorski, B.;Duchaineau, M.;Lindstrom, P.;Pascucci, V.;Joy, K.I.",
                "FirstAuthorAffiliation": "Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA|c|;;;;",
                "AuthorIDs": "37267290500;37267813100;37269320000;37284312600;37267811400",
                "Dedupedauthornames": "Gregorski, B.;Duchaineau, M.;Lindstrom, P.;Pascucci, V.;Joy, K.I.",
                "References": "10.1109/VISUAL.2000.885681;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1999.809878;10.1109/VISUAL.2001.964502;10.1109/VISUAL.1997.663869;10.1109/VISUAL.2000.885705;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2001.964524;10.1109/VISUAL.2000.885703",
                "AuthorKeywords": "View-Dependent Rendering, Isosurfaces, Multiresolution Tetrahedal Meshes, Multiresolution Techniques",
                "IEEEXPLOREArticleNumberdeprecated": "1183810",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885681;964533;809878;964502;663869;885705;745300;663860;964524;885703"
            }
        },
        {
            "name": "Kanitsar, A.",
            "value": 318,
            "numPapers": 25,
            "cluster": "2",
            "index": 106,
            "weight": 23,
            "x": 60.08824145241425,
            "y": 118.48865632883465,
            "px": 106.18057740461039,
            "py": 91.43477374324756,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "Firstpage": "37",
                "Lastpage": "44",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "References": "10.1109/VISUAL.2001.964555;10.1109/VISUAL.2001.964538",
                "AuthorKeywords": "computed tomography angiography, vessel analysis, curved planar reformation",
                "IEEEXPLOREArticleNumberdeprecated": "1183754",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964555;964538"
            }
        },
        {
            "name": "Fleischmann, D.",
            "value": 228,
            "numPapers": 13,
            "cluster": "2",
            "index": 107,
            "weight": 17,
            "x": -13.725558440969648,
            "y": 307.04321976035015,
            "px": 17.143872406514628,
            "py": 271.6610720877978,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "Firstpage": "37",
                "Lastpage": "44",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "References": "10.1109/VISUAL.2001.964555;10.1109/VISUAL.2001.964538",
                "AuthorKeywords": "computed tomography angiography, vessel analysis, curved planar reformation",
                "IEEEXPLOREArticleNumberdeprecated": "1183754",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964555;964538"
            }
        },
        {
            "name": "Wegenkittl, R.",
            "value": 291,
            "numPapers": 31,
            "cluster": "2",
            "index": 108,
            "weight": 20,
            "x": 53.508109411906204,
            "y": 212.99823220319487,
            "px": 64.39547190364405,
            "py": 186.1654110681474,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "Visualizing the behaviour of higher dimensional dynamical systems",
                "PaperDOI": "10.1109/VISUAL.1997.663867",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663867",
                "Firstpage": "119",
                "Lastpage": "125",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In recent years scientific visualization has been driven by the need to visualize high-dimensional data sets within high-dimensional spaces. However most visualization methods are designed to show only some statistical features of the data set. The paper deals with the visualization of trajectories of high-dimensional dynamical systems which form a L n n data set of a smooth n-dimensional flow. Three methods that are based on the idea of parallel coordinates are presented and discussed. Visualizations done with these new methods are shown and an interactive visualization tool for the exploration of high-dimensional dynamical systems is proposed.",
                "AuthorNames": "Wegenkittl, R.;Loffelmann, H.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics, Wien Univ. of Technol., Austria|c|;;",
                "AuthorIDs": "37267822600;37427428300;38471589500",
                "Dedupedauthornames": "Wegenkittl, R.;Loffelmann, H.;Groller, E.",
                "References": "10.1109/VISUAL.1990.146373;10.1109/VISUAL.1991.175796;10.1109/VISUAL.1993.398869;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1993.398849",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "663867",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146373;175796;398869;175795;146386;146402;398849"
            }
        },
        {
            "name": "Felkel, P.",
            "value": 145,
            "numPapers": 6,
            "cluster": "2",
            "index": 109,
            "weight": 6,
            "x": 195.57224684344166,
            "y": -59.593958924592656,
            "px": 185.01354922903437,
            "py": 53.087888964094915,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "CPR - curved planar reformation",
                "PaperDOI": "10.1109/VISUAL.2002.1183754",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183754",
                "Firstpage": "37",
                "Lastpage": "44",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37267788200;37282552200",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Felkel, P.;Groller, E.",
                "References": "10.1109/VISUAL.2001.964555;10.1109/VISUAL.2001.964538",
                "AuthorKeywords": "computed tomography angiography, vessel analysis, curved planar reformation",
                "IEEEXPLOREArticleNumberdeprecated": "1183754",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964555;964538"
            }
        },
        {
            "name": "Viola, I.",
            "value": 131,
            "numPapers": 46,
            "cluster": "2",
            "index": 110,
            "weight": 5,
            "x": 301.99881728178855,
            "y": 45.85841076444919,
            "px": 315.3297117710292,
            "py": 31.630256037737023,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Caricaturistic Visualization",
                "PaperDOI": "10.1109/TVCG.2006.123",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.123",
                "Firstpage": "1085",
                "Lastpage": "1092",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable",
                "AuthorNames": "Rautek, P.;Viola, I.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;",
                "AuthorIDs": "37828701300;37282726800;37284271200",
                "Dedupedauthornames": "Rautek, P.;Viola, I.;Groller, E.",
                "References": "10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2004.48;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.2005.1532835",
                "AuthorKeywords": "Illustrative Visualization, Focus+Context Techniques, Volume Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015468",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532856;1372190;1532857;1532835"
            }
        },
        {
            "name": "Correa, C.",
            "value": 280,
            "numPapers": 73,
            "cluster": "2",
            "index": 111,
            "weight": 21,
            "x": 282.64242316241865,
            "y": 156.08705442811953,
            "px": 307.46900597040724,
            "py": 148.9669079422014,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Curve-Centric Volume Reformation for Comparative Visualization",
                "PaperDOI": "10.1109/TVCG.2009.136",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.136",
                "Firstpage": "1235",
                "Lastpage": "1242",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present two visualization techniques for curve-centric volume reformation with the aim to create compelling comparative visualizations. A curve-centric volume reformation deforms a volume, with regards to a curve in space, to create a new space in which the curve evaluates to zero in two dimensions and spans its arc-length in the third. The volume surrounding the curve is deformed such that spatial neighborhood to the curve is preserved. The result of the curve-centric reformation produces images where one axis is aligned to arc-length, and thus allows researchers and practitioners to apply their arc-length parameterized data visualizations in parallel for comparison. Furthermore we show that when visualizing dense data, our technique provides an inside out projection, from the curve and out into the volume, which allows for inspection what is around the curve. Finally we demonstrate the usefulness of our techniques in the context of two application cases. We show that existing data visualizations of arc-length parameterized data can be enhanced by using our techniques, in addition to creating a new view and perspective on volumetric data around curves. Additionally we show how volumetric data can be brought into plotting environments that allow precise readouts. In the first case we inspect streamlines in a flow field around a car, and in the second we inspect seismic volumes and well logs from drilling.",
                "AuthorNames": "Lampe, O.D.;Correa, C.;Kwan-Liu Ma;Hauser, H.",
                "FirstAuthorAffiliation": "CMR AS, Univ. of Bergen, Bergen, Norway|c|;;;",
                "AuthorIDs": "37842366200;37282925900;37275869400;37274158800",
                "Dedupedauthornames": "Lampe, O.D.;Correa, C.;Kwan-Liu Ma;Hauser, H.",
                "References": "10.1109/TVCG.2006.144;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964540;10.1109/VISUAL.1992.235194;10.1109/VISUAL.2003.1250353",
                "AuthorKeywords": "Volume Deformation, Curve-Centric-Reformation, Comparative Visualization, Radial Ray-Casting",
                "IEEEXPLOREArticleNumberdeprecated": "5290734",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015466;1183754;964540;235194;1250353"
            }
        },
        {
            "name": "Kwan-Liu Ma",
            "value": 756,
            "numPapers": 233,
            "cluster": "2",
            "index": 112,
            "weight": 62,
            "x": 325.7002978045132,
            "y": 201.11993171819506,
            "px": 326.2710836891051,
            "py": 191.97808085065128,
            "node": {
                "Conference": "InfoVis",
                "Year": "2003",
                "PaperTitle": "MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes",
                "PaperDOI": "10.1109/INFVIS.2003.1249009",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2003.1249009",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focus+context radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.",
                "AuthorNames": "Jankun-Kelly, T.J.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Mississippi State Univ., Starkville, MS, USA|c|;",
                "AuthorIDs": "38198374100;37275869400",
                "Dedupedauthornames": "Jankun-Kelly, T.J.;Kwan-Liu Ma",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1996.559214;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173151",
                "AuthorKeywords": "information visualization, focus+context, radial graph layout, graph drawing",
                "IEEEXPLOREArticleNumberdeprecated": "1249009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;636718;559214;963279;1173151"
            }
        },
        {
            "name": "Hege, H.-C.",
            "value": 400,
            "numPapers": 97,
            "cluster": "3",
            "index": 113,
            "weight": 27,
            "x": 205.5100384439408,
            "y": 486.08594574247104,
            "px": 219.49372650536444,
            "py": 480.5624775900853,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Voronoi-Based Extraction and Visualization of Molecular Paths",
                "PaperDOI": "10.1109/TVCG.2011.259",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.259",
                "Firstpage": "2025",
                "Lastpage": "2034",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual analysis is widely used to study the behavior of molecules. Of particular interest are the analysis of molecular interactions and the investigation of binding sites. For large molecules, however, it is difficult to detect possible binding sites and paths leading to these sites by pure visual inspection. In this paper, we present new methods for the computation and visualization of potential molecular paths. Using a novel filtering method, we extract the significant paths from the Voronoi diagram of spheres. For the interactive visualization of molecules and their paths, we present several methods using deferred shading and other state-of-theart techniques. To allow for a fast overview of reachable regions of the molecule, we illuminate the molecular surface using a large number of light sources placed on the extracted paths. We also provide a method to compute the extension surface of selected paths and visualize it using the skin surface. Furthermore, we use the extension surface to clip the molecule to allow easy visual tracking of even deeply buried paths. The methods are applied to several proteins to demonstrate their usefulness.",
                "AuthorNames": "Lindow, N.;Baum, D.;Hege, H.-C.",
                "FirstAuthorAffiliation": "Zuse Inst. Berlin, Berlin, Germany|c|;;",
                "AuthorIDs": "38017029700;38182750200;37282272000",
                "Dedupedauthornames": "Lindow, N.;Baum, D.;Hege, H.-C.",
                "References": "10.1109/TVCG.2010.218;10.1109/TVCG.2006.115;10.1109/TVCG.2009.157",
                "AuthorKeywords": "Molecular visualization, data filtering, geometry-based techniques, view-dependent visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6064966",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613501;4015487;5290753"
            }
        },
        {
            "name": "Ament, M.",
            "value": 16,
            "numPapers": 53,
            "cluster": "2",
            "index": 114,
            "weight": 6,
            "x": 131.10674476765504,
            "y": 187.9209300341646,
            "px": 146.29425443956578,
            "py": 182.63502590011424,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Direct Interval Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2010.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.145",
                "Firstpage": "1505",
                "Lastpage": "1514",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",
                "AuthorNames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "FirstAuthorAffiliation": "VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;;",
                "AuthorIDs": "37393968500;37268045000;37282624500",
                "Dedupedauthornames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "References": "10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.85;10.1109/VISUAL.1995.480789;10.1109/VISUAL.2002.1183762;10.1109/TVCG.2009.149;10.1109/TVCG.2006.113;10.1109/TVCG.2008.186;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532808;10.1109/TVCG.2008.160;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.204;10.1109/VISUAL.1995.480807",
                "AuthorKeywords": "Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",
                "IEEEXPLOREArticleNumberdeprecated": "5613492",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745713;663886;1372176;480789;1183762;5290780;4015502;4658152;885683;1532808;4658188;1250384;5290775;480807"
            }
        },
        {
            "name": "Sadlo, F.",
            "value": 88,
            "numPapers": 62,
            "cluster": "2",
            "index": 115,
            "weight": 7,
            "x": 244.69934169303195,
            "y": 159.66999801273587,
            "px": 261.2006545321502,
            "py": 157.23005415437157,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Low-Pass Filtered Volumetric Shadows",
                "PaperDOI": "10.1109/TVCG.2014.2346333",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346333",
                "Firstpage": "2437",
                "Lastpage": "2446",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.",
                "AuthorNames": "Ament, M.;Sadlo, F.;Dachsbacher, C.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Karlsruhe Inst. of Technol., Karlsruhe, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Ament, M.;Sadlo, F.;Dachsbacher, C.;Weiskopf, D.",
                "References": "10.1109/TVCG.2013.172;10.1109/TVCG.2013.129;10.1109/TVCG.2011.211;10.1109/VISUAL.2003.1250394;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764",
                "AuthorKeywords": "Direct volume rendering, volume illumination, soft shadows, filtered shadows, summed area table",
                "IEEEXPLOREArticleNumberdeprecated": "6875905",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634193;6634150;6064977;1250394;6327241;6064955;6064942;1183764"
            }
        },
        {
            "name": "Weiskopf, D.",
            "value": 417,
            "numPapers": 159,
            "cluster": "2",
            "index": 116,
            "weight": 30,
            "x": 282.90280879868385,
            "y": 259.66385159429274,
            "px": 269.52714221233634,
            "py": 255.45871727149375,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study",
                "PaperDOI": "10.1109/TVCG.2011.193",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.193",
                "Firstpage": "2440",
                "Lastpage": "2448",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.",
                "AuthorNames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": "VISUS, Univ. of Stuttgart, Germany|c|;;;;",
                "AuthorIDs": "37586953400;38017426500;37665271000;;38470313100",
                "Dedupedauthornames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "References": "10.1109/TVCG.2010.209;10.1109/INFVIS.2004.70",
                "AuthorKeywords": "Hierarchy visualization, node-link layout, eye tracking, user study",
                "IEEEXPLOREArticleNumberdeprecated": "6065011",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613430;1382885"
            }
        },
        {
            "name": "Dachsbacher, C.",
            "value": 2,
            "numPapers": 22,
            "cluster": "2",
            "index": 117,
            "weight": 2,
            "x": 350.806168584119,
            "y": 175.12529073625484,
            "px": 362.08550946209976,
            "py": 194.04995184495667,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Low-Pass Filtered Volumetric Shadows",
                "PaperDOI": "10.1109/TVCG.2014.2346333",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346333",
                "Firstpage": "2437",
                "Lastpage": "2446",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.",
                "AuthorNames": "Ament, M.;Sadlo, F.;Dachsbacher, C.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Karlsruhe Inst. of Technol., Karlsruhe, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Ament, M.;Sadlo, F.;Dachsbacher, C.;Weiskopf, D.",
                "References": "10.1109/TVCG.2013.172;10.1109/TVCG.2013.129;10.1109/TVCG.2011.211;10.1109/VISUAL.2003.1250394;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764",
                "AuthorKeywords": "Direct volume rendering, volume illumination, soft shadows, filtered shadows, summed area table",
                "IEEEXPLOREArticleNumberdeprecated": "6875905",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634193;6634150;6064977;1250394;6327241;6064955;6064942;1183764"
            }
        },
        {
            "name": "Ropinski, T.",
            "value": 82,
            "numPapers": 47,
            "cluster": "2",
            "index": 118,
            "weight": 6,
            "x": 226.73778172252068,
            "y": 130.98692537727226,
            "px": 248.71950457140278,
            "py": 138.55550099760987,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping",
                "PaperDOI": "10.1109/TVCG.2012.232",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.232",
                "Firstpage": "2364",
                "Lastpage": "2371",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.",
                "AuthorNames": "Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.",
                "FirstAuthorAffiliation": "Linkoping Univ., Linkoping, Sweden|c|;;;",
                "AuthorIDs": "38228659100;38230927900;37295281400;37284192000",
                "Dedupedauthornames": "Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.",
                "References": "10.1109/TVCG.2011.211",
                "AuthorKeywords": "Volume rendering, photon mapping, global illumination, participating media",
                "IEEEXPLOREArticleNumberdeprecated": "6327241",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064977"
            }
        },
        {
            "name": "Ynnerman, A.",
            "value": 110,
            "numPapers": 48,
            "cluster": "2",
            "index": 119,
            "weight": 9,
            "x": 193.27273278757934,
            "y": 147.689856660959,
            "px": 198.09389408964486,
            "py": 141.51736189621948,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping",
                "PaperDOI": "10.1109/TVCG.2012.232",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.232",
                "Firstpage": "2364",
                "Lastpage": "2371",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.",
                "AuthorNames": "Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.",
                "FirstAuthorAffiliation": "Linkoping Univ., Linkoping, Sweden|c|;;;",
                "AuthorIDs": "38228659100;38230927900;37295281400;37284192000",
                "Dedupedauthornames": "Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.",
                "References": "10.1109/TVCG.2011.211",
                "AuthorKeywords": "Volume rendering, photon mapping, global illumination, participating media",
                "IEEEXPLOREArticleNumberdeprecated": "6327241",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064977"
            }
        },
        {
            "name": "Han-Wei Shen",
            "value": 507,
            "numPapers": 185,
            "cluster": "2",
            "index": 120,
            "weight": 55,
            "x": 366.3113488521111,
            "y": 167.90232610170972,
            "px": 339.6659105503274,
            "py": 160.96810118420487,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Information-Aware Framework for Exploring Multivariate Data Sets",
                "PaperDOI": "10.1109/TVCG.2013.133",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.133",
                "Firstpage": "2683",
                "Lastpage": "2692",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.",
                "AuthorNames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "FirstAuthorAffiliation": "Gravity Group, Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "References": "10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785",
                "AuthorKeywords": "Information theory, framework, isosurface, multivariate uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "6634187",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613460;5290764;146402;5613461;4015449;4658163;5613439;1382895;4658188;4658174;4389000;6064997;485139;1532833;5613459;663875;1183785"
            }
        },
        {
            "name": "Woodring, J.",
            "value": 76,
            "numPapers": 30,
            "cluster": "7",
            "index": 121,
            "weight": 2,
            "x": 1347.69201925867,
            "y": 339.6569916509997,
            "px": 1328.3532457520835,
            "py": 308.3979461619389,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Information-Aware Framework for Exploring Multivariate Data Sets",
                "PaperDOI": "10.1109/TVCG.2013.133",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.133",
                "Firstpage": "2683",
                "Lastpage": "2692",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.",
                "AuthorNames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "FirstAuthorAffiliation": "Gravity Group, Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "References": "10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785",
                "AuthorKeywords": "Information theory, framework, isosurface, multivariate uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "6634187",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613460;5290764;146402;5613461;4015449;4658163;5613439;1382895;4658188;4658174;4389000;6064997;485139;1532833;5613459;663875;1183785"
            }
        },
        {
            "name": "Jnicke, H.",
            "value": 122,
            "numPapers": 23,
            "cluster": "2",
            "index": 122,
            "weight": 2,
            "x": -115.27231514775772,
            "y": 1011.7633988677882,
            "px": -55.407439725499096,
            "py": 928.360470973263,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Visual Exploration of Climate Variability Changes Using Wavelet Analysis",
                "PaperDOI": "10.1109/TVCG.2009.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.197",
                "Firstpage": "1375",
                "Lastpage": "1382",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.",
                "AuthorNames": "Janicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig, Germany|c|;;;",
                "AuthorIDs": "37393638200;37869987100;38108879000;37282574800",
                "Dedupedauthornames": "Jnicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.",
                "References": "10.1109/TVCG.2008.116;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1997.663871",
                "AuthorKeywords": "Wavelet analysis, multivariate data, time-dependent data, climate variability change visualization, El Nino",
                "IEEEXPLOREArticleNumberdeprecated": "5290751",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658163;1250383;663871"
            }
        },
        {
            "name": "Scheuermann, G.",
            "value": 505,
            "numPapers": 146,
            "cluster": "3",
            "index": 123,
            "weight": 51,
            "x": 254.9083156120017,
            "y": 478.33856570589217,
            "px": 254.02695763622714,
            "py": 481.1711596190811,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Visual Exploration of Climate Variability Changes Using Wavelet Analysis",
                "PaperDOI": "10.1109/TVCG.2009.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.197",
                "Firstpage": "1375",
                "Lastpage": "1382",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.",
                "AuthorNames": "Janicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig, Germany|c|;;;",
                "AuthorIDs": "37393638200;37869987100;38108879000;37282574800",
                "Dedupedauthornames": "Jnicke, H.;Bottinger, M.;Mikolajewicz, U.;Scheuermann, G.",
                "References": "10.1109/TVCG.2008.116;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1997.663871",
                "AuthorKeywords": "Wavelet analysis, multivariate data, time-dependent data, climate variability change visualization, El Nino",
                "IEEEXPLOREArticleNumberdeprecated": "5290751",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658163;1250383;663871"
            }
        },
        {
            "name": "Kollmann, W.",
            "value": 83,
            "numPapers": 15,
            "cluster": "3",
            "index": 124,
            "weight": 4,
            "x": 224.27116383626884,
            "y": 566.3757848517758,
            "px": 238.8095028683402,
            "py": 559.9233227037482,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Multifield Visualization Using Local Statistical Complexity",
                "PaperDOI": "10.1109/TVCG.2007.70615",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70615",
                "Firstpage": "1384",
                "Lastpage": "1391",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.",
                "AuthorNames": "Janicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Jnicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "References": "10.1109/VISUAL.1999.809865;10.1109/VISUAL.2003.1250372;10.1109/TVCG.2006.165;10.1109/VISUAL.1999.809905;10.1109/TVCG.2006.183;10.1109/VISUAL.2003.1250383",
                "AuthorKeywords": "Local statistical complexity, multifield visualization, time-dependent, coherent structures, feature detection, information theroy, flow visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4376165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809865;1250372;4015447;809905;4015473;1250383"
            }
        },
        {
            "name": "Lingyun Yu",
            "value": 24,
            "numPapers": 13,
            "cluster": "5",
            "index": 125,
            "weight": 2,
            "x": 1226.3719307435015,
            "y": 97.2147688992821,
            "px": 1253.462853520959,
            "py": 131.32728148795212,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation",
                "PaperDOI": "10.1109/TVCG.2008.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.153",
                "Firstpage": "1141",
                "Lastpage": "1148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.",
                "AuthorNames": "Elmqvist, N.;Dragicevic, P.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA, Paris|c|;;",
                "AuthorIDs": "37295438200;37590932700;37407972900",
                "Dedupedauthornames": "Elmqvist, N.;Dragicevic, P.;Fekete, J.",
                "References": "10.1109/TVCG.2007.70515;10.1109/VAST.2007.4389013;10.1109/TVCG.2007.70577;10.1109/VISUAL.1990.146386;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.15",
                "AuthorKeywords": "Visual exploration, visual queries, visual analytics, navigation, multivariate data, interaction",
                "IEEEXPLOREArticleNumberdeprecated": "4658123",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376144;4389013;4376131;146386;4035743;1532136;346302;729568;485139;1249016;885086;1382892;1382905;4376146;1382895"
            }
        },
        {
            "name": "Efstathiou, K.",
            "value": 8,
            "numPapers": 10,
            "cluster": "5",
            "index": 126,
            "weight": 2,
            "x": 1290.140355036683,
            "y": 173.34748688629247,
            "px": 1310.9312265229048,
            "py": 199.500255570186,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation",
                "PaperDOI": "10.1109/TVCG.2008.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.153",
                "Firstpage": "1141",
                "Lastpage": "1148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.",
                "AuthorNames": "Elmqvist, N.;Dragicevic, P.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA, Paris|c|;;",
                "AuthorIDs": "37295438200;37590932700;37407972900",
                "Dedupedauthornames": "Elmqvist, N.;Dragicevic, P.;Fekete, J.",
                "References": "10.1109/TVCG.2007.70515;10.1109/VAST.2007.4389013;10.1109/TVCG.2007.70577;10.1109/VISUAL.1990.146386;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.15",
                "AuthorKeywords": "Visual exploration, visual queries, visual analytics, navigation, multivariate data, interaction",
                "IEEEXPLOREArticleNumberdeprecated": "4658123",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376144;4389013;4376131;146386;4035743;1532136;346302;729568;485139;1249016;885086;1382892;1382905;4376146;1382895"
            }
        },
        {
            "name": "Vos, F.M.",
            "value": 53,
            "numPapers": 12,
            "cluster": "5",
            "index": 127,
            "weight": 2,
            "x": 1293.324173610846,
            "y": 265.6944566014312,
            "px": 1232.5156753957106,
            "py": 290.68013541987085,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "WYSIWYP: What You See Is What You Pick",
                "PaperDOI": "10.1109/TVCG.2012.292",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.292",
                "Firstpage": "2236",
                "Lastpage": "2244",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (what you see is what you pick) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.",
                "AuthorNames": "Wiebel, A.;Vos, F.M.;Foerster, D.;Hege, H.-C.",
                "FirstAuthorAffiliation": "Zuse Inst. Berlin (ZIB), Berlin, Germany|c|;;;",
                "AuthorIDs": "37565763400;37271678400;38489178700;37282272000",
                "Dedupedauthornames": "Wiebel, A.;Vos, F.M.;Foerster, D.;Hege, H.-C.",
                "References": "10.1109/TVCG.2012.217;10.1109/VISUAL.1998.745337;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70576;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2009.121",
                "AuthorKeywords": "Picking, volume rendering, WYSIWYG",
                "IEEEXPLOREArticleNumberdeprecated": "6327228",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327229;745337;1250384;4376185;1532833;5290766"
            }
        },
        {
            "name": "Preim, B.",
            "value": 195,
            "numPapers": 81,
            "cluster": "6",
            "index": 128,
            "weight": 23,
            "x": 888.2774626951382,
            "y": 581.2651030007602,
            "px": 892.3630157129604,
            "py": 588.3914346757114,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Interactive Visual Analysis of Image-Centric Cohort Study Data",
                "PaperDOI": "10.1109/TVCG.2014.2346591",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346591",
                "Firstpage": "1673",
                "Lastpage": "1682",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.",
                "AuthorNames": "Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.",
                "FirstAuthorAffiliation": "Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.",
                "References": "10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569",
                "AuthorKeywords": "Interactive Visual Analysis, Epidemiology, Spine",
                "IEEEXPLOREArticleNumberdeprecated": "6876009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634192;6064996;885739;6064951;4376166"
            }
        },
        {
            "name": "Everts, M.H.",
            "value": 77,
            "numPapers": 15,
            "cluster": "6",
            "index": 129,
            "weight": 2,
            "x": 1151.8541181806754,
            "y": 733.8821190245195,
            "px": 1150.5472144487915,
            "py": 742.5713209636381,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces",
                "PaperDOI": "10.1109/TVCG.2010.157",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.157",
                "Firstpage": "1613",
                "Lastpage": "1622",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.",
                "AuthorNames": "Lingyun Yu;Svetachov, P.;Isenberg, P.;Everts, M.H.;Isenberg, T.",
                "FirstAuthorAffiliation": "Univ. of Groningen, Groningen, Netherlands|c|;;;;",
                "AuthorIDs": "37593898200;37591151000;37591317800;37591149600;37297057400",
                "Dedupedauthornames": "Lingyun Yu;Svetachov, P.;Isenberg, P.;Everts, M.H.;Isenberg, T.",
                "References": "10.1109/VISUAL.2005.1532778;10.1109/TVCG.2007.70515;10.1109/VISUAL.2004.30",
                "AuthorKeywords": "Direct-touch interaction, wall displays, 3D navigation and exploration, evaluation, illustrative visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5613504",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532778;4376144;1372220"
            }
        },
        {
            "name": "Bekker, H.",
            "value": 61,
            "numPapers": 12,
            "cluster": "6",
            "index": 130,
            "weight": 2,
            "x": 1212.4123831260388,
            "y": 580.8046262884781,
            "px": 1213.4699287668002,
            "py": 590.9951378952204,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Depth-Dependent Halos: Illustrative Rendering of Dense Line Data",
                "PaperDOI": "10.1109/TVCG.2009.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.138",
                "Firstpage": "1299",
                "Lastpage": "1306",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.",
                "AuthorNames": "Everts, M.H.;Bekker, H.;Roerdink, J.B.T.M.;Isenberg, T.",
                "FirstAuthorAffiliation": "Univ. of Groningen, Groningen, Netherlands|c|;;;",
                "AuthorIDs": "37591149600;38105196000;37279298200;37297057400",
                "Dedupedauthornames": "Everts, M.H.;Bekker, H.;Roerdink, J.B.T.;Isenberg, T.",
                "References": "10.1109/VISUAL.2000.885694;10.1109/TVCG.2007.70532;10.1109/TVCG.2006.172;10.1109/VISUAL.2000.885696;10.1109/VISUAL.2005.1532778;10.1109/TVCG.2006.115;10.1109/VISUAL.2005.1532859;10.1109/TVCG.2006.197;10.1109/VISUAL.2005.1532858;10.1109/TVCG.2007.70555;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2004.48",
                "AuthorKeywords": "Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique",
                "IEEEXPLOREArticleNumberdeprecated": "5290742",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885694;4376178;4015442;885696;1532778;4015487;1532859;4015478;1532858;4376160;567777;1372190"
            }
        },
        {
            "name": "Roerdink, J.B.T.",
            "value": 71,
            "numPapers": 12,
            "cluster": "6",
            "index": 131,
            "weight": 2,
            "x": 966.792543817365,
            "y": 1048.6008336538944,
            "px": 976.4332625660026,
            "py": 1062.5618048782896,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Depth-Dependent Halos: Illustrative Rendering of Dense Line Data",
                "PaperDOI": "10.1109/TVCG.2009.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.138",
                "Firstpage": "1299",
                "Lastpage": "1306",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.",
                "AuthorNames": "Everts, M.H.;Bekker, H.;Roerdink, J.B.T.M.;Isenberg, T.",
                "FirstAuthorAffiliation": "Univ. of Groningen, Groningen, Netherlands|c|;;;",
                "AuthorIDs": "37591149600;38105196000;37279298200;37297057400",
                "Dedupedauthornames": "Everts, M.H.;Bekker, H.;Roerdink, J.B.T.;Isenberg, T.",
                "References": "10.1109/VISUAL.2000.885694;10.1109/TVCG.2007.70532;10.1109/TVCG.2006.172;10.1109/VISUAL.2000.885696;10.1109/VISUAL.2005.1532778;10.1109/TVCG.2006.115;10.1109/VISUAL.2005.1532859;10.1109/TVCG.2006.197;10.1109/VISUAL.2005.1532858;10.1109/TVCG.2007.70555;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2004.48",
                "AuthorKeywords": "Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique",
                "IEEEXPLOREArticleNumberdeprecated": "5290742",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885694;4376178;4015442;885696;1532778;4015487;1532859;4015478;1532858;4376160;567777;1372190"
            }
        },
        {
            "name": "Oeltze-Jafra, S.",
            "value": 14,
            "numPapers": 15,
            "cluster": "6",
            "index": 132,
            "weight": 1,
            "x": 1080.5667022649673,
            "y": 564.6643535663754,
            "px": 1078.8282235674644,
            "py": 588.932198321914,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Interactive Visual Analysis of Image-Centric Cohort Study Data",
                "PaperDOI": "10.1109/TVCG.2014.2346591",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346591",
                "Firstpage": "1673",
                "Lastpage": "1682",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.",
                "AuthorNames": "Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.",
                "FirstAuthorAffiliation": "Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.",
                "References": "10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569",
                "AuthorKeywords": "Interactive Visual Analysis, Epidemiology, Spine",
                "IEEEXPLOREArticleNumberdeprecated": "6876009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634192;6064996;885739;6064951;4376166"
            }
        },
        {
            "name": "Janiga, G.",
            "value": 9,
            "numPapers": 16,
            "cluster": "6",
            "index": 133,
            "weight": 1,
            "x": 913.6343687044389,
            "y": 546.1907907932543,
            "px": 941.5901055765303,
            "py": 565.1399397981681,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Depth-Dependent Halos: Illustrative Rendering of Dense Line Data",
                "PaperDOI": "10.1109/TVCG.2009.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.138",
                "Firstpage": "1299",
                "Lastpage": "1306",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.",
                "AuthorNames": "Everts, M.H.;Bekker, H.;Roerdink, J.B.T.M.;Isenberg, T.",
                "FirstAuthorAffiliation": "Univ. of Groningen, Groningen, Netherlands|c|;;;",
                "AuthorIDs": "37591149600;38105196000;37279298200;37297057400",
                "Dedupedauthornames": "Everts, M.H.;Bekker, H.;Roerdink, J.B.T.;Isenberg, T.",
                "References": "10.1109/VISUAL.2000.885694;10.1109/TVCG.2007.70532;10.1109/TVCG.2006.172;10.1109/VISUAL.2000.885696;10.1109/VISUAL.2005.1532778;10.1109/TVCG.2006.115;10.1109/VISUAL.2005.1532859;10.1109/TVCG.2006.197;10.1109/VISUAL.2005.1532858;10.1109/TVCG.2007.70555;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2004.48",
                "AuthorKeywords": "Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique",
                "IEEEXPLOREArticleNumberdeprecated": "5290742",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885694;4376178;4015442;885696;1532778;4015487;1532859;4015478;1532858;4376160;567777;1372190"
            }
        },
        {
            "name": "Gasteiger, R.",
            "value": 45,
            "numPapers": 20,
            "cluster": "6",
            "index": 134,
            "weight": 8,
            "x": 1013.4178995539017,
            "y": 645.1938597270677,
            "px": 1008.9719135361377,
            "py": 660.5889202055246,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms",
                "PaperDOI": "10.1109/TVCG.2012.202",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.202",
                "Firstpage": "2178",
                "Lastpage": "2187",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",
                "AuthorNames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "FirstAuthorAffiliation": "Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;;;",
                "AuthorIDs": "38017015100;37601992200;37390973400;37833255000;38017002900;37282551500;37266875400;37424645300",
                "Dedupedauthornames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "References": "10.1109/TVCG.2011.215;10.1109/TVCG.2011.159;10.1109/TVCG.2011.243;10.1109/TVCG.2009.138;10.1109/TVCG.2010.153;10.1109/TVCG.2010.173",
                "AuthorKeywords": "Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph",
                "IEEEXPLOREArticleNumberdeprecated": "6327222",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064980;6064968;6064983;5290742;5613474;5613472"
            }
        },
        {
            "name": "van Pelt, R.",
            "value": 54,
            "numPapers": 18,
            "cluster": "6",
            "index": 135,
            "weight": 5,
            "x": 930.9297929086883,
            "y": 619.7424415263313,
            "px": 938.4023948133058,
            "py": 622.0552124483817,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms",
                "PaperDOI": "10.1109/TVCG.2012.202",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.202",
                "Firstpage": "2178",
                "Lastpage": "2187",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",
                "AuthorNames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "FirstAuthorAffiliation": "Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;;;",
                "AuthorIDs": "38017015100;37601992200;37390973400;37833255000;38017002900;37282551500;37266875400;37424645300",
                "Dedupedauthornames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "References": "10.1109/TVCG.2011.215;10.1109/TVCG.2011.159;10.1109/TVCG.2011.243;10.1109/TVCG.2009.138;10.1109/TVCG.2010.153;10.1109/TVCG.2010.173",
                "AuthorKeywords": "Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph",
                "IEEEXPLOREArticleNumberdeprecated": "6327222",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064980;6064968;6064983;5290742;5613474;5613472"
            }
        },
        {
            "name": "Beuing, O.",
            "value": 28,
            "numPapers": 12,
            "cluster": "6",
            "index": 136,
            "weight": 1,
            "x": 1601.1098751186632,
            "y": 696.5363808879305,
            "px": 1524.547042540966,
            "py": 691.7257885466029,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms",
                "PaperDOI": "10.1109/TVCG.2012.202",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.202",
                "Firstpage": "2178",
                "Lastpage": "2187",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",
                "AuthorNames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "FirstAuthorAffiliation": "Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;;;",
                "AuthorIDs": "38017015100;37601992200;37390973400;37833255000;38017002900;37282551500;37266875400;37424645300",
                "Dedupedauthornames": "Gasteiger, R.;Lehmann, D.J.;van Pelt, R.;Janiga, G.;Beuing, O.;Vilanova, A.;Theisel, H.;Preim, B.",
                "References": "10.1109/TVCG.2011.215;10.1109/TVCG.2011.159;10.1109/TVCG.2011.243;10.1109/TVCG.2009.138;10.1109/TVCG.2010.153;10.1109/TVCG.2010.173",
                "AuthorKeywords": "Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph",
                "IEEEXPLOREArticleNumberdeprecated": "6327222",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064980;6064968;6064983;5290742;5613474;5613472"
            }
        },
        {
            "name": "Wald, I.",
            "value": 0,
            "numPapers": 10,
            "cluster": "2",
            "index": 137,
            "weight": 1,
            "x": 294.8819760724056,
            "y": 92.37014537989786,
            "px": 299.0289424150877,
            "py": 99.21016730605018,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Westermann, R.",
            "value": 434,
            "numPapers": 168,
            "cluster": "2",
            "index": 138,
            "weight": 39,
            "x": 235.78885283653577,
            "y": 213.35195831021858,
            "px": 244.85276576308277,
            "py": 206.71411194503602,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Knoll, A.",
            "value": 19,
            "numPapers": 26,
            "cluster": "2",
            "index": 139,
            "weight": 3,
            "x": 118.19749794236378,
            "y": 102.34837347393145,
            "px": 132.2577148430512,
            "py": 109.53815778181334,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Kindlmann, G.",
            "value": 574,
            "numPapers": 115,
            "cluster": "3",
            "index": 140,
            "weight": 40,
            "x": 121.88422295614711,
            "y": 526.7143438257142,
            "px": 135.27353436349773,
            "py": 509.8973413869403,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "An Algebraic Process for Visualization Design",
                "PaperDOI": "10.1109/TVCG.2014.2346325",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346325",
                "Firstpage": "2181",
                "Lastpage": "2190",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.",
                "AuthorNames": "Kindlmann, G.;Scheidegger, C.",
                "FirstAuthorAffiliation": "Univ. of Chicago, Chicago, IL, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Kindlmann, G.;Scheidegger, C.E.",
                "References": "10.1109/TVCG.2013.173;10.1109/INFVIS.1999.801860;10.1109/TVCG.2010.132;10.1109/TVCG.2010.199;10.1109/VISUAL.1996.568118;10.1109/TVCG.2013.124;10.1109/TVCG.2009.125;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594;10.1109/TVCG.2013.119;10.1109/INFVIS.2003.1249005;10.1109/INFVIS.2004.59;10.1109/VISUAL.1996.567784;10.1109/TVCG.2013.126;10.1109/TVCG.2008.121;10.1109/TVCG.2012.230;10.1109/TVCG.2010.161",
                "AuthorKeywords": "Visualization Design, Symmetries, Visualization Theory",
                "IEEEXPLOREArticleNumberdeprecated": "6875930",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634146;801860;5613460;5613502;568118;6634168;5290761;5290695;4376133;6634182;1249005;1382903;567784;6634108;4658127;6327249;5613434"
            }
        },
        {
            "name": "Tasdizen, T.",
            "value": 170,
            "numPapers": 10,
            "cluster": "2",
            "index": 141,
            "weight": 5,
            "x": 228.6409769611724,
            "y": 194.3370834808443,
            "px": 82.73493399026248,
            "py": 289.00891128632867,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Curvature-based transfer functions for direct volume rendering: methods and applications",
                "PaperDOI": "10.1109/VISUAL.2003.1250414",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250414",
                "Firstpage": "513",
                "Lastpage": "520",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: nonphotorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.",
                "AuthorNames": "Kindlmann, G.;Whitaker, R.;Tasdizen, T.;Moller, T.",
                "FirstAuthorAffiliation": "Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake, UT, USA|c|;;;",
                "AuthorIDs": "37282742400;37267322600;37265762400;37275858700",
                "Dedupedauthornames": "Kindlmann, G.;Whitaker, R.T.;Tasdizen, T.;Moller, T.",
                "References": "10.1109/VISUAL.2000.885696;10.1109/VISUAL.2002.1183766;10.1109/VISUAL.1995.480795;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183777",
                "AuthorKeywords": "volume rendering, implicit surface curvature, convolution-based differentiation, non-photorealistic rendering, surface processing, uncertainty visualization, flowline curvature",
                "IEEEXPLOREArticleNumberdeprecated": "1250414",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885696;1183766;480795;885694;346331;1183777"
            }
        },
        {
            "name": "Peikert, R.",
            "value": 283,
            "numPapers": 62,
            "cluster": "3",
            "index": 142,
            "weight": 24,
            "x": 270.17388327674456,
            "y": 655.440057318284,
            "px": 271.89141041847466,
            "py": 626.3479891949507,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Illuminated lines revisited",
                "PaperDOI": "10.1109/VISUAL.2005.1532772",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532772",
                "Firstpage": "19",
                "Lastpage": "26",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.",
                "AuthorNames": "Mallo, O.;Peikert, R.;Sigg, C.;Sadlo, F.",
                "FirstAuthorAffiliation": "Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;",
                "AuthorIDs": "37550865700;37282541100;37565783800;37282541900",
                "Dedupedauthornames": "Mallo, O.;Peikert, R.;Sigg, C.;Sadlo, F.",
                "References": "10.1109/VISUAL.2004.5;10.1109/VISUAL.2003.1250378;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1997.663912",
                "AuthorKeywords": "Field lines, illumination, vector field visualization,texture mapping, graphics hardware",
                "IEEEXPLOREArticleNumberdeprecated": "1532772",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372186;1250378;1183797;567777;663912"
            }
        },
        {
            "name": "Roth, M.",
            "value": 174,
            "numPapers": 19,
            "cluster": "3",
            "index": 143,
            "weight": 12,
            "x": 184.8172581478322,
            "y": 777.0131262670973,
            "px": 192.4493285052925,
            "py": 743.6034464428963,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "The \"Parallel Vectors\" operator-a vector field visualization primitive",
                "PaperDOI": "10.1109/VISUAL.1999.809896",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809896",
                "Firstpage": "263",
                "Lastpage": "532",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We propose an elementary operation on a pair of vector fields as a building block for defining and computing global line-type features of vector or scalar fields. While usual feature definitions often are procedural and therefore implicit, our operator allows precise mathematical definitions. It can serve as a basis for comparing feature definitions and for reuse of algorithms and implementations. Applications focus on vortex core methods.",
                "AuthorNames": "Peikert, R.;Roth, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;",
                "AuthorIDs": "37282541100;37365755100",
                "Dedupedauthornames": "Peikert, R.;Roth, M.",
                "References": "10.1109/VISUAL.1998.745290;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1995.480795;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1997.663894;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1996.567807",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809896",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745290;568137;745296;480795;346327;663894;745297;567807"
            }
        },
        {
            "name": "Westin, C.-F.",
            "value": 91,
            "numPapers": 22,
            "cluster": "3",
            "index": 144,
            "weight": 3,
            "x": 405.3145540350118,
            "y": 376.37838611744974,
            "px": 541.6130987160133,
            "py": 378.41400061892483,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Invariant Crease Lines for Topological and Structural Analysis of Tensor fields",
                "PaperDOI": "10.1109/TVCG.2008.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.148",
                "Firstpage": "1627",
                "Lastpage": "1634",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.",
                "AuthorNames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;",
                "AuthorIDs": "37282575100;37282742400;37294318400",
                "Dedupedauthornames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "References": "10.1109/VISUAL.2004.105;10.1109/TVCG.2007.70602;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1990.146359;10.1109/TVCG.2007.70554",
                "AuthorKeywords": "Tensor fields, tensor invariants, ridge lines, crease extraction, structural analysis, topology",
                "IEEEXPLOREArticleNumberdeprecated": "4658184",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372212;4376179;809896;175773;346326;346326;146359;4376174"
            }
        },
        {
            "name": "Seidel, H.-P.",
            "value": 296,
            "numPapers": 78,
            "cluster": "3",
            "index": 145,
            "weight": 20,
            "x": 245.28627395089046,
            "y": 505.4637697350717,
            "px": 252.32712464921426,
            "py": 499.4838162404357,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data",
                "PaperDOI": "10.1109/TVCG.2006.165",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.165",
                "Firstpage": "917",
                "Lastpage": "924",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets",
                "AuthorNames": "Sauber, N.;Theisel, H.;Seidel, H.-P.",
                "FirstAuthorAffiliation": "Max-Planck-Inst. fur Inf., Saarbrucken|c|;;",
                "AuthorIDs": "37550815800;37266875400;37271851300",
                "Dedupedauthornames": "Sauber, N.;Theisel, H.;Seidel, H.-P.",
                "References": "10.1109/VISUAL.1999.809865;10.1109/VISUAL.2004.68;10.1109/VISUAL.2004.46;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2003.1250362",
                "AuthorKeywords": "Visualization, multifield, correlation",
                "IEEEXPLOREArticleNumberdeprecated": "4015447",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809865;1372207;1372239;809905;1250362"
            }
        },
        {
            "name": "Rheingans, P.",
            "value": 357,
            "numPapers": 66,
            "cluster": "2",
            "index": 146,
            "weight": 15,
            "x": 296.38253933388245,
            "y": 194.65699099073493,
            "px": 276.82667641560687,
            "py": 179.8286222808871,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Texture-based feature tracking for effective time-varying data visualization",
                "PaperDOI": "10.1109/TVCG.2007.70599",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70599",
                "Firstpage": "1472",
                "Lastpage": "1479",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.",
                "AuthorNames": "Caban, J.J.;Joshi, A.;Rheingans, P.",
                "FirstAuthorAffiliation": "Univ. of Maryland Baltimore County, Baltimore|c|;;",
                "AuthorIDs": ";37278517400;37282292000",
                "Dedupedauthornames": "Caban, J.J.;Joshi, A.;Rheingans, P.",
                "References": "10.1109/VISUAL.2003.1250374;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1996.567807",
                "AuthorKeywords": "Feature tracking, texture-based analysis, flow visualization, time-varying data, visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4376176",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250374;885694;745288;567807"
            }
        },
        {
            "name": "Crawfis, R.",
            "value": 341,
            "numPapers": 61,
            "cluster": "2",
            "index": 147,
            "weight": 20,
            "x": 227.17284771787513,
            "y": 113.2585333716692,
            "px": 220.84906353453545,
            "py": 109.71391879167322,
            "node": {
                "Conference": "Vis",
                "Year": "1993",
                "PaperTitle": "Texture splats for 3D scalar and vector field visualization",
                "PaperDOI": "10.1109/VISUAL.1993.398877",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398877",
                "Firstpage": "261",
                "Lastpage": "266",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume visualization is becoming an important tool for understanding large 3D data sets. A popular technique for volume rendering is known as splatting. With new hardware architectures offering substantial improvements in the performance of rendering texture mapped objects, we present textured splats. An ideal reconstruction function for 3D signals is developed which can be used as a texture map for a splat. Extensions to the basic splatting technique are then developed to additionally represent vector fields",
                "AuthorNames": "Crawfis, R.A.;Max, N.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;",
                "AuthorIDs": "37284273900;37267387800",
                "Dedupedauthornames": "Crawfis, R.;Max, N.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "398877",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Max, N.",
            "value": 296,
            "numPapers": 22,
            "cluster": "2",
            "index": 148,
            "weight": 10,
            "x": 163.51257481959664,
            "y": 142.26623289788083,
            "px": 146.70048817725095,
            "py": 127.28856873472182,
            "node": {
                "Conference": "Vis",
                "Year": "1993",
                "PaperTitle": "Texture splats for 3D scalar and vector field visualization",
                "PaperDOI": "10.1109/VISUAL.1993.398877",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398877",
                "Firstpage": "261",
                "Lastpage": "266",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume visualization is becoming an important tool for understanding large 3D data sets. A popular technique for volume rendering is known as splatting. With new hardware architectures offering substantial improvements in the performance of rendering texture mapped objects, we present textured splats. An ideal reconstruction function for 3D signals is developed which can be used as a texture map for a splat. Extensions to the basic splatting technique are then developed to additionally represent vector fields",
                "AuthorNames": "Crawfis, R.A.;Max, N.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;",
                "AuthorIDs": "37284273900;37267387800",
                "Dedupedauthornames": "Crawfis, R.;Max, N.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "398877",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Chaoli Wang",
            "value": 103,
            "numPapers": 45,
            "cluster": "2",
            "index": 149,
            "weight": 5,
            "x": 218.3280469179126,
            "y": 37.56456750877792,
            "px": 211.45855274140186,
            "py": 27.47170694281682,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data",
                "PaperDOI": "10.1109/TVCG.2011.246",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.246",
                "Firstpage": "2015",
                "Lastpage": "2024",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.",
                "AuthorNames": "Yi Gu;Chaoli Wang",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MA, USA|c|;",
                "AuthorIDs": "38021343000;37405886900",
                "Dedupedauthornames": "Yi Gu;Chaoli Wang",
                "References": "10.1109/TVCG.2008.119;10.1109/VISUAL.1994.346321;10.1109/VAST.2006.261451;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2008.116;10.1109/TVCG.2010.190;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.1995.480809;10.1109/TVCG.2008.140;10.1109/VISUAL.2001.964531;10.1109/TVCG.2009.200",
                "AuthorKeywords": "Time-varying data visualization, hierarchical representation, states, transition relationship, user interface",
                "IEEEXPLOREArticleNumberdeprecated": "6064965",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658159;346321;4035742;809871;4015447;1250401;4658163;5613488;1250402;480809;4658174;964531;5290749"
            }
        },
        {
            "name": "Dutta, S.",
            "value": 17,
            "numPapers": 38,
            "cluster": "2",
            "index": 150,
            "weight": 1,
            "x": 348.54058643529333,
            "y": 20.754652523715865,
            "px": 351.49029683247346,
            "py": 8.763677004195923,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Information-Aware Framework for Exploring Multivariate Data Sets",
                "PaperDOI": "10.1109/TVCG.2013.133",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.133",
                "Firstpage": "2683",
                "Lastpage": "2692",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.",
                "AuthorNames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "FirstAuthorAffiliation": "Gravity Group, Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Biswas, A.;Dutta, S.;Han-Wei Shen;Woodring, J.",
                "References": "10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785",
                "AuthorKeywords": "Information theory, framework, isosurface, multivariate uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "6634187",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613460;5290764;146402;5613461;4015449;4658163;5613439;1382895;4658188;4658174;4389000;6064997;485139;1532833;5613459;663875;1183785"
            }
        },
        {
            "name": "Wenger, R.",
            "value": 52,
            "numPapers": 27,
            "cluster": "3",
            "index": 151,
            "weight": 2,
            "x": 326.0824103570532,
            "y": 524.4586255514648,
            "px": 333.0111519838994,
            "py": 510.2651455941291,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Volume tracking using higher dimensional isosurfacing",
                "PaperDOI": "10.1109/VISUAL.2003.1250374",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250374",
                "Firstpage": "209",
                "Lastpage": "216",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Tracking and visualizing local features from a time-varying volumetric data allows the user to focus on selected regions of interest, both in space and time, which can lead to a better understanding of the underlying dynamics. In this paper, we present an efficient algorithm to track time-varying isosurfaces and interval volumes using isosurfacing in higher dimensions. Instead of extracting the data features such as isosurfaces or interval volumes separately from multiple time steps and computing the spatial correspondence between those features, our algorithm extracts the correspondence directly from the higher dimensional geometry and thus can more efficiently follow the user selected local features in time. In addition, by analyzing the resulting higher dimensional geometry, it becomes easier to detect important topological events and the corresponding critical time steps for the selected features. With our algorithm, the user can interact with the underlying time-varying data more easily. The computation cost for performing time-varying volume tracking is also minimized.",
                "AuthorNames": "Guangfeng Ji;Han-Wei Shen;Wenger, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;",
                "AuthorIDs": "38202947500;37279493500;37284274100",
                "Dedupedauthornames": "Guangfeng Ji;Han-Wei Shen;Wenger, R.",
                "References": "10.1109/VISUAL.2000.885704;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1996.568103;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.1996.567807;10.1109/VISUAL.2000.885703;10.1109/VISUAL.1995.480789;10.1109/VISUAL.1997.663886",
                "AuthorKeywords": "tracking, isosurface, interval volume, higher dimensional isosurfacing",
                "IEEEXPLOREArticleNumberdeprecated": "1250374",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885704;745288;568103;1183774;567807;885703;480789;663886"
            }
        },
        {
            "name": "Hongfeng Yu",
            "value": 35,
            "numPapers": 14,
            "cluster": "2",
            "index": 152,
            "weight": 2,
            "x": 244.8817285388757,
            "y": -27.66284219214239,
            "px": 266.1998637297982,
            "py": -26.50014808255528,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets",
                "PaperDOI": "10.1109/TVCG.2014.2346423",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346423",
                "Firstpage": "2565",
                "Lastpage": "2574",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.",
                "AuthorNames": "Sauer, F.;Hongfeng Yu;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, Davis, CA, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Sauer, F.;Hongfeng Yu;Kwan-Liu Ma",
                "References": "10.1109/VISUAL.1997.663930;10.1109/VISUAL.1996.567807;10.1109/TVCG.2007.70599;10.1109/VISUAL.2003.1250374;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1998.745288",
                "AuthorKeywords": "Feature extraction and tracking, particle data, volume data, particle trajectories, flow visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6875975",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663930;567807;4376176;1250374;146391;745288"
            }
        },
        {
            "name": "Silver, D.",
            "value": 226,
            "numPapers": 50,
            "cluster": "2",
            "index": 153,
            "weight": 14,
            "x": 246.45294633292622,
            "y": 157.00782103472716,
            "px": 235.91696430102965,
            "py": 140.480737012033,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Understanding visualization through spatial ability differences",
                "PaperDOI": "10.1109/VISUAL.2005.1532836",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532836",
                "Firstpage": "511",
                "Lastpage": "518",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.",
                "AuthorNames": "Velez, M.C.;Silver, D.;Tremaine, M.",
                "FirstAuthorAffiliation": "Center for Adv. Inf. Process., Rutgers State Univ., NJ, USA|c|;;",
                "AuthorIDs": "37562536700;37274132700;37424321800",
                "Dedupedauthornames": "Velez, M.C.;Silver, D.;Tremaine, M.",
                "References": "10.1109/INFVIS.2003.1249022;10.1109/VISUAL.2003.1250396",
                "AuthorKeywords": "Gender differences, orthogonal projections, spatial ability, standardized testing",
                "IEEEXPLOREArticleNumberdeprecated": "1532836",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249022;1250396"
            }
        },
        {
            "name": "Wang, X.",
            "value": 62,
            "numPapers": 6,
            "cluster": "2",
            "index": 154,
            "weight": 2,
            "x": 273.1740166940379,
            "y": -49.83246051203207,
            "px": 298.8898321495675,
            "py": -19.506387918646215,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "Volume tracking",
                "PaperDOI": "10.1109/VISUAL.1996.567807",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567807",
                "Firstpage": "157",
                "Lastpage": "164",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "3D time varying datasets are difficult to visualize and analyze because of the immense amount of data involved. This is especially true when the datasets are turbulent with many evolving amorphous regions, as it is difficult to observe patterns and follow regions of interest. We present our volume based feature tracking algorithm and discuss how it can be used to help visualize and analyze large time varying datasets. We also address efficiency issues in dealing with massive time varying datasets.",
                "AuthorNames": "Silver, D.;Wang, X.",
                "FirstAuthorAffiliation": "Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;",
                "AuthorIDs": "37274132700;37367862600",
                "Dedupedauthornames": "Silver, D.;Wang, X.",
                "References": "10.1109/VISUAL.1995.485141;10.1109/VISUAL.1995.480789",
                "AuthorKeywords": "Scientific Visualization, Multi-dimensional Visualization, Feature Tracking, Computer Vision, CFD",
                "IEEEXPLOREArticleNumberdeprecated": "567807",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "485141;480789"
            }
        },
        {
            "name": "Kruger, J.",
            "value": 223,
            "numPapers": 44,
            "cluster": "2",
            "index": 155,
            "weight": 11,
            "x": 265.3661091841017,
            "y": 176.5167518303415,
            "px": 276.41066764458003,
            "py": 181.69156663753432,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Texture-based visualization of uncertainty in flow fields",
                "PaperDOI": "10.1109/VISUAL.2005.1532853",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532853",
                "Firstpage": "647",
                "Lastpage": "654",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.",
                "AuthorNames": "Botchen, R.P.;Weiskopf, D.;Ertl, T.",
                "FirstAuthorAffiliation": "Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37565744300;37268045000;37268023800",
                "Dedupedauthornames": "Botchen, R.P.;Weiskopf, D.;Ertl, T.",
                "References": "10.1109/VISUAL.1996.567784;10.1109/VISUAL.2000.885689;10.1109/VISUAL.1996.568116",
                "AuthorKeywords": "Uncertainty visualization, unsteady flow visualization, texture advection, GPU programming",
                "IEEEXPLOREArticleNumberdeprecated": "1532853",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567784;885689;568116"
            }
        },
        {
            "name": "Hanqi Guo",
            "value": 38,
            "numPapers": 56,
            "cluster": "2",
            "index": 156,
            "weight": 4,
            "x": 415.89674385655957,
            "y": 58.44080517339053,
            "px": 404.71086193832514,
            "py": 53.73096642251317,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "WYSIWYG (What You See is What You Get) Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2011.261",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.261",
                "Firstpage": "2106",
                "Lastpage": "2114",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.",
                "AuthorNames": "Hanqi Guo;Ningyu Mao;Xiaoru Yuan",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;",
                "AuthorIDs": "37595201300;38027433600;37403856700",
                "Dedupedauthornames": "Hanqi Guo;Ningyu Mao;Xiaoru Yuan",
                "References": "10.1109/TVCG.2010.145;10.1109/VISUAL.1998.745319;10.1109/TVCG.2008.120;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70591;10.1109/VISUAL.1996.568113;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.1997.663875;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Volume rendering, Sketching input, Human-computer interaction, Transfer functions, Feature space",
                "IEEEXPLOREArticleNumberdeprecated": "6064975",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613492;745319;4658154;1250414;4376159;568112;5290762;4658153;1250386;1250413;885694;1532856;663875;4015460"
            }
        },
        {
            "name": "Hesselink, L.",
            "value": 177,
            "numPapers": 12,
            "cluster": "3",
            "index": 157,
            "weight": 8,
            "x": 182.18870406342677,
            "y": 470.94985607338106,
            "px": 206.16583769645115,
            "py": 457.4475381899638,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "The topology of symmetric, second-order tensor fields",
                "PaperDOI": "10.1109/VISUAL.1994.346326",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346326",
                "Firstpage": "140",
                "Lastpage": "147, C15",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data. The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities-such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields. Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Poincare-Hopf theorem for vector fields",
                "AuthorNames": "Delmarcelle, T.;Hesselink, Lambertus",
                "FirstAuthorAffiliation": "Dept. of Appl. Phys., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37378372200;37274095200",
                "Dedupedauthornames": "Delmarcelle, T.;Hesselink, L.",
                "References": "10.1109/VISUAL.1991.175773",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346326",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175773"
            }
        },
        {
            "name": "Kurzhals, K.",
            "value": 8,
            "numPapers": 22,
            "cluster": "2",
            "index": 158,
            "weight": 2,
            "x": 237.35919043808616,
            "y": 131.12289549255152,
            "px": 242.24344193387475,
            "py": 128.40119631891918,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization",
                "PaperDOI": "10.1109/TVCG.2011.232",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.232",
                "Firstpage": "2392",
                "Lastpage": "2401",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.",
                "AuthorNames": "Albers, D.;Dewey, C.;Gleicher, M.",
                "FirstAuthorAffiliation": "Univ. of Wisconsin-Madison, Madison, WI, USA|c|;;",
                "AuthorIDs": "38019392100;37994248400;37282585700",
                "Dedupedauthornames": "Albers, D.;Dewey, C.;Gleicher, M.",
                "References": "10.1109/TVCG.2007.70623;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2009.128;10.1109/TVCG.2009.167",
                "AuthorKeywords": "Bioinformatics Visualization, Perception Theory, Scalability Issues, Visual Design",
                "IEEEXPLOREArticleNumberdeprecated": "6065006",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376150;1173156;5290702;5290692"
            }
        },
        {
            "name": "Burch, M.",
            "value": 103,
            "numPapers": 27,
            "cluster": "2",
            "index": 159,
            "weight": 3,
            "x": 286.0914206328238,
            "y": 176.397843128922,
            "px": 290.8325518215859,
            "py": 177.5283516306698,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study",
                "PaperDOI": "10.1109/TVCG.2011.193",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.193",
                "Firstpage": "2440",
                "Lastpage": "2448",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.",
                "AuthorNames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": "VISUS, Univ. of Stuttgart, Germany|c|;;;;",
                "AuthorIDs": "37586953400;38017426500;37665271000;;38470313100",
                "Dedupedauthornames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "References": "10.1109/TVCG.2010.209;10.1109/INFVIS.2004.70",
                "AuthorKeywords": "Hierarchy visualization, node-link layout, eye tracking, user study",
                "IEEEXPLOREArticleNumberdeprecated": "6065011",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613430;1382885"
            }
        },
        {
            "name": "Heimerl, F.",
            "value": 54,
            "numPapers": 36,
            "cluster": "0",
            "index": 160,
            "weight": 4,
            "x": 635.2623390434215,
            "y": 272.9942593225489,
            "px": 646.8382336591748,
            "py": 286.37526738476566,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Lawonn, K.",
            "value": 29,
            "numPapers": 29,
            "cluster": "6",
            "index": 161,
            "weight": 3,
            "x": 1108.130476121401,
            "y": 623.6308188196166,
            "px": 1070.5936063649638,
            "py": 639.1692251325205,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Interactive Visual Analysis of Image-Centric Cohort Study Data",
                "PaperDOI": "10.1109/TVCG.2014.2346591",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346591",
                "Firstpage": "1673",
                "Lastpage": "1682",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.",
                "AuthorNames": "Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.",
                "FirstAuthorAffiliation": "Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Klemm, P.;Oeltze-Jafra, S.;Lawonn, K.;Hegenscheid, K.;Volzke, H.;Preim, B.",
                "References": "10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569",
                "AuthorKeywords": "Interactive Visual Analysis, Epidemiology, Spine",
                "IEEEXPLOREArticleNumberdeprecated": "6876009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634192;6064996;885739;6064951;4376166"
            }
        },
        {
            "name": "Hagen, H.",
            "value": 395,
            "numPapers": 107,
            "cluster": "3",
            "index": 162,
            "weight": 34,
            "x": 285.9538786178128,
            "y": 484.3584681337782,
            "px": 281.49956022230765,
            "py": 481.1723911793157,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Moment Invariants for the Analysis of 2D Flow fields",
                "PaperDOI": "10.1109/TVCG.2007.70579",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70579",
                "Firstpage": "1743",
                "Lastpage": "1750",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.",
                "AuthorNames": "Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertram, M.-H.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern|c|;;;;;;;;",
                "AuthorIDs": "37946182500;37945209200;37945208900;37282721800;37282067000;37282573700;37722986700;37282068700;37282578800",
                "Dedupedauthornames": "Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertam, M.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.",
                "References": "10.1109/VISUAL.2004.68;10.1109/VISUAL.1999.809873;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2003.1250372",
                "AuthorKeywords": "Flow Visualization, Feature Detection, Pattern Extraction, Pattern Recognition, Image Processing",
                "IEEEXPLOREArticleNumberdeprecated": "4376210",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372207;809873;1532858;1250372"
            }
        },
        {
            "name": "Hamann, B.",
            "value": 424,
            "numPapers": 103,
            "cluster": "3",
            "index": 163,
            "weight": 25,
            "x": 241.73564136507832,
            "y": 576.6623656268688,
            "px": 243.45732505369907,
            "py": 571.0828410323599,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Moment Invariants for the Analysis of 2D Flow fields",
                "PaperDOI": "10.1109/TVCG.2007.70579",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70579",
                "Firstpage": "1743",
                "Lastpage": "1750",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.",
                "AuthorNames": "Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertram, M.-H.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern|c|;;;;;;;;",
                "AuthorIDs": "37946182500;37945209200;37945208900;37282721800;37282067000;37282573700;37722986700;37282068700;37282578800",
                "Dedupedauthornames": "Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertam, M.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.",
                "References": "10.1109/VISUAL.2004.68;10.1109/VISUAL.1999.809873;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2003.1250372",
                "AuthorKeywords": "Flow Visualization, Feature Detection, Pattern Extraction, Pattern Recognition, Image Processing",
                "IEEEXPLOREArticleNumberdeprecated": "4376210",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372207;809873;1532858;1250372"
            }
        },
        {
            "name": "Carr, H.",
            "value": 183,
            "numPapers": 58,
            "cluster": "3",
            "index": 164,
            "weight": 16,
            "x": 278.9924947211175,
            "y": 579.7376284721544,
            "px": 288.1239924039691,
            "py": 582.3147672981856,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Direct Interval Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2010.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.145",
                "Firstpage": "1505",
                "Lastpage": "1514",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",
                "AuthorNames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "FirstAuthorAffiliation": "VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;;",
                "AuthorIDs": "37393968500;37268045000;37282624500",
                "Dedupedauthornames": "Ament, M.;Weiskopf, D.;Carr, H.",
                "References": "10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.85;10.1109/VISUAL.1995.480789;10.1109/VISUAL.2002.1183762;10.1109/TVCG.2009.149;10.1109/TVCG.2006.113;10.1109/TVCG.2008.186;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532808;10.1109/TVCG.2008.160;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.204;10.1109/VISUAL.1995.480807",
                "AuthorKeywords": "Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",
                "IEEEXPLOREArticleNumberdeprecated": "5613492",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745713;663886;1372176;480789;1183762;5290780;4015502;4658152;885683;1532808;4658188;1250384;5290775;480807"
            }
        },
        {
            "name": "Sakurai, D.",
            "value": 0,
            "numPapers": 10,
            "cluster": "3",
            "index": 165,
            "weight": 1,
            "x": 288.07906474384606,
            "y": 787.9207613857058,
            "px": 279.76640904449437,
            "py": 741.4716244159455,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Continuous Scatterplots",
                "PaperDOI": "10.1109/TVCG.2008.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.119",
                "Firstpage": "1428",
                "Lastpage": "1435",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",
                "AuthorNames": "Bachthaler, S.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;",
                "AuthorIDs": "37869985900;37268045000",
                "Dedupedauthornames": "Bachthaler, S.;Weiskopf, D.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.160",
                "AuthorKeywords": "Scatterplot, histogram, continuous frequency plot, interpolation",
                "IEEEXPLOREArticleNumberdeprecated": "4658159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658188"
            }
        },
        {
            "name": "Saeki, O.",
            "value": 0,
            "numPapers": 10,
            "cluster": "3",
            "index": 166,
            "weight": 1,
            "x": 30.065352594724622,
            "y": 899.5318471553747,
            "px": 77.96800257931022,
            "py": 849.2279599118938,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Continuous Scatterplots",
                "PaperDOI": "10.1109/TVCG.2008.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.119",
                "Firstpage": "1428",
                "Lastpage": "1435",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",
                "AuthorNames": "Bachthaler, S.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;",
                "AuthorIDs": "37869985900;37268045000",
                "Dedupedauthornames": "Bachthaler, S.;Weiskopf, D.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.160",
                "AuthorKeywords": "Scatterplot, histogram, continuous frequency plot, interpolation",
                "IEEEXPLOREArticleNumberdeprecated": "4658159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658188"
            }
        },
        {
            "name": "Bajaj, C.L.",
            "value": 178,
            "numPapers": 25,
            "cluster": "3",
            "index": 167,
            "weight": 3,
            "x": 282.48519800441125,
            "y": 669.4004338909563,
            "px": 278.4215801987192,
            "py": 668.6982175086172,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "The contour spectrum",
                "PaperDOI": "10.1109/VISUAL.1997.663875",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663875",
                "Firstpage": "167",
                "Lastpage": "173",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.",
                "AuthorNames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "FirstAuthorAffiliation": "Shastra Lab., Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "37282899200;37284312600;37355637500",
                "Dedupedauthornames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "References": "10.1109/VISUAL.1996.568123;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1998.745284;10.1109/VISUAL.1996.568113",
                "AuthorKeywords": "Visualization, Scalar Data, User Interfaces, Real-time Quantitative Query",
                "IEEEXPLOREArticleNumberdeprecated": "663875",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568123;480803;745284;568112"
            }
        },
        {
            "name": "Schikore, D.R.",
            "value": 135,
            "numPapers": 15,
            "cluster": "3",
            "index": 168,
            "weight": 3,
            "x": 249.24383454876198,
            "y": 650.8379235333226,
            "px": 247.26839138629634,
            "py": 644.9588849289668,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "The contour spectrum",
                "PaperDOI": "10.1109/VISUAL.1997.663875",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663875",
                "Firstpage": "167",
                "Lastpage": "173",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The authors introduce the contour spectrum, a user interface component that improves qualitative user interaction and provides real-time exact quantification in the visualization of isocontours. The contour spectrum is a signature consisting of a variety of scalar data and contour attributes, computed over the range of scalar values /spl omega//spl isin/R. They explore the use of surface, area, volume, and gradient integral of the contour that are shown to be univariate B-spline functions of the scalar value /spl omega/ for multi-dimensional unstructured triangular grids. These quantitative properties are calculated in real-time and presented to the user as a collection of signature graphs (plots of functions of /spl omega/) to assist in selecting relevant isovalues /spl omega//sub 0/ for informative visualization. For time-varying data, these quantitative properties can also be computed over time, and displayed using a 2D interface, giving the user an overview of the time-varying function, and allowing interaction in both isovalue and time step. The effectiveness of the current system and potential extensions are discussed.",
                "AuthorNames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "FirstAuthorAffiliation": "Shastra Lab., Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "37282899200;37284312600;37355637500",
                "Dedupedauthornames": "Bajaj, C.L.;Pascucci, V.;Schikore, D.R.",
                "References": "10.1109/VISUAL.1996.568123;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1998.745284;10.1109/VISUAL.1996.568113",
                "AuthorKeywords": "Visualization, Scalar Data, User Interfaces, Real-time Quantitative Query",
                "IEEEXPLOREArticleNumberdeprecated": "663875",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568123;480803;745284;568112"
            }
        },
        {
            "name": "Hsiang-Yun Wu",
            "value": 0,
            "numPapers": 10,
            "cluster": "3",
            "index": 169,
            "weight": 1,
            "x": 304.85926567303375,
            "y": 849.2456814897662,
            "px": 297.813500724561,
            "py": 796.1298035164326,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Continuous Scatterplots",
                "PaperDOI": "10.1109/TVCG.2008.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.119",
                "Firstpage": "1428",
                "Lastpage": "1435",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",
                "AuthorNames": "Bachthaler, S.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;",
                "AuthorIDs": "37869985900;37268045000",
                "Dedupedauthornames": "Bachthaler, S.;Weiskopf, D.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.160",
                "AuthorKeywords": "Scatterplot, histogram, continuous frequency plot, interpolation",
                "IEEEXPLOREArticleNumberdeprecated": "4658159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658188"
            }
        },
        {
            "name": "Yamamoto, T.",
            "value": 0,
            "numPapers": 10,
            "cluster": "3",
            "index": 170,
            "weight": 1,
            "x": 221.43141603870248,
            "y": 575.5810761686089,
            "px": 245.6704884585063,
            "py": 594.9457723734989,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Continuous Scatterplots",
                "PaperDOI": "10.1109/TVCG.2008.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.119",
                "Firstpage": "1428",
                "Lastpage": "1435",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",
                "AuthorNames": "Bachthaler, S.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;",
                "AuthorIDs": "37869985900;37268045000",
                "Dedupedauthornames": "Bachthaler, S.;Weiskopf, D.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.160",
                "AuthorKeywords": "Scatterplot, histogram, continuous frequency plot, interpolation",
                "IEEEXPLOREArticleNumberdeprecated": "4658159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658188"
            }
        },
        {
            "name": "Duke, D.",
            "value": 7,
            "numPapers": 17,
            "cluster": "3",
            "index": 171,
            "weight": 1,
            "x": 12.689930611266773,
            "y": 862.1256480465698,
            "px": 66.22206231875735,
            "py": 821.2616561170114,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Continuous Scatterplots",
                "PaperDOI": "10.1109/TVCG.2008.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.119",
                "Firstpage": "1428",
                "Lastpage": "1435",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",
                "AuthorNames": "Bachthaler, S.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;",
                "AuthorIDs": "37869985900;37268045000",
                "Dedupedauthornames": "Bachthaler, S.;Weiskopf, D.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.160",
                "AuthorKeywords": "Scatterplot, histogram, continuous frequency plot, interpolation",
                "IEEEXPLOREArticleNumberdeprecated": "4658159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658188"
            }
        },
        {
            "name": "Takahashi, S.",
            "value": 84,
            "numPapers": 23,
            "cluster": "3",
            "index": 172,
            "weight": 2,
            "x": 217.34641292722847,
            "y": 853.9129441012017,
            "px": 214.97115103298455,
            "py": 844.5568805451131,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Continuous Scatterplots",
                "PaperDOI": "10.1109/TVCG.2008.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.119",
                "Firstpage": "1428",
                "Lastpage": "1435",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",
                "AuthorNames": "Bachthaler, S.;Weiskopf, D.",
                "FirstAuthorAffiliation": "Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;",
                "AuthorIDs": "37869985900;37268045000",
                "Dedupedauthornames": "Bachthaler, S.;Weiskopf, D.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.160",
                "AuthorKeywords": "Scatterplot, histogram, continuous frequency plot, interpolation",
                "IEEEXPLOREArticleNumberdeprecated": "4658159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658188"
            }
        },
        {
            "name": "Wiebel, A.",
            "value": 151,
            "numPapers": 53,
            "cluster": "3",
            "index": 173,
            "weight": 9,
            "x": 205.59374256408637,
            "y": 504.64024204137814,
            "px": 221.85646198348442,
            "py": 506.31383490821565,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Multifield Visualization Using Local Statistical Complexity",
                "PaperDOI": "10.1109/TVCG.2007.70615",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70615",
                "Firstpage": "1384",
                "Lastpage": "1391",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.",
                "AuthorNames": "Janicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "FirstAuthorAffiliation": "Univ. of Leipzig, Leipzig|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Jnicke, H.;Wiebel, A.;Scheuermann, G.;Kollmann, W.",
                "References": "10.1109/VISUAL.1999.809865;10.1109/VISUAL.2003.1250372;10.1109/TVCG.2006.165;10.1109/VISUAL.1999.809905;10.1109/TVCG.2006.183;10.1109/VISUAL.2003.1250383",
                "AuthorKeywords": "Local statistical complexity, multifield visualization, time-dependent, coherent structures, feature detection, information theroy, flow visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4376165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809865;1250372;4015447;809905;4015473;1250383"
            }
        },
        {
            "name": "Gyulassy, A.",
            "value": 161,
            "numPapers": 45,
            "cluster": "3",
            "index": 174,
            "weight": 20,
            "x": 292.79108420609526,
            "y": 652.101780248683,
            "px": 297.69900363019013,
            "py": 639.6150482031014,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Topology-based simplification for feature extraction from 3D scalar fields",
                "PaperDOI": "10.1109/VISUAL.2005.1532839",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532839",
                "Firstpage": "535",
                "Lastpage": "542",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.",
                "AuthorNames": "Gyulassy, A.;Vijay Natarajan",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Gyulassy, A.;Vijay Natarajan",
                "References": "10.1109/VISUAL.1999.809907;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2004.96;10.1109/VISUAL.2001.964507",
                "AuthorKeywords": "Morse theory, Morse-Smale complexes, computational topology, multiresolution, simplification, feature detection, 3D scalar fields",
                "IEEEXPLOREArticleNumberdeprecated": "1532839",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809907;885680;1372235;964507"
            }
        },
        {
            "name": "Bremer, P.-T.",
            "value": 224,
            "numPapers": 67,
            "cluster": "3",
            "index": 175,
            "weight": 29,
            "x": 233.85405178055333,
            "y": 559.0731951599226,
            "px": 237.66573935393728,
            "py": 555.5118583858454,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Adaptive Extraction and Quantification of Geophysical Vortices",
                "PaperDOI": "10.1109/TVCG.2011.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.162",
                "Firstpage": "2088",
                "Lastpage": "2095",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We consider the problem of extracting discrete two-dimensional vortices from a turbulent flow. In our approach we use a reference model describing the expected physics and geometry of an idealized vortex. The model allows us to derive a novel correlation between the size of the vortex and its strength, measured as the square of its strain minus the square of its vorticity. For vortex detection in real models we use the strength parameter to locate potential vortex cores, then measure the similarity of our ideal analytical vortex and the real vortex core for different strength thresholds. This approach provides a metric for how well a vortex core is modeled by an ideal vortex. Moreover, this provides insight into the problem of choosing the thresholds that identify a vortex. By selecting a target coefficient of determination (i.e., statistical confidence), we determine on a per-vortex basis what threshold of the strength parameter would be required to extract that vortex at the chosen confidence. We validate our approach on real data from a global ocean simulation and derive from it a map of expected vortex strengths over the global ocean.",
                "AuthorNames": "Williams, S.;Petersen, M.;Bremer, P.-T.;Hecht, M.;Pascucci, V.;Ahrens, J.;Hlawitschka, M.;Hamann, B.",
                "FirstAuthorAffiliation": "Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;;;;;;",
                "AuthorIDs": "37534471500;38028525800;37564112000;38028545000;37284312600;37282713700;37403333700;37282068700",
                "Dedupedauthornames": "Williams, S.;Petersen, M.;Bremer, P.-T.;Hecht, M.;Pascucci, V.;Ahrens, J.;Hlawitschka, M.;Hamann, B.",
                "References": "10.1109/VISUAL.1994.346327;10.1109/TVCG.2008.143;10.1109/VISUAL.1993.398877",
                "AuthorKeywords": "Vortex extraction, feature extraction, statistical data analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6064973",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346327;4658165;398877"
            }
        },
        {
            "name": "Vijay Natarajan",
            "value": 100,
            "numPapers": 10,
            "cluster": "3",
            "index": 176,
            "weight": 3,
            "x": 337.6904642855571,
            "y": 582.5247140755321,
            "px": 341.3295479768549,
            "py": 562.802251813305,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Topology-based simplification for feature extraction from 3D scalar fields",
                "PaperDOI": "10.1109/VISUAL.2005.1532839",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532839",
                "Firstpage": "535",
                "Lastpage": "542",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.",
                "AuthorNames": "Gyulassy, A.;Vijay Natarajan",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Gyulassy, A.;Vijay Natarajan",
                "References": "10.1109/VISUAL.1999.809907;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2004.96;10.1109/VISUAL.2001.964507",
                "AuthorKeywords": "Morse theory, Morse-Smale complexes, computational topology, multiresolution, simplification, feature detection, 3D scalar fields",
                "IEEEXPLOREArticleNumberdeprecated": "1532839",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809907;885680;1372235;964507"
            }
        },
        {
            "name": "Jonsson, D.",
            "value": 9,
            "numPapers": 15,
            "cluster": "2",
            "index": 177,
            "weight": 1,
            "x": 319.2675120477796,
            "y": 130.42680178814373,
            "px": 318.41050769019984,
            "py": 120.10981213505248,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping",
                "PaperDOI": "10.1109/TVCG.2012.232",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.232",
                "Firstpage": "2364",
                "Lastpage": "2371",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.",
                "AuthorNames": "Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.",
                "FirstAuthorAffiliation": "Linkoping Univ., Linkoping, Sweden|c|;;;",
                "AuthorIDs": "38228659100;38230927900;37295281400;37284192000",
                "Dedupedauthornames": "Jonsson, D.;Kronander, J.;Ropinski, T.;Ynnerman, A.",
                "References": "10.1109/TVCG.2011.211",
                "AuthorKeywords": "Volume rendering, photon mapping, global illumination, participating media",
                "IEEEXPLOREArticleNumberdeprecated": "6327241",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064977"
            }
        },
        {
            "name": "Lundstrom, C.",
            "value": 75,
            "numPapers": 23,
            "cluster": "2",
            "index": 178,
            "weight": 1,
            "x": 294.6945833393511,
            "y": 121.45793223244527,
            "px": 324.77775489524964,
            "py": 137.51971030002704,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Spatial Conditioning of Transfer Functions Using Local Material Distributions",
                "PaperDOI": "10.1109/TVCG.2010.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.195",
                "Firstpage": "1301",
                "Lastpage": "1310",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.",
                "AuthorNames": "Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37591265100;37284208400;37284209100;37604521200;37284192000",
                "Dedupedauthornames": "Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.",
                "References": "10.1109/TVCG.2009.185;10.1109/TVCG.2009.120;10.1109/TVCG.2008.147;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2007.70591;10.1109/VISUAL.2001.964516;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.1999.809932;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Direct Volume Rendering, Transfer Function, Spatial Conditioning, Neighborhood Meta-Data",
                "IEEEXPLOREArticleNumberdeprecated": "5613470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290763;5290764;4658169;1250412;4376159;964516;5290762;4658153;1250413;809932;4015460"
            }
        },
        {
            "name": "Persson, A.",
            "value": 75,
            "numPapers": 30,
            "cluster": "2",
            "index": 179,
            "weight": 2,
            "x": 278.2400888617266,
            "y": 38.54829559463074,
            "px": 283.7318226435993,
            "py": 41.909600394863425,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Spatial Conditioning of Transfer Functions Using Local Material Distributions",
                "PaperDOI": "10.1109/TVCG.2010.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.195",
                "Firstpage": "1301",
                "Lastpage": "1310",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.",
                "AuthorNames": "Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37591265100;37284208400;37284209100;37604521200;37284192000",
                "Dedupedauthornames": "Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.",
                "References": "10.1109/TVCG.2009.185;10.1109/TVCG.2009.120;10.1109/TVCG.2008.147;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2007.70591;10.1109/VISUAL.2001.964516;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.1999.809932;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Direct Volume Rendering, Transfer Function, Spatial Conditioning, Neighborhood Meta-Data",
                "IEEEXPLOREArticleNumberdeprecated": "5613470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290763;5290764;4658169;1250412;4376159;964516;5290762;4658153;1250413;809932;4015460"
            }
        },
        {
            "name": "Hadwiger, M.",
            "value": 190,
            "numPapers": 90,
            "cluster": "2",
            "index": 180,
            "weight": 29,
            "x": 266.4782561595635,
            "y": 88.04327257492756,
            "px": 252.1404793469204,
            "py": 84.37341621281834,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach",
                "PaperDOI": "10.1109/TVCG.2012.240",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.240",
                "Firstpage": "2285",
                "Lastpage": "2294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.",
                "AuthorNames": "Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37394809600;37409575800;38490133400;37275698100",
                "Dedupedauthornames": "Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.",
                "References": "10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.161",
                "AuthorKeywords": "Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience",
                "IEEEXPLOREArticleNumberdeprecated": "6327233",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809908;1250384;5290773"
            }
        },
        {
            "name": "Beyer, J.",
            "value": 111,
            "numPapers": 41,
            "cluster": "2",
            "index": 181,
            "weight": 14,
            "x": 250.5514250991061,
            "y": -49.71289980929194,
            "px": 225.489701418346,
            "py": -31.912835828340373,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach",
                "PaperDOI": "10.1109/TVCG.2012.240",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.240",
                "Firstpage": "2285",
                "Lastpage": "2294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.",
                "AuthorNames": "Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37394809600;37409575800;38490133400;37275698100",
                "Dedupedauthornames": "Hadwiger, M.;Beyer, J.;Won-Ki Jeong;Pfister, H.",
                "References": "10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.161",
                "AuthorKeywords": "Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience",
                "IEEEXPLOREArticleNumberdeprecated": "6327233",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809908;1250384;5290773"
            }
        },
        {
            "name": "Won-Ki Jeong",
            "value": 50,
            "numPapers": 12,
            "cluster": "2",
            "index": 182,
            "weight": 5,
            "x": 283.8303417016857,
            "y": 25.22395065532889,
            "px": 343.1971866591785,
            "py": -98.605137264515,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems",
                "PaperDOI": "10.1109/TVCG.2014.2346322",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346322",
                "Firstpage": "2407",
                "Lastpage": "2416",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.",
                "AuthorNames": "Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;Hildebrand, D.G.C.;Pfister, H.;Won-Ki Jeong",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;Hildebrand, D.G.C.;Pfister, H.;Won-Ki Jeong",
                "References": "10.1109/VISUAL.2004.95",
                "AuthorKeywords": "Domain-specific language, volume rendering, GPU computing, distributed heterogeneous systems",
                "IEEEXPLOREArticleNumberdeprecated": "6875916",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372194"
            }
        },
        {
            "name": "Yi Gu",
            "value": 15,
            "numPapers": 21,
            "cluster": "2",
            "index": 183,
            "weight": 2,
            "x": 418.0480241435195,
            "y": -21.46634040013757,
            "px": 433.42987902696274,
            "py": -19.602125766287372,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data",
                "PaperDOI": "10.1109/TVCG.2011.246",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.246",
                "Firstpage": "2015",
                "Lastpage": "2024",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.",
                "AuthorNames": "Yi Gu;Chaoli Wang",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MA, USA|c|;",
                "AuthorIDs": "38021343000;37405886900",
                "Dedupedauthornames": "Yi Gu;Chaoli Wang",
                "References": "10.1109/TVCG.2008.119;10.1109/VISUAL.1994.346321;10.1109/VAST.2006.261451;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2008.116;10.1109/TVCG.2010.190;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.1995.480809;10.1109/TVCG.2008.140;10.1109/VISUAL.2001.964531;10.1109/TVCG.2009.200",
                "AuthorKeywords": "Time-varying data visualization, hierarchical representation, states, transition relationship, user interface",
                "IEEEXPLOREArticleNumberdeprecated": "6064965",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658159;346321;4035742;809871;4015447;1250401;4658163;5613488;1250402;480809;4658174;964531;5290749"
            }
        },
        {
            "name": "Weinkauf, T.",
            "value": 206,
            "numPapers": 68,
            "cluster": "3",
            "index": 184,
            "weight": 22,
            "x": 233.8098624686056,
            "y": 503.0526884873571,
            "px": 232.41939533013985,
            "py": 490.1859574507374,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments",
                "PaperDOI": "10.1109/TVCG.2008.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.163",
                "Firstpage": "1396",
                "Lastpage": "1403",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.",
                "AuthorNames": "von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.",
                "FirstAuthorAffiliation": "MPI Informatlk, Saarbrucken|c|;;;",
                "AuthorIDs": "37869714300;37282635100;37266875400;37271851300",
                "Dedupedauthornames": "von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.",
                "References": "10.1109/VISUAL.1995.485141;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2001.964506;10.1109/VISUAL.1993.398877",
                "AuthorKeywords": "Unsteady flow visualization, streak surfaces, smoke visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4658155",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "485141;398846;235211;964506;398877"
            }
        },
        {
            "name": "Garth, C.",
            "value": 284,
            "numPapers": 90,
            "cluster": "3",
            "index": 185,
            "weight": 35,
            "x": 233.0558725286454,
            "y": 495.6578087767611,
            "px": 236.48540387137263,
            "py": 499.2845658660527,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Tracking of vector field singularities in unstructured 3D time-dependent datasets",
                "PaperDOI": "10.1109/VISUAL.2004.107",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.107",
                "Firstpage": "329",
                "Lastpage": "336",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an approach for monitoring the positions of vector field singularities and related structural changes in time-dependent datasets. The concept of singularity index is discussed and extended from the well-understood planar case to the more intricate three-dimensional setting. Assuming a tetrahedral grid with linear interpolation in space and time, vector field singularities obey rules imposed by fundamental invariants (Poincare index), which we use as a basis for an efficient tracking algorithm. We apply the presented algorithm to CFD datasets to illustrate its purpose. We examine structures that exhibit topological variations with time and describe some of the insight gained with our method. Examples are given that show a correlation in the evolution of physical quantities that play a role in vortex breakdown.",
                "AuthorNames": "Garth, C.;Tricoche, X.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;",
                "AuthorIDs": "37282573700;37282575100;37282574800",
                "Dedupedauthornames": "Garth, C.;Tricoche, X.;Scheuermann, G.",
                "References": "10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183786;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663910",
                "AuthorKeywords": "flow visualization, topology tracking, time-dependent datasets, vortex breakdown",
                "IEEEXPLOREArticleNumberdeprecated": "1372214",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250376;1183786;175773;663910"
            }
        },
        {
            "name": "Al-Awami, A.",
            "value": 35,
            "numPapers": 27,
            "cluster": "2",
            "index": 186,
            "weight": 11,
            "x": 389.7157332851844,
            "y": -55.71586731550754,
            "px": 360.15754858523775,
            "py": -28.955875779998763,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity",
                "PaperDOI": "10.1109/TVCG.2014.2346312",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346312",
                "Firstpage": "2369",
                "Lastpage": "2378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",
                "AuthorNames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "References": "10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154",
                "AuthorKeywords": "Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context",
                "IEEEXPLOREArticleNumberdeprecated": "6875935",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634132;6327233;6875931;5290766;6102439;5290699;6065015;1183754;6634190"
            }
        },
        {
            "name": "Kasthuri, N.",
            "value": 49,
            "numPapers": 29,
            "cluster": "2",
            "index": 187,
            "weight": 14,
            "x": 398.929549622452,
            "y": 6.595335437302545,
            "px": 383.0262745986786,
            "py": 22.726003484476,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity",
                "PaperDOI": "10.1109/TVCG.2014.2346312",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346312",
                "Firstpage": "2369",
                "Lastpage": "2378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",
                "AuthorNames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "References": "10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154",
                "AuthorKeywords": "Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context",
                "IEEEXPLOREArticleNumberdeprecated": "6875935",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634132;6327233;6875931;5290766;6102439;5290699;6065015;1183754;6634190"
            }
        },
        {
            "name": "Lichtman, J.",
            "value": 49,
            "numPapers": 37,
            "cluster": "2",
            "index": 188,
            "weight": 14,
            "x": 263.7128165521718,
            "y": -50.17923477167797,
            "px": 238.3020739712371,
            "py": -32.06229627673594,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity",
                "PaperDOI": "10.1109/TVCG.2014.2346312",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346312",
                "Firstpage": "2369",
                "Lastpage": "2378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",
                "AuthorNames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "References": "10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154",
                "AuthorKeywords": "Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context",
                "IEEEXPLOREArticleNumberdeprecated": "6875935",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634132;6327233;6875931;5290766;6102439;5290699;6065015;1183754;6634190"
            }
        },
        {
            "name": "Haehn, D.",
            "value": 14,
            "numPapers": 11,
            "cluster": "2",
            "index": 189,
            "weight": 5,
            "x": 283.12325531476125,
            "y": -9.684901138909378,
            "px": 161.03752072053297,
            "py": 52.873772796610126,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity",
                "PaperDOI": "10.1109/TVCG.2014.2346312",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346312",
                "Firstpage": "2369",
                "Lastpage": "2378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",
                "AuthorNames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.W.;Pfister, H.;Hadwiger, M.",
                "FirstAuthorAffiliation": "King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Al-Awami, A.;Beyer, J.;Strobelt, H.;Kasthuri, N.;Lichtman, J.;Pfister, H.;Hadwiger, M.",
                "References": "10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154",
                "AuthorKeywords": "Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context",
                "IEEEXPLOREArticleNumberdeprecated": "6875935",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634132;6327233;6875931;5290766;6102439;5290699;6065015;1183754;6634190"
            }
        },
        {
            "name": "Crossno, P.",
            "value": 140,
            "numPapers": 24,
            "cluster": "2",
            "index": 190,
            "weight": 3,
            "x": 7.99655095346594,
            "y": -551.7179379761462,
            "px": -71.32385598944126,
            "py": -681.4141186249261,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "Firstpage": "135",
                "Lastpage": "142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "References": "10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "interrogative visualization, dataflow, caching, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "1532788",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Freire, J.",
            "value": 252,
            "numPapers": 56,
            "cluster": "2",
            "index": 191,
            "weight": 11,
            "x": 281.4448387799621,
            "y": 46.37346669605283,
            "px": 292.93512722050156,
            "py": 79.43303572545472,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "Firstpage": "135",
                "Lastpage": "142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "References": "10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "interrogative visualization, dataflow, caching, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "1532788",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Scheidegger, C.E.",
            "value": 230,
            "numPapers": 71,
            "cluster": "2",
            "index": 192,
            "weight": 10,
            "x": 469.74954677686446,
            "y": 218.85688545695288,
            "px": 442.51851719665103,
            "py": 205.37156055913968,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Silva, C.T.",
            "value": 594,
            "numPapers": 202,
            "cluster": "2",
            "index": 193,
            "weight": 50,
            "x": 284.35890394605553,
            "y": 206.01634511499307,
            "px": 273.0041961864138,
            "py": 202.7587558960175,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Two-Phase Mapping for Projecting Massive Data Sets",
                "PaperDOI": "10.1109/TVCG.2010.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.207",
                "Firstpage": "1281",
                "Lastpage": "1290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.",
                "AuthorNames": "Paulovich, F.V.;Silva, C.T.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sa&#x0303;o Carlos, Brazil|c|;;",
                "AuthorIDs": "37590969400;37275249200;37590974800",
                "Dedupedauthornames": "Paulovich, F.V.;Silva, C.T.;Nonato, L.G.",
                "References": "10.1109/INFVIS.2002.1173159;10.1109/VISUAL.1996.567787;10.1109/TVCG.2008.138;10.1109/TVCG.2009.131;10.1109/INFVIS.2004.60;10.1109/TVCG.2007.70580;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173161",
                "AuthorKeywords": "Dimensionality Reduction,Projection Methods,Visual Data Mining,Streaming Technique",
                "IEEEXPLOREArticleNumberdeprecated": "5613468",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173159;567787;4658134;5290770;1382891;4376155;4658123;1173161"
            }
        },
        {
            "name": "Vo, H.T.",
            "value": 211,
            "numPapers": 29,
            "cluster": "2",
            "index": 194,
            "weight": 4,
            "x": 200.49186365957001,
            "y": -119.748415619184,
            "px": 123.58023322573285,
            "py": -202.0105976268877,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "Firstpage": "135",
                "Lastpage": "142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "References": "10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "interrogative visualization, dataflow, caching, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "1532788",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Bavoil, L.",
            "value": 108,
            "numPapers": 9,
            "cluster": "2",
            "index": 195,
            "weight": 2,
            "x": 1053.952892376396,
            "y": 34.48975048497802,
            "px": 1015.1299919882439,
            "py": 22.63705709868324,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "Firstpage": "135",
                "Lastpage": "142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "References": "10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "interrogative visualization, dataflow, caching, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "1532788",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Callahan, S.P.",
            "value": 139,
            "numPapers": 27,
            "cluster": "2",
            "index": 196,
            "weight": 6,
            "x": 337.766564809386,
            "y": 270.4205182707653,
            "px": 332.24033180639265,
            "py": 289.52048722964133,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "Firstpage": "135",
                "Lastpage": "142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "References": "10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "interrogative visualization, dataflow, caching, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "1532788",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Buhler, K.",
            "value": 61,
            "numPapers": 15,
            "cluster": "2",
            "index": 197,
            "weight": 6,
            "x": 241.8878914179564,
            "y": -20.283151100416937,
            "px": 285.7028600944803,
            "py": -36.95073612853343,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "BrainGazer - Visual Queries for Neurobiology Research",
                "PaperDOI": "10.1109/TVCG.2009.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.121",
                "Firstpage": "1497",
                "Lastpage": "1504",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.",
                "AuthorNames": "Bruckner, S.;Solteszova, V.;Groller, E.;Hladuvka, J.;Buhler, K.;Yu, J.Y.;Dickson, B.J.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;",
                "AuthorIDs": "37265895700;;37284271200;38108878100;37267821300;38105995800;38100422000",
                "Dedupedauthornames": "Bruckner, S.;Solteszova, V.;Groller, E.;Hladuvka, J.;Buhler, K.;Yu, J.Y.;Dickson, B.J.",
                "References": "10.1109/VISUAL.2004.104;10.1109/VISUAL.1990.146378;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2006.197;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1996.568136;10.1109/TVCG.2006.195;10.1109/VAST.2008.4677354",
                "AuthorKeywords": "Biomedical visualization, neurobiology, visual queries, volume visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5290766",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372221;146378;1250412;4015478;485139;568136;4015489;4677354"
            }
        },
        {
            "name": "Bruckner, S.",
            "value": 410,
            "numPapers": 136,
            "cluster": "2",
            "index": 198,
            "weight": 33,
            "x": 195.00573890990322,
            "y": 184.12915026676794,
            "px": 205.28559331176544,
            "py": 162.9834457586697,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Visual Parameter Space Analysis: A Conceptual Framework",
                "PaperDOI": "10.1109/TVCG.2014.2346321",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346321",
                "Firstpage": "2161",
                "Lastpage": "2170",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.",
                "AuthorNames": "Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.",
                "FirstAuthorAffiliation": "Univ. of Vienna, Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.",
                "References": "10.1109/INFVIS.1995.528680;10.1109/TVCG.2010.177;10.1109/TVCG.2008.145;10.1109/TVCG.2012.219;10.1109/TVCG.2009.155;10.1109/TVCG.2010.223;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2010.190;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1993.398859;10.1109/VAST.2009.5333431;10.1109/TVCG.2007.70581;10.1109/TVCG.2013.142;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.130;10.1109/TVCG.2013.147;10.1109/TVCG.2013.124;10.1109/TVCG.2012.190;10.1109/TVCG.2009.111;10.1109/TVCG.2011.229;10.1109/TVCG.2013.157;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102450;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.126;10.1109/TVCG.2011.248;10.1109/TVCG.2010.214;10.1109/TVCG.2009.170;10.1109/VAST.2011.6102457;10.1109/TVCG.2013.120;10.1109/TVCG.2011.253",
                "AuthorKeywords": "Parameter space analysis, input-output model, simulation, task characterization, literature analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6876043",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528680;5613437;4658193;6327298;5290748;5613487;6327293;6327248;5613488;1532136;398859;5333431;4376186;6634132;5652392;1532142;6634181;6634138;6634168;6327226;5290695;6064985;6634124;6634169;6102450;1532788;6634108;6064952;5613489;5290759;6102457;6634156;6065007"
            }
        },
        {
            "name": "Olivan Bescos, J.",
            "value": 45,
            "numPapers": 12,
            "cluster": "6",
            "index": 199,
            "weight": 3,
            "x": 1263.5837514249777,
            "y": 643.350201501331,
            "px": 1310.8373720972265,
            "py": 653.0948759193157,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Exploration of 4D MRI Blood Flow using Stylistic Visualization",
                "PaperDOI": "10.1109/TVCG.2010.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.153",
                "Firstpage": "1339",
                "Lastpage": "1347",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.",
                "AuthorNames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "FirstAuthorAffiliation": "Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;",
                "AuthorIDs": "37390973400;37591606800;37374875300;37603313200;37284271200;;37282551500",
                "Dedupedauthornames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "References": "10.1109/TVCG.2006.140;10.1109/TVCG.2009.138",
                "AuthorKeywords": "4D MRI blood-flow, Probing, Flow visualization, Illustrative visualization, Phase-contrast cine MRI",
                "IEEEXPLOREArticleNumberdeprecated": "5613474",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015467;5290742"
            }
        },
        {
            "name": "Clough, R.E.",
            "value": 45,
            "numPapers": 12,
            "cluster": "6",
            "index": 200,
            "weight": 3,
            "x": 1102.9935581673155,
            "y": 680.4784941968785,
            "px": 1110.054006380401,
            "py": 695.6974460027208,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Exploration of 4D MRI Blood Flow using Stylistic Visualization",
                "PaperDOI": "10.1109/TVCG.2010.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.153",
                "Firstpage": "1339",
                "Lastpage": "1347",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.",
                "AuthorNames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "FirstAuthorAffiliation": "Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;",
                "AuthorIDs": "37390973400;37591606800;37374875300;37603313200;37284271200;;37282551500",
                "Dedupedauthornames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "References": "10.1109/TVCG.2006.140;10.1109/TVCG.2009.138",
                "AuthorKeywords": "4D MRI blood-flow, Probing, Flow visualization, Illustrative visualization, Phase-contrast cine MRI",
                "IEEEXPLOREArticleNumberdeprecated": "5613474",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015467;5290742"
            }
        },
        {
            "name": "ter Haar Romenij, B.",
            "value": 54,
            "numPapers": 21,
            "cluster": "6",
            "index": 201,
            "weight": 3,
            "x": 1149.8419858119198,
            "y": 700.2437336249105,
            "px": 1165.6038202301572,
            "py": 715.9129270877067,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Exploration of 4D MRI Blood Flow using Stylistic Visualization",
                "PaperDOI": "10.1109/TVCG.2010.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.153",
                "Firstpage": "1339",
                "Lastpage": "1347",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.",
                "AuthorNames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "FirstAuthorAffiliation": "Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;",
                "AuthorIDs": "37390973400;37591606800;37374875300;37603313200;37284271200;;37282551500",
                "Dedupedauthornames": "van Pelt, R.;Olivan Bescos, J.;Breeuwer, M.;Clough, R.E.;Groller, E.;ter Haar Romenij, B.;Vilanova, A.",
                "References": "10.1109/TVCG.2006.140;10.1109/TVCG.2009.138",
                "AuthorKeywords": "4D MRI blood-flow, Probing, Flow visualization, Illustrative visualization, Phase-contrast cine MRI",
                "IEEEXPLOREArticleNumberdeprecated": "5613474",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015467;5290742"
            }
        },
        {
            "name": "Marino, J.",
            "value": 11,
            "numPapers": 17,
            "cluster": "2",
            "index": 202,
            "weight": 3,
            "x": -42.90854372573017,
            "y": 420.1428342705359,
            "px": -137.96560496182212,
            "py": 503.87265942563005,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Straightening Tubular Flow for Side-by-Side Visualization",
                "PaperDOI": "10.1109/TVCG.2011.235",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.235",
                "Firstpage": "2063",
                "Lastpage": "2070",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Flows through tubular structures are common in many fields, including blood flow in medicine and tubular fluid flows in engineering. The analysis of such flows is often done with a strong reference to the main flow direction along the tubular boundary. In this paper we present an approach for straightening the visualization of tubular flow. By aligning the main reference direction of the flow, i.e., the center line of the bounding tubular structure, with one axis of the screen, we are able to natively juxtapose (1.) different visualizations of the same flow, either utilizing different flow visualization techniques, or by varying parameters of a chosen approach such as the choice of seeding locations for integration-based flow visualization, (2.) the different time steps of a time-dependent flow, (3.) different projections around the center line , and (4.) quantitative flow visualizations in immediate spatial relation to the more qualitative classical flow visualization. We describe how to utilize this approach for an informative interactive visual analysis. We demonstrate the potential of our approach by visualizing two datasets from two different fields: an arterial blood flow measurement and a tubular gas flow simulation from the automotive industry.",
                "AuthorNames": "Angelelli, P.;Hauser, H.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37889160600;37274158800",
                "Dedupedauthornames": "Angelelli, P.;Hauser, H.",
                "References": "10.1109/TVCG.2009.169;10.1109/TVCG.2010.218;10.1109/VISUAL.1996.568137;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2010.153;10.1109/VISUAL.2001.964540;10.1109/TVCG.2009.136",
                "AuthorKeywords": "Flow Visualization, Data Reformation, Comparative Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6064970",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290768;5613501;568137;1250353;5613474;964540;5290734"
            }
        },
        {
            "name": "Kaufman, A.",
            "value": 556,
            "numPapers": 146,
            "cluster": "2",
            "index": 203,
            "weight": 52,
            "x": 164.0931548759121,
            "y": 258.3225538843139,
            "px": 150.3158896241152,
            "py": 249.54978588287523,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "Generation of Transfer Functions with Stochastic Search Technique",
                "PaperDOI": "10.1109/VISUAL.1996.568113",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568113",
                "Firstpage": "227",
                "Lastpage": "234",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a novel approach to assist the user in exploring appropriate transfer functions for the visualization of volumetric datasets. The search for a transfer function is treated as a parameter optimization problem and addressed with stochastic search techniques. Starting from an initial population of (random or pre-defined) transfer functions, the evolution of the stochastic algorithms is controlled by either direct user selection of intermediate images or automatic fitness evaluation using user-specified objective functions. This approach essentially shields the user from the complex and tedious trial and error approach, and demonstrates effective and convenient generation of transfer functions.",
                "AuthorNames": "He, T.;Hong, L.;Kaufman, A.;Pfister, H.",
                "FirstAuthorAffiliation": "Department of Computer Science, State University of New York at Stony Brook, Stony Brook, NY",
                "AuthorIDs": "",
                "Dedupedauthornames": "He, T.;Hong, L.;Kaufman, A.;Pfister, H.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "568112",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Vilanova Bartroli, A.V.",
            "value": 50,
            "numPapers": 2,
            "cluster": "2",
            "index": 204,
            "weight": 1,
            "x": 81.30920054342104,
            "y": -1167.8968419910693,
            "px": 80.68968699788196,
            "py": -1043.6496406192248,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Nonlinear virtual colon unfolding",
                "PaperDOI": "10.1109/VISUAL.2001.964540",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964540",
                "Firstpage": "411",
                "Lastpage": "418",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.",
                "AuthorNames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37728231400;37267822600;38180242000;38471589800",
                "Dedupedauthornames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "References": "10.1109/INFVIS.1997.636786;10.1109/VISUAL.1999.809914",
                "AuthorKeywords": "Volume Rendering, Virtual Endoscopy",
                "IEEEXPLOREArticleNumberdeprecated": "964540",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636786;809914"
            }
        },
        {
            "name": "Konig, A.",
            "value": 50,
            "numPapers": 2,
            "cluster": "2",
            "index": 205,
            "weight": 1,
            "x": 283.59270636484337,
            "y": -1213.8389909955436,
            "px": 261.0900403529671,
            "py": -1085.0423278057144,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Nonlinear virtual colon unfolding",
                "PaperDOI": "10.1109/VISUAL.2001.964540",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964540",
                "Firstpage": "411",
                "Lastpage": "418",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.",
                "AuthorNames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;",
                "AuthorIDs": "37728231400;37267822600;38180242000;38471589800",
                "Dedupedauthornames": "Vilanova Bartroli, A.V.;Wegenkittl, R.;Konig, A.;Groller, E.",
                "References": "10.1109/INFVIS.1997.636786;10.1109/VISUAL.1999.809914",
                "AuthorKeywords": "Volume Rendering, Virtual Endoscopy",
                "IEEEXPLOREArticleNumberdeprecated": "964540",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636786;809914"
            }
        },
        {
            "name": "Xianfeng Gu",
            "value": 46,
            "numPapers": 25,
            "cluster": "11",
            "index": 206,
            "weight": 5,
            "x": 515.8023942938297,
            "y": 1764.9114124473558,
            "px": 446.4663024838994,
            "py": 1873.8818540708285,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Context Preserving Maps of Tubular Structures",
                "PaperDOI": "10.1109/TVCG.2011.182",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.182",
                "Firstpage": "1997",
                "Lastpage": "2004",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When visualizing tubular 3D structures, external representations are often used for guidance and display, and such views in 2D can often contain occlusions. Virtual dissection methods have been proposed where the entire 3D structure can be mapped to the 2D plane, though these will lose context by straightening curved sections. We present a new method of creating maps of 3D tubular structures that yield a succinct view while preserving the overall geometric structure. Given a dominant view plane for the structure, its curve skeleton is first projected to a 2D skeleton. This 2D skeleton is adjusted to account for distortions in length, modified to remove intersections, and optimized to preserve the shape of the original 3D skeleton. Based on this shaped 2D skeleton, a boundary for the map of the object is obtained based on a slicing path through the structure and the radius around the skeleton. The sliced structure is conformally mapped to a rectangle and then deformed via harmonic mapping to match the boundary placement. This flattened map preserves the general geometric context of a 3D object in a 2D display, and rendering of this flattened map can be accomplished using volumetric ray casting. We have evaluated our method on real datasets of human colon models.",
                "AuthorNames": "Marino, J.;Wei Zeng;Xianfeng Gu;Kaufman, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;;",
                "AuthorIDs": "37605959300;38231202300;38183364800;37268052800",
                "Dedupedauthornames": "Marino, J.;Wei Zeng;Xianfeng Gu;Kaufman, A.",
                "References": "10.1109/TVCG.2006.112;10.1109/TVCG.2010.200;10.1109/VISUAL.2001.964540",
                "AuthorKeywords": "Geometry-based technique, volume rendering, biomedical visualization, medical visualization, conformal mapping",
                "IEEEXPLOREArticleNumberdeprecated": "6064963",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015440;5613475;964540"
            }
        },
        {
            "name": "Hansen, C.",
            "value": 734,
            "numPapers": 112,
            "cluster": "2",
            "index": 207,
            "weight": 48,
            "x": 216.01443157920633,
            "y": 127.44894191562803,
            "px": 231.34734533915613,
            "py": 135.9644683752797,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Real-Time Illustration of Vascular Structures",
                "PaperDOI": "10.1109/TVCG.2006.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.172",
                "Firstpage": "877",
                "Lastpage": "884",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects",
                "AuthorNames": "Ritter, F.;Hansen, C.;Dicken, V.;Konrad, O.;Preim, B.;Peitgen, H.-O.",
                "FirstAuthorAffiliation": "MeVis GmbH|c|;;;;;",
                "AuthorIDs": "37645939800;37824134900;37828698600;37828698700;37424645300;37442956900",
                "Dedupedauthornames": "Ritter, F.;Hansen, C.;Dicken, V.;Konrad, O.;Preim, B.;Peitgen, H.-O.",
                "References": "10.1109/VISUAL.2005.1532782;10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2005.1532835;10.1109/VISUAL.2001.964538;10.1109/INFVIS.2003.1249022;10.1109/VISUAL.2005.1532855",
                "AuthorKeywords": "Vessel visualization, functional realism, illustrative rendering, spatial perception, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4015442",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532782;1532859;1250394;1532835;964538;1249022;1532855"
            }
        },
        {
            "name": "Gunther, T.",
            "value": 3,
            "numPapers": 16,
            "cluster": "3",
            "index": 208,
            "weight": 6,
            "x": 340.67330529423174,
            "y": 640.7361205571901,
            "px": 334.08161247109615,
            "py": 591.3166510960635,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Vortex Cores of Inertial Particles",
                "PaperDOI": "10.1109/TVCG.2014.2346415",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346415",
                "Firstpage": "2535",
                "Lastpage": "2544",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.",
                "AuthorNames": "Gunther, T.;Theisel, H.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Gunther, T.;Theisel, H.",
                "References": "10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296",
                "AuthorKeywords": "Inertial particles, flow visualization, vortex cores",
                "IEEEXPLOREArticleNumberdeprecated": "6875993",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532851;4376212;5613462;809896;745296"
            }
        },
        {
            "name": "Schulze, M.",
            "value": 0,
            "numPapers": 11,
            "cluster": "3",
            "index": 209,
            "weight": 1,
            "x": -1037.9692554989479,
            "y": 1649.068319578718,
            "px": -945.3881997720952,
            "py": 1534.5505944575968,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Vortex Cores of Inertial Particles",
                "PaperDOI": "10.1109/TVCG.2014.2346415",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346415",
                "Firstpage": "2535",
                "Lastpage": "2544",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.",
                "AuthorNames": "Gunther, T.;Theisel, H.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Gunther, T.;Theisel, H.",
                "References": "10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296",
                "AuthorKeywords": "Inertial particles, flow visualization, vortex cores",
                "IEEEXPLOREArticleNumberdeprecated": "6875993",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532851;4376212;5613462;809896;745296"
            }
        },
        {
            "name": "Sahner, J.",
            "value": 57,
            "numPapers": 11,
            "cluster": "3",
            "index": 210,
            "weight": 4,
            "x": 365.8676551421665,
            "y": 789.9198810988173,
            "px": 319.8030914326347,
            "py": 893.325040612565,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking",
                "PaperDOI": "10.1109/VISUAL.2005.1532851",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532851",
                "Firstpage": "631",
                "Lastpage": "638",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.",
                "AuthorNames": "Theisel, H.;Sahner, J.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.",
                "FirstAuthorAffiliation": "MPI Saarbrucken, Germany|c|;;;;",
                "AuthorIDs": ";37565764600;37282635100;37282272000;37271851300",
                "Dedupedauthornames": "Theisel, H.;Sahner, J.;Weinkauf, T.;Hege, H.-C.;Seidel, H.-P.",
                "References": "10.1109/VISUAL.2004.99;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/VISUAL.1998.745290;10.1109/VISUAL.1998.745296",
                "AuthorKeywords": "flow visualization, vortex core lines, bifurcations",
                "IEEEXPLOREArticleNumberdeprecated": "1532851",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372213;346327;809896;235211;398875;964506;745290;745296"
            }
        },
        {
            "name": "Ferstl, F.",
            "value": 40,
            "numPapers": 28,
            "cluster": "3",
            "index": 211,
            "weight": 4,
            "x": 324.5449274148803,
            "y": 505.5567946521478,
            "px": 308.8995918363925,
            "py": 502.71323284379577,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Interactive Separating Streak Surfaces",
                "PaperDOI": "10.1109/TVCG.2010.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.169",
                "Firstpage": "1569",
                "Lastpage": "1577",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.",
                "AuthorNames": "Ferstl, F.;Burger, K.;Theisel, H.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization group, Tech. Univ. Munchen, Mnchen, Germany|c|;;;",
                "AuthorIDs": "37606419000;37587634700;37266875400;37444424000",
                "Dedupedauthornames": "Ferstl, F.;Burger, K.;Theisel, H.;Westermann, R.",
                "References": "10.1109/TVCG.2009.190;10.1109/TVCG.2007.70557;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.133;10.1109/VISUAL.2001.964506;10.1109/TVCG.2007.70554;10.1109/VISUAL.1993.398875;10.1109/TVCG.2009.177;10.1109/TVCG.2009.154;10.1109/TVCG.2006.151;10.1109/TVCG.2007.70551;10.1109/TVCG.2008.163;10.1109/VISUAL.2005.1532780",
                "AuthorKeywords": "Unsteady flow visualization, feature extraction, streak surface generation, GPUs",
                "IEEEXPLOREArticleNumberdeprecated": "5613499",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290738;4376209;235211;4658156;964506;4376174;398875;5290756;5290737;4015480;4376175;4658155;1532780"
            }
        },
        {
            "name": "Joy, K.I.",
            "value": 365,
            "numPapers": 123,
            "cluster": "3",
            "index": 212,
            "weight": 30,
            "x": 258.09345089113185,
            "y": 539.4774904166769,
            "px": 251.93590113838573,
            "py": 525.7819194875952,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging",
                "PaperDOI": "10.1109/TVCG.2013.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.138",
                "Firstpage": "2703",
                "Lastpage": "2712",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.",
                "AuthorNames": "Gosink, L.;Bensema, K.;Pulsipher, T.;Obermaier, H.;Henry, M.;Childs, H.;Joy, K.I.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Gosink, L.;Bensema, K.;Pulsipher, T.;Obermaier, H.;Henry, M.;Childs, H.;Joy, K.I.",
                "References": "10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.208;10.1109/TVCG.2010.181",
                "AuthorKeywords": "Uncertainty visualization, numerical ensembles, statistical visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634123",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183769;1532853;568116;5613476;5613483"
            }
        },
        {
            "name": "Wenchao Wu",
            "value": 8,
            "numPapers": 25,
            "cluster": "5",
            "index": 213,
            "weight": 2,
            "x": 1238.2768578687528,
            "y": 189.56672258512899,
            "px": 1252.7422565885306,
            "py": 196.7312972352197,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Discovering bits of place histories from people's activity traces",
                "PaperDOI": "10.1109/VAST.2010.5652478",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652478",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;",
                "AuthorIDs": "37283047100;37283047700;37545515700;37279597900;37589346900",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.",
                "References": "10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70621",
                "AuthorKeywords": "event detection, spatio-temporal data, time series analysis, scalable visualization, geovisualization \n",
                "IEEEXPLOREArticleNumberdeprecated": "5652478",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801851;4376136"
            }
        },
        {
            "name": "Andrienko, G.",
            "value": 290,
            "numPapers": 48,
            "cluster": "5",
            "index": 214,
            "weight": 27,
            "x": 1103.0445679852676,
            "y": 236.29143965768418,
            "px": 1108.8266953717123,
            "py": 246.75723339726926,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Analytics Methodology for Eye Movement Studies",
                "PaperDOI": "10.1109/TVCG.2012.276",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.276",
                "Firstpage": "2889",
                "Lastpage": "2898",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37283047100;37283047700;37586953400;37268045000",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.",
                "References": "10.1109/VAST.2009.5332593;10.1109/TVCG.2011.193;10.1109/INFVIS.2005.1532150",
                "AuthorKeywords": "Visual analytics, eye tracking, movement data, trajectory analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6327295",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5332593;6065011;1532150"
            }
        },
        {
            "name": "Andrienko, N.",
            "value": 290,
            "numPapers": 48,
            "cluster": "5",
            "index": 215,
            "weight": 27,
            "x": 1093.5655902138187,
            "y": 206.86122275664246,
            "px": 1098.987334018964,
            "py": 220.89665098608202,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Analytics Methodology for Eye Movement Studies",
                "PaperDOI": "10.1109/TVCG.2012.276",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.276",
                "Firstpage": "2889",
                "Lastpage": "2898",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37283047100;37283047700;37586953400;37268045000",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Burch, M.;Weiskopf, D.",
                "References": "10.1109/VAST.2009.5332593;10.1109/TVCG.2011.193;10.1109/INFVIS.2005.1532150",
                "AuthorKeywords": "Visual analytics, eye tracking, movement data, trajectory analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6327295",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5332593;6065011;1532150"
            }
        },
        {
            "name": "Yixian Zheng",
            "value": 8,
            "numPapers": 25,
            "cluster": "5",
            "index": 216,
            "weight": 2,
            "x": 1255.7250491159682,
            "y": 205.00445476931688,
            "px": 1267.1086287787662,
            "py": 204.74687220959277,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Discovering bits of place histories from people's activity traces",
                "PaperDOI": "10.1109/VAST.2010.5652478",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652478",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;",
                "AuthorIDs": "37283047100;37283047700;37545515700;37279597900;37589346900",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.",
                "References": "10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70621",
                "AuthorKeywords": "event detection, spatio-temporal data, time series analysis, scalable visualization, geovisualization \n",
                "IEEEXPLOREArticleNumberdeprecated": "5652478",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801851;4376136"
            }
        },
        {
            "name": "Ni, L.M.",
            "value": 52,
            "numPapers": 24,
            "cluster": "5",
            "index": 217,
            "weight": 2,
            "x": 1345.1602801056854,
            "y": 257.2260926778474,
            "px": 1347.7878193668419,
            "py": 252.21555811123102,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Discovering bits of place histories from people's activity traces",
                "PaperDOI": "10.1109/VAST.2010.5652478",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652478",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;",
                "AuthorIDs": "37283047100;37283047700;37545515700;37279597900;37589346900",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Mladenov, M.;Mock, M.;Politz, C.",
                "References": "10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70621",
                "AuthorKeywords": "event detection, spatio-temporal data, time series analysis, scalable visualization, geovisualization \n",
                "IEEEXPLOREArticleNumberdeprecated": "5652478",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801851;4376136"
            }
        },
        {
            "name": "Tominski, C.",
            "value": 78,
            "numPapers": 29,
            "cluster": "0",
            "index": 218,
            "weight": 3,
            "x": 692.8189873809359,
            "y": 1336.4244572950402,
            "px": 680.0732849122131,
            "py": 1457.2064402954927,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Stacking-Based Visualization of Trajectory Attribute Data",
                "PaperDOI": "10.1109/TVCG.2012.265",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.265",
                "Firstpage": "2565",
                "Lastpage": "2574",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.",
                "AuthorNames": "Tominski, C.;Schumann, H.;Andrienko, G.;Andrienko, N.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37283236000;37283240400;37283047100;37283047700",
                "Dedupedauthornames": "Tominski, C.;Schumann, H.;Andrienko, G.;Andrienko, N.",
                "References": "10.1109/TVCG.2010.197;10.1109/VAST.2011.6102455;10.1109/VAST.2009.5332593;10.1109/VISUAL.1995.480803;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532144;10.1109/VAST.2011.6102454",
                "AuthorKeywords": "Visualization, interaction, exploratory analysis, trajectory attribute data, spatio-temporal data",
                "IEEEXPLOREArticleNumberdeprecated": "6327262",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613442;6102455;5332593;480803;1382887;1532144;6102454"
            }
        },
        {
            "name": "Schumann, H.",
            "value": 158,
            "numPapers": 65,
            "cluster": "1",
            "index": 219,
            "weight": 4,
            "x": -922.2343458289263,
            "y": -437.1404406078403,
            "px": -929.2456809070284,
            "py": -435.62878659537967,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Design Space of Visualization Tasks",
                "PaperDOI": "10.1109/TVCG.2013.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.120",
                "Firstpage": "2366",
                "Lastpage": "2375",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.",
                "AuthorNames": "Schulz, H.-J.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "FirstAuthorAffiliation": "Univ. of Rostock, Rostock, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Schulz, H.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "References": "10.1109/INFVIS.1996.559213;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146372;10.1109/TVCG.2012.205;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/INFVIS.1996.559211;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885093;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Task taxonomy, design space, climate impact research, visualization recommendation",
                "IEEEXPLOREArticleNumberdeprecated": "6634156",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559213;1532136;4376144;146372;6327265;235203;1382903;4677365;559211;1382902;636792;885093;885092;146375"
            }
        },
        {
            "name": "Xiaoru Yuan",
            "value": 197,
            "numPapers": 161,
            "cluster": "5",
            "index": 220,
            "weight": 26,
            "x": 895.3354595286413,
            "y": 204.6298021383912,
            "px": 916.9748706083152,
            "py": 242.29864322406456,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Scattering Points in Parallel Coordinates",
                "PaperDOI": "10.1109/TVCG.2009.179",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.179",
                "Firstpage": "1001",
                "Lastpage": "1008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.",
                "AuthorNames": "Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": "37403856700;37411096400;37397293900;37405368200;37272637300",
                "Dedupedauthornames": "Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu",
                "References": "10.1109/TVCG.2008.119;10.1109/INFVIS.2005.1532139;10.1109/VISUAL.1997.663867;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1997.663916;10.1109/TVCG.2006.138;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2005.1532138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1996.567787;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.68;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153",
                "AuthorKeywords": "Parallel Coordinates, Scatterplots, Information Visualization, Multidimensional Scaling",
                "IEEEXPLOREArticleNumberdeprecated": "5290705",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658159;1532139;663867;146402;1532141;663916;4015422;663866;567800;1532138;1249015;567787;729568;1249008;1173157;809866;1249023;4015444;1382894;1382895;4658123"
            }
        },
        {
            "name": "Doraiswamy, H.",
            "value": 22,
            "numPapers": 38,
            "cluster": "3",
            "index": 221,
            "weight": 3,
            "x": 344.4488427181533,
            "y": 613.4006734797554,
            "px": 357.8229501668031,
            "py": 591.402097744507,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Exploration Framework to Identify and Track Movement of Cloud Systems",
                "PaperDOI": "10.1109/TVCG.2013.131",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.131",
                "Firstpage": "2896",
                "Lastpage": "2905",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.",
                "AuthorNames": "Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.",
                "References": "10.1109/TVCG.2007.70519;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250383",
                "AuthorKeywords": "Cloud clusters, tracking, computational topology, split tree, weather and climate simulations",
                "IEEEXPLOREArticleNumberdeprecated": "6634109",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376167;4015464;1250383"
            }
        },
        {
            "name": "Poco, J.",
            "value": 80,
            "numPapers": 28,
            "cluster": "5",
            "index": 222,
            "weight": 2,
            "x": 1775.3103241450585,
            "y": 451.99448195171146,
            "px": 1677.3344899376168,
            "py": 473.46247014367503,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling",
                "PaperDOI": "10.1109/TVCG.2014.2346755",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346755",
                "Firstpage": "1923",
                "Lastpage": "1932",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.",
                "AuthorNames": "Poco, J.;Dasgupta, A.;Yaxing Wei;Hargrove, W.;Schwalm, C.R.;Huntzinger, D.N.;Cook, R.;Bertini, E.;Silva, C.T.",
                "FirstAuthorAffiliation": "New York Univ., New York, NY, USA|c|;;;;;;;;",
                "AuthorIDs": ";;;;;;;;",
                "Dedupedauthornames": "Poco, J.;Dasgupta, A.;Yaxing Wei;Hargrove, W.;Schwalm, C.R.;Huntzinger, D.N.;Cook, R.;Bertini, E.;Silva, C.T.",
                "References": "10.1109/TVCG.2008.139;10.1109/TVCG.2012.256;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.157;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.188;10.1109/TVCG.2013.224;10.1109/VAST.2008.4677350;10.1109/TVCG.2013.120",
                "AuthorKeywords": "Similarity, clustering, matrix, optimization, climate model",
                "IEEEXPLOREArticleNumberdeprecated": "6876041",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658178;6327268;1532821;6634124;6400486;6634115;6634158;4677350;6634156"
            }
        },
        {
            "name": "Natarajan, V.",
            "value": 74,
            "numPapers": 27,
            "cluster": "3",
            "index": 223,
            "weight": 7,
            "x": 301.1959294921748,
            "y": 619.4944512717597,
            "px": 311.8211019203055,
            "py": 598.6337836363704,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Exploration Framework to Identify and Track Movement of Cloud Systems",
                "PaperDOI": "10.1109/TVCG.2013.131",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.131",
                "Firstpage": "2896",
                "Lastpage": "2905",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.",
                "AuthorNames": "Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.",
                "References": "10.1109/TVCG.2007.70519;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250383",
                "AuthorKeywords": "Cloud clusters, tracking, computational topology, split tree, weather and climate simulations",
                "IEEEXPLOREArticleNumberdeprecated": "6634109",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376167;4015464;1250383"
            }
        },
        {
            "name": "Schroeder, D.",
            "value": 0,
            "numPapers": 26,
            "cluster": "5",
            "index": 224,
            "weight": 2,
            "x": 1401.1478714453146,
            "y": 188.61650943408242,
            "px": 1401.1963193101349,
            "py": 189.18782267027328,
            "node": {
                "Conference": "VAST",
                "Year": "2008",
                "PaperTitle": "Spatio-temporal aggregation for visual analysis of movements",
                "PaperDOI": "10.1109/VAST.2008.4677356",
                "Link": "http://dx.doi.org/10.1109/VAST.2008.4677356",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS, Sankt Augustin|c|;",
                "AuthorIDs": "37283047100;37283047700",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.",
                "References": "",
                "AuthorKeywords": "Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization",
                "IEEEXPLOREArticleNumberdeprecated": "4677356",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Keefe, D.F.",
            "value": 41,
            "numPapers": 41,
            "cluster": "5",
            "index": 225,
            "weight": 3,
            "x": 1129.3448038741553,
            "y": 272.4399644554898,
            "px": 1150.2265557913138,
            "py": 307.44942655203414,
            "node": {
                "Conference": "VAST",
                "Year": "2008",
                "PaperTitle": "Spatio-temporal aggregation for visual analysis of movements",
                "PaperDOI": "10.1109/VAST.2008.4677356",
                "Link": "http://dx.doi.org/10.1109/VAST.2008.4677356",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS, Sankt Augustin|c|;",
                "AuthorIDs": "37283047100;37283047700",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.",
                "References": "",
                "AuthorKeywords": "Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization",
                "IEEEXPLOREArticleNumberdeprecated": "4677356",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Abbasloo, A.",
            "value": 5,
            "numPapers": 9,
            "cluster": "3",
            "index": 226,
            "weight": 1,
            "x": 938.4018403688669,
            "y": 53.28212811362886,
            "px": 946.7848818820788,
            "py": 47.83445019267727,
            "node": {
                "Conference": "SciVis",
                "Year": "2015",
                "PaperTitle": "Visualizing Tensor Normal Distributions at Multiple Levels of Detail",
                "PaperDOI": "10.1109/TVCG.2015.2467031",
                "Link": "http://dx.doi.org/10.1109/TVCG.2015.2467031",
                "Firstpage": "975",
                "Lastpage": "984",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.",
                "AuthorNames": "Abbasloo, A.;Wiens, V.;Hermann, M.;Schultz, T.",
                "FirstAuthorAffiliation": "Univ. of Bonn, Bonn, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Abbasloo, A.;Wiens, V.;Hermann, M.;Schultz, T.",
                "References": "10.1109/TVCG.2009.170;10.1109/TVCG.2009.184;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2006.181;10.1109/TVCG.2006.134;10.1109/TVCG.2010.199;10.1109/TVCG.2008.128;10.1109/TVCG.2007.70602;10.1109/TVCG.2015.2467435",
                "AuthorKeywords": "Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "7192624",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290759;5290754;1532773;4015482;4015499;5613502;4658185;4376179;7192722"
            }
        },
        {
            "name": "Wiens, V.",
            "value": 5,
            "numPapers": 9,
            "cluster": "3",
            "index": 227,
            "weight": 1,
            "x": 480.20772421519746,
            "y": 300.5683430249331,
            "px": 542.4239382814286,
            "py": 261.3387407979192,
            "node": {
                "Conference": "SciVis",
                "Year": "2015",
                "PaperTitle": "Visualizing Tensor Normal Distributions at Multiple Levels of Detail",
                "PaperDOI": "10.1109/TVCG.2015.2467031",
                "Link": "http://dx.doi.org/10.1109/TVCG.2015.2467031",
                "Firstpage": "975",
                "Lastpage": "984",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.",
                "AuthorNames": "Abbasloo, A.;Wiens, V.;Hermann, M.;Schultz, T.",
                "FirstAuthorAffiliation": "Univ. of Bonn, Bonn, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Abbasloo, A.;Wiens, V.;Hermann, M.;Schultz, T.",
                "References": "10.1109/TVCG.2009.170;10.1109/TVCG.2009.184;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2006.181;10.1109/TVCG.2006.134;10.1109/TVCG.2010.199;10.1109/TVCG.2008.128;10.1109/TVCG.2007.70602;10.1109/TVCG.2015.2467435",
                "AuthorKeywords": "Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "7192624",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290759;5290754;1532773;4015482;4015499;5613502;4658185;4376179;7192722"
            }
        },
        {
            "name": "Hermann, M.",
            "value": 5,
            "numPapers": 14,
            "cluster": "3",
            "index": 228,
            "weight": 1,
            "x": 457.0081417531741,
            "y": 518.0964348079718,
            "px": 527.5324054123594,
            "py": 428.0522478344442,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Exploded Views for Volume Data",
                "PaperDOI": "10.1109/TVCG.2006.140",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.140",
                "Firstpage": "1077",
                "Lastpage": "1084",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second",
                "AuthorNames": "Bruckner, S.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;",
                "AuthorIDs": "37265895700;37284271200",
                "Dedupedauthornames": "Bruckner, S.;Groller, E.",
                "References": "10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2005.1532783;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250384;10.1109/INFVIS.1996.559215;10.1109/VISUAL.2004.104;10.1109/VISUAL.2005.1532817",
                "AuthorKeywords": "Illustrative visualization, exploded views, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "4015467",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250400;1532783;1532856;1532807;1250384;559215;1372221;1532817"
            }
        },
        {
            "name": "Hua Guo",
            "value": 4,
            "numPapers": 23,
            "cluster": "0",
            "index": 229,
            "weight": 2,
            "x": -57.96937809298214,
            "y": -11.042727811478587,
            "px": -130.68959357708403,
            "py": -8.23503946778133,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Low-level components of analytic activity in information visualization",
                "PaperDOI": "10.1109/INFVIS.2005.1532136",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532136",
                "Firstpage": "111",
                "Lastpage": "117",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",
                "AuthorNames": "Amar, R.;Eagan, J.;Stasko, J.",
                "FirstAuthorAffiliation": "Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;",
                "AuthorIDs": "37418696100;37550755100;37267736900",
                "Dedupedauthornames": "Amar, R.;Eagan, J.;Stasko, J.",
                "References": "10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.5;10.1109/INFVIS.2001.963289",
                "AuthorKeywords": "Analytic activity, taxonomy, knowledge discovery, design, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1532136",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146375;729560;885092;1382884;963289"
            }
        },
        {
            "name": "Gomez, S.R.",
            "value": 4,
            "numPapers": 23,
            "cluster": "0",
            "index": 230,
            "weight": 2,
            "x": -86.1339264922733,
            "y": -200.5277759853973,
            "px": -167.8946289616228,
            "py": -214.48180613469086,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Low-level components of analytic activity in information visualization",
                "PaperDOI": "10.1109/INFVIS.2005.1532136",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532136",
                "Firstpage": "111",
                "Lastpage": "117",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",
                "AuthorNames": "Amar, R.;Eagan, J.;Stasko, J.",
                "FirstAuthorAffiliation": "Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;",
                "AuthorIDs": "37418696100;37550755100;37267736900",
                "Dedupedauthornames": "Amar, R.;Eagan, J.;Stasko, J.",
                "References": "10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.5;10.1109/INFVIS.2001.963289",
                "AuthorKeywords": "Analytic activity, taxonomy, knowledge discovery, design, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1532136",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146375;729560;885092;1382884;963289"
            }
        },
        {
            "name": "Mengchen Liu",
            "value": 53,
            "numPapers": 41,
            "cluster": "1",
            "index": 231,
            "weight": 10,
            "x": 828.2181881503077,
            "y": 610.3585432691625,
            "px": 798.0081901460775,
            "py": 589.1607840643721,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering",
                "PaperDOI": "10.1109/TVCG.2013.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.186",
                "Firstpage": "2022",
                "Lastpage": "2031",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.",
                "AuthorNames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",
                "AuthorKeywords": "Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",
                "IEEEXPLOREArticleNumberdeprecated": "6634195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532781;6400492;6400557;6327271;6327290;6400485;4389013;4389006;6102456;4658131"
            }
        },
        {
            "name": "Shixia Liu",
            "value": 508,
            "numPapers": 176,
            "cluster": "1",
            "index": 232,
            "weight": 83,
            "x": 629.9580087744243,
            "y": 556.379264011536,
            "px": 622.2122933840278,
            "py": 531.1543012674056,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering",
                "PaperDOI": "10.1109/TVCG.2013.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.186",
                "Firstpage": "2022",
                "Lastpage": "2031",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.",
                "AuthorNames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",
                "AuthorKeywords": "Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",
                "IEEEXPLOREArticleNumberdeprecated": "6634195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532781;6400492;6400557;6327271;6327290;6400485;4389013;4389006;6102456;4658131"
            }
        },
        {
            "name": "Nan Cao",
            "value": 151,
            "numPapers": 53,
            "cluster": "1",
            "index": 233,
            "weight": 7,
            "x": 817.6930327616769,
            "y": 519.418878691937,
            "px": 820.598539156174,
            "py": 496.7469679760922,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346922",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346922",
                "Firstpage": "1773",
                "Lastpage": "1782",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.",
                "AuthorNames": "Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Collins, C.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto, ON, Canada|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Collins, C.",
                "References": "10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/TVCG.2012.226;10.1109/TVCG.2013.227;10.1109/VAST.2012.6400485;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6876013",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102456;6327271;6400557;6065010;6065008;6327270;6634152;6400485;5652922;5613451;6634134;6634160"
            }
        },
        {
            "name": "Yu-Ru Lin",
            "value": 130,
            "numPapers": 39,
            "cluster": "1",
            "index": 234,
            "weight": 6,
            "x": 798.3944597440005,
            "y": 458.7100713979982,
            "px": 795.3640137465429,
            "py": 437.82312216614537,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346922",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346922",
                "Firstpage": "1773",
                "Lastpage": "1782",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.",
                "AuthorNames": "Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Collins, C.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto, ON, Canada|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Collins, C.",
                "References": "10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/TVCG.2012.226;10.1109/TVCG.2013.227;10.1109/VAST.2012.6400485;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6876013",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102456;6327271;6400557;6065010;6065008;6327270;6634152;6400485;5652922;5613451;6634134;6634160"
            }
        },
        {
            "name": "Xiaohua Sun",
            "value": 70,
            "numPapers": 8,
            "cluster": "1",
            "index": 235,
            "weight": 1,
            "x": 1079.6538877487765,
            "y": -1074.2688562741641,
            "px": 1000.7545455080757,
            "py": -936.5806590220147,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time",
                "PaperDOI": "10.1109/TVCG.2012.291",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.291",
                "Firstpage": "2649",
                "Lastpage": "2658",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, Whisper, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.",
                "AuthorNames": "Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": "37604309600;37598450200;38488930200;38489726300;37406039100;37272637300",
                "Dedupedauthornames": "Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu",
                "References": "10.1109/TVCG.2009.171;10.1109/TVCG.2006.147;10.1109/INFVIS.2000.885098;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70535;10.1109/TVCG.2010.129;10.1109/TVCG.2008.125;10.1109/TVCG.2011.188",
                "AuthorKeywords": "Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns",
                "IEEEXPLOREArticleNumberdeprecated": "6327271",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290722;4015425;885098;4015427;4376143;5613451;4658146;6065026"
            }
        },
        {
            "name": "Lazer, D.",
            "value": 70,
            "numPapers": 8,
            "cluster": "1",
            "index": 236,
            "weight": 1,
            "x": 1829.5173604249055,
            "y": -777.147846286083,
            "px": 1677.2871340772056,
            "py": -670.8636618114651,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time",
                "PaperDOI": "10.1109/TVCG.2012.291",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.291",
                "Firstpage": "2649",
                "Lastpage": "2658",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, Whisper, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.",
                "AuthorNames": "Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": "37604309600;37598450200;38488930200;38489726300;37406039100;37272637300",
                "Dedupedauthornames": "Nan Cao;Yu-Ru Lin;Xiaohua Sun;Lazer, D.;Shixia Liu;Huamin Qu",
                "References": "10.1109/TVCG.2009.171;10.1109/TVCG.2006.147;10.1109/INFVIS.2000.885098;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70535;10.1109/TVCG.2010.129;10.1109/TVCG.2008.125;10.1109/TVCG.2011.188",
                "AuthorKeywords": "Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns",
                "IEEEXPLOREArticleNumberdeprecated": "6327271",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290722;4015425;885098;4015427;4376143;5613451;4658146;6065026"
            }
        },
        {
            "name": "Xizhou Zhu",
            "value": 0,
            "numPapers": 18,
            "cluster": "1",
            "index": 237,
            "weight": 2,
            "x": 1288.1437374630166,
            "y": 807.121683710109,
            "px": 1300.9695930799392,
            "py": 802.6829296677063,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering",
                "PaperDOI": "10.1109/TVCG.2013.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.186",
                "Firstpage": "2022",
                "Lastpage": "2031",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.",
                "AuthorNames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",
                "AuthorKeywords": "Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",
                "IEEEXPLOREArticleNumberdeprecated": "6634195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532781;6400492;6400557;6327271;6327290;6400485;4389013;4389006;6102456;4658131"
            }
        },
        {
            "name": "Qinying Liao",
            "value": 0,
            "numPapers": 18,
            "cluster": "1",
            "index": 238,
            "weight": 2,
            "x": 1318.130655910814,
            "y": 920.7785625411991,
            "px": 1337.232991993862,
            "py": 927.1356577774656,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering",
                "PaperDOI": "10.1109/TVCG.2013.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.186",
                "Firstpage": "2022",
                "Lastpage": "2031",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.",
                "AuthorNames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",
                "AuthorKeywords": "Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",
                "IEEEXPLOREArticleNumberdeprecated": "6634195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532781;6400492;6400557;6327271;6327290;6400485;4389013;4389006;6102456;4658131"
            }
        },
        {
            "name": "Furu Wei",
            "value": 99,
            "numPapers": 35,
            "cluster": "1",
            "index": 239,
            "weight": 7,
            "x": 721.7732420421654,
            "y": 499.39520886320554,
            "px": 741.8140059210575,
            "py": 476.6726144564439,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering",
                "PaperDOI": "10.1109/TVCG.2013.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.186",
                "Firstpage": "2022",
                "Lastpage": "2031",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.",
                "AuthorNames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",
                "AuthorKeywords": "Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",
                "IEEEXPLOREArticleNumberdeprecated": "6634195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532781;6400492;6400557;6327271;6327290;6400485;4389013;4389006;6102456;4658131"
            }
        },
        {
            "name": "Shimei Pan",
            "value": 0,
            "numPapers": 18,
            "cluster": "1",
            "index": 240,
            "weight": 2,
            "x": 1398.784117259509,
            "y": 691.1044763902014,
            "px": 1418.6911231919535,
            "py": 681.4402364471695,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering",
                "PaperDOI": "10.1109/TVCG.2013.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.186",
                "Firstpage": "2022",
                "Lastpage": "2031",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.",
                "AuthorNames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Bosch, H.;Thom, D.;Heimerl, F.;Puttmann, E.;Koch, S.;Kruger, R.;Worner, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175",
                "AuthorKeywords": "Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification",
                "IEEEXPLOREArticleNumberdeprecated": "6634195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532781;6400492;6400557;6327271;6327290;6400485;4389013;4389006;6102456;4658131"
            }
        },
        {
            "name": "Shi, L.",
            "value": 80,
            "numPapers": 16,
            "cluster": "1",
            "index": 241,
            "weight": 4,
            "x": 847.3216295346281,
            "y": 530.3834761186082,
            "px": 851.3722076210536,
            "py": 511.33190112878884,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Understanding text corpora with multiple facets",
                "PaperDOI": "10.1109/VAST.2010.5652931",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652931",
                "Firstpage": "99",
                "Lastpage": "106",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.",
                "AuthorNames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "FirstAuthorAffiliation": "IBM Res. - China, Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37396839900;37406039100;37597343100;37604004300;37399569300",
                "Dedupedauthornames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "References": "10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389005;10.1109/TVCG.2008.172;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2009.165;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801866;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2000.885097",
                "AuthorKeywords": "text visualization, multi-facet data visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5652931",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5333443;4389005;4658133;5290722;4658136;5290726;1173155;801866;4389006;1532122;885097"
            }
        },
        {
            "name": "Li Tan",
            "value": 172,
            "numPapers": 21,
            "cluster": "1",
            "index": 242,
            "weight": 13,
            "x": 694.0447111656698,
            "y": 560.5718462751063,
            "px": 671.4490437842126,
            "py": 534.7003043892554,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Understanding text corpora with multiple facets",
                "PaperDOI": "10.1109/VAST.2010.5652931",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652931",
                "Firstpage": "99",
                "Lastpage": "106",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.",
                "AuthorNames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "FirstAuthorAffiliation": "IBM Res. - China, Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37396839900;37406039100;37597343100;37604004300;37399569300",
                "Dedupedauthornames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "References": "10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389005;10.1109/TVCG.2008.172;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2009.165;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801866;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2000.885097",
                "AuthorKeywords": "text visualization, multi-facet data visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5652931",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5333443;4389005;4658133;5290722;4658136;5290726;1173155;801866;4389006;1532122;885097"
            }
        },
        {
            "name": "Xiaoxiao Lian",
            "value": 64,
            "numPapers": 11,
            "cluster": "1",
            "index": 243,
            "weight": 4,
            "x": 717.6022959282355,
            "y": 538.3381215260515,
            "px": 694.3527024455868,
            "py": 515.1126978521186,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Understanding text corpora with multiple facets",
                "PaperDOI": "10.1109/VAST.2010.5652931",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652931",
                "Firstpage": "99",
                "Lastpage": "106",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.",
                "AuthorNames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "FirstAuthorAffiliation": "IBM Res. - China, Beijing, China|c|;;;;;",
                "AuthorIDs": "37287511900;37396839900;37406039100;37597343100;37604004300;37399569300",
                "Dedupedauthornames": "Shi, L.;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Zhou, M.X.",
                "References": "10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389005;10.1109/TVCG.2008.172;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2009.165;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801866;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2000.885097",
                "AuthorKeywords": "text visualization, multi-facet data visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5652931",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5333443;4389005;4658133;5290722;4658136;5290726;1173155;801866;4389006;1532122;885097"
            }
        },
        {
            "name": "Zhou, M.X.",
            "value": 236,
            "numPapers": 53,
            "cluster": "1",
            "index": 244,
            "weight": 10,
            "x": 765.5128680589102,
            "y": 529.364342885391,
            "px": 764.6155805756033,
            "py": 501.5224098634201,
            "node": {
                "Conference": "VAST",
                "Year": "2008",
                "PaperTitle": "Characterizing users' visual analytic activity for insight provenance",
                "PaperDOI": "10.1109/VAST.2008.4677365",
                "Link": "http://dx.doi.org/10.1109/VAST.2008.4677365",
                "Firstpage": "123",
                "Lastpage": "130",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.",
                "AuthorNames": "Gotz, D.;Zhou, M.X.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37601397400;37399569300",
                "Dedupedauthornames": "Gotz, D.;Zhou, M.X.",
                "References": "10.1109/INFVIS.2004.2;10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70577;10.1109/VISUAL.2005.1532788;10.1109/VAST.2007.4388992;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/VAST.2006.261430;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "Taxonomy, Information Visualization, Analytic Activity, Visual Analytics, Insight Provenance",
                "IEEEXPLOREArticleNumberdeprecated": "4677365",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382890;559213;4376131;1532788;4388992;1532136;729560;1382902;4035747;885092;146375;1183791"
            }
        },
        {
            "name": "Yingcai Wu",
            "value": 189,
            "numPapers": 111,
            "cluster": "1",
            "index": 245,
            "weight": 38,
            "x": 592.4430755803356,
            "y": 475.86233938502147,
            "px": 577.3120589205599,
            "py": 450.8864267232177,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "Firstpage": "1753",
                "Lastpage": "1762",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cooperation and competition (jointly called coopetition) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., topic leaders) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "References": "10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Topic coopetition, information diffusion, information propagation, time-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6875992",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6327271;4658136;6065008;6327273;6876032;6634134;6634164;6634160"
            }
        },
        {
            "name": "Tai-Quan Peng",
            "value": 68,
            "numPapers": 23,
            "cluster": "1",
            "index": 246,
            "weight": 9,
            "x": 686.511906550475,
            "y": 507.2861403794728,
            "px": 705.6625018881991,
            "py": 490.24199685693435,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "Firstpage": "1753",
                "Lastpage": "1762",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cooperation and competition (jointly called coopetition) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., topic leaders) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "References": "10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Topic coopetition, information diffusion, information propagation, time-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6875992",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6327271;4658136;6065008;6327273;6876032;6634134;6634164;6634160"
            }
        },
        {
            "name": "Zhu, J.J.H.",
            "value": 68,
            "numPapers": 23,
            "cluster": "1",
            "index": 247,
            "weight": 9,
            "x": 708.0167181461225,
            "y": 536.5414488623256,
            "px": 716.9226113706511,
            "py": 515.7000488184372,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "Firstpage": "1753",
                "Lastpage": "1762",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cooperation and competition (jointly called coopetition) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., topic leaders) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "References": "10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Topic coopetition, information diffusion, information propagation, time-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6875992",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6327271;4658136;6065008;6327273;6876032;6634134;6634164;6634160"
            }
        },
        {
            "name": "Weiwei Cui",
            "value": 256,
            "numPapers": 60,
            "cluster": "1",
            "index": 248,
            "weight": 13,
            "x": 739.0183584821123,
            "y": 519.7609902735755,
            "px": 747.0284479636668,
            "py": 497.08130820532415,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Geometry-Based Edge Clustering for Graph Visualization",
                "PaperDOI": "10.1109/TVCG.2008.135",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.135",
                "Firstpage": "1277",
                "Lastpage": "1284",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method.",
                "AuthorNames": "Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Kowloon|c|;;;;",
                "AuthorIDs": "37391623900;37405368200;37272637300;37280665600;37293190400",
                "Dedupedauthornames": "Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li",
                "References": "10.1109/TVCG.2007.70535;10.1109/TVCG.2007.70580;10.1109/INFVIS.2004.43;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2004.66;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147",
                "AuthorKeywords": "Graph visualization, visual clutter, mesh, edge clustering",
                "IEEEXPLOREArticleNumberdeprecated": "4658140",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376143;4376155;1382909;1249008;1532150;1382906;1532138;4015425"
            }
        },
        {
            "name": "Hong Zhou",
            "value": 136,
            "numPapers": 47,
            "cluster": "1",
            "index": 249,
            "weight": 4,
            "x": 1034.0271275037103,
            "y": 426.3523316182416,
            "px": 1014.9641743911993,
            "py": 406.8672599208764,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Scattering Points in Parallel Coordinates",
                "PaperDOI": "10.1109/TVCG.2009.179",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.179",
                "Firstpage": "1001",
                "Lastpage": "1008",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.",
                "AuthorNames": "Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": "37403856700;37411096400;37397293900;37405368200;37272637300",
                "Dedupedauthornames": "Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu",
                "References": "10.1109/TVCG.2008.119;10.1109/INFVIS.2005.1532139;10.1109/VISUAL.1997.663867;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1997.663916;10.1109/TVCG.2006.138;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2005.1532138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1996.567787;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.68;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153",
                "AuthorKeywords": "Parallel Coordinates, Scatterplots, Information Visualization, Multidimensional Scaling",
                "IEEEXPLOREArticleNumberdeprecated": "5290705",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658159;1532139;663867;146402;1532141;663916;4015422;663866;567800;1532138;1249015;567787;729568;1249008;1173157;809866;1249023;4015444;1382894;1382895;4658123"
            }
        },
        {
            "name": "Panpan Xu",
            "value": 80,
            "numPapers": 34,
            "cluster": "1",
            "index": 250,
            "weight": 8,
            "x": 956.911355749071,
            "y": 429.7670933193223,
            "px": 883.21784933116,
            "py": 441.9696887515332,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analysis of Topic Competition on Social Media",
                "PaperDOI": "10.1109/TVCG.2013.221",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.221",
                "Firstpage": "2012",
                "Lastpage": "2021",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",
                "AuthorNames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "References": "10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2012.225;10.1109/VAST.2009.5333437;10.1109/TVCG.2010.194;10.1109/TVCG.2012.291;10.1109/VAST.2010.5652931;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.212;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/INFVIS.1999.801851",
                "AuthorKeywords": "Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting",
                "IEEEXPLOREArticleNumberdeprecated": "6634134",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658136;6065008;6327273;6327272;5333437;5613457;6327271;5652931;6634164;963273;6327274;5652922;5613451;801851"
            }
        },
        {
            "name": "Enxun Wei",
            "value": 77,
            "numPapers": 25,
            "cluster": "1",
            "index": 251,
            "weight": 7,
            "x": 755.0038882184093,
            "y": 554.3150131113873,
            "px": 757.4651569694007,
            "py": 530.5972957554901,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analysis of Topic Competition on Social Media",
                "PaperDOI": "10.1109/TVCG.2013.221",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.221",
                "Firstpage": "2012",
                "Lastpage": "2021",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",
                "AuthorNames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Zhu, J.J.H.;Huamin Qu",
                "References": "10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2012.225;10.1109/VAST.2009.5333437;10.1109/TVCG.2010.194;10.1109/TVCG.2012.291;10.1109/VAST.2010.5652931;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.212;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/INFVIS.1999.801851",
                "AuthorKeywords": "Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting",
                "IEEEXPLOREArticleNumberdeprecated": "6634134",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658136;6065008;6327273;6327272;5333437;5613457;6327271;5652931;6634164;963273;6327274;5652922;5613451;801851"
            }
        },
        {
            "name": "Collins, C.",
            "value": 338,
            "numPapers": 64,
            "cluster": "0",
            "index": 252,
            "weight": 17,
            "x": 627.3495095188476,
            "y": 280.57320837755054,
            "px": 628.8728122106565,
            "py": 296.61139929293944,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations",
                "PaperDOI": "10.1109/TVCG.2009.122",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.122",
                "Firstpage": "1009",
                "Lastpage": "1016",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.",
                "AuthorNames": "Collins, C.;Penn, G.;Carpendale, S.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto, ON, Canada|c|;;",
                "AuthorIDs": "37669874100;37830217600;37285000100",
                "Dedupedauthornames": "Collins, C.;Penn, G.;Carpendale, S.",
                "References": "10.1109/TVCG.2006.122;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.130;10.1109/TVCG.2008.144;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.153",
                "AuthorKeywords": "clustering, spatial layout, graph visualization, tree visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5290706",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015419;1532150;4658142;4658148;1532126;4376140;4658123"
            }
        },
        {
            "name": "Maoyuan Sun",
            "value": 12,
            "numPapers": 32,
            "cluster": "0",
            "index": 253,
            "weight": 6,
            "x": 770.0887468852886,
            "y": 358.02177212836943,
            "px": 736.0326260824057,
            "py": 341.6587489564354,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "A Five-Level Design Framework for Bicluster Visualizations",
                "PaperDOI": "10.1109/TVCG.2014.2346665",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346665",
                "Firstpage": "1713",
                "Lastpage": "1722",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.",
                "AuthorNames": "Maoyuan Sun;North, C.;Ramakrishnan, N.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Maoyuan Sun;North, C.;Ramakrishnan, N.",
                "References": "10.1109/TVCG.2006.147;10.1109/TVCG.2009.153;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/VISUAL.1999.809866;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.1;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.167;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70582",
                "AuthorKeywords": "Biclusters, interactive visual analytics, coordinated relationships, design framework",
                "IEEEXPLOREArticleNumberdeprecated": "6875974",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015425;5290704;1532126;5613440;146402;6064995;4015417;5290706;809866;4035752;1382886;6102449;6634163;4015444;4376154"
            }
        },
        {
            "name": "North, C.",
            "value": 270,
            "numPapers": 88,
            "cluster": "0",
            "index": 254,
            "weight": 24,
            "x": 870.203705688245,
            "y": 156.34107167746456,
            "px": 863.45427323015,
            "py": 172.40536790142588,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "An Evaluation of Microarray Visualization Tools for Biological Insight",
                "PaperDOI": "10.1109/INFVIS.2004.5",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.5",
                "Firstpage": "1",
                "Lastpage": "8",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "High-throughput experiments such as gene expression microarrays in the life sciences result in large datasets. In response, a wide variety of visualization tools have been created to facilitate data analysis. Biologists often face a dilemma in choosing the best tool for their situation. The tool that works best for one biologist may not work well for another due to differences in the type of insight they seek from their data. A primary purpose of a visualization tool is to provide domain-relevant insight into the data. Ideally, any user wants maximum information in the least possible time. In this paper we identify several distinct characteristics of insight that enable us to recognize and quantify it. Based on this, we empirically evaluate five popular microarray visualization tools. Our conclusions can guide biologists in selecting the best tool for their data, and computer scientists in developing and evaluating visualizations",
                "AuthorNames": "Saraiya, P.;North, C.;Duca, K.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA|c|;;",
                "AuthorIDs": "37419557200;37419565900;37419559500",
                "Dedupedauthornames": "Saraiya, P.;North, C.;Duca, K.",
                "References": "10.1109/INFVIS.2001.963289",
                "AuthorKeywords": "Data visualization, empirical evaluation, insight, high throughput experiments, microarray data, bioinformatics",
                "IEEEXPLOREArticleNumberdeprecated": "1382884",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963289"
            }
        },
        {
            "name": "Ramakrishnan, N.",
            "value": 19,
            "numPapers": 37,
            "cluster": "0",
            "index": 255,
            "weight": 6,
            "x": 754.0967632683339,
            "y": 368.28620013072145,
            "px": 724.7951224797816,
            "py": 348.84865222983103,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "A Five-Level Design Framework for Bicluster Visualizations",
                "PaperDOI": "10.1109/TVCG.2014.2346665",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346665",
                "Firstpage": "1713",
                "Lastpage": "1722",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.",
                "AuthorNames": "Maoyuan Sun;North, C.;Ramakrishnan, N.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Maoyuan Sun;North, C.;Ramakrishnan, N.",
                "References": "10.1109/TVCG.2006.147;10.1109/TVCG.2009.153;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/VISUAL.1999.809866;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.1;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.167;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70582",
                "AuthorKeywords": "Biclusters, interactive visual analytics, coordinated relationships, design framework",
                "IEEEXPLOREArticleNumberdeprecated": "6875974",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015425;5290704;1532126;5613440;146402;6064995;4015417;5290706;809866;4035752;1382886;6102449;6634163;4015444;4376154"
            }
        },
        {
            "name": "Endert, A.",
            "value": 126,
            "numPapers": 52,
            "cluster": "0",
            "index": 256,
            "weight": 7,
            "x": 636.3272817483804,
            "y": 239.8205310218692,
            "px": 656.5276818027386,
            "py": 252.66818860130027,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Finding Waldo: Learning about Users from their Interactions",
                "PaperDOI": "10.1109/TVCG.2014.2346575",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346575",
                "Firstpage": "1663",
                "Lastpage": "1672",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.",
                "AuthorNames": "Brown, E.T.;Ottley, A.;Zhao, H.;Quan Lin;Souvenir, R.;Endert, A.;Chang, R.",
                "FirstAuthorAffiliation": "Tufts Univ., Medford, MA, USA|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Brown, E.T.;Ottley, A.;Zhao, H.;Quan Lin;Souvenir, R.;Endert, A.;Chang, R.",
                "References": "10.1109/TVCG.2012.204;10.1109/VAST.2010.5653587;10.1109/VAST.2009.5333020;10.1109/VAST.2012.6400486;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.276;10.1109/VAST.2006.261436;10.1109/VAST.2008.4677352",
                "AuthorKeywords": "User Interactions, Analytic Provenance, Visualization, Applied Machine Learning",
                "IEEEXPLOREArticleNumberdeprecated": "6875913",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327275;5653587;5333020;6400486;1532788;6327295;4035754;4677352"
            }
        },
        {
            "name": "Peng Mi",
            "value": 0,
            "numPapers": 17,
            "cluster": "0",
            "index": 257,
            "weight": 3,
            "x": 122.92503694352172,
            "y": 387.04455508816056,
            "px": 32.45362569162842,
            "py": 351.1809279967535,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "VisLink: Revealing Relationships Amongst Visualizations",
                "PaperDOI": "10.1109/TVCG.2007.70521",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70521",
                "Firstpage": "1192",
                "Lastpage": "1199",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.",
                "AuthorNames": "Collins, C.;Carpendale, S.",
                "FirstAuthorAffiliation": "Univ. of Toronto, Toronto|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Collins, C.;Carpendale, S.",
                "References": "10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1990.146402;10.1109/TVCG.2006.166;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2001.963279;10.1109/TVCG.2006.147",
                "AuthorKeywords": "Graph visualization, node-link diagrams, structural comparison, hierarchies, 3D visualization, edge aggregation",
                "IEEEXPLOREArticleNumberdeprecated": "4376140",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250400;146402;4015424;175815;1249008;963279;4015425"
            }
        },
        {
            "name": "Gorg, C.",
            "value": 251,
            "numPapers": 8,
            "cluster": "0",
            "index": 258,
            "weight": 9,
            "x": 835.9732321954976,
            "y": 196.72398946317796,
            "px": 783.5798751615606,
            "py": 117.02650751140597,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Jigsaw: Supporting Investigative Analysis through Interactive Visualization",
                "PaperDOI": "10.1109/VAST.2007.4389006",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389006",
                "Firstpage": "131",
                "Lastpage": "138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.",
                "AuthorNames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": "37267736900;37428446300;37592993600;37968367000",
                "Dedupedauthornames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/INFVIS.2004.27;10.1109/VAST.2006.261432",
                "AuthorKeywords": "Visual analytics, investigative analysis, intelligence analysis, information visualization, multiple views",
                "IEEEXPLOREArticleNumberdeprecated": "4389006",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;1382887;4035749"
            }
        },
        {
            "name": "Partl, C.",
            "value": 80,
            "numPapers": 28,
            "cluster": "0",
            "index": 259,
            "weight": 6,
            "x": 656.143047564867,
            "y": 245.44633258167562,
            "px": 719.4614502650152,
            "py": 223.54110015361533,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "VisBricks: Multiform Visualization of Large, Inhomogeneous Data",
                "PaperDOI": "10.1109/TVCG.2011.250",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.250",
                "Firstpage": "2291",
                "Lastpage": "2300",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.",
                "AuthorNames": "Lex, A.;Schulz, H.;Streit, M.;Partl, C.;Schmalstieg, D.",
                "FirstAuthorAffiliation": "Graz Univ. of Technol., Graz, Austria|c|;;;;",
                "AuthorIDs": "37395933400;37408482600;37403918900;37591066400;37297103800",
                "Dedupedauthornames": "Lex, A.;Schulz, H.;Streit, M.;Partl, C.;Schmalstieg, D.",
                "References": "10.1109/INFVIS.2005.1532129;10.1109/TVCG.2010.138;10.1109/TVCG.2006.120;10.1109/TVCG.2007.70582;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2006.147;10.1109/TVCG.2009.167;10.1109/TVCG.2010.216;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Inhomogeneous data, multiple coordinated views, multiform visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6064995",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532129;5613440;4015416;4376154;1249006;4015425;5290692;5613443;4015424"
            }
        },
        {
            "name": "Brown, E.T.",
            "value": 109,
            "numPapers": 15,
            "cluster": "0",
            "index": 260,
            "weight": 1,
            "x": 915.0954569528172,
            "y": 1399.2508330957062,
            "px": 857.9641986556969,
            "py": 1217.2966911623257,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Finding Waldo: Learning about Users from their Interactions",
                "PaperDOI": "10.1109/TVCG.2014.2346575",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346575",
                "Firstpage": "1663",
                "Lastpage": "1672",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.",
                "AuthorNames": "Brown, E.T.;Ottley, A.;Zhao, H.;Quan Lin;Souvenir, R.;Endert, A.;Chang, R.",
                "FirstAuthorAffiliation": "Tufts Univ., Medford, MA, USA|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Brown, E.T.;Ottley, A.;Zhao, H.;Quan Lin;Souvenir, R.;Endert, A.;Chang, R.",
                "References": "10.1109/TVCG.2012.204;10.1109/VAST.2010.5653587;10.1109/VAST.2009.5333020;10.1109/VAST.2012.6400486;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.276;10.1109/VAST.2006.261436;10.1109/VAST.2008.4677352",
                "AuthorKeywords": "User Interactions, Analytic Provenance, Visualization, Applied Machine Learning",
                "IEEEXPLOREArticleNumberdeprecated": "6875913",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327275;5653587;5333020;6400486;1532788;6327295;4035754;4677352"
            }
        },
        {
            "name": "Jingjing Liu",
            "value": 82,
            "numPapers": 7,
            "cluster": "0",
            "index": 261,
            "weight": 1,
            "x": -1061.065604912429,
            "y": 263.3131872976416,
            "px": -862.3516220322327,
            "py": 235.5106396845584,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Dis-function: Learning distance functions interactively",
                "PaperDOI": "10.1109/VAST.2012.6400486",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400486",
                "Firstpage": "83",
                "Lastpage": "92",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.",
                "AuthorNames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4388999;10.1109/VAST.2009.5332584;10.1109/VAST.2011.6102448;10.1109/VAST.2008.4677352;10.1109/VAST.2010.5652443",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "6400486",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;6102449;4388999;5332584;6102448;4677352;5652443"
            }
        },
        {
            "name": "Brodley, C.E.",
            "value": 82,
            "numPapers": 7,
            "cluster": "0",
            "index": 262,
            "weight": 1,
            "x": -22.62460235427835,
            "y": -956.0056656587224,
            "px": 46.75137226644068,
            "py": -819.7612109254552,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Dis-function: Learning distance functions interactively",
                "PaperDOI": "10.1109/VAST.2012.6400486",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400486",
                "Firstpage": "83",
                "Lastpage": "92",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.",
                "AuthorNames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Brown, E.T.;Jingjing Liu;Brodley, C.E.;Chang, R.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4388999;10.1109/VAST.2009.5332584;10.1109/VAST.2011.6102448;10.1109/VAST.2008.4677352;10.1109/VAST.2010.5652443",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "6400486",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;6102449;4388999;5332584;6102448;4677352;5652443"
            }
        },
        {
            "name": "Qi Han",
            "value": 3,
            "numPapers": 17,
            "cluster": "1",
            "index": 263,
            "weight": 1,
            "x": 794.185899679529,
            "y": 634.262733417007,
            "px": 774.488442184349,
            "py": 623.4542564035311,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "WilmaScope Graph Visualisation",
                "PaperDOI": "10.1109/INFVIS.2004.77",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.77",
                "Firstpage": "r4",
                "Lastpage": "r4",
                "PanelKeynoteCaptstoneDemoPoster": "X",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "M",
                "Abstract": "Our visualisation of the IEEE InfoVis citation network is based on 3D graph visualisation techniques. To make effective use of the third dimension we use a layered approach, constraining nodes to lie on parallel planes depending on parameters such as year of publication or link degree. Within the parallel planes nodes are arranged using a fast force-directed layout method. A number of clusters representing different research areas were identified using a self organising map approach.",
                "AuthorNames": "Ahmed, A.;Dwyer, T.;Murray, C.;Le Song;Ying Xin Wu",
                "FirstAuthorAffiliation": "University of Sydney,|c|;;;;",
                "AuthorIDs": "37288875000;37326161000;37553339300;37554043900;37293511300",
                "Dedupedauthornames": "Ahmed, A.;Dwyer, T.;Murray, C.;Le Song;Ying Xin Wu",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "1382937",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Wenwen Dou",
            "value": 217,
            "numPapers": 50,
            "cluster": "0",
            "index": 264,
            "weight": 17,
            "x": 566.7344145129177,
            "y": 193.72471208381936,
            "px": 521.6663525819397,
            "py": 240.714520272028,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Helping users recall their reasoning process",
                "PaperDOI": "10.1109/VAST.2010.5653598",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5653598",
                "Firstpage": "187",
                "Lastpage": "194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The final product of an analyst's investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.",
                "AuthorNames": "Lipford, H.R.;Stukes, F.;Wenwen Dou;Hawkins, M.E.;Chang, R.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": "37601288800;37601289000;37606064200;37601287300;37592409400",
                "Dedupedauthornames": "Lipford, H.R.;Stukes, F.;Wenwen Dou;Hawkins, M.E.;Chang, R.",
                "References": "10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/VAST.2008.4677365;10.1109/VAST.2008.4677360;10.1109/VAST.2007.4389009",
                "AuthorKeywords": "Visual analytics, visualization, reasoning process ",
                "IEEEXPLOREArticleNumberdeprecated": "5653598",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658129;4388992;4677365;4677360;4389009"
            }
        },
        {
            "name": "Xiaoyu Wang",
            "value": 171,
            "numPapers": 51,
            "cluster": "0",
            "index": 265,
            "weight": 15,
            "x": 612.1773581016288,
            "y": 333.44127098532897,
            "px": 538.6610872597012,
            "py": 376.53046824005077,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies",
                "PaperDOI": "10.1109/TVCG.2013.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.162",
                "Firstpage": "2002",
                "Lastpage": "2011",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.",
                "AuthorNames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485",
                "AuthorKeywords": "Hierarchical topic representation, topic modeling, visual analytics, rose tree",
                "IEEEXPLOREArticleNumberdeprecated": "6634160",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6400557;6065008;6102461;6400485"
            }
        },
        {
            "name": "Ribarsky, W.",
            "value": 389,
            "numPapers": 116,
            "cluster": "0",
            "index": 266,
            "weight": 41,
            "x": 730.7232400400578,
            "y": 147.68296982667724,
            "px": 650.1041181974924,
            "py": 195.79343702659222,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies",
                "PaperDOI": "10.1109/TVCG.2013.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.162",
                "Firstpage": "2002",
                "Lastpage": "2011",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.",
                "AuthorNames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485",
                "AuthorKeywords": "Hierarchical topic representation, topic modeling, visual analytics, rose tree",
                "IEEEXPLOREArticleNumberdeprecated": "6634160",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6400557;6065008;6102461;6400485"
            }
        },
        {
            "name": "Bosch, H.",
            "value": 128,
            "numPapers": 20,
            "cluster": "0",
            "index": 267,
            "weight": 3,
            "x": 208.2516742928052,
            "y": -613.0048245648624,
            "px": 145.04222107650065,
            "py": -687.7630680081693,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Visual Classifier Training for Text Document Retrieval",
                "PaperDOI": "10.1109/TVCG.2012.277",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.277",
                "Firstpage": "2839",
                "Lastpage": "2848",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.",
                "AuthorNames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;",
                "AuthorIDs": "38490630000;37593029700;37683989300;37268023800",
                "Dedupedauthornames": "Heimerl, F.;Koch, S.;Bosch, H.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492",
                "AuthorKeywords": "Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6102453;4389006;6400492"
            }
        },
        {
            "name": "Kehrer, J.",
            "value": 71,
            "numPapers": 32,
            "cluster": "2",
            "index": 268,
            "weight": 3,
            "x": -493.35666749437223,
            "y": 437.6385144801697,
            "px": -597.2082804287492,
            "py": 473.4006744593099,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees",
                "PaperDOI": "10.1109/TVCG.2014.2346626",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346626",
                "Firstpage": "1693",
                "Lastpage": "1702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.",
                "AuthorNames": "Beham, M.;Herzner, W.;Groller, M.E.;Kehrer, J.",
                "FirstAuthorAffiliation": "Austrian Inst. of Technol., Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Beham, M.;Herzner, W.;Groller, E.;Kehrer, J.",
                "References": "10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581",
                "AuthorKeywords": "Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6875958",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634138;6634107;5613440;5290748;1532856;5613488;4015425;398859;809866;4376186"
            }
        },
        {
            "name": "Jaegul Choo",
            "value": 106,
            "numPapers": 46,
            "cluster": "1",
            "index": 269,
            "weight": 3,
            "x": 1139.5734889369423,
            "y": 568.9172011111626,
            "px": 1098.560541449835,
            "py": 750.4720791884745,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization",
                "PaperDOI": "10.1109/TVCG.2013.212",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.212",
                "Firstpage": "1992",
                "Lastpage": "2001",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.",
                "AuthorNames": "Jaegul Choo;Changhyun Lee;Reddy, C.K.;Park, H.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Jaegul Choo;Changhyun Lee;Reddy, C.K.;Haesun Park",
                "References": "10.1109/TVCG.2012.258;10.1109/VAST.2009.5332629;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4389006;10.1109/TVCG.2008.138;10.1109/VAST.2010.5652443",
                "AuthorKeywords": "Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics\n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6634167",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327289;5332629;6065008;6102461;6400485;4388999;4389006;4658134;5652443"
            }
        },
        {
            "name": "Haesun Park",
            "value": 106,
            "numPapers": 26,
            "cluster": "1",
            "index": 270,
            "weight": 2,
            "x": 666.2716118955394,
            "y": -348.07851303389833,
            "px": 437.2755178603532,
            "py": -271.4817480966811,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization",
                "PaperDOI": "10.1109/TVCG.2013.212",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.212",
                "Firstpage": "1992",
                "Lastpage": "2001",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.",
                "AuthorNames": "Jaegul Choo;Changhyun Lee;Reddy, C.K.;Park, H.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Jaegul Choo;Changhyun Lee;Reddy, C.K.;Haesun Park",
                "References": "10.1109/TVCG.2012.258;10.1109/VAST.2009.5332629;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4389006;10.1109/TVCG.2008.138;10.1109/VAST.2010.5652443",
                "AuthorKeywords": "Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics\n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6634167",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327289;5332629;6065008;6102461;6400485;4388999;4389006;4658134;5652443"
            }
        },
        {
            "name": "Yafeng Lu",
            "value": 0,
            "numPapers": 27,
            "cluster": "5",
            "index": 271,
            "weight": 2,
            "x": 280.1932489340228,
            "y": 458.9106917210036,
            "px": 349.62897235217287,
            "py": 424.488568543985,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analytics for Model Selection in Time Series Analysis",
                "PaperDOI": "10.1109/TVCG.2013.222",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.222",
                "Firstpage": "2237",
                "Lastpage": "2246",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.",
                "AuthorNames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "References": "10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views",
                "IEEEXPLOREArticleNumberdeprecated": "6634112",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634096;6327248;4376146"
            }
        },
        {
            "name": "Yun Jang",
            "value": 152,
            "numPapers": 65,
            "cluster": "5",
            "index": 272,
            "weight": 7,
            "x": 713.582455939008,
            "y": 420.71078281888776,
            "px": 696.0989020807145,
            "py": 437.3694711258918,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition",
                "PaperDOI": "10.1109/VAST.2012.6400557",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400557",
                "Firstpage": "143",
                "Lastpage": "152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.",
                "AuthorNames": "Junghoon Chae;Thom, D.;Bosch, H.;Yun Jang;Maciejewski, R.;Ebert, D.S.;Ertl, T.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Junghoon Chae;Thom, D.;Bosch, H.;Yun Jang;Maciejewski, R.;Ebert, D.S.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102456;10.1109/VAST.2011.6102461;10.1109/TVCG.2008.175",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "6400557",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102456;6102461;4658131"
            }
        },
        {
            "name": "Ebert, D.S.",
            "value": 607,
            "numPapers": 168,
            "cluster": "2",
            "index": 273,
            "weight": 42,
            "x": 326.9856024754827,
            "y": 227.88979319326674,
            "px": 332.5158248780201,
            "py": 216.58292385672829,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition",
                "PaperDOI": "10.1109/VAST.2012.6400557",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400557",
                "Firstpage": "143",
                "Lastpage": "152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.",
                "AuthorNames": "Junghoon Chae;Thom, D.;Bosch, H.;Yun Jang;Maciejewski, R.;Ebert, D.S.;Ertl, T.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Junghoon Chae;Thom, D.;Bosch, H.;Yun Jang;Maciejewski, R.;Ebert, D.S.;Ertl, T.",
                "References": "10.1109/VAST.2011.6102456;10.1109/VAST.2011.6102461;10.1109/TVCG.2008.175",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "6400557",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102456;6102461;4658131"
            }
        },
        {
            "name": "Maciejewski, R.",
            "value": 196,
            "numPapers": 89,
            "cluster": "0",
            "index": 274,
            "weight": 13,
            "x": 561.4690351870249,
            "y": 365.4716764320174,
            "px": 540.1042498965671,
            "py": 409.01337596539264,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analytics for Model Selection in Time Series Analysis",
                "PaperDOI": "10.1109/TVCG.2013.222",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.222",
                "Firstpage": "2237",
                "Lastpage": "2246",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.",
                "AuthorNames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "References": "10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views",
                "IEEEXPLOREArticleNumberdeprecated": "6634112",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634096;6327248;4376146"
            }
        },
        {
            "name": "Van Selow, E.R.",
            "value": 121,
            "numPapers": 0,
            "cluster": "0",
            "index": 275,
            "weight": 3,
            "x": 278.71852296319753,
            "y": 431.8162944117539,
            "px": 334.64063659746085,
            "py": 358.52911630194313,
            "node": {
                "Conference": "InfoVis",
                "Year": "1999",
                "PaperTitle": "Cluster and calendar based visualization of time series data",
                "PaperDOI": "10.1109/INFVIS.1999.801851",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1999.801851",
                "Firstpage": "4",
                "Lastpage": "9, 140",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new method is presented to get an insight into univariate time series data. The problem addressed is how to identify patterns and trends on multiple time scales (days, weeks, seasons) simultaneously. The solution presented is to cluster similar daily data patterns, and to visualize the average patterns as graphs and the corresponding days on a calendar. This presentation provides a quick insight into both standard and exceptional patterns. Furthermore, it is well suited to interactive exploration. Two applications, numbers of employees present and energy consumption, are presented",
                "AuthorNames": "van Wijk, J.J.;Van Selow, E.R.",
                "FirstAuthorAffiliation": "Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;",
                "AuthorIDs": "37267249200;37444386900",
                "Dedupedauthornames": "van Wijk, J.J.;Van Selow, E.R.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "801851",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Robinson, A.",
            "value": 90,
            "numPapers": 11,
            "cluster": "0",
            "index": 276,
            "weight": 2,
            "x": 1307.6639745940527,
            "y": -908.4118420273026,
            "px": 1283.228998472618,
            "py": -963.7223062688273,
            "node": {
                "Conference": "VAST",
                "Year": "2008",
                "PaperTitle": "Collaborative synthesis of visual analytic results",
                "PaperDOI": "10.1109/VAST.2008.4677358",
                "Link": "http://dx.doi.org/10.1109/VAST.2008.4677358",
                "Firstpage": "67",
                "Lastpage": "74",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.",
                "AuthorNames": "Robinson, A.C.",
                "FirstAuthorAffiliation": "Dept. of Geogr., Pennsylvania State Univ., State College, PA|c|",
                "AuthorIDs": "37829187900",
                "Dedupedauthornames": "Robinson, A.",
                "References": "10.1109/VAST.2007.4389011;10.1109/TVCG.2007.70594;10.1109/TVCG.2007.70568",
                "AuthorKeywords": "Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization",
                "IEEEXPLOREArticleNumberdeprecated": "4677358",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4389011;4376133;4376145"
            }
        },
        {
            "name": "Byron, L.",
            "value": 82,
            "numPapers": 4,
            "cluster": "1",
            "index": 277,
            "weight": 2,
            "x": -152.43783077810386,
            "y": 617.5788210294292,
            "px": -250.02631717310712,
            "py": 606.3740372605804,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Stacked Graphs - Geometry & Aesthetics",
                "PaperDOI": "10.1109/TVCG.2008.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.166",
                "Firstpage": "1245",
                "Lastpage": "1252",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.",
                "AuthorNames": "Byron, L.;Wattenberg, M.",
                "FirstAuthorAffiliation": "New York Times, New York, NY|c|;",
                "AuthorIDs": "37868017200;37550759700",
                "Dedupedauthornames": "Byron, L.;Wattenberg, M.",
                "References": "10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70577;10.1109/INFVIS.2000.885098",
                "AuthorKeywords": "Streamgraph, ThemeRiver, listening history, lastfm, aesthetics, communication-minded visualization, time series",
                "IEEEXPLOREArticleNumberdeprecated": "4658136",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015420;1532122;4376131;885098"
            }
        },
        {
            "name": "Havre, S.",
            "value": 128,
            "numPapers": 7,
            "cluster": "0",
            "index": 278,
            "weight": 2,
            "x": 1411.555231798058,
            "y": -176.09057887420036,
            "px": 1329.529875524372,
            "py": -142.47549254228883,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "Firstpage": "115",
                "Lastpage": "123",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The river flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored currents flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636789;10.1109/INFVIS.1998.729570",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885098",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;636789;729555"
            }
        },
        {
            "name": "Hetzler, E.",
            "value": 203,
            "numPapers": 20,
            "cluster": "5",
            "index": 279,
            "weight": 3,
            "x": 1565.4307581714932,
            "y": -441.59059975352994,
            "px": 1483.3893351776169,
            "py": -367.74587965856426,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "Firstpage": "115",
                "Lastpage": "123",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The river flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored currents flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636789;10.1109/INFVIS.1998.729570",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885098",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;636789;729555"
            }
        },
        {
            "name": "Nowell, L.",
            "value": 132,
            "numPapers": 8,
            "cluster": "0",
            "index": 280,
            "weight": 2,
            "x": 1213.3585327232672,
            "y": -712.1297333987375,
            "px": 1153.4569872921504,
            "py": -640.1796878298999,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "ThemeRiver: visualizing theme changes over time",
                "PaperDOI": "10.1109/INFVIS.2000.885098",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885098",
                "Firstpage": "115",
                "Lastpage": "123",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "ThemeRiverTM is a prototype system that visualizes thematic variations over time within a large collection of documents. The river flows from left to right through time, changing width to depict changes in thematic strength of temporally associated documents. Colored currents flowing within the river narrow or widen to indicate decreases or increases in the strength of an individual topic or a group of topics in the associated documents. The river is shown within the context of a timeline and a corresponding textual presentation of external events",
                "AuthorNames": "Havre, S.;Hetzler, B.;Nowell, L.",
                "FirstAuthorAffiliation": "Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;",
                "AuthorIDs": "37282588900;37374614800;37725426400",
                "Dedupedauthornames": "Havre, S.;Hetzler, E.;Nowell, L.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636789;10.1109/INFVIS.1998.729570",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885098",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;636789;729555"
            }
        },
        {
            "name": "Jing Yang",
            "value": 280,
            "numPapers": 96,
            "cluster": "5",
            "index": 281,
            "weight": 28,
            "x": 969.4751860968604,
            "y": 150.81626187400292,
            "px": 956.3229247180192,
            "py": 186.68755284581084,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Measuring Data Abstraction Quality in Multiresolution Visualizations",
                "PaperDOI": "10.1109/TVCG.2006.161",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.161",
                "Firstpage": "709",
                "Lastpage": "716",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",
                "AuthorNames": "Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Yang, J.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA|c|;;;",
                "AuthorIDs": "37841616400;37268441700;37279217900;37292632600",
                "Dedupedauthornames": "Cui, Q.;Ward, M.O.;Rundensteiner, E.A.;Jing Yang",
                "References": "10.1109/INFVIS.2004.19;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2004.15;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2000.885088",
                "AuthorKeywords": "Metrics, Clustering, Sampling, Multiresolution Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015421",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382900;1532819;1382895;485139;885088"
            }
        },
        {
            "name": "Weber, M.",
            "value": 71,
            "numPapers": 3,
            "cluster": "1",
            "index": 282,
            "weight": 1,
            "x": 1262.0796298077576,
            "y": -517.9217225035115,
            "px": 1171.572434910021,
            "py": -414.71040107778686,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "Visualizing time-series on spirals",
                "PaperDOI": "10.1109/INFVIS.2001.963273",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963273",
                "Firstpage": "7",
                "Lastpage": "13",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identication of periodic patterns.",
                "AuthorNames": "Weber, M.;Alexa, M.;Muller, W.",
                "FirstAuthorAffiliation": "Technische Universitat Darmstadt|c|;;",
                "AuthorIDs": "37734022800;37267466700;38184260700",
                "Dedupedauthornames": "Weber, M.;Alexa, M.;Muller, W.",
                "References": "10.1109/VISUAL.1991.175794;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1995.528685",
                "AuthorKeywords": "Information Visualization, Graph Drawing, Visualization of Time-Series Data, Data Mining ",
                "IEEEXPLOREArticleNumberdeprecated": "963273",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175794;885098;528685"
            }
        },
        {
            "name": "Alexa, M.",
            "value": 99,
            "numPapers": 5,
            "cluster": "1",
            "index": 283,
            "weight": 1,
            "x": 178.6617839441615,
            "y": -345.81056546718196,
            "px": 207.29900665096142,
            "py": -254.1321256016667,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "Visualizing time-series on spirals",
                "PaperDOI": "10.1109/INFVIS.2001.963273",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963273",
                "Firstpage": "7",
                "Lastpage": "13",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identication of periodic patterns.",
                "AuthorNames": "Weber, M.;Alexa, M.;Muller, W.",
                "FirstAuthorAffiliation": "Technische Universitat Darmstadt|c|;;",
                "AuthorIDs": "37734022800;37267466700;38184260700",
                "Dedupedauthornames": "Weber, M.;Alexa, M.;Muller, W.",
                "References": "10.1109/VISUAL.1991.175794;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1995.528685",
                "AuthorKeywords": "Information Visualization, Graph Drawing, Visualization of Time-Series Data, Data Mining ",
                "IEEEXPLOREArticleNumberdeprecated": "963273",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175794;885098;528685"
            }
        },
        {
            "name": "Muller, W.",
            "value": 71,
            "numPapers": 3,
            "cluster": "1",
            "index": 284,
            "weight": 1,
            "x": -487.8711117724009,
            "y": -493.2613318061888,
            "px": -393.8137406337485,
            "py": -398.18622812913264,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "Visualizing time-series on spirals",
                "PaperDOI": "10.1109/INFVIS.2001.963273",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963273",
                "Firstpage": "7",
                "Lastpage": "13",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a new approach for the visualization of time-series data based on spirals. Different to classical bar charts and line graphs, the spiral is suited to visualize large data sets and supports much better the identification of periodic structures in the data. Moreover, it supports both the visualization of nominal and quantitative data based on a similar visualization metaphor. The extension of the spiral visualization to 3D gives access to concepts for zooming and focusing and linking in the data set. As such, spirals complement other visualization techniques for time series and specifically enhance the identication of periodic patterns.",
                "AuthorNames": "Weber, M.;Alexa, M.;Muller, W.",
                "FirstAuthorAffiliation": "Technische Universitat Darmstadt|c|;;",
                "AuthorIDs": "37734022800;37267466700;38184260700",
                "Dedupedauthornames": "Weber, M.;Alexa, M.;Muller, W.",
                "References": "10.1109/VISUAL.1991.175794;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1995.528685",
                "AuthorKeywords": "Information Visualization, Graph Drawing, Visualization of Time-Series Data, Data Mining ",
                "IEEEXPLOREArticleNumberdeprecated": "963273",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175794;885098;528685"
            }
        },
        {
            "name": "Song Zhang",
            "value": 121,
            "numPapers": 24,
            "cluster": "2",
            "index": 285,
            "weight": 1,
            "x": 468.47879417363464,
            "y": 1752.368001849346,
            "px": 416.7398145498834,
            "py": 1581.455399252896,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets",
                "PaperDOI": "10.1109/TVCG.2009.114",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.114",
                "Firstpage": "1209",
                "Lastpage": "1218",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig- - n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.",
                "AuthorNames": "Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.",
                "FirstAuthorAffiliation": "Geosystems Res. Inst., Mississippi State Univ., Starkville, MS, USA|c|;;;;",
                "AuthorIDs": "37567906800;37277708500;38100000900;37411386700;37282559500",
                "Dedupedauthornames": "Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.",
                "References": "10.1109/TVCG.2007.70518;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2000.885679;10.1109/INFVIS.2002.1173145;10.1109/INFVIS.2004.59;10.1109/TVCG.2007.70530",
                "AuthorKeywords": "User study, uncertainty visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5290731",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376198;568105;885679;1173145;1382903;4376197"
            }
        },
        {
            "name": "Moorhead, R.J.",
            "value": 186,
            "numPapers": 25,
            "cluster": "2",
            "index": 286,
            "weight": 3,
            "x": -1058.1909906639276,
            "y": 1209.0785704600542,
            "px": -1079.0450063460003,
            "py": 1171.1287374323613,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets",
                "PaperDOI": "10.1109/TVCG.2009.114",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.114",
                "Firstpage": "1209",
                "Lastpage": "1218",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig- - n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.",
                "AuthorNames": "Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.",
                "FirstAuthorAffiliation": "Geosystems Res. Inst., Mississippi State Univ., Starkville, MS, USA|c|;;;;",
                "AuthorIDs": "37567906800;37277708500;38100000900;37411386700;37282559500",
                "Dedupedauthornames": "Sanyal, J.;Song Zhang;Bhattacharya, G.;Amburn, P.;Moorhead, R.J.",
                "References": "10.1109/TVCG.2007.70518;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2000.885679;10.1109/INFVIS.2002.1173145;10.1109/INFVIS.2004.59;10.1109/TVCG.2007.70530",
                "AuthorKeywords": "User study, uncertainty visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5290731",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376198;568105;885679;1173145;1382903;4376197"
            }
        },
        {
            "name": "Rinzivillo, S.",
            "value": 67,
            "numPapers": 4,
            "cluster": "5",
            "index": 287,
            "weight": 2,
            "x": 1322.5469287775827,
            "y": 315.5390894550043,
            "px": 1289.2281905680936,
            "py": 309.85350881748275,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Interactive visual clustering of large collections of trajectories",
                "PaperDOI": "10.1109/VAST.2009.5332584",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332584",
                "Firstpage": "3",
                "Lastpage": "10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;;",
                "AuthorIDs": "37283047100;37283047700;37670571400;37669195900;37394413600;37268539100",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.",
                "References": "10.1109/VAST.2008.4677356;10.1109/VAST.2007.4388999",
                "AuthorKeywords": "Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization",
                "IEEEXPLOREArticleNumberdeprecated": "5332584",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4677356;4388999"
            }
        },
        {
            "name": "Zuchao Wang",
            "value": 92,
            "numPapers": 56,
            "cluster": "5",
            "index": 288,
            "weight": 7,
            "x": 1000.8517152329614,
            "y": 280.67103243977664,
            "px": 1017.3373042610075,
            "py": 288.5229505023573,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "Firstpage": "2159",
                "Lastpage": "2168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.",
                "References": "10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455",
                "AuthorKeywords": "Traffic visualization, traffic jam propagation",
                "IEEEXPLOREArticleNumberdeprecated": "6634174",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Jiawan Zhang",
            "value": 8,
            "numPapers": 31,
            "cluster": "5",
            "index": 289,
            "weight": 3,
            "x": 1236.032496022423,
            "y": 212.94826411267442,
            "px": 1249.5648358995697,
            "py": 209.4833613613255,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Interactive visual clustering of large collections of trajectories",
                "PaperDOI": "10.1109/VAST.2009.5332584",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332584",
                "Firstpage": "3",
                "Lastpage": "10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;;",
                "AuthorIDs": "37283047100;37283047700;37670571400;37669195900;37394413600;37268539100",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.",
                "References": "10.1109/VAST.2008.4677356;10.1109/VAST.2007.4388999",
                "AuthorKeywords": "Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization",
                "IEEEXPLOREArticleNumberdeprecated": "5332584",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4677356;4388999"
            }
        },
        {
            "name": "Splechtna, R.",
            "value": 5,
            "numPapers": 10,
            "cluster": "5",
            "index": 290,
            "weight": 4,
            "x": 499.4410969488515,
            "y": -500.3289045951491,
            "px": 359.54581981706735,
            "py": -531.3737032204905,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System",
                "PaperDOI": "10.1109/TVCG.2008.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.145",
                "Firstpage": "1699",
                "Lastpage": "1706",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.",
                "AuthorNames": "Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna|c|;;;",
                "AuthorIDs": "38188281400;37272650400;38188282900;37274158800",
                "Dedupedauthornames": "Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.",
                "References": "10.1109/INFVIS.2004.12;10.1109/VISUAL.1998.745289;10.1109/VISUAL.2005.1532821;10.1109/INFVIS.2005.1532143;10.1109/VISUAL.2003.1250417;10.1109/VISUAL.2005.1532850",
                "AuthorKeywords": "Interactive computational steering, interactive visual analysis, simulation, common rail injection system",
                "IEEEXPLOREArticleNumberdeprecated": "4658193",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382904;745289;1532821;1532143;1250417;1532850"
            }
        },
        {
            "name": "Matkovic, K.",
            "value": 192,
            "numPapers": 49,
            "cluster": "5",
            "index": 291,
            "weight": 12,
            "x": 709.2762621475629,
            "y": -88.30603624871631,
            "px": 697.6345037723431,
            "py": -95.08034257255478,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Interactive Visual Analysis of Set-Typed Data",
                "PaperDOI": "10.1109/TVCG.2008.144",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.144",
                "Firstpage": "1340",
                "Lastpage": "1347",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.",
                "AuthorNames": "Freiler, W.;Matkovic, K.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna|c|;;",
                "AuthorIDs": "38017008700;38220979200;37274158800",
                "Dedupedauthornames": "Freiler, W.;Matkovic, K.;Hauser, H.",
                "References": "10.1109/INFVIS.1999.801860;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2001.963288;10.1109/INFVIS.2003.1249016;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532139;10.1109/VISUAL.1991.175815",
                "AuthorKeywords": "Interactive Visual Analysis, Multidimensional Multivariate Data Visualization, Categorical Data Visualization, Interactive Visualization, Focus+Context Visualization, Multiple Coordinated Views",
                "IEEEXPLOREArticleNumberdeprecated": "4658148",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801860;146402;963288;1249016;4389006;1532139;175815"
            }
        },
        {
            "name": "Gracanin, D.",
            "value": 131,
            "numPapers": 27,
            "cluster": "5",
            "index": 292,
            "weight": 9,
            "x": 564.5240025872882,
            "y": -419.8940414811597,
            "px": 604.3038606971467,
            "py": -303.9037132194915,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces",
                "PaperDOI": "10.1109/TVCG.2009.155",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.155",
                "Firstpage": "1351",
                "Lastpage": "1358",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.",
                "AuthorNames": "Matkovic, K.;Gracanin, D.;Klarin, B.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;",
                "AuthorIDs": "38220979200;37272650400;38246833000;37274158800",
                "Dedupedauthornames": "Matkovic, K.;Gracanin, D.;Klarin, B.;Hauser, H.",
                "References": "10.1109/VISUAL.1997.663867;10.1109/TVCG.2008.145;10.1109/INFVIS.2001.963273;10.1109/TVCG.2006.170",
                "AuthorKeywords": "Interactive visual analysis, family of surfaces, coordinated multiple views, multidimensional multivariate data",
                "IEEEXPLOREArticleNumberdeprecated": "5290748",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663867;4658193;963273;4015444"
            }
        },
        {
            "name": "Jelovic, M.",
            "value": 101,
            "numPapers": 23,
            "cluster": "5",
            "index": 293,
            "weight": 7,
            "x": 861.4654331375306,
            "y": -269.3171858573723,
            "px": 801.6174948463171,
            "py": -207.62480243167886,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System",
                "PaperDOI": "10.1109/TVCG.2008.145",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.145",
                "Firstpage": "1699",
                "Lastpage": "1706",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.",
                "AuthorNames": "Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna|c|;;;",
                "AuthorIDs": "38188281400;37272650400;38188282900;37274158800",
                "Dedupedauthornames": "Matkovic, K.;Gracanin, D.;Jelovic, M.;Hauser, H.",
                "References": "10.1109/INFVIS.2004.12;10.1109/VISUAL.1998.745289;10.1109/VISUAL.2005.1532821;10.1109/INFVIS.2005.1532143;10.1109/VISUAL.2003.1250417;10.1109/VISUAL.2005.1532850",
                "AuthorKeywords": "Interactive computational steering, interactive visual analysis, simulation, common rail injection system",
                "IEEEXPLOREArticleNumberdeprecated": "4658193",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382904;745289;1532821;1532143;1250417;1532850"
            }
        },
        {
            "name": "Waser, J.",
            "value": 166,
            "numPapers": 39,
            "cluster": "4",
            "index": 294,
            "weight": 14,
            "x": 1065.7844266360173,
            "y": 203.78078318038308,
            "px": 956.456190100004,
            "py": 308.7882205329999,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "Firstpage": "1458",
                "Lastpage": "1467",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "References": "10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289",
                "AuthorKeywords": "Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics",
                "IEEEXPLOREArticleNumberdeprecated": "5613487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Fuchs, R.",
            "value": 162,
            "numPapers": 35,
            "cluster": "4",
            "index": 295,
            "weight": 11,
            "x": 838.865681262549,
            "y": 334.45225608627067,
            "px": 747.1409679778711,
            "py": 287.67188639228954,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "Firstpage": "1458",
                "Lastpage": "1467",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "References": "10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289",
                "AuthorKeywords": "Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics",
                "IEEEXPLOREArticleNumberdeprecated": "5613487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Piringer, H.",
            "value": 155,
            "numPapers": 112,
            "cluster": "0",
            "index": 296,
            "weight": 16,
            "x": 613.3504657776434,
            "y": 300.41108329021597,
            "px": 611.9961875299904,
            "py": 239.53343585429772,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations",
                "PaperDOI": "10.1109/TVCG.2014.2346578",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346578",
                "Firstpage": "1643",
                "Lastpage": "1652",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.",
                "AuthorNames": "Muhlbacher, T.;Piringer, H.;Gratzl, S.;Sedlmair, M.;Streit, M.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Muhlbacher, T.;Piringer, H.;Gratzl, S.;Sedlmair, M.;Streit, M.",
                "References": "10.1109/VAST.2012.6400486;10.1109/VAST.2007.4388999;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.151;10.1109/TVCG.2014.2346321;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.171;10.1109/TVCG.2013.212;10.1109/TVCG.2013.125;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.110;10.1109/INFVIS.2004.60;10.1109/VAST.2011.6102453;10.1109/TVCG.2012.195;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.229",
                "AuthorKeywords": "Visual analytics infrastructures, integration, interactive algorithms, user involvement, problem subdivision",
                "IEEEXPLOREArticleNumberdeprecated": "6875995",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6400486;4388999;6102449;4376144;5290697;6876043;4677350;4015496;6634167;6634169;1173145;5290719;1382891;6102453;6327292;1249014;6064985"
            }
        },
        {
            "name": "Heinzl, C.",
            "value": 74,
            "numPapers": 50,
            "cluster": "2",
            "index": 297,
            "weight": 5,
            "x": 362.142420476243,
            "y": 161.09076866595095,
            "px": 320.25911476785075,
            "py": 344.38570728675563,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Visual Parameter Space Analysis: A Conceptual Framework",
                "PaperDOI": "10.1109/TVCG.2014.2346321",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346321",
                "Firstpage": "2161",
                "Lastpage": "2170",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.",
                "AuthorNames": "Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.",
                "FirstAuthorAffiliation": "Univ. of Vienna, Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Sedlmair, M.;Heinzl, C.;Bruckner, S.;Piringer, H.;Moller, T.",
                "References": "10.1109/INFVIS.1995.528680;10.1109/TVCG.2010.177;10.1109/TVCG.2008.145;10.1109/TVCG.2012.219;10.1109/TVCG.2009.155;10.1109/TVCG.2010.223;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2010.190;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1993.398859;10.1109/VAST.2009.5333431;10.1109/TVCG.2007.70581;10.1109/TVCG.2013.142;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.130;10.1109/TVCG.2013.147;10.1109/TVCG.2013.124;10.1109/TVCG.2012.190;10.1109/TVCG.2009.111;10.1109/TVCG.2011.229;10.1109/TVCG.2013.157;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102450;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.126;10.1109/TVCG.2011.248;10.1109/TVCG.2010.214;10.1109/TVCG.2009.170;10.1109/VAST.2011.6102457;10.1109/TVCG.2013.120;10.1109/TVCG.2011.253",
                "AuthorKeywords": "Parameter space analysis, input-output model, simulation, task characterization, literature analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6876043",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528680;5613437;4658193;6327298;5290748;5613487;6327293;6327248;5613488;1532136;398859;5333431;4376186;6634132;5652392;1532142;6634181;6634138;6634168;6327226;5290695;6064985;6634124;6634169;6102450;1532788;6634108;6064952;5613489;5290759;6102457;6634156;6065007"
            }
        },
        {
            "name": "von Landesberger, T.",
            "value": 74,
            "numPapers": 38,
            "cluster": "5",
            "index": 298,
            "weight": 1,
            "x": 1260.7299620349188,
            "y": 1833.4824174683345,
            "px": 1049.3269959917366,
            "py": 1348.8680931108531,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Flow Map Layout via Spiral Trees",
                "PaperDOI": "10.1109/TVCG.2011.202",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.202",
                "Firstpage": "2536",
                "Lastpage": "2544",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.",
                "AuthorNames": "Buchin, K.;Speckmann, B.;Verbeek, K.",
                "FirstAuthorAffiliation": "Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;",
                "AuthorIDs": "37402703700;37591266000;37591265900",
                "Dedupedauthornames": "Buchin, K.;Speckmann, B.;Verbeek, K.",
                "References": "10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.1996.559226;10.1109/TVCG.2006.147",
                "AuthorKeywords": "Flow maps, Automated Cartography, Spiral Trees",
                "IEEEXPLOREArticleNumberdeprecated": "6065021",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290710;4658140;1532150;559226;4015425"
            }
        },
        {
            "name": "Gotz, D.",
            "value": 271,
            "numPapers": 80,
            "cluster": "0",
            "index": 299,
            "weight": 13,
            "x": 915.3597324401657,
            "y": 328.9832933088525,
            "px": 978.221257972261,
            "py": 344.4927320235248,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data",
                "PaperDOI": "10.1109/TVCG.2014.2346682",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346682",
                "Firstpage": "1783",
                "Lastpage": "1792",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.",
                "AuthorNames": "Gotz, D.;Stavropoulos, H.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Gotz, D.;Stavropoulos, H.",
                "References": "10.1109/TVCG.2013.206;10.1109/TVCG.2012.225;10.1109/TVCG.2011.179;10.1109/INFVIS.2000.885097;10.1109/VAST.2009.5332595;10.1109/VAST.2010.5652890;10.1109/TVCG.2009.117;10.1109/VAST.2006.261421;10.1109/TVCG.2013.200",
                "AuthorKeywords": "Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics",
                "IEEEXPLOREArticleNumberdeprecated": "6875996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634096;6327272;6065010;885097;5332595;5652890;5290698;4035762;6634100"
            }
        },
        {
            "name": "Chevalier, F.",
            "value": 50,
            "numPapers": 39,
            "cluster": "0",
            "index": 300,
            "weight": 2,
            "x": 1272.287684912572,
            "y": 94.69161247622556,
            "px": 1287.1923220414142,
            "py": 88.74535946637059,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Exploratory Analysis of Time-Series with ChronoLenses",
                "PaperDOI": "10.1109/TVCG.2011.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.195",
                "Firstpage": "2422",
                "Lastpage": "2431",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.",
                "AuthorNames": "Jian Zhao;Chevalier, F.;Pietriga, E.;Balakrishnan, R.",
                "FirstAuthorAffiliation": "DGP, Univ. of Toronto, Toronto, ON, Canada|c|;;;",
                "AuthorIDs": "38024987300;37395495900;37563810700;37394495600",
                "Dedupedauthornames": "Jian Zhao;Chevalier, F.;Pietriga, E.;Balakrishnan, R.",
                "References": "10.1109/TVCG.2010.162;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389007;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2007.70583;10.1109/TVCG.2010.193",
                "AuthorKeywords": "Time-series Data, Exploratory Visualization, Focus+Context, Lens, Interaction Techniques",
                "IEEEXPLOREArticleNumberdeprecated": "6065009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613429;801851;4389007;963273;1532148;4376151;5613426"
            }
        },
        {
            "name": "Blaas, J.",
            "value": 82,
            "numPapers": 23,
            "cluster": "3",
            "index": 301,
            "weight": 1,
            "x": -834.3047010330372,
            "y": -384.22992093761945,
            "px": -750.2868526160503,
            "py": -287.72349815085823,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Smooth Graphs for Visual Exploration of Higher-Order State Transitions",
                "PaperDOI": "10.1109/TVCG.2009.181",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.181",
                "Firstpage": "969",
                "Lastpage": "976",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.",
                "AuthorNames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.",
                "FirstAuthorAffiliation": "Visualization Group, Delft Univ. of Technol., Delft, Netherlands|c|;;;;;",
                "AuthorIDs": "37550793100;37373834100;38110391600;37335785800;37267247900;37295045800",
                "Dedupedauthornames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.W.;Laramee, R.S.;Post, F.H.",
                "References": "10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.155;10.1109/TVCG.2008.135;10.1109/TVCG.2006.192;10.1109/INFVIS.2001.963281;10.1109/INFVIS.2001.963281;10.1109/TVCG.2006.147",
                "AuthorKeywords": "State transitions, Graph drawing, Time series, Biological data",
                "IEEEXPLOREArticleNumberdeprecated": "5290701",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528685;4658147;4658140;4015418;963281;963281;4015425"
            }
        },
        {
            "name": "Nguyen, P.H.",
            "value": 24,
            "numPapers": 34,
            "cluster": "0",
            "index": 302,
            "weight": 1,
            "x": 0.49269165414530747,
            "y": -1075.8409288315709,
            "px": 52.84228605566572,
            "py": -939.2844125286304,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "A User Study on Curved Edges in Graph Visualization",
                "PaperDOI": "10.1109/TVCG.2012.189",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.189",
                "Firstpage": "2449",
                "Lastpage": "2456",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.",
                "AuthorNames": "Kai Xu;Rooney, C.;Passmore, P.;Dong-Han Ham;Nguyen, P.H.",
                "FirstAuthorAffiliation": "Middlesex Univ., London, UK|c|;;;;",
                "AuthorIDs": "38489059400;38488869200;38180787500;38489463400;38490354300",
                "Dedupedauthornames": "Kai Xu;Rooney, C.;Passmore, P.;Dong-Han Ham;Nguyen, P.H.",
                "References": "10.1109/TVCG.2011.233;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Graph, visualization, curved edges, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327250",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065003;1173155;4015425;1532136;1532131;1249008;4015424"
            }
        },
        {
            "name": "Kai Xu",
            "value": 24,
            "numPapers": 34,
            "cluster": "0",
            "index": 303,
            "weight": 1,
            "x": -846.7503878666333,
            "y": -341.1732169648348,
            "px": -703.2560560953603,
            "py": -285.3142126145361,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "A User Study on Curved Edges in Graph Visualization",
                "PaperDOI": "10.1109/TVCG.2012.189",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.189",
                "Firstpage": "2449",
                "Lastpage": "2456",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.",
                "AuthorNames": "Kai Xu;Rooney, C.;Passmore, P.;Dong-Han Ham;Nguyen, P.H.",
                "FirstAuthorAffiliation": "Middlesex Univ., London, UK|c|;;;;",
                "AuthorIDs": "38489059400;38488869200;38180787500;38489463400;38490354300",
                "Dedupedauthornames": "Kai Xu;Rooney, C.;Passmore, P.;Dong-Han Ham;Nguyen, P.H.",
                "References": "10.1109/TVCG.2011.233;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.166",
                "AuthorKeywords": "Graph, visualization, curved edges, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327250",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065003;1173155;4015425;1532136;1532131;1249008;4015424"
            }
        },
        {
            "name": "Wong, B.L.W.",
            "value": 17,
            "numPapers": 30,
            "cluster": "0",
            "index": 304,
            "weight": 1,
            "x": -1030.7281147487704,
            "y": 162.93022286922192,
            "px": -868.0599352893746,
            "py": 162.52674858954353,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "VisTrails: enabling interactive multiple-view visualizations",
                "PaperDOI": "10.1109/VISUAL.2005.1532788",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532788",
                "Firstpage": "135",
                "Lastpage": "142",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.",
                "AuthorNames": "Bavoil, L.;Callahan, S.P.;Crossno, P.J.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37565304300;37426872800;37282576500;37283149600;37550809300;37275249200;37549893300",
                "Dedupedauthornames": "Bavoil, L.;Callahan, S.P.;Crossno, P.;Freire, J.;Scheidegger, C.E.;Silva, C.T.;Vo, H.T.",
                "References": "10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791",
                "AuthorKeywords": "interrogative visualization, dataflow, caching, coordinated views",
                "IEEEXPLOREArticleNumberdeprecated": "1532788",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745299;1382890;1372192;1183791"
            }
        },
        {
            "name": "Perer, A.",
            "value": 104,
            "numPapers": 56,
            "cluster": "0",
            "index": 305,
            "weight": 5,
            "x": 632.0786557080613,
            "y": 341.0043382404943,
            "px": 536.4214734979605,
            "py": 328.9355625351616,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2014.2346482",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346482",
                "Firstpage": "1614",
                "Lastpage": "1623",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.",
                "AuthorNames": "Krause, J.;Perer, A.;Bertini, E.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Krause, J.;Perer, A.;Bertini, E.",
                "References": "10.1109/INFVIS.2004.71;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2011.229;10.1109/VAST.2011.6102448;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102453;10.1109/TVCG.2013.125;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652443",
                "AuthorKeywords": "Predictive modeling, feature selection, classification, visual analytics, high-dimensional data",
                "IEEEXPLOREArticleNumberdeprecated": "6876047",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382893;5332586;1532142;6064985;6102448;1249015;6065027;6102453;6634169;5290704;5652443"
            }
        },
        {
            "name": "Stavropoulos, H.",
            "value": 20,
            "numPapers": 21,
            "cluster": "0",
            "index": 306,
            "weight": 1,
            "x": 1550.8068529815607,
            "y": 733.8594443969671,
            "px": 1401.7532909036145,
            "py": 647.142574594406,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data",
                "PaperDOI": "10.1109/TVCG.2014.2346682",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346682",
                "Firstpage": "1783",
                "Lastpage": "1792",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.",
                "AuthorNames": "Gotz, D.;Stavropoulos, H.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Gotz, D.;Stavropoulos, H.",
                "References": "10.1109/TVCG.2013.206;10.1109/TVCG.2012.225;10.1109/TVCG.2011.179;10.1109/INFVIS.2000.885097;10.1109/VAST.2009.5332595;10.1109/VAST.2010.5652890;10.1109/TVCG.2009.117;10.1109/VAST.2006.261421;10.1109/TVCG.2013.200",
                "AuthorKeywords": "Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics",
                "IEEEXPLOREArticleNumberdeprecated": "6875996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634096;6327272;6065010;885097;5332595;5652890;5290698;4035762;6634100"
            }
        },
        {
            "name": "Plaisant, C.",
            "value": 258,
            "numPapers": 29,
            "cluster": "0",
            "index": 307,
            "weight": 4,
            "x": 450.63286869056503,
            "y": 340.9059706393615,
            "px": 491.4563442210967,
            "py": 407.1650027126446,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Temporal Event Sequence Simplification",
                "PaperDOI": "10.1109/TVCG.2013.200",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.200",
                "Firstpage": "2227",
                "Lastpage": "2236",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.",
                "AuthorNames": "Monroe, M.;Rongjian Lan;Hanseung Lee;Plaisant, C.;Shneiderman, B.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Monroe, M.;Rongjian Lan;Hanseung Lee;Plaisant, C.;Shneiderman, B.",
                "References": "10.1109/TVCG.2009.117;10.1109/TVCG.2012.213;10.1109/VAST.2010.5652890",
                "AuthorKeywords": "Event sequences, simplification, electronic heath records, temporal query",
                "IEEEXPLOREArticleNumberdeprecated": "6634100",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290698;6327248;5652890"
            }
        },
        {
            "name": "Inselberg, A.",
            "value": 311,
            "numPapers": 3,
            "cluster": "5",
            "index": 308,
            "weight": 9,
            "x": 975.064697640281,
            "y": 244.17078792137607,
            "px": 1006.2123552487864,
            "py": 282.88221603036584,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "Parallel coordinates: a tool for visualizing multi-dimensional geometry",
                "PaperDOI": "10.1109/VISUAL.1990.146402",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146402",
                "Firstpage": "361",
                "Lastpage": "378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A methodology for visualizing analytic and synthetic geometry in RN is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point - line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R N. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications to Air Traffic Control, Robotics, Computer Vision, Computational Geometry, Statistics, Instrumentation and other areas are discussed.",
                "AuthorNames": "Inselberg, A.;Dimsdale, B.",
                "FirstAuthorAffiliation": "IBM Sci. Center, Los Angeles, CA, USA|c|;",
                "AuthorIDs": "37294162600;37426169800",
                "Dedupedauthornames": "Inselberg, A.;Dimsdale, B.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146402",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Dimsdale, B.",
            "value": 249,
            "numPapers": 0,
            "cluster": "5",
            "index": 309,
            "weight": 7,
            "x": 1015.9351404024337,
            "y": 253.02352563914621,
            "px": 1048.3230318618726,
            "py": 287.82423763243463,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "Parallel coordinates: a tool for visualizing multi-dimensional geometry",
                "PaperDOI": "10.1109/VISUAL.1990.146402",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146402",
                "Firstpage": "361",
                "Lastpage": "378",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A methodology for visualizing analytic and synthetic geometry in RN is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point - line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R N. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications to Air Traffic Control, Robotics, Computer Vision, Computational Geometry, Statistics, Instrumentation and other areas are discussed.",
                "AuthorNames": "Inselberg, A.;Dimsdale, B.",
                "FirstAuthorAffiliation": "IBM Sci. Center, Los Angeles, CA, USA|c|;",
                "AuthorIDs": "37294162600;37426169800",
                "Dedupedauthornames": "Inselberg, A.;Dimsdale, B.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146402",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Kriegel, H.-P.",
            "value": 61,
            "numPapers": 10,
            "cluster": "5",
            "index": 310,
            "weight": 3,
            "x": 1179.6030315562584,
            "y": 251.72831440788894,
            "px": 1194.1493578018694,
            "py": 279.2982299354868,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "Recursive pattern: a technique for visualizing very large amounts of data",
                "PaperDOI": "10.1109/VISUAL.1995.485140",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.485140",
                "Firstpage": "279",
                "Lastpage": "286, 463",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An important goal of visualization technology is to support the exploration and analysis of very large amounts of data. In this paper, we propose a new visualization technique called a `recursive pattern', which has been developed for visualizing large amounts of multidimensional data. The technique is based on a generic recursive scheme which generalizes a wide range of pixel-oriented arrangements for displaying large data sets. By instantiating the technique with adequate data- and application-dependent parameters, the user may greatly influence the structure of the resulting visualizations. Since the technique uses one pixel for presenting each data value, the amount of data which can be displayed is only limited by the resolution of current display technology and by the limitations of human perceptibility. Beside describing the basic idea of the `recursive pattern' technique, we provide several examples of useful parameter settings for the various recursion levels. We further show that our `recursive pattern' technique is particularly advantageous for the large class of data sets which have a natural order according to one dimension (e.g. time series data). We demonstrate the usefulness of our technique by using a stock market application",
                "AuthorNames": "Keim, D.A.;Kriegel, H.-P.;Ankerst, M.",
                "FirstAuthorAffiliation": "Inst. for Comput. Sci., Munchen Univ., Germany|c|;;",
                "AuthorIDs": "37283138700;37276747000;37371609900",
                "Dedupedauthornames": "Keim, D.A.;Kriegel, H.-P.;Ankerst, M.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1991.175809;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146389",
                "AuthorKeywords": "Visualizing Large Data Sets, Visualizing Multidimensional and Multivariate Data, Visualizing Large Sequential Data Sets, Recursive Visualization Techniques, Interfaces to Databases",
                "IEEEXPLOREArticleNumberdeprecated": "485140",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;528688;175809;146386;146387;146389"
            }
        },
        {
            "name": "Ankerst, M.",
            "value": 162,
            "numPapers": 9,
            "cluster": "5",
            "index": 311,
            "weight": 4,
            "x": 1088.854093409674,
            "y": 276.99217775232137,
            "px": 1104.1290334368969,
            "py": 299.70605194293415,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "LeBlanc, J.",
            "value": 85,
            "numPapers": 0,
            "cluster": "5",
            "index": 312,
            "weight": 3,
            "x": 1159.6555462855426,
            "y": 245.54785348320354,
            "px": 1181.335989433864,
            "py": 264.59322133273713,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "Exploring N-dimensional databases",
                "PaperDOI": "10.1109/VISUAL.1990.146386",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146386",
                "Firstpage": "230",
                "Lastpage": "237",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The ability of researchers in the scientific and engineering community to generate or acquire data far outstrips their ability to analyze it. This problem is even more pronounced when the data is of high dimensionality. Visualization has been identified as a critical technique for exploring data sets, but the visualization tools developed to date have mostly concentrated on the display of low (one to four) dimensional data. Ideally a tool for examining N-dimensional data should allow the presentation of the data in a way that can be intuitively interpreted and allow the display of arbitrary views and subsets of the data. The work presented in this paper describes the creation of such a tool using a technique which we term dimensional stacking.",
                "AuthorNames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA, USA|c|;;",
                "AuthorIDs": "38225805300;37268441700;38223933400",
                "Dedupedauthornames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146386",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Wittels, N.",
            "value": 85,
            "numPapers": 0,
            "cluster": "5",
            "index": 313,
            "weight": 3,
            "x": 1161.3004416504211,
            "y": 296.6633536167849,
            "px": 1184.201610841345,
            "py": 310.9276045830729,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "Exploring N-dimensional databases",
                "PaperDOI": "10.1109/VISUAL.1990.146386",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146386",
                "Firstpage": "230",
                "Lastpage": "237",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The ability of researchers in the scientific and engineering community to generate or acquire data far outstrips their ability to analyze it. This problem is even more pronounced when the data is of high dimensionality. Visualization has been identified as a critical technique for exploring data sets, but the visualization tools developed to date have mostly concentrated on the display of low (one to four) dimensional data. Ideally a tool for examining N-dimensional data should allow the presentation of the data in a way that can be intuitively interpreted and allow the display of arbitrary views and subsets of the data. The work presented in this paper describes the creation of such a tool using a technique which we term dimensional stacking.",
                "AuthorNames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "FirstAuthorAffiliation": "Worcester Polytech. Inst., MA, USA|c|;;",
                "AuthorIDs": "38225805300;37268441700;38223933400",
                "Dedupedauthornames": "LeBlanc, J.;Ward, M.O.;Wittels, N.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146386",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Mueller, K.",
            "value": 360,
            "numPapers": 130,
            "cluster": "2",
            "index": 314,
            "weight": 36,
            "x": 153.60970269135066,
            "y": 78.74910901229977,
            "px": 165.33059274447655,
            "py": 83.02784997190747,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2011.218",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.218",
                "Firstpage": "1959",
                "Lastpage": "1968",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.",
                "AuthorNames": "Ziyi Zheng;Ahmed, N.;Mueller, K.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "37599599100;38021380500;37273119700",
                "Dedupedauthornames": "Ziyi Zheng;Ahmed, N.;Mueller, K.",
                "References": "10.1109/TVCG.2009.156;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.162;10.1109/TVCG.2008.159;10.1109/TVCG.2010.214;10.1109/TVCG.2009.172;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.124;10.1109/TVCG.2009.185;10.1109/TVCG.2009.189;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2005.1532834",
                "AuthorKeywords": "Direct volume rendering, k-means, entropy, view suggestion, set-cover problem, ant colony optimization",
                "IEEEXPLOREArticleNumberdeprecated": "6064959",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290746;4376185;4658153;4658191;5613489;5290740;1532833;1532818;4015450;5290763;5290762;1250414;1532834"
            }
        },
        {
            "name": "Nonato, L.G.",
            "value": 72,
            "numPapers": 62,
            "cluster": "10",
            "index": 315,
            "weight": 5,
            "x": 60.59198856037172,
            "y": 75.21707169500397,
            "px": -95.64771618319587,
            "py": -115.76447939250075,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Local Affine Multidimensional Projection",
                "PaperDOI": "10.1109/TVCG.2011.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.220",
                "Firstpage": "2563",
                "Lastpage": "2571",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",
                "AuthorNames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;",
                "AuthorIDs": "38017343000;37590969400;38017342500;38017346900;37590974800",
                "Dedupedauthornames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "References": "10.1109/VISUAL.1996.567787;10.1109/TVCG.2009.140;10.1109/TVCG.2007.70580;10.1109/INFVIS.2002.1173159;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173161",
                "AuthorKeywords": "Multidimensional Projection, High Dimensional Data, Visual Data Mining",
                "IEEEXPLOREArticleNumberdeprecated": "6065024",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567787;5290725;4376155;1173159;5613468;5613498;1173161"
            }
        },
        {
            "name": "Fisher, B.",
            "value": 76,
            "numPapers": 23,
            "cluster": "0",
            "index": 316,
            "weight": 4,
            "x": 916.839511619717,
            "y": -88.35119203428945,
            "px": 965.9173011141752,
            "py": -121.14184420388929,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Visual analytic roadblocks for novice investigators",
                "PaperDOI": "10.1109/VAST.2011.6102435",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102435",
                "Firstpage": "3",
                "Lastpage": "11",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users' perspectives is still limited. Therefore, we attempted to identify such visual analytic roadblocks for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.",
                "AuthorNames": "Bum chul Kwon;Fisher, B.;Ji Soo Yi",
                "FirstAuthorAffiliation": "Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "38235486800;37267458000;38238292000",
                "Dedupedauthornames": "Bum Chul Kwon;Fisher, B.;Ji Soo Yi",
                "References": "10.1109/INFVIS.2004.10;10.1109/VAST.2007.4389006;10.1109/TVCG.2010.164;10.1109/VAST.2009.5333878;10.1109/TVCG.2010.179;10.1109/TVCG.2008.121;10.1109/INFVIS.2004.5;10.1109/TVCG.2007.70515;10.1109/TVCG.2010.177;10.1109/VAST.2006.261416;10.1109/TVCG.2008.171;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70535;10.1109/VAST.2008.4677361;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70594",
                "AuthorKeywords": "Visual analytics, investigative analysis, cognitive \nmodel, framework, roadblock, qualitative experiment \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6102435",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382902;4389006;5613431;5333878;5613452;4658127;1382884;4376144;5613437;4035759;4658138;4658124;4376143;4677361;4376132;4376133"
            }
        },
        {
            "name": "Ellis, G.",
            "value": 160,
            "numPapers": 45,
            "cluster": "5",
            "index": 317,
            "weight": 5,
            "x": 1075.8483558861249,
            "y": 286.6276533016401,
            "px": 1099.944670239072,
            "py": 301.06684374636853,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "A Taxonomy of Clutter Reduction for Information Visualisation",
                "PaperDOI": "10.1109/TVCG.2007.70535",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70535",
                "Firstpage": "1216",
                "Lastpage": "1223",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.",
                "AuthorNames": "Ellis, G.;Dix, A.",
                "FirstAuthorAffiliation": "Lancaster Univ, Lancaster|c|;",
                "AuthorIDs": "37283380700;37283381700",
                "Dedupedauthornames": "Ellis, G.;Dix, A.",
                "References": "10.1109/INFVIS.2003.1249018;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.138;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1998.745301;10.1109/INFVIS.1997.636789;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249019;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1995.528685;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.170",
                "AuthorKeywords": "Clutter reduction, information visualisation, occlusion, large datasets, taxonomy",
                "IEEEXPLOREArticleNumberdeprecated": "4376143",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249018;885092;4015422;1532819;1249008;809866;885091;745301;636789;1173156;1249019;636792;528685;1382895;4015444"
            }
        },
        {
            "name": "Fulda, J.",
            "value": 0,
            "numPapers": 16,
            "cluster": "0",
            "index": 318,
            "weight": 1,
            "x": 779.6012149702517,
            "y": 154.95331419704974,
            "px": 722.9391523488358,
            "py": 132.01627430812894,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Serendip: Topic Model-Driven Visual Exploration of Text Corpora",
                "PaperDOI": "10.1109/VAST.2014.7042493",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042493",
                "Firstpage": "173",
                "Lastpage": "182",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.",
                "AuthorNames": "Alexander, E.;Kohlmann, J.;Valenza, R.;Witmore, M.;Gleicher, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Alexander, E.;Kohlmann, J.;Valenza, R.;Witmore, M.;Gleicher, M.",
                "References": "10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1998.729568;10.1109/TVCG.2011.239;10.1109/TVCG.2011.220;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.157;10.1109/TVCG.2013.162;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389004",
                "AuthorKeywords": "Text visualization, topic modeling",
                "IEEEXPLOREArticleNumberdeprecated": "7042493",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;885098;729570;6065008;6065024;6400486;6102461;6634124;6634160;4389006;4389004"
            }
        },
        {
            "name": "Nielsen, C.B.",
            "value": 36,
            "numPapers": 9,
            "cluster": "0",
            "index": 319,
            "weight": 1,
            "x": 1344.4847016876802,
            "y": 1401.4749420390474,
            "px": 1246.7126540023721,
            "py": 1257.1143125979677,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Variant View: Visualizing Sequence Variants in their Gene Context",
                "PaperDOI": "10.1109/TVCG.2013.214",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.214",
                "Firstpage": "2546",
                "Lastpage": "2555",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.",
                "AuthorNames": "Ferstay, J.A.;Nielsen, C.B.;Munzner, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Ferstay, J.A.;Nielsen, C.B.;Munzner, T.",
                "References": "10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/TVCG.2012.213;10.1109/TVCG.2011.185;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.116;10.1109/TVCG.2009.167;10.1109/TVCG.2011.209",
                "AuthorKeywords": "Information visualization, design study, bioinformatics, genetic variants",
                "IEEEXPLOREArticleNumberdeprecated": "6634170",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290695;4658124;6327248;6064996;1249023;5290690;5290692;6065017"
            }
        },
        {
            "name": "van de Wetering, H.",
            "value": 178,
            "numPapers": 29,
            "cluster": "5",
            "index": 320,
            "weight": 4,
            "x": 1241.6111677235406,
            "y": 283.9447301604089,
            "px": 1220.4508083629314,
            "py": 292.51272933967425,
            "node": {
                "Conference": "InfoVis",
                "Year": "1999",
                "PaperTitle": "Cushion treemaps: visualization of hierarchical information",
                "PaperDOI": "10.1109/INFVIS.1999.801860",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1999.801860",
                "Firstpage": "73",
                "Lastpage": "78, 147",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new method is presented for the visualization of hierarchical information, such as directory structures and organization structures. Cushion treemaps inherit the elegance of standard treemaps: compact, space-filling displays of hierarchical information, based on recursive subdivision of a rectangular image space. Intuitive shading is used to provide insight in the hierarchical structure. During the subdivision, ridges are added per rectangle, which are rendered with a simple shading model. The result is a surface that consists of recursive cushions. The method is efficient, effective, easy to use and implement, and has a wide applicability",
                "AuthorNames": "van Wijk, J.J.;van de Wetering, H.",
                "FirstAuthorAffiliation": "Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;",
                "AuthorIDs": "37267249200;37294473300",
                "Dedupedauthornames": "van Wijk, J.J.;van de Wetering, H.",
                "References": "10.1109/VISUAL.1991.175815",
                "AuthorKeywords": "Information Visualization, Tree Visualization, Treemaps",
                "IEEEXPLOREArticleNumberdeprecated": "801860",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175815"
            }
        },
        {
            "name": "Ferreira, N.",
            "value": 85,
            "numPapers": 34,
            "cluster": "5",
            "index": 321,
            "weight": 4,
            "x": 1180.8269482829833,
            "y": 192.07097826472244,
            "px": 1187.1662181484007,
            "py": 192.47650187987068,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips",
                "PaperDOI": "10.1109/TVCG.2013.226",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.226",
                "Firstpage": "2149",
                "Lastpage": "2158",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.",
                "AuthorNames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Ferreira, N.;Poco, J.;Vo, H.T.;Freire, J.;Silva, C.T.",
                "References": "10.1109/INFVIS.2004.12;10.1109/VAST.2008.4677356;10.1109/VAST.2011.6102454;10.1109/TVCG.2007.70535;10.1109/VAST.2010.5652467;10.1109/INFVIS.2005.1532150;10.1109/VAST.2008.4677370;10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Spatio-temporal queries, urban data, taxi movement data, visual exploration",
                "IEEEXPLOREArticleNumberdeprecated": "6634127",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382904;4677356;6102454;4376143;5652467;1532150;4677370;885086"
            }
        },
        {
            "name": "Riche, N.H.",
            "value": 233,
            "numPapers": 61,
            "cluster": "0",
            "index": 322,
            "weight": 10,
            "x": 676.9466051920008,
            "y": 273.6345440932387,
            "px": 671.6771471197299,
            "py": 290.45196380937915,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Singhal, K.",
            "value": 213,
            "numPapers": 3,
            "cluster": "0",
            "index": 323,
            "weight": 6,
            "x": 650.6747532466875,
            "y": 127.54047473082399,
            "px": 701.1444529622848,
            "py": 92.21263497691913,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "Jigsaw: Supporting Investigative Analysis through Interactive Visualization",
                "PaperDOI": "10.1109/VAST.2007.4389006",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389006",
                "Firstpage": "131",
                "Lastpage": "138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.",
                "AuthorNames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "FirstAuthorAffiliation": "Georgia Inst. of Technol., Atlanta|c|;;;",
                "AuthorIDs": "37267736900;37428446300;37592993600;37968367000",
                "Dedupedauthornames": "Stasko, J.;Gorg, C.;Zhicheng Liu;Singhal, K.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/INFVIS.2004.27;10.1109/VAST.2006.261432",
                "AuthorKeywords": "Visual analytics, investigative analysis, intelligence analysis, information visualization, multiple views",
                "IEEEXPLOREArticleNumberdeprecated": "4389006",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;1382887;4035749"
            }
        },
        {
            "name": "Bezerianos, A.",
            "value": 88,
            "numPapers": 34,
            "cluster": "0",
            "index": 324,
            "weight": 3,
            "x": 230.79081096429266,
            "y": 328.20655790487797,
            "px": 106.33859884581962,
            "py": 334.64022400391167,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications",
                "PaperDOI": "10.1109/TVCG.2012.251",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.251",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.",
                "AuthorNames": "Bezerianos, A.;Isenberg, P.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37413699200;37591317800",
                "Dedupedauthornames": "Bezerianos, A.;Isenberg, P.",
                "References": "10.1109/TVCG.2011.160;10.1109/TVCG.2006.184",
                "AuthorKeywords": "Information visualization, perception, wall-displays",
                "IEEEXPLOREArticleNumberdeprecated": "6327257",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065014;4015437"
            }
        },
        {
            "name": "Heinrich, J.",
            "value": 56,
            "numPapers": 21,
            "cluster": "5",
            "index": 325,
            "weight": 2,
            "x": 1044.2769500811355,
            "y": 377.07236600115925,
            "px": 1057.0203955451973,
            "py": 413.2219639059389,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study",
                "PaperDOI": "10.1109/TVCG.2011.193",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.193",
                "Firstpage": "2440",
                "Lastpage": "2448",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.",
                "AuthorNames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "FirstAuthorAffiliation": "VISUS, Univ. of Stuttgart, Germany|c|;;;;",
                "AuthorIDs": "37586953400;38017426500;37665271000;;38470313100",
                "Dedupedauthornames": "Burch, M.;Konevtsova, N.;Heinrich, J.;Hoeferlin, M.;Weiskopf, D.",
                "References": "10.1109/TVCG.2010.209;10.1109/INFVIS.2004.70",
                "AuthorKeywords": "Hierarchy visualization, node-link layout, eye tracking, user study",
                "IEEEXPLOREArticleNumberdeprecated": "6065011",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613430;1382885"
            }
        },
        {
            "name": "Grammel, L.",
            "value": 32,
            "numPapers": 17,
            "cluster": "1",
            "index": 326,
            "weight": 2,
            "x": -257.54205399022385,
            "y": 680.0059481670773,
            "px": -215.77761168075148,
            "py": 655.1159885577725,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "How Information Visualization Novices Construct Visualizations",
                "PaperDOI": "10.1109/TVCG.2010.164",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.164",
                "Firstpage": "943",
                "Lastpage": "952",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.",
                "AuthorNames": "Grammel, Lars;Tory, M.;Storey, M.",
                "FirstAuthorAffiliation": "Univ. of Victoria, Victoria, BC, Canada|c|;;",
                "AuthorIDs": "37322138200;37275861300;37268043300",
                "Dedupedauthornames": "Grammel, L.;Tory, M.;Storey, M.",
                "References": "10.1109/TVCG.2007.70515;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70541;10.1109/VAST.2009.5333878;10.1109/TVCG.2008.109;10.1109/VAST.2006.261428;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677358;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70594;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2001.963289;10.1109/INFVIS.2000.885092;10.1109/TVCG.2008.137",
                "AuthorKeywords": "Empirical study, visualization, visualization construction, visual analytics, visual mapping, novices",
                "IEEEXPLOREArticleNumberdeprecated": "5613431",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376144;4015420;4376134;5333878;4658124;4035745;4376131;4677358;4677365;4376143;1532136;729560;4376133;885086;963289;885092;4658129"
            }
        },
        {
            "name": "Tory, M.",
            "value": 210,
            "numPapers": 84,
            "cluster": "0",
            "index": 327,
            "weight": 13,
            "x": 773.29006850503,
            "y": 86.14053726414379,
            "px": 747.3081531079818,
            "py": 86.28007748200025,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Rethinking Visualization: A High-Level Taxonomy",
                "PaperDOI": "10.1109/INFVIS.2004.59",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.59",
                "Firstpage": "151",
                "Lastpage": "158",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present the novel high-level visualization taxonomy. Our taxonomy classifies visualization algorithms rather than data. Algorithms are categorized based on the assumptions they make about the data being visualized; we call this set of assumptions the design model. Because our taxonomy is based on design models, it is more flexible than existing taxonomies and considers the user's conceptual model, emphasizing the human aspect of visualization. Design models are classified according to whether they are discrete or continuous and by how much the algorithm designer chooses display attributes such as spatialization, timing, colour, and transparency. This novel approach provides an alternative view of the visualization field that helps explain how traditional divisions (e.g., information and scientific visualization) relates and overlap, and that may inspire research ideas in hybrid visualization areas",
                "AuthorNames": "Tory, M.;Moller, T.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC|c|;",
                "AuthorIDs": "37275861300;37275858700",
                "Dedupedauthornames": "Tory, M.;Moller, T.",
                "References": "10.1109/VISUAL.1990.146375;10.1109/INFVIS.2000.885092;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1999.801856",
                "AuthorKeywords": "visualization, taxonomy, classification, design model, user model, conceptual model",
                "IEEEXPLOREArticleNumberdeprecated": "1382903",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146375;885092;636792;801856"
            }
        },
        {
            "name": "Storey, M.",
            "value": 37,
            "numPapers": 18,
            "cluster": "1",
            "index": 328,
            "weight": 2,
            "x": 91.97395503776411,
            "y": -996.4350186649051,
            "px": 92.88428556407405,
            "py": -891.696890759108,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "How Information Visualization Novices Construct Visualizations",
                "PaperDOI": "10.1109/TVCG.2010.164",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.164",
                "Firstpage": "943",
                "Lastpage": "952",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.",
                "AuthorNames": "Grammel, Lars;Tory, M.;Storey, M.",
                "FirstAuthorAffiliation": "Univ. of Victoria, Victoria, BC, Canada|c|;;",
                "AuthorIDs": "37322138200;37275861300;37268043300",
                "Dedupedauthornames": "Grammel, L.;Tory, M.;Storey, M.",
                "References": "10.1109/TVCG.2007.70515;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70541;10.1109/VAST.2009.5333878;10.1109/TVCG.2008.109;10.1109/VAST.2006.261428;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677358;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70594;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2001.963289;10.1109/INFVIS.2000.885092;10.1109/TVCG.2008.137",
                "AuthorKeywords": "Empirical study, visualization, visualization construction, visual analytics, visual mapping, novices",
                "IEEEXPLOREArticleNumberdeprecated": "5613431",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376144;4015420;4376134;5333878;4658124;4035745;4376131;4677358;4677365;4376143;1532136;729560;4376133;885086;963289;885092;4658129"
            }
        },
        {
            "name": "Dork, M.",
            "value": 148,
            "numPapers": 27,
            "cluster": "1",
            "index": 329,
            "weight": 5,
            "x": 910.8145701708697,
            "y": 470.21225350446434,
            "px": 925.2895931256775,
            "py": 445.96670616366765,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery",
                "PaperDOI": "10.1109/TVCG.2008.175",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.175",
                "Firstpage": "1205",
                "Lastpage": "1212",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.",
                "AuthorNames": "Dork, M.;Carpendale, S.;Collins, C.;Williamson, C.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of Calgary, Calgary, AB|c|;;;",
                "AuthorIDs": ";37285000100;37669874100;37276124700",
                "Dedupedauthornames": "Dork, M.;Carpendale, S.;Collins, C.;Williamson, C.",
                "References": "10.1109/TVCG.2007.70570;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70577;10.1109/VISUAL.1993.398863;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1996.567610",
                "AuthorKeywords": "Information visualization, World Wide Web, information retrieval, exploratory search, visual information seeking",
                "IEEEXPLOREArticleNumberdeprecated": "4658131",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376138;4376132;4376131;398863;1532122;567610"
            }
        },
        {
            "name": "Gratzl, S.",
            "value": 47,
            "numPapers": 42,
            "cluster": "0",
            "index": 330,
            "weight": 3,
            "x": -55.145207232818265,
            "y": 263.50676379998043,
            "px": -221.91678763787027,
            "py": 193.15849252169556,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "LineUp: Visual Analysis of Multi-Attribute Rankings",
                "PaperDOI": "10.1109/TVCG.2013.173",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.173",
                "Firstpage": "2277",
                "Lastpage": "2286",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.",
                "AuthorNames": "Gratzl, S.;Lex, A.;Gehlenborg, N.;Pfister, H.;Streit, M.",
                "FirstAuthorAffiliation": "Johannes Kepler Univ. Linz, Linz, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Gratzl, S.;Lex, A.;Gehlenborg, N.;Pfister, H.;Streit, M.",
                "References": "10.1109/TVCG.2012.253;10.1109/TVCG.2008.166;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.181;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts",
                "IEEEXPLOREArticleNumberdeprecated": "6634146",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327273;4658136;568118;4658150;4376146"
            }
        },
        {
            "name": "Gehlenborg, N.",
            "value": 47,
            "numPapers": 26,
            "cluster": "0",
            "index": 331,
            "weight": 3,
            "x": 365.0663439941112,
            "y": 249.04600987294813,
            "px": 329.7580059854076,
            "py": 200.81014512468548,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "UpSet: Visualization of Intersecting Sets",
                "PaperDOI": "10.1109/TVCG.2014.2346248",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346248",
                "Firstpage": "1983",
                "Lastpage": "1992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.",
                "AuthorNames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "FirstAuthorAffiliation": "Hendrik Strobelt & Hanspeter Pfister, Harvard Univ., Cambridge, MA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183",
                "AuthorKeywords": "Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data",
                "IEEEXPLOREArticleNumberdeprecated": "6876017",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;6634104;6064991;5613447;5290706;6064996;6064990"
            }
        },
        {
            "name": "McGuffin, M.J.",
            "value": 271,
            "numPapers": 60,
            "cluster": "0",
            "index": 332,
            "weight": 9,
            "x": 619.0555495424034,
            "y": 411.760710139993,
            "px": 529.2140160523052,
            "py": 276.7236478857627,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data",
                "PaperDOI": "10.1109/TVCG.2013.160",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.160",
                "Firstpage": "2606",
                "Lastpage": "2614",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.",
                "AuthorNames": "Im, J.-F.;McGuffin, M.J.;Leung, R.",
                "FirstAuthorAffiliation": "Ecole de Technol. Super., Montreal, QC, Canada|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Im, J.-F.;McGuffin, M.J.;Leung, R.",
                "References": "10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/TVCG.2007.70594;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2010.205;10.1109/TVCG.2011.183;10.1109/VISUAL.1993.398859;10.1109/TVCG.2011.201;10.1109/TVCG.2010.164;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/VISUAL.1991.175796",
                "AuthorKeywords": "Multidimensional data, tabular data, relational data, mdmv, high-dimensional data, database visualization, database overview, parallel coordinates, scatterplot matrix, user interfaces, business intelligence",
                "IEEEXPLOREArticleNumberdeprecated": "6634192",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532142;4376168;5290705;5332586;4376133;146386;6064996;5613448;6064990;398859;6064997;5613431;885086;4376140;1382895;4658123;175796"
            }
        },
        {
            "name": "Aris, A.",
            "value": 109,
            "numPapers": 3,
            "cluster": "0",
            "index": 333,
            "weight": 2,
            "x": -29.349865086645575,
            "y": -617.8632310126334,
            "px": -58.65941116877419,
            "py": -702.6868867337739,
            "node": {
                "Conference": "InfoVis",
                "Year": "2006",
                "PaperTitle": "Network Visualization by Semantic Substrates",
                "PaperDOI": "10.1109/TVCG.2006.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.166",
                "Firstpage": "733",
                "Lastpage": "740",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations",
                "AuthorNames": "Shneiderman, B.;Aris, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;",
                "AuthorIDs": "37283016400;37561646300",
                "Dedupedauthornames": "Shneiderman, B.;Aris, A.",
                "References": "10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Network visualization, semantic substrate, information visualization, graphical user interfaces",
                "IEEEXPLOREArticleNumberdeprecated": "4015424",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382886;1532124;1532126"
            }
        },
        {
            "name": "Agrawala, M.",
            "value": 277,
            "numPapers": 36,
            "cluster": "0",
            "index": 334,
            "weight": 9,
            "x": 839.5554705764891,
            "y": 77.72721824311766,
            "px": 793.7203632527438,
            "py": 73.35655465392122,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "Scented Widgets: Improving Navigation Cues with Embedded Visualizations",
                "PaperDOI": "10.1109/TVCG.2007.70589",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70589",
                "Firstpage": "1129",
                "Lastpage": "1136",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.",
                "AuthorNames": "Willett, W.;Heer, J.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California, Berkeley|c|;;",
                "AuthorIDs": "37945380800;37550791300;37282718200",
                "Dedupedauthornames": "Willett, W.;Heer, J.;Agrawala, M.",
                "References": "10.1109/INFVIS.1999.801862",
                "AuthorKeywords": "Information visualization, user interface toolkits, information foraging, social navigation, social data analysis",
                "IEEEXPLOREArticleNumberdeprecated": "4376132",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801862"
            }
        },
        {
            "name": "Stolper, C.D.",
            "value": 17,
            "numPapers": 30,
            "cluster": "0",
            "index": 335,
            "weight": 2,
            "x": 526.2845880020888,
            "y": 1531.1812441720435,
            "px": 487.5415434657215,
            "py": 1637.7147125356403,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "Firstpage": "1189",
                "Lastpage": "1196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Visualization, history, undo, analysis, presentation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Kahng, M.",
            "value": 0,
            "numPapers": 15,
            "cluster": "0",
            "index": 336,
            "weight": 1,
            "x": -454.62437449410606,
            "y": -943.4795733636416,
            "px": -357.4095773639222,
            "py": -810.5546454167406,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "Firstpage": "1189",
                "Lastpage": "1196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Visualization, history, undo, analysis, presentation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Zhiyuan Lin",
            "value": 0,
            "numPapers": 15,
            "cluster": "0",
            "index": 337,
            "weight": 1,
            "x": -150.7447360219269,
            "y": -748.5844432809207,
            "px": -82.01614784466642,
            "py": -631.5290642232751,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "Firstpage": "1189",
                "Lastpage": "1196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Visualization, history, undo, analysis, presentation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Foerster, F.",
            "value": 0,
            "numPapers": 15,
            "cluster": "0",
            "index": 338,
            "weight": 1,
            "x": 595.6355171082514,
            "y": -1146.0711907327463,
            "px": 584.204651453767,
            "py": -988.3628290950368,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "Firstpage": "1189",
                "Lastpage": "1196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Visualization, history, undo, analysis, presentation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Goel, A.",
            "value": 6,
            "numPapers": 20,
            "cluster": "0",
            "index": 339,
            "weight": 1,
            "x": -616.6468631651923,
            "y": -1313.7794200948588,
            "px": -507.7458516378683,
            "py": -1149.0869271295908,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "Firstpage": "1189",
                "Lastpage": "1196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Visualization, history, undo, analysis, presentation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Duen Horng Chau",
            "value": 0,
            "numPapers": 15,
            "cluster": "0",
            "index": 340,
            "weight": 1,
            "x": -1361.5563390531072,
            "y": 836.4397336587771,
            "px": -1180.6916730895719,
            "py": 789.6071806208338,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation",
                "PaperDOI": "10.1109/TVCG.2008.137",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.137",
                "Firstpage": "1189",
                "Lastpage": "1196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.",
                "AuthorNames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "FirstAuthorAffiliation": "Univ. of California at Berkeley, Berkeley, CA|c|;;;",
                "AuthorIDs": "37550791300;37372036700;37442008700;37282718200",
                "Dedupedauthornames": "Heer, J.;Mackinlay, J.;Stolte, C.;Agrawala, M.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992",
                "AuthorKeywords": "Visualization, history, undo, analysis, presentation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658129",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;398857;809871;1382890;480801;4376133;4388992"
            }
        },
        {
            "name": "Yang Liu",
            "value": 25,
            "numPapers": 11,
            "cluster": "1",
            "index": 341,
            "weight": 1,
            "x": 1101.0270100744729,
            "y": 1178.8673224691515,
            "px": 1013.7377464673461,
            "py": 1073.0201361728275,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "StoryFlow: Tracking the Evolution of Stories",
                "PaperDOI": "10.1109/TVCG.2013.196",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.196",
                "Firstpage": "2436",
                "Lastpage": "2445",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.",
                "AuthorNames": "Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu",
                "References": "10.1109/TVCG.2012.253;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/TVCG.2011.226;10.1109/VAST.2008.4677364;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/VAST.2006.261421;10.1109/VAST.2009.5333437;10.1109/TVCG.2011.239",
                "AuthorKeywords": "Storylines, story-telling visualization, user interactions, level-of-detail, optimization",
                "IEEEXPLOREArticleNumberdeprecated": "6634164",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327273;6064988;5613452;6065001;4677364;6327274;6634134;6327272;4035762;5333437;6065008"
            }
        },
        {
            "name": "Zhuofeng Wu",
            "value": 25,
            "numPapers": 11,
            "cluster": "1",
            "index": 342,
            "weight": 1,
            "x": 1155.8549001635317,
            "y": 1004.9769365777717,
            "px": 1058.6919478151397,
            "py": 917.4186627440263,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "How Hierarchical Topics Evolve in Large Text Corpora",
                "PaperDOI": "10.1109/TVCG.2014.2346433",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346433",
                "Firstpage": "2281",
                "Lastpage": "2290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "References": "10.1109/TVCG.2013.196;10.1109/TVCG.2009.108;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346920;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/TVCG.2013.162;10.1109/TVCG.2013.200",
                "AuthorKeywords": "Hierarchical topic visualization, evolutionary tree clustering, data transformation",
                "IEEEXPLOREArticleNumberdeprecated": "6875938",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634164;5290699;7042494;5290695;6065008;6876032;6327274;6634134;6327272;6634160;6634100"
            }
        },
        {
            "name": "Hao Wei",
            "value": 25,
            "numPapers": 11,
            "cluster": "1",
            "index": 343,
            "weight": 1,
            "x": 1606.3411714378724,
            "y": 1326.7352435132684,
            "px": 1469.8636928985986,
            "py": 1215.4700134006237,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "How Hierarchical Topics Evolve in Large Text Corpora",
                "PaperDOI": "10.1109/TVCG.2014.2346433",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346433",
                "Firstpage": "2281",
                "Lastpage": "2290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei",
                "References": "10.1109/TVCG.2013.196;10.1109/TVCG.2009.108;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346920;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/TVCG.2013.162;10.1109/TVCG.2013.200",
                "AuthorKeywords": "Hierarchical topic visualization, evolutionary tree clustering, data transformation",
                "IEEEXPLOREArticleNumberdeprecated": "6875938",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634164;5290699;7042494;5290695;6065008;6876032;6327274;6634134;6327272;6634160;6634100"
            }
        },
        {
            "name": "Yangqiu Song",
            "value": 108,
            "numPapers": 10,
            "cluster": "1",
            "index": 344,
            "weight": 4,
            "x": 793.5724681886492,
            "y": 514.6932664146171,
            "px": 877.515299190405,
            "py": 503.9963557336265,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "Firstpage": "2412",
                "Lastpage": "2421",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333443;10.1109/TVCG.2006.156;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2010.129;10.1109/VAST.2008.4677364;10.1109/INFVIS.2005.1532122;10.1109/VAST.2009.5333437;10.1109/INFVIS.2005.1532152",
                "AuthorKeywords": "Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event",
                "IEEEXPLOREArticleNumberdeprecated": "6065008",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Zekai Gao",
            "value": 108,
            "numPapers": 10,
            "cluster": "1",
            "index": 345,
            "weight": 4,
            "x": 828.4276850416846,
            "y": 518.5694904437505,
            "px": 844.3078172644362,
            "py": 500.3245414712371,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "Firstpage": "2412",
                "Lastpage": "2421",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333443;10.1109/TVCG.2006.156;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2010.129;10.1109/VAST.2008.4677364;10.1109/INFVIS.2005.1532122;10.1109/VAST.2009.5333437;10.1109/INFVIS.2005.1532152",
                "AuthorKeywords": "Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event",
                "IEEEXPLOREArticleNumberdeprecated": "6065008",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Xin Tong",
            "value": 108,
            "numPapers": 10,
            "cluster": "1",
            "index": 346,
            "weight": 4,
            "x": 660.4125132471132,
            "y": 498.77467866716734,
            "px": 620.5310223764518,
            "py": 475.561787483735,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "TextFlow: Towards Better Understanding of Evolving Topics in Text",
                "PaperDOI": "10.1109/TVCG.2011.239",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.239",
                "Firstpage": "2412",
                "Lastpage": "2421",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.",
                "AuthorNames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;",
                "AuthorIDs": "37391623900;37406039100;38024441100;38019494400;37407140300;38023993900;37272637300;37394723000",
                "Dedupedauthornames": "Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333443;10.1109/TVCG.2006.156;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2010.129;10.1109/VAST.2008.4677364;10.1109/INFVIS.2005.1532122;10.1109/VAST.2009.5333437;10.1109/INFVIS.2005.1532152",
                "AuthorKeywords": "Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event",
                "IEEEXPLOREArticleNumberdeprecated": "6065008",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;5333443;4015435;5290722;4658136;5613451;4677364;1532122;5333437;1532152"
            }
        },
        {
            "name": "Tanahashi, Y.",
            "value": 35,
            "numPapers": 9,
            "cluster": "1",
            "index": 347,
            "weight": 1,
            "x": -693.0604686050467,
            "y": 1496.8099312416055,
            "px": -593.8411791863647,
            "py": 1374.2884100256097,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Design Considerations for Optimizing Storyline Visualizations",
                "PaperDOI": "10.1109/TVCG.2012.212",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.212",
                "Firstpage": "2679",
                "Lastpage": "2688",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's Movie Narrative Charts [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.",
                "AuthorNames": "Tanahashi, Y.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "ViDi Res. Group, Univ. of California, Davis, CA, USA|c|;",
                "AuthorIDs": "38490419400;38490054000",
                "Dedupedauthornames": "Tanahashi, Y.;Kwan-Liu Ma",
                "References": "10.1109/TVCG.2008.166;10.1109/TVCG.2008.135;10.1109/TVCG.2011.190;10.1109/TVCG.2011.239;10.1109/TVCG.2006.193;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.125;10.1109/INFVIS.2002.1173160",
                "AuthorKeywords": "Layout algorithm, timeline visualization, storyline visualization, design study",
                "IEEEXPLOREArticleNumberdeprecated": "6327274",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658136;4658140;6065002;6065008;4015433;4376143;1249008;4658146;1173160"
            }
        },
        {
            "name": "Wongsuphasawat, K.",
            "value": 75,
            "numPapers": 29,
            "cluster": "0",
            "index": 348,
            "weight": 3,
            "x": 1383.354877193732,
            "y": 895.0628513722806,
            "px": 1321.5881228548826,
            "py": 886.9581111282483,
            "node": {
                "Conference": "InfoVis",
                "Year": "2015",
                "PaperTitle": "Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations",
                "PaperDOI": "10.1109/TVCG.2015.2467191",
                "Link": "http://dx.doi.org/10.1109/TVCG.2015.2467191",
                "Firstpage": "649",
                "Lastpage": "658",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.",
                "AuthorNames": "Wongsuphasawat, K.;Moritz, D.;Anand, A.;Mackinlay, J.;Howe, B.;Heer, J.",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Wongsuphasawat, K.;Moritz, D.;Anand, A.;Mackinlay, J.;Howe, B.;Heer, J.",
                "References": "10.1109/TVCG.2014.2346297;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346291;10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems",
                "IEEEXPLOREArticleNumberdeprecated": "7192728",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6875927;5290720;6064996;4376133;6876042;885086"
            }
        },
        {
            "name": "Li Yu",
            "value": 67,
            "numPapers": 5,
            "cluster": "1",
            "index": 349,
            "weight": 1,
            "x": 248.89903607645067,
            "y": 3255.0241221055294,
            "px": 250.947096689002,
            "py": 2977.832107674819,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies",
                "PaperDOI": "10.1109/TVCG.2013.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.162",
                "Firstpage": "2002",
                "Lastpage": "2011",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.",
                "AuthorNames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485",
                "AuthorKeywords": "Hierarchical topic representation, topic modeling, visual analytics, rose tree",
                "IEEEXPLOREArticleNumberdeprecated": "6634160",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6400557;6065008;6102461;6400485"
            }
        },
        {
            "name": "Zhiqiang Ma",
            "value": 67,
            "numPapers": 5,
            "cluster": "1",
            "index": 350,
            "weight": 1,
            "x": -306.7144561169988,
            "y": 1449.6213787295599,
            "px": -242.19277598033833,
            "py": 1326.432573805226,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies",
                "PaperDOI": "10.1109/TVCG.2013.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.162",
                "Firstpage": "2002",
                "Lastpage": "2011",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.",
                "AuthorNames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;Ribarsky, W.",
                "References": "10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485",
                "AuthorKeywords": "Hierarchical topic representation, topic modeling, visual analytics, rose tree",
                "IEEEXPLOREArticleNumberdeprecated": "6634160",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6400557;6065008;6102461;6400485"
            }
        },
        {
            "name": "Beecham, R.",
            "value": 0,
            "numPapers": 11,
            "cluster": "0",
            "index": 351,
            "weight": 1,
            "x": -528.5413255537593,
            "y": 1624.4301926561222,
            "px": -421.91724906008636,
            "py": 1468.8446410664098,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning",
                "PaperDOI": "10.1109/TVCG.2012.272",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.272",
                "Firstpage": "2789",
                "Lastpage": "2798",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.",
                "AuthorNames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37884160900;38490270400;38490599200;38489620500;38490437100;38490180100",
                "Dedupedauthornames": "Block, F.;Horn, M.S.;Phillips, B.C.;Diamond, J.;Evans, E.M.;Chia Shen",
                "References": "10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541",
                "AuthorKeywords": "Informal science education, collaborative learning, large tree visualizations, multi-touch interaction",
                "IEEEXPLOREArticleNumberdeprecated": "6327285",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963285;636718;5290695;4376146;1173153;4658128;1173148;4376134"
            }
        },
        {
            "name": "Chen, M.",
            "value": 253,
            "numPapers": 82,
            "cluster": "9",
            "index": 352,
            "weight": 15,
            "x": -121.76324716228163,
            "y": 843.447283755961,
            "px": -168.73455952084774,
            "py": 880.2729654092375,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "An Empirical Study on Using Visual Embellishments in Visualization",
                "PaperDOI": "10.1109/TVCG.2012.197",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.197",
                "Firstpage": "2759",
                "Lastpage": "2768",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces divided attention, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.",
                "AuthorNames": "Borgo, R.;Abdul-Rahman, A.;Mohamed, F.;Grant, P.W.;Reppa, I.;Floridi, L.;Min Chen",
                "FirstAuthorAffiliation": "Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": "37591074800;38489317800;38489907300;37267321300;38489814200;38490006300;38273288300",
                "Dedupedauthornames": "Borgo, R.;Abdul-Rahman, A.;Mohamed, F.;Grant, P.W.;Reppa, I.;Floridi, L.;Chen, M.",
                "References": "10.1109/TVCG.2010.132;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.171;10.1109/TVCG.2011.175",
                "AuthorKeywords": "Visual embellishments, metaphors, icons, cognition, working memory, long-term memory, visual search, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "6327282",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613460;568118;4658138;6064986"
            }
        },
        {
            "name": "Drucker, S.",
            "value": 10,
            "numPapers": 29,
            "cluster": "0",
            "index": 353,
            "weight": 5,
            "x": 913.4516526783771,
            "y": 135.46576038718774,
            "px": 847.7636263201091,
            "py": 269.0173206680291,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Deeper Understanding of Sequence in Narrative Visualization",
                "PaperDOI": "10.1109/TVCG.2013.119",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.119",
                "Firstpage": "2406",
                "Lastpage": "2415",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.",
                "AuthorNames": "Hullman, J.;Drucker, S.;Riche, N.H.;Bongshin Lee;Fisher, D.;Adar, E.",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Hullman, J.;Drucker, S.;Riche, N.H.;Bongshin Lee;Fisher, D.;Adar, E.",
                "References": "10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/TVCG.2008.137;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70539;10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Data storytelling, narrative visualization, narrative structure",
                "IEEEXPLOREArticleNumberdeprecated": "6634182",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532788;4376131;4376133;5613452;4658129;6064988;4376187;4376146;885086"
            }
        },
        {
            "name": "Zgraggen, E.",
            "value": 0,
            "numPapers": 13,
            "cluster": "1",
            "index": 354,
            "weight": 1,
            "x": 423.5548238983116,
            "y": -887.8974482284733,
            "px": 406.860201245049,
            "py": -744.7635084964658,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Polaris: a system for query, analysis and visualization of multi-dimensional relational databases",
                "PaperDOI": "10.1109/INFVIS.2000.885086",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885086",
                "Firstpage": "5",
                "Lastpage": "14",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations",
                "AuthorNames": "Stolte, C.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37442008700;37349803800",
                "Dedupedauthornames": "Stolte, C.;Hanrahan, P.",
                "References": "10.1109/INFVIS.1996.559210",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885086",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559210"
            }
        },
        {
            "name": "Zeleznik, R.",
            "value": 0,
            "numPapers": 13,
            "cluster": "1",
            "index": 355,
            "weight": 1,
            "x": 44.7084649201331,
            "y": -73.41628434191543,
            "px": 80.8713681123782,
            "py": -8.251571087765216,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Polaris: a system for query, analysis and visualization of multi-dimensional relational databases",
                "PaperDOI": "10.1109/INFVIS.2000.885086",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885086",
                "Firstpage": "5",
                "Lastpage": "14",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In the last several years, large multi-dimensional databases have become common in a variety of applications such as data warehousing and scientific computing. Analysis and exploration tasks place significant demands on the interfaces to these databases. Because of the size of the data sets, dense graphical representations are more effective for exploration than spreadsheets and charts. Furthermore, because of the exploratory nature of the analysis, it must be possible for the analysts to change visualizations rapidly as they pursue a cycle involving first hypothesis and then experimentation. The authors present Polaris, an interface for exploring large multi-dimensional databases that extends the well-known Pivot Table interface. The novel features of Polaris include an interface for constructing visual specifications of table based graphical displays and the ability to generate a precise set of relational queries from the visual specifications. The visual specifications can be rapidly and incrementally developed, giving the analyst visual feedback as they construct complex queries and visualizations",
                "AuthorNames": "Stolte, C.;Hanrahan, P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37442008700;37349803800",
                "Dedupedauthornames": "Stolte, C.;Hanrahan, P.",
                "References": "10.1109/INFVIS.1996.559210",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885086",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559210"
            }
        },
        {
            "name": "Henry, N.",
            "value": 176,
            "numPapers": 18,
            "cluster": "0",
            "index": 356,
            "weight": 3,
            "x": 294.1638750876062,
            "y": 662.2613036620149,
            "px": 189.32027174625577,
            "py": 779.8142003152706,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Improving the Readability of Clustered Social Networks using Node Duplication",
                "PaperDOI": "10.1109/TVCG.2008.141",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.141",
                "Firstpage": "1317",
                "Lastpage": "1324",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.",
                "AuthorNames": "Henry, N.;Bezerianos, A.;Fekete, J.",
                "FirstAuthorAffiliation": "INRIA-LRI, Univ. of Sydney, Sydney, NSW|c|;;",
                "AuthorIDs": ";37413699200;37407972900",
                "Dedupedauthornames": "Henry, N.;Bezerianos, A.;Fekete, J.",
                "References": "10.1109/TVCG.2007.70582;10.1109/TVCG.2006.160;10.1109/VAST.2006.261426;10.1109/TVCG.2006.120;10.1109/INFVIS.1997.636792;10.1109/TVCG.2006.147;10.1109/INFVIS.2003.1249011",
                "AuthorKeywords": "Clustering, Graph Visualization, Node Duplications, Social Networks",
                "IEEEXPLOREArticleNumberdeprecated": "4658145",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376154;4015417;4035752;4015416;636792;4015425;1249011"
            }
        },
        {
            "name": "Bertini, E.",
            "value": 131,
            "numPapers": 70,
            "cluster": "5",
            "index": 357,
            "weight": 4,
            "x": 965.2102074747057,
            "y": 315.41168526799095,
            "px": 989.7158046463377,
            "py": 337.5810070075426,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization",
                "PaperDOI": "10.1109/TVCG.2011.229",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.229",
                "Firstpage": "2203",
                "Lastpage": "2212",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.",
                "AuthorNames": "Bertini, E.;Tatu, A.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;",
                "AuthorIDs": "37283307700;37590724000;37283138700",
                "Dedupedauthornames": "Bertini, E.;Tatu, A.;Keim, D.A.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/VAST.2010.5652433;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.161;10.1109/TVCG.2007.70515;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249006;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.138;10.1109/INFVIS.2004.59;10.1109/VAST.2009.5332628;10.1109/INFVIS.2003.1249015;10.1109/VAST.2010.5652450;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153;10.1109/INFVIS.1997.636794",
                "AuthorKeywords": "Quality Metrics, High-Dimensional Data Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6064985",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;5652433;4035766;5613439;5613452;1382895;4015421;4376144;1532142;146402;1249006;146386;4015422;1382903;5332628;1249015;5652450;4376143;729568;885092;1382892;5290704;636794"
            }
        },
        {
            "name": "Vuillemot, R.",
            "value": 58,
            "numPapers": 26,
            "cluster": "0",
            "index": 358,
            "weight": 1,
            "x": -1024.0022759457524,
            "y": 1349.1020701520479,
            "px": -875.4532881482597,
            "py": 1250.4878496046563,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "UpSet: Visualization of Intersecting Sets",
                "PaperDOI": "10.1109/TVCG.2014.2346248",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346248",
                "Firstpage": "1983",
                "Lastpage": "1992",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.",
                "AuthorNames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "FirstAuthorAffiliation": "Hendrik Strobelt & Hanspeter Pfister, Harvard Univ., Cambridge, MA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Lex, A.;Gehlenborg, N.;Strobelt, H.;Vuillemot, R.;Pfister, H.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183",
                "AuthorKeywords": "Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data",
                "IEEEXPLOREArticleNumberdeprecated": "6876017",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;6634104;6064991;5613447;5290706;6064996;6064990"
            }
        },
        {
            "name": "Zhenyu Guo",
            "value": 28,
            "numPapers": 13,
            "cluster": "0",
            "index": 359,
            "weight": 1,
            "x": 1832.3861598716094,
            "y": 361.35933460106264,
            "px": 1659.1392070766526,
            "py": 350.02601857272293,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Model space visualization for multivariate linear trend discovery",
                "PaperDOI": "10.1109/VAST.2009.5333431",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5333431",
                "Firstpage": "75",
                "Lastpage": "82",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations.",
                "AuthorNames": "Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Worcester Polytech. Inst., Worcester, MA, USA|c|;;",
                "AuthorIDs": "37668783300;37268441700;37279217900",
                "Dedupedauthornames": "Zhenyu Guo;Ward, M.O.;Rundensteiner, E.A.",
                "References": "10.1109/VAST.2008.4677350;10.1109/VAST.2007.4389000;10.1109/VAST.2008.4677363;10.1109/VAST.2007.4388999;10.1109/VISUAL.1990.146402;10.1109/VAST.2008.4677352;10.1109/VAST.2008.4677368",
                "AuthorKeywords": "Knowledge Discovery, visual analysis, multivariate linear model construction, model space visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5333431",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4677350;4389000;4677363;4388999;146402;4677352;4677368"
            }
        },
        {
            "name": "Mller, T.",
            "value": 88,
            "numPapers": 16,
            "cluster": "2",
            "index": 360,
            "weight": 3,
            "x": 308.11507395384257,
            "y": -145.9032838633671,
            "px": 344.66939262870494,
            "py": -79.23969395192393,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "DimStiller: Workflows for dimensional analysis and reduction",
                "PaperDOI": "10.1109/VAST.2010.5652392",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652392",
                "Firstpage": "3",
                "Lastpage": "10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.",
                "AuthorNames": "Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;Mller, T.",
                "FirstAuthorAffiliation": "Univ. of British Columbia, Vancouver, BC, Canada|c|;;;;;",
                "AuthorIDs": "37587716200;37349490300;37589529600;37275861300;37418878100;37275858700",
                "Dedupedauthornames": "Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;Mller, T.",
                "References": "10.1109/INFVIS.2003.1249013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2006.178;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.71",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652392",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249013;346302;4015439;1249015;5290704;1382893"
            }
        },
        {
            "name": "Tatu, A.",
            "value": 101,
            "numPapers": 37,
            "cluster": "5",
            "index": 361,
            "weight": 4,
            "x": 1119.8233447529497,
            "y": 249.99629899222074,
            "px": 1141.8906196344706,
            "py": 268.25316841919243,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Combining automated analysis and visualization techniques for effective exploration of high-dimensional data",
                "PaperDOI": "10.1109/VAST.2009.5332628",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332628",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.",
                "AuthorNames": "Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;;;;",
                "AuthorIDs": "37590724000;37603943800;37546817000;37669961800;37266875400;37273816400;37283138700",
                "Dedupedauthornames": "Tatu, A.;Albuquerque, G.;Eisemann, M.;Schneidewind, J.;Theisel, H.;Magnor, M.;Keim, D.A.",
                "References": "10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249017;10.1109/VISUAL.1994.346302;10.1109/VAST.2006.261423",
                "AuthorKeywords": "\n",
                "IEEEXPLOREArticleNumberdeprecated": "5332628",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532142;729568;1249017;346302;4035766"
            }
        },
        {
            "name": "Kriss, J.",
            "value": 172,
            "numPapers": 3,
            "cluster": "1",
            "index": 362,
            "weight": 1,
            "x": 712.9605109823767,
            "y": 576.2821610796783,
            "px": 728.3794240457077,
            "py": 571.7661705958049,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "ManyEyes: a Site for Visualization at Internet Scale",
                "PaperDOI": "10.1109/TVCG.2007.70577",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70577",
                "Firstpage": "1121",
                "Lastpage": "1128",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "FirstAuthorAffiliation": "IBM Res., Yorktown Heights|c|;;;;",
                "AuthorIDs": "37681355300;37550759700;37326291000;37830149600;37542455400",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "References": "10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1991.175820;10.1109/INFVIS.2003.1249007",
                "AuthorKeywords": "Visualization, World Wide Web, Social Software, Social Data Analysis, Communication-Minded Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4376131",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532122;175820;1249007"
            }
        },
        {
            "name": "McKeon, M.",
            "value": 186,
            "numPapers": 11,
            "cluster": "1",
            "index": 363,
            "weight": 2,
            "x": 735.7767364537436,
            "y": 589.7793632367566,
            "px": 729.7881115912974,
            "py": 586.1672840425974,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "ManyEyes: a Site for Visualization at Internet Scale",
                "PaperDOI": "10.1109/TVCG.2007.70577",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70577",
                "Firstpage": "1121",
                "Lastpage": "1128",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "FirstAuthorAffiliation": "IBM Res., Yorktown Heights|c|;;;;",
                "AuthorIDs": "37681355300;37550759700;37326291000;37830149600;37542455400",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;van Ham, F.;Kriss, J.;McKeon, M.",
                "References": "10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1991.175820;10.1109/INFVIS.2003.1249007",
                "AuthorKeywords": "Visualization, World Wide Web, Social Software, Social Data Analysis, Communication-Minded Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4376131",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532122;175820;1249007"
            }
        },
        {
            "name": "Kretschmer, J.",
            "value": 4,
            "numPapers": 8,
            "cluster": "2",
            "index": 364,
            "weight": 1,
            "x": -1129.3272513483546,
            "y": 1272.489850983547,
            "px": -1013.5671743564335,
            "py": 1164.860695378643,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "ADR - Anatomy-Driven Reformation",
                "PaperDOI": "10.1109/TVCG.2014.2346405",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346405",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",
                "AuthorNames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351",
                "AuthorKeywords": "Medical Visualization, Volume Reformation, Viewing Algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "6876018",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;6634141;964540;4376196;1183754;1250351"
            }
        },
        {
            "name": "Soza, G.",
            "value": 4,
            "numPapers": 6,
            "cluster": "2",
            "index": 365,
            "weight": 1,
            "x": 32.489541788466425,
            "y": 1480.4993583398948,
            "px": 37.90567090657038,
            "py": 1344.6645185377001,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "ADR - Anatomy-Driven Reformation",
                "PaperDOI": "10.1109/TVCG.2014.2346405",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346405",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",
                "AuthorNames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351",
                "AuthorKeywords": "Medical Visualization, Volume Reformation, Viewing Algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "6876018",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;6634141;964540;4376196;1183754;1250351"
            }
        },
        {
            "name": "Tietjen, C.",
            "value": 14,
            "numPapers": 6,
            "cluster": "2",
            "index": 366,
            "weight": 1,
            "x": 62.61372063361156,
            "y": -312.26492757007725,
            "px": 66.60375411030196,
            "py": -241.63142399776828,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "ADR - Anatomy-Driven Reformation",
                "PaperDOI": "10.1109/TVCG.2014.2346405",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346405",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",
                "AuthorNames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351",
                "AuthorKeywords": "Medical Visualization, Volume Reformation, Viewing Algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "6876018",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;6634141;964540;4376196;1183754;1250351"
            }
        },
        {
            "name": "Suehling, M.",
            "value": 4,
            "numPapers": 6,
            "cluster": "2",
            "index": 367,
            "weight": 1,
            "x": -165.1842835158253,
            "y": 1984.634109713259,
            "px": -143.30653054252866,
            "py": 1807.8128441695192,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "ADR - Anatomy-Driven Reformation",
                "PaperDOI": "10.1109/TVCG.2014.2346405",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346405",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",
                "AuthorNames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351",
                "AuthorKeywords": "Medical Visualization, Volume Reformation, Viewing Algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "6876018",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;6634141;964540;4376196;1183754;1250351"
            }
        },
        {
            "name": "Stamminger, M.",
            "value": 40,
            "numPapers": 18,
            "cluster": "2",
            "index": 368,
            "weight": 1,
            "x": 409.37161878602484,
            "y": -968.8857779972914,
            "px": 372.9569388302439,
            "py": -847.4174159755829,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "ADR - Anatomy-Driven Reformation",
                "PaperDOI": "10.1109/TVCG.2014.2346405",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346405",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",
                "AuthorNames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Kretschmer, J.;Soza, G.;Tietjen, C.;Suehling, M.;Preim, B.;Stamminger, M.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351",
                "AuthorKeywords": "Medical Visualization, Volume Reformation, Viewing Algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "6876018",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;6634141;964540;4376196;1183754;1250351"
            }
        },
        {
            "name": "Kniss, J.",
            "value": 308,
            "numPapers": 18,
            "cluster": "2",
            "index": 369,
            "weight": 8,
            "x": 297.2510922682284,
            "y": 190.97515878656898,
            "px": 299.72258564885436,
            "py": 200.29099757538245,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Statistically quantitative volume visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532807",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532807",
                "Firstpage": "287",
                "Lastpage": "294",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined \"fuzzy\" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.",
                "AuthorNames": "Kniss, J.M.;Van Uitert, R.;Stephens, A.;Li, G.-S.;Tasdizen, T.;Hansen, C.",
                "FirstAuthorAffiliation": "Utah Univ., Salt Lake City, UT, USA|c|;;;;;",
                "AuthorIDs": "37324263400;37266085500;37567174900;37558766900;37265762400;37266777200",
                "Dedupedauthornames": "Kniss, J.;Van Uitert, R.;Stephens, A.;Li, G.-S.;Tasdizen, T.;Hansen, C.",
                "References": "10.1109/VISUAL.2003.1250386;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2004.48;10.1109/VISUAL.1997.663875",
                "AuthorKeywords": "volume visualization, uncertainty, classification, risk analysis",
                "IEEEXPLOREArticleNumberdeprecated": "1532807",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250386;745311;1372190;663875"
            }
        },
        {
            "name": "Gunther, D.",
            "value": 15,
            "numPapers": 22,
            "cluster": "3",
            "index": 370,
            "weight": 4,
            "x": 195.29398175497298,
            "y": 754.6303414460127,
            "px": 207.0157319005215,
            "py": 757.6658351230067,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Characterizing Molecular Interactions in Chemical Systems",
                "PaperDOI": "10.1109/TVCG.2014.2346403",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346403",
                "Firstpage": "2476",
                "Lastpage": "2485",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.",
                "AuthorNames": "Gunther, D.;Boto, R.A.;Contreras-Garcia, J.;Piquemal, J.-P.;Tierny, J.",
                "FirstAuthorAffiliation": "Inst. Mines-Telecom, Telecom ParisTech, Paris, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Gunther, D.;Boto, R.A.;Contreras-Garcia, J.;Piquemal, J.-P.;Tierny, J.",
                "References": "10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250376;10.1109/TVCG.2008.110;10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2007.70578;10.1109/TVCG.2013.158",
                "AuthorKeywords": "Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree",
                "IEEEXPLOREArticleNumberdeprecated": "6875922",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290727;1372235;1250376;4658183;5290753;6064966;4376193;6634161"
            }
        },
        {
            "name": "Tierny, J.",
            "value": 28,
            "numPapers": 22,
            "cluster": "3",
            "index": 371,
            "weight": 4,
            "x": 332.6653898974388,
            "y": 600.6061560986819,
            "px": 372.48283342616685,
            "py": 574.752070224931,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Characterizing Molecular Interactions in Chemical Systems",
                "PaperDOI": "10.1109/TVCG.2014.2346403",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346403",
                "Firstpage": "2476",
                "Lastpage": "2485",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.",
                "AuthorNames": "Gunther, D.;Boto, R.A.;Contreras-Garcia, J.;Piquemal, J.-P.;Tierny, J.",
                "FirstAuthorAffiliation": "Inst. Mines-Telecom, Telecom ParisTech, Paris, France|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Gunther, D.;Boto, R.A.;Contreras-Garcia, J.;Piquemal, J.-P.;Tierny, J.",
                "References": "10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250376;10.1109/TVCG.2008.110;10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2007.70578;10.1109/TVCG.2013.158",
                "AuthorKeywords": "Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree",
                "IEEEXPLOREArticleNumberdeprecated": "6875922",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290727;1372235;1250376;4658183;5290753;6064966;4376193;6634161"
            }
        },
        {
            "name": "Levine, J.A.",
            "value": 10,
            "numPapers": 9,
            "cluster": "3",
            "index": 372,
            "weight": 2,
            "x": 372.76658218411757,
            "y": 667.512858797295,
            "px": 384.4230908370868,
            "py": 650.3679529548994,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations",
                "PaperDOI": "10.1109/TVCG.2012.286",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.286",
                "Firstpage": "2467",
                "Lastpage": "2476",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.",
                "AuthorNames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": ";;;;;;;;",
                "AuthorIDs": "38490116900;37853884500;37572974300;38490580100;37892085700;37290317700;37297252300;37564112000;37284312600",
                "Dedupedauthornames": "Landge, A.G.;Levine, J.A.;Bhatele, A.;Isaacs, K.E.;Gamblin, T.;Schulz, M.;Langer, S.;Bremer, P.-T.;Pascucci, V.",
                "References": "10.1109/TVCG.2009.196;10.1109/INFVIS.2004.66",
                "AuthorKeywords": "Performance analysis, network traffic visualization, projected graph layouts",
                "IEEEXPLOREArticleNumberdeprecated": "6327252",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290721;1382906"
            }
        },
        {
            "name": "Bringa, E.M.",
            "value": 40,
            "numPapers": 6,
            "cluster": "3",
            "index": 373,
            "weight": 1,
            "x": 373.1662239632542,
            "y": 665.3801129487285,
            "px": 341.2525412793064,
            "py": 656.0692401523175,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Topologically Clean Distance fields",
                "PaperDOI": "10.1109/TVCG.2007.70603",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70603",
                "Firstpage": "1432",
                "Lastpage": "1439",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.",
                "AuthorNames": "Gyulassy, A.G.;Duchaineau, M.A.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis|c|;;;;;;",
                "AuthorIDs": "37870001700;37267813100;37278509300;;37320622500;37848485600;37282068700",
                "Dedupedauthornames": "Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "References": "10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532783;10.1109/VISUAL.2003.1250356;10.1109/VISUAL.2004.96;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2000.885703",
                "AuthorKeywords": "Morse theory, Morse-Smale complex, distance field, topological simplification, wavefront, critical point, porous solid, material science",
                "IEEEXPLOREArticleNumberdeprecated": "4376171",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532839;1532783;1250356;1372235;885680;885703"
            }
        },
        {
            "name": "Higginbotham, A.",
            "value": 40,
            "numPapers": 6,
            "cluster": "3",
            "index": 374,
            "weight": 1,
            "x": 298.7434181902032,
            "y": 717.1958150822536,
            "px": 304.180145217597,
            "py": 722.4387643789439,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Topologically Clean Distance fields",
                "PaperDOI": "10.1109/TVCG.2007.70603",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70603",
                "Firstpage": "1432",
                "Lastpage": "1439",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the \"difference\" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.",
                "AuthorNames": "Gyulassy, A.G.;Duchaineau, M.A.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis|c|;;;;;;",
                "AuthorIDs": "37870001700;37267813100;37278509300;;37320622500;37848485600;37282068700",
                "Dedupedauthornames": "Gyulassy, A.;Duchaineau, M.;Vijay Natarajan;Pascucci, V.;Bringa, E.M.;Higginbotham, A.;Hamann, B.",
                "References": "10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532783;10.1109/VISUAL.2003.1250356;10.1109/VISUAL.2004.96;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2000.885703",
                "AuthorKeywords": "Morse theory, Morse-Smale complex, distance field, topological simplification, wavefront, critical point, porous solid, material science",
                "IEEEXPLOREArticleNumberdeprecated": "4376171",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532839;1532783;1250356;1372235;885680;885703"
            }
        },
        {
            "name": "Laney, D.",
            "value": 61,
            "numPapers": 17,
            "cluster": "3",
            "index": 375,
            "weight": 3,
            "x": 284.12731070552223,
            "y": 631.8343367100509,
            "px": 289.450616328563,
            "py": 634.1614926761174,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities",
                "PaperDOI": "10.1109/TVCG.2006.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.186",
                "Firstpage": "1053",
                "Lastpage": "1060",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",
                "AuthorNames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;",
                "AuthorIDs": "37281901900;37564112000;37284319900;;37284312600",
                "Dedupedauthornames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "References": "10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183772;10.1109/VISUAL.2005.1532842;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2004.107;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2005.1532839",
                "AuthorKeywords": "topology, multi-resolution, Morse theory",
                "IEEEXPLOREArticleNumberdeprecated": "4015464",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250376;1183772;1532842;885716;1372235;1250408;1372214;809907;745288;1532839"
            }
        },
        {
            "name": "Mascarenhas, A.",
            "value": 58,
            "numPapers": 11,
            "cluster": "3",
            "index": 376,
            "weight": 2,
            "x": 589.3111007272619,
            "y": 342.3762458675387,
            "px": 608.1634998033336,
            "py": 335.0577614120609,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities",
                "PaperDOI": "10.1109/TVCG.2006.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.186",
                "Firstpage": "1053",
                "Lastpage": "1060",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",
                "AuthorNames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;",
                "AuthorIDs": "37281901900;37564112000;37284319900;;37284312600",
                "Dedupedauthornames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "References": "10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183772;10.1109/VISUAL.2005.1532842;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2004.107;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2005.1532839",
                "AuthorKeywords": "topology, multi-resolution, Morse theory",
                "IEEEXPLOREArticleNumberdeprecated": "4015464",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250376;1183772;1532842;885716;1372235;1250408;1372214;809907;745288;1532839"
            }
        },
        {
            "name": "Miller, P.",
            "value": 56,
            "numPapers": 10,
            "cluster": "3",
            "index": 377,
            "weight": 2,
            "x": 62.24501692390168,
            "y": 845.9540591838319,
            "px": 71.90723834693095,
            "py": 846.5945246100582,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities",
                "PaperDOI": "10.1109/TVCG.2006.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.186",
                "Firstpage": "1053",
                "Lastpage": "1060",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",
                "AuthorNames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;",
                "AuthorIDs": "37281901900;37564112000;37284319900;;37284312600",
                "Dedupedauthornames": "Laney, D.;Bremer, P.-T.;Mascarenhas, A.;Miller, P.;Pascucci, V.",
                "References": "10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183772;10.1109/VISUAL.2005.1532842;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2004.107;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2005.1532839",
                "AuthorKeywords": "topology, multi-resolution, Morse theory",
                "IEEEXPLOREArticleNumberdeprecated": "4015464",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250376;1183772;1532842;885716;1372235;1250408;1372214;809907;745288;1532839"
            }
        },
        {
            "name": "Kirby, R.M.",
            "value": 181,
            "numPapers": 53,
            "cluster": "3",
            "index": 378,
            "weight": 5,
            "x": 248.59064605834342,
            "y": 188.7022467656259,
            "px": 295.0652447317816,
            "py": 56.87263461712199,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Visualizing Multivalued Data from 2D Incompressible Flows Using Concepts from Painting",
                "PaperDOI": "10.1109/VISUAL.1999.809905",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809905",
                "Firstpage": "333",
                "Lastpage": "540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a new visualization method for 2D flows which allows us to combine multiple data values in an image for simultaneous viewing. We utilize concepts from oil painting, art and design as introduced in (Laidlaw et al., 1998) to examine problems within fluid mechanics. We use a combination of discrete and continuous visual elements arranged in multiple layers to visually represent the data. The representations are inspired by the brush strokes artists apply in layers to create an oil painting. We display commonly visualized quantities such as velocity and vorticity together with three additional mathematically derived quantities: the rate of strain tensor, and the turbulent charge and turbulent current. We describe the motivation for simultaneously examining these quantities and use the motivation to guide our choice of visual representation for each particular quantity. We present visualizations of three flow examples and observations concerning some of the physical relationships made apparent by the simultaneous display technique that we employed.",
                "AuthorNames": "Kirby, R.M.;Marmanis, H.;Laidlaw, D.H.",
                "FirstAuthorAffiliation": "Div. of Appl. Math., Brown Univ., Providence, RI, USA|c|;;",
                "AuthorIDs": "37275716100;37442720100;37275712600",
                "Dedupedauthornames": "Kirby, R.M.;Marmanis, H.;Laidlaw, D.H.",
                "References": "10.1109/VISUAL.1998.745294",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809905",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745294"
            }
        },
        {
            "name": "Tricoche, X.",
            "value": 324,
            "numPapers": 88,
            "cluster": "3",
            "index": 379,
            "weight": 38,
            "x": 203.8088586958875,
            "y": 493.3347508316508,
            "px": 209.23209979628362,
            "py": 485.82950145998507,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Invariant Crease Lines for Topological and Structural Analysis of Tensor fields",
                "PaperDOI": "10.1109/TVCG.2008.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.148",
                "Firstpage": "1627",
                "Lastpage": "1634",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.",
                "AuthorNames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;",
                "AuthorIDs": "37282575100;37282742400;37294318400",
                "Dedupedauthornames": "Tricoche, X.;Kindlmann, G.;Westin, C.-F.",
                "References": "10.1109/VISUAL.2004.105;10.1109/TVCG.2007.70602;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1990.146359;10.1109/TVCG.2007.70554",
                "AuthorKeywords": "Tensor fields, tensor invariants, ridge lines, crease extraction, structural analysis, topology",
                "IEEEXPLOREArticleNumberdeprecated": "4658184",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372212;4376179;809896;175773;346326;346326;146359;4376174"
            }
        },
        {
            "name": "Reininghaus, J.",
            "value": 27,
            "numPapers": 12,
            "cluster": "3",
            "index": 380,
            "weight": 1,
            "x": 294.76047703886167,
            "y": 595.0764940418309,
            "px": 297.36637697910265,
            "py": 615.1331638042876,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Two-Dimensional Time-Dependent Vortex Regions Based on the Acceleration Magnitude",
                "PaperDOI": "10.1109/TVCG.2011.249",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.249",
                "Firstpage": "2080",
                "Lastpage": "2087",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Acceleration is a fundamental quantity of flow fields that captures Galilean invariant properties of particle motion. Considering the magnitude of this field, minima represent characteristic structures of the flow that can be classified as saddle- or vortex-like. We made the interesting observation that vortex-like minima are enclosed by particularly pronounced ridges. This makes it possible to define boundaries of vortex regions in a parameter-free way. Utilizing scalar field topology, a robust algorithm can be designed to extract such boundaries. They can be arbitrarily shaped. An efficient tracking algorithm allows us to display the temporal evolution of vortices. Various vortex models are used to evaluate the method. We apply our method to two-dimensional model systems from computational fluid dynamics and compare the results to those arising from existing definitions.",
                "AuthorNames": "Kasten, J.;Reininghaus, J.;Hotz, I.;Hege, H.-C.",
                "FirstAuthorAffiliation": "Zuse Inst. Berlin, Berlin, Germany|c|;;;",
                "AuthorIDs": "38028453100;37590998600;37282721800;37282272000",
                "Dedupedauthornames": "Kasten, J.;Reininghaus, J.;Hotz, I.;Hege, H.-C.",
                "References": "10.1109/VISUAL.2005.1532830;10.1109/VISUAL.2004.107;10.1109/TVCG.2008.143;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2006.201",
                "AuthorKeywords": "Vortex regions, time-dependent flow fields, feature extraction",
                "IEEEXPLOREArticleNumberdeprecated": "6064972",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532830;1372214;4658165;1183821;4015452"
            }
        },
        {
            "name": "Isenburg, M.",
            "value": 47,
            "numPapers": 17,
            "cluster": "3",
            "index": 381,
            "weight": 1,
            "x": 248.2851501116735,
            "y": 649.671790571745,
            "px": 237.36932289625156,
            "py": 655.9016012487192,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Fast and Efficient Compression of Floating-Point Data",
                "PaperDOI": "10.1109/TVCG.2006.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.143",
                "Firstpage": "1245",
                "Lastpage": "1250",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data",
                "AuthorNames": "Lindstrom, P.;Isenburg, M.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;",
                "AuthorIDs": "37269320000;37281897600",
                "Dedupedauthornames": "Lindstrom, P.;Isenburg, M.",
                "References": "10.1109/VISUAL.1999.809868;10.1109/VISUAL.2000.885711;10.1109/VISUAL.2002.1183768;10.1109/VISUAL.1996.568138",
                "AuthorKeywords": "High throughput, lossless compression, file compaction for I/O efficiency, fast entropy coding, range coder, predictive coding, large scale simulation and visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015488",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809867;885711;1183768;568138"
            }
        },
        {
            "name": "Johnson, C.R.",
            "value": 156,
            "numPapers": 46,
            "cluster": "2",
            "index": 382,
            "weight": 11,
            "x": 214.84374050448764,
            "y": 101.44997428217546,
            "px": 210.73347822736335,
            "py": 91.11289461574746,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Differential volume rendering: a fast volume visualization technique for flow animation",
                "PaperDOI": "10.1109/VISUAL.1994.346321",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346321",
                "Firstpage": "180",
                "Lastpage": "187, C20",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a direct volume rendering algorithm to speed up volume animation for flow visualizations. Data coherency between consecutive simulation time steps is used to avoid casting rays from those pixels retaining color values assigned to the previous image. The algorithm calculates the differential information among a sequence of 3D volumetric simulation data. At each time step the differential information is used to compute the locations of pixels that need updating and a ray-casting method as utilized to produce the updated image. We illustrate the utility and speed of the differential volume rendering algorithm with simulation data from computational bioelectric and fluid dynamics applications. We can achieve considerable disk-space savings and nearly real-time rendering of 3D flows using low-cost, single processor workstations for models which contain hundreds of thousands of data points",
                "AuthorNames": "Han-Wei Shen;Johnson, C.R.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;",
                "AuthorIDs": "37350367200;37276931400",
                "Dedupedauthornames": "Han-Wei Shen;Johnson, C.R.",
                "References": "10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1992.235210;10.1109/VISUAL.1991.175772;10.1109/VISUAL.1993.398852;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1993.398846",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346321",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398877;235227;235210;175772;398852;175773;398846"
            }
        },
        {
            "name": "Thomas, D.M.",
            "value": 27,
            "numPapers": 18,
            "cluster": "3",
            "index": 383,
            "weight": 2,
            "x": 361.48849259647955,
            "y": 618.5429490636161,
            "px": 355.3706691092421,
            "py": 594.9641555332191,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Multiscale Symmetry Detection in Scalar Fields by Clustering Contours",
                "PaperDOI": "10.1109/TVCG.2014.2346332",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346332",
                "Firstpage": "2427",
                "Lastpage": "2436",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.",
                "AuthorNames": "Thomas, D.M.;Natarajan, V.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Thomas, D.M.;Natarajan, V.",
                "References": "10.1109/TVCG.2013.142;10.1109/VISUAL.1999.809869;10.1109/TVCG.2006.149;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.258;10.1109/TVCG.2013.148",
                "AuthorKeywords": "Scalar field visualization, symmetry detection, contour tree, data exploration",
                "IEEEXPLOREArticleNumberdeprecated": "6875976",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634132;809869;4015483;6064967;4658165;6064960;6634095"
            }
        },
        {
            "name": "La Mar, E.C.",
            "value": 62,
            "numPapers": 0,
            "cluster": "2",
            "index": 384,
            "weight": 1,
            "x": 409.0450130901528,
            "y": -236.0618600680762,
            "px": 347.2559803771429,
            "py": -157.14903729716553,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multiresolution Techniques for Interactive Texture-based Volume Visualization",
                "PaperDOI": "10.1109/VISUAL.1999.809908",
                "Link": "http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809908",
                "Firstpage": "355",
                "Lastpage": "",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a multiresolution technique for interactive texture-basedvolume visualization of very large data sets. This method uses anadaptive scheme that renders the volume in a region-of-interest ata high resolution and the volume away from this region at progressivelylower resolutions. The algorithm is based on the segmentationof texture space into an octree, where the leaves of the tree definethe original data and the internal nodes define lower-resolutionversions. Rendering is done adaptively by selecting high-resolutioncells close to a center of attention and low-resolution cells awayfrom this area. We limit the artifacts introduced by this method bymodifying the transfer functions in the lower-resolution data setsand utilizing spherical shells as a proxy geometry. It is possibleto use this technique to produce viewpoint-dependent renderings ofvery large data sets.",
                "AuthorNames": "La Mar, E. C.;Hamann, B.;Joy K. I.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "Dedupedauthornames": "La Mar, E.C.;Hamann, B.;Joy, K.I.",
                "References": "",
                "AuthorKeywords": "multiresolution rendering, volume visualization, hardware texture",
                "IEEEXPLOREArticleNumberdeprecated": "809908",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Born, S.",
            "value": 32,
            "numPapers": 19,
            "cluster": "2",
            "index": 385,
            "weight": 1,
            "x": -294.071698745669,
            "y": -145.5257018600334,
            "px": -242.43006091779495,
            "py": -99.99569478059331,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "Firstpage": "1515",
                "Lastpage": "1522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/VISUAL.1992.235203;10.1109/TVCG.2007.70576;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964538;10.1109/TVCG.2007.70560;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250396",
                "AuthorKeywords": "Vessel visualization, plaque growth, multipath CPR, vessel flattening",
                "IEEEXPLOREArticleNumberdeprecated": "5290768",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "McCormick, P.",
            "value": 54,
            "numPapers": 5,
            "cluster": "2",
            "index": 386,
            "weight": 1,
            "x": -741.9800786284759,
            "y": 1044.5231699350165,
            "px": -658.3523447394821,
            "py": 954.1349722059414,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Scout: a hardware-accelerated system for quantitatively driven visualization and analysis",
                "PaperDOI": "10.1109/VISUAL.2004.95",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.95",
                "Firstpage": "171",
                "Lastpage": "178",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Quantitative techniques for visualization are critical to the successful analysis of both acquired and simulated scientific data. Many visualization techniques rely on indirect mappings, such as transfer functions, to produce the final imagery. In many situations, it is preferable and more powerful to express these mappings as mathematical expressions, or queries, that can then be directly applied to the data. We present a hardware-accelerated system that provides such capabilities and exploits current graphics hardware for portions of the computational tasks that would otherwise be executed on the CPU. In our approach, the direct programming of the graphics processor using a concise data parallel language, gives scientists the capability to efficiently explore and visualize data sets.",
                "AuthorNames": "McCormick, P.S.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.",
                "FirstAuthorAffiliation": "Advanced Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;",
                "AuthorIDs": "37282708700;37282707800;37282713700;37266777200;37269487100",
                "Dedupedauthornames": "McCormick, P.;Inman, J.;Ahrens, J.;Hansen, C.;Roth, G.",
                "References": "10.1109/VISUAL.1995.480821;10.1109/VISUAL.1999.809864;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250357",
                "AuthorKeywords": "Visualization systems, hardware acceleration, multi-variate visualization, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1372194",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480821;809864;964519;1250357"
            }
        },
        {
            "name": "Bista, S.",
            "value": 2,
            "numPapers": 11,
            "cluster": "2",
            "index": 387,
            "weight": 1,
            "x": 2087.8254858859837,
            "y": 1569.6696333652583,
            "px": 1880.524245489738,
            "py": 1424.5785144094507,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields",
                "PaperDOI": "10.1109/TVCG.2014.2346411",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346411",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.",
                "AuthorNames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "References": "10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148",
                "AuthorKeywords": "Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields",
                "IEEEXPLOREArticleNumberdeprecated": "6875910",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634193;4376179;5613502;6327240;809886;1372208;4658153;1372209;1372186;6064942;4658184"
            }
        },
        {
            "name": "Jiachen Zhuo",
            "value": 2,
            "numPapers": 11,
            "cluster": "2",
            "index": 388,
            "weight": 1,
            "x": 220.6630553322538,
            "y": -779.824764362319,
            "px": 192.65261004747438,
            "py": -680.1780374648624,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields",
                "PaperDOI": "10.1109/TVCG.2014.2346411",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346411",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.",
                "AuthorNames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "References": "10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148",
                "AuthorKeywords": "Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields",
                "IEEEXPLOREArticleNumberdeprecated": "6875910",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634193;4376179;5613502;6327240;809886;1372208;4658153;1372209;1372186;6064942;4658184"
            }
        },
        {
            "name": "Gullapalli, R.P.",
            "value": 2,
            "numPapers": 11,
            "cluster": "2",
            "index": 389,
            "weight": 1,
            "x": 327.59398846433163,
            "y": 130.2961450561725,
            "px": 274.9131204874234,
            "py": 126.61900491762121,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields",
                "PaperDOI": "10.1109/TVCG.2014.2346411",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346411",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.",
                "AuthorNames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "References": "10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148",
                "AuthorKeywords": "Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields",
                "IEEEXPLOREArticleNumberdeprecated": "6875910",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634193;4376179;5613502;6327240;809886;1372208;4658153;1372209;1372186;6064942;4658184"
            }
        },
        {
            "name": "Varshney, A.",
            "value": 168,
            "numPapers": 51,
            "cluster": "3",
            "index": 390,
            "weight": 5,
            "x": 296.95075324380633,
            "y": 607.5123472041182,
            "px": 299.3822764675138,
            "py": 587.8914446997036,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields",
                "PaperDOI": "10.1109/TVCG.2014.2346411",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346411",
                "Firstpage": "2516",
                "Lastpage": "2525",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.",
                "AuthorNames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "FirstAuthorAffiliation": "Univ. of Maryland, College Park, MD, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Bista, S.;Jiachen Zhuo;Gullapalli, R.P.;Varshney, A.",
                "References": "10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148",
                "AuthorKeywords": "Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields",
                "IEEEXPLOREArticleNumberdeprecated": "6875910",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634193;4376179;5613502;6327240;809886;1372208;4658153;1372209;1372186;6064942;4658184"
            }
        },
        {
            "name": "Jianguang Weng",
            "value": 3,
            "numPapers": 9,
            "cluster": "7",
            "index": 391,
            "weight": 2,
            "x": 1450.0557810242824,
            "y": 527.5460086088481,
            "px": 1444.2666999319397,
            "py": 519.734120864779,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves",
                "PaperDOI": "10.1109/TVCG.2012.242",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.242",
                "Firstpage": "2051",
                "Lastpage": "2060",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.",
                "AuthorNames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "FirstAuthorAffiliation": "Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;;",
                "AuthorIDs": "38490442700;38490274900;38489766500;38490597900",
                "Dedupedauthornames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "References": "10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2007.70593",
                "AuthorKeywords": "Knot Theory, Math Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6327209",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532804;1532843;4376203"
            }
        },
        {
            "name": "Hui Zhang",
            "value": 27,
            "numPapers": 12,
            "cluster": "7",
            "index": 392,
            "weight": 2,
            "x": 1478.5624839738787,
            "y": 524.8727632309538,
            "px": 1462.6419716377543,
            "py": 511.0858842933864,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves",
                "PaperDOI": "10.1109/TVCG.2012.242",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.242",
                "Firstpage": "2051",
                "Lastpage": "2060",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.",
                "AuthorNames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "FirstAuthorAffiliation": "Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;;",
                "AuthorIDs": "38490442700;38490274900;38489766500;38490597900",
                "Dedupedauthornames": "Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong",
                "References": "10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2007.70593",
                "AuthorKeywords": "Knot Theory, Math Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6327209",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532804;1532843;4376203"
            }
        },
        {
            "name": "Hanson, A.J.",
            "value": 185,
            "numPapers": 58,
            "cluster": "7",
            "index": 393,
            "weight": 16,
            "x": 1314.895501284716,
            "y": 472.3947925242056,
            "px": 1309.0077732197303,
            "py": 464.21614200036686,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Multimodal exploration of the fourth dimension",
                "PaperDOI": "10.1109/VISUAL.2005.1532804",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532804",
                "Firstpage": "263",
                "Lastpage": "270",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.",
                "AuthorNames": "Hanson, A.J.;Hui Zhang",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37333439100;37559775500",
                "Dedupedauthornames": "Hanson, A.J.;Hui Zhang",
                "References": "10.1109/VISUAL.1995.480804",
                "AuthorKeywords": " multimodal, haptics, visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1532804",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480804"
            }
        },
        {
            "name": "Jiaxi Hu",
            "value": 10,
            "numPapers": 10,
            "cluster": "11",
            "index": 394,
            "weight": 2,
            "x": 710.9512005789793,
            "y": -151.41579405665232,
            "px": 629.3187993052782,
            "py": -122.8346264955978,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Geodesic Distance-weighted Shape Vector Image Diffusion",
                "PaperDOI": "10.1109/TVCG.2008.134",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.134",
                "Firstpage": "1643",
                "Lastpage": "1650",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",
                "AuthorNames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "FirstAuthorAffiliation": "Wayne State Univ., Detroit, MI|c|;;;;",
                "AuthorIDs": "37285799200;37868989800;37290589700;37276603700;37276553900",
                "Dedupedauthornames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "References": "",
                "AuthorKeywords": "Surface Matching, Shape Vector Image, Multiscale Diffusion, Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4658186",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Jing Hua",
            "value": 68,
            "numPapers": 18,
            "cluster": "11",
            "index": 395,
            "weight": 4,
            "x": 845.9203361029284,
            "y": 5.212261322626233,
            "px": 648.3597982353248,
            "py": 89.1601432587172,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Exemplar-based Visualization of Large Document Corpus",
                "PaperDOI": "10.1109/TVCG.2009.140",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.140",
                "Firstpage": "1161",
                "Lastpage": "1168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.",
                "AuthorNames": "Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;;",
                "AuthorIDs": "37965966100;37900114200;37290589700;37285799200",
                "Dedupedauthornames": "Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua",
                "References": "10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.138",
                "AuthorKeywords": "Exemplar, large-scale document visualization, multidimensional projection",
                "IEEEXPLOREArticleNumberdeprecated": "5290725",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809866;4658134"
            }
        },
        {
            "name": "Zhaoqiang Lai",
            "value": 18,
            "numPapers": 1,
            "cluster": "11",
            "index": 396,
            "weight": 1,
            "x": 2449.4874742045886,
            "y": -42.74186778469239,
            "px": 2062.6327373504623,
            "py": 308.36047240815105,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Geodesic Distance-weighted Shape Vector Image Diffusion",
                "PaperDOI": "10.1109/TVCG.2008.134",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.134",
                "Firstpage": "1643",
                "Lastpage": "1650",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",
                "AuthorNames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "FirstAuthorAffiliation": "Wayne State Univ., Detroit, MI|c|;;;;",
                "AuthorIDs": "37285799200;37868989800;37290589700;37276603700;37276553900",
                "Dedupedauthornames": "Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin",
                "References": "",
                "AuthorKeywords": "Surface Matching, Shape Vector Image, Multiscale Diffusion, Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4658186",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Ming Dong",
            "value": 48,
            "numPapers": 3,
            "cluster": "11",
            "index": 397,
            "weight": 1,
            "x": 1759.0558154663768,
            "y": 585.8421142250929,
            "px": 1465.245978177417,
            "py": 845.5974243957163,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Exemplar-based Visualization of Large Document Corpus",
                "PaperDOI": "10.1109/TVCG.2009.140",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.140",
                "Firstpage": "1161",
                "Lastpage": "1168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.",
                "AuthorNames": "Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;;",
                "AuthorIDs": "37965966100;37900114200;37290589700;37285799200",
                "Dedupedauthornames": "Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua",
                "References": "10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.138",
                "AuthorKeywords": "Exemplar, large-scale document visualization, multidimensional projection",
                "IEEEXPLOREArticleNumberdeprecated": "5290725",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809866;4658134"
            }
        },
        {
            "name": "Jian Zhao",
            "value": 84,
            "numPapers": 43,
            "cluster": "1",
            "index": 398,
            "weight": 2,
            "x": -130.17088027268602,
            "y": 873.4270031214212,
            "px": -229.4729648231342,
            "py": 885.2798306140652,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Exploratory Analysis of Time-Series with ChronoLenses",
                "PaperDOI": "10.1109/TVCG.2011.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.195",
                "Firstpage": "2422",
                "Lastpage": "2431",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.",
                "AuthorNames": "Jian Zhao;Chevalier, F.;Pietriga, E.;Balakrishnan, R.",
                "FirstAuthorAffiliation": "DGP, Univ. of Toronto, Toronto, ON, Canada|c|;;;",
                "AuthorIDs": "38024987300;37395495900;37563810700;37394495600",
                "Dedupedauthornames": "Jian Zhao;Chevalier, F.;Pietriga, E.;Balakrishnan, R.",
                "References": "10.1109/TVCG.2010.162;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389007;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2007.70583;10.1109/TVCG.2010.193",
                "AuthorKeywords": "Time-series Data, Exploratory Visualization, Focus+Context, Lens, Interaction Techniques",
                "IEEEXPLOREArticleNumberdeprecated": "6065009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613429;801851;4389007;963273;1532148;4376151;5613426"
            }
        },
        {
            "name": "Chao Han",
            "value": 49,
            "numPapers": 0,
            "cluster": "0",
            "index": 399,
            "weight": 1,
            "x": 1011.0967238834046,
            "y": 610.2881020630165,
            "px": 912.6753339306451,
            "py": 546.1021595390797,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "Firstpage": "121",
                "Lastpage": "130",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus observation) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "References": "",
                "AuthorKeywords": "observation-level interaction, visual analytics, statistical models",
                "IEEEXPLOREArticleNumberdeprecated": "6102449",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Maiti, D.",
            "value": 67,
            "numPapers": 5,
            "cluster": "0",
            "index": 400,
            "weight": 1,
            "x": 1363.365461470772,
            "y": 457.0517373702475,
            "px": 1221.8659356049227,
            "py": 419.7946146534519,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "Firstpage": "121",
                "Lastpage": "130",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus observation) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "References": "",
                "AuthorKeywords": "observation-level interaction, visual analytics, statistical models",
                "IEEEXPLOREArticleNumberdeprecated": "6102449",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "House, L.",
            "value": 67,
            "numPapers": 5,
            "cluster": "0",
            "index": 401,
            "weight": 1,
            "x": 1437.6073759511194,
            "y": 353.70307819530456,
            "px": 1286.4150532530296,
            "py": 331.50792300143337,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "Firstpage": "121",
                "Lastpage": "130",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus observation) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "References": "",
                "AuthorKeywords": "observation-level interaction, visual analytics, statistical models",
                "IEEEXPLOREArticleNumberdeprecated": "6102449",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Leman, S.",
            "value": 74,
            "numPapers": 11,
            "cluster": "0",
            "index": 402,
            "weight": 2,
            "x": 1323.854792901385,
            "y": 378.35025995147555,
            "px": 1279.667930895874,
            "py": 379.57341747816355,
            "node": {
                "Conference": "VAST",
                "Year": "2011",
                "PaperTitle": "Observation-level interaction with statistical models for visual analytics",
                "PaperDOI": "10.1109/VAST.2011.6102449",
                "Link": "http://dx.doi.org/10.1109/VAST.2011.6102449",
                "Firstpage": "121",
                "Lastpage": "130",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus observation) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.",
                "AuthorNames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37681759500;38238038000;38232394400;38241765600;38236156800;37419565900",
                "Dedupedauthornames": "Endert, A.;Chao Han;Maiti, D.;House, L.;Leman, S.;North, C.",
                "References": "",
                "AuthorKeywords": "observation-level interaction, visual analytics, statistical models",
                "IEEEXPLOREArticleNumberdeprecated": "6102449",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Wei Chen",
            "value": 97,
            "numPapers": 114,
            "cluster": "2",
            "index": 403,
            "weight": 12,
            "x": 387.1690355392014,
            "y": 128.96461585755782,
            "px": 423.30839572886146,
            "py": 123.86745397242521,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "BoundarySeer: Visual Analysis of 2D Boundary Changes",
                "PaperDOI": "10.1109/VAST.2014.7042490",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042490",
                "Firstpage": "143",
                "Lastpage": "152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.",
                "AuthorNames": "Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Groller, E.;Lionel Ni",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Groller, E.;Lionel Ni",
                "References": "10.1109/TVCG.2013.230;10.1109/INFVIS.2004.27;10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.239;10.1109/TVCG.2008.166;10.1109/INFVIS.2005.1532149;10.1109/TVCG.2013.213;10.1109/TVCG.2012.265;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70561",
                "AuthorKeywords": "Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization",
                "IEEEXPLOREArticleNumberdeprecated": "7042490",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634092;1382887;963273;6065008;4658136;1532149;6634107;6327262;4376143;4658146;4376139"
            }
        },
        {
            "name": "Ronghua Liang",
            "value": 16,
            "numPapers": 15,
            "cluster": "1",
            "index": 404,
            "weight": 2,
            "x": -48.72600957594746,
            "y": 1032.558922146803,
            "px": -143.10476836091732,
            "py": 1057.963602516775,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "Firstpage": "1753",
                "Lastpage": "1762",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cooperation and competition (jointly called coopetition) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., topic leaders) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "References": "10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Topic coopetition, information diffusion, information propagation, time-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6875992",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6327271;4658136;6065008;6327273;6876032;6634134;6634164;6634160"
            }
        },
        {
            "name": "Hujun Bao",
            "value": 4,
            "numPapers": 19,
            "cluster": "2",
            "index": 405,
            "weight": 1,
            "x": 13887.132344044741,
            "y": 5772.846432950531,
            "px": 12707.295438769688,
            "py": 5261.309271333778,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Structure-Aware Lighting Design for Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2012.267",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.267",
                "Firstpage": "2372",
                "Lastpage": "2381",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.",
                "AuthorNames": "Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao",
                "FirstAuthorAffiliation": "State Key Lab. of CAD&amp;CG, Zhejiang Univ., Hangzhou, China|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao",
                "References": "10.1109/TVCG.2006.137;10.1109/TVCG.2011.218;10.1109/VISUAL.2004.62;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2003.1250395;10.1109/VISUAL.2002.1183785",
                "AuthorKeywords": "Automatic lighting design, structural dissimilarity, lighting similarity, lighting stability, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "6327242",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015471;6064959;1372208;1532834;1532833;1250395;1183785"
            }
        },
        {
            "name": "Malik, A.",
            "value": 55,
            "numPapers": 30,
            "cluster": "0",
            "index": 406,
            "weight": 4,
            "x": 47.12166233714075,
            "y": 615.8872444292704,
            "px": -76.66400772196651,
            "py": 701.1831650016541,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration",
                "PaperDOI": "10.1109/VAST.2014.7042484",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042484",
                "Firstpage": "83",
                "Lastpage": "92",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.",
                "AuthorNames": "Sungahn Ko;Afzal, S.;Walton, S.;Yang Yang;Junghoon Chae;Malik, A.;Yun Jang;Min Chen;Ebert, D.",
                "FirstAuthorAffiliation": "Purdue University|c|;;;;;;;;",
                "AuthorIDs": ";;;;;;;;",
                "Dedupedauthornames": "Sungahn Ko;Afzal, S.;Walton, S.;Yang Yang;Junghoon Chae;Malik, A.;Yun Jang;Chen, M.;Ebert, D.S.",
                "References": "10.1109/VAST.2012.6400554;10.1109/TVCG.2010.150;10.1109/TVCG.2007.70582;10.1109/TVCG.2011.190;10.1109/VAST.2011.6102440;10.1109/TVCG.2009.143;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.166;10.1109/VAST.2007.4389013",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "7042484",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6400554;5613433;4376154;6065002;6102440;5290710;801851;4015424;4389013"
            }
        },
        {
            "name": "Dix, A.",
            "value": 144,
            "numPapers": 20,
            "cluster": "1",
            "index": 407,
            "weight": 3,
            "x": 1086.38095076904,
            "y": 398.54943843725334,
            "px": 1031.7971637251815,
            "py": 404.45833079637305,
            "node": {
                "Conference": "InfoVis",
                "Year": "2007",
                "PaperTitle": "A Taxonomy of Clutter Reduction for Information Visualisation",
                "PaperDOI": "10.1109/TVCG.2007.70535",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70535",
                "Firstpage": "1216",
                "Lastpage": "1223",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.",
                "AuthorNames": "Ellis, G.;Dix, A.",
                "FirstAuthorAffiliation": "Lancaster Univ, Lancaster|c|;",
                "AuthorIDs": "37283380700;37283381700",
                "Dedupedauthornames": "Ellis, G.;Dix, A.",
                "References": "10.1109/INFVIS.2003.1249018;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.138;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1998.745301;10.1109/INFVIS.1997.636789;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249019;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1995.528685;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.170",
                "AuthorKeywords": "Clutter reduction, information visualisation, occlusion, large datasets, taxonomy",
                "IEEEXPLOREArticleNumberdeprecated": "4376143",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249018;885092;4015422;1532819;1249008;809866;885091;745301;636789;1173156;1249019;636792;528685;1382895;4015444"
            }
        },
        {
            "name": "Fisher, D.",
            "value": 213,
            "numPapers": 29,
            "cluster": "0",
            "index": 408,
            "weight": 6,
            "x": 1076.7534282609083,
            "y": 78.98941500992412,
            "px": 1105.0930197985674,
            "py": 72.42279168659208,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "A Comparison of User-Generated and Automatic Graph Layouts",
                "PaperDOI": "10.1109/TVCG.2009.109",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.109",
                "Firstpage": "961",
                "Lastpage": "968",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.",
                "AuthorNames": "Dwyer, T.;Bongshin Lee;Fisher, D.;Quinn, K.I.;Isenberg, P.;Robertson, G.;North, C.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": "37326161000;37293389400;37542391000;38108819900;37591317800;37448060300;37419565900",
                "Dedupedauthornames": "Dwyer, T.;Bongshin Lee;Fisher, D.;Quinn, K.I.;Isenberg, P.;Robertson, G.;North, C.",
                "References": "10.1109/TVCG.2008.155",
                "AuthorKeywords": "Graph layout, network layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics",
                "IEEEXPLOREArticleNumberdeprecated": "5290700",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658147"
            }
        },
        {
            "name": "van Liere, R.",
            "value": 138,
            "numPapers": 27,
            "cluster": "3",
            "index": 409,
            "weight": 3,
            "x": -839.3158660704171,
            "y": 394.7140178860529,
            "px": -932.0247815967364,
            "py": 397.44956630895604,
            "node": {
                "Conference": "Vis",
                "Year": "1993",
                "PaperTitle": "HyperSlice - Visualization of Scalar Functions of Many Variables",
                "PaperDOI": "10.1109/VISUAL.1993.398859",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398859",
                "Firstpage": "119",
                "Lastpage": "125",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "HyperSlice is a new method for the visualization of scalar functions of many variables. With this method the multi-dimensional function is presented in a simple and easy to understand way in which all dimensions are treated identically. The central concept is the representation of a multi-dimensional function as a matrix of orthogonal two-dimensional slices. These two-dimensional slices lend themselves very well to interaction via direct manipulation, due to a one to one relation between screen space and variable space. Several interaction techniques, for navigation, the location of maxima, and the use of user-defined paths, are presented",
                "AuthorNames": "van Wijk, J.J.;van Liere, R.",
                "FirstAuthorAffiliation": "Netherlands Energy Res. Foundation, Petten, Netherlands|c|;",
                "AuthorIDs": "37267249200;37282925600",
                "Dedupedauthornames": "van Wijk, J.J.;van Liere, R.",
                "References": "10.1109/VISUAL.1990.146387;10.1109/VISUAL.1991.175809",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "398859",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146387;175809"
            }
        },
        {
            "name": "Pak Chung Wong",
            "value": 281,
            "numPapers": 56,
            "cluster": "5",
            "index": 410,
            "weight": 20,
            "x": 1080.8851369737797,
            "y": 194.14873167375134,
            "px": 1046.666529097016,
            "py": 244.76357278666222,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "Multiresolution multidimensional wavelet brushing",
                "PaperDOI": "10.1109/VISUAL.1996.567800",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567800",
                "Firstpage": "141",
                "Lastpage": "148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Brushing is a data visualization technique that identifies and highlights data subsets. We introduce a form of brushing in which the brushed data is usually displayed at a different resolution than the non brushed data. The paper presents the rationale behind the multiresolution support of multivariate data visualization and describes the construction of multiresolution brushing using wavelet approximations. The idea is implemented in an enhanced version of XmdvTool. Real scientific data is used for demonstration and practical applications are suggested.",
                "AuthorNames": "Pak Chung Wong;Bergeron, R.D.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;",
                "AuthorIDs": "37280665600;",
                "Dedupedauthornames": "Pak Chung Wong;Bergeron, R.D.",
                "References": "10.1109/VISUAL.1990.146386;10.1109/VISUAL.1993.398864;10.1109/VISUAL.1995.480811;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "567800",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146386;398864;480811;346302;485139;146402"
            }
        },
        {
            "name": "Foote, H.",
            "value": 120,
            "numPapers": 27,
            "cluster": "5",
            "index": 411,
            "weight": 5,
            "x": 997.4632671213743,
            "y": 504.0567049588315,
            "px": 967.1486773531839,
            "py": 592.655852095057,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "TOPIC ISLANDS TM - a wavelet-based text visualization system",
                "PaperDOI": "10.1109/VISUAL.1998.745302",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745302",
                "Firstpage": "189",
                "Lastpage": "196",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel approach to visualize and explore unstructured text. The underlying technology, called TOPIC-O-GRAPHY TM, applies wavelet transforms to a custom digital signal constructed from words within a document. The resultant multiresolution wavelet energy is used to analyze the characteristics of the narrative flow in the frequency domain, such as theme changes, which is then related to the overall thematic content of the text document using statistical methods. The thematic characteristics of a document can be analyzed at varying degrees of detail, ranging from section-sized text partitions to partitions consisting of a few words. Using this technology, we are developing a visualization system prototype known as TOPIC ISLANDS to browse a document, generate fuzzy document outlines, summarize text by levels of detail and according to user interests, define meaningful subdocuments, query text content, and provide summaries of topic evolution.",
                "AuthorNames": "Miller, N.E.;Pak Chung Wong;Brewster, M.;Foote, H.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;",
                "AuthorIDs": "37361698400;37280665600;37371985000;37372586800",
                "Dedupedauthornames": "Miller, N.;Pak Chung Wong;Brewster, M.;Foote, H.",
                "References": "10.1109/VISUAL.1997.663872;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1997.663871;10.1109/VISUAL.1995.480811;10.1109/VISUAL.1994.346333;10.1109/VISUAL.1994.346332;10.1109/VISUAL.1992.235206",
                "AuthorKeywords": "text visualization, information visualization,wavelet transform, information retrieval",
                "IEEEXPLOREArticleNumberdeprecated": "745302",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663872;528686;567800;663871;480811;346333;346332;235206"
            }
        },
        {
            "name": "Thomas, J.",
            "value": 334,
            "numPapers": 27,
            "cluster": "5",
            "index": 412,
            "weight": 22,
            "x": 1244.749469283719,
            "y": 16.020320216880883,
            "px": 1118.6751699735173,
            "py": 130.21148795705548,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Guodao Sun",
            "value": 16,
            "numPapers": 9,
            "cluster": "1",
            "index": 413,
            "weight": 2,
            "x": 65.45497297448006,
            "y": 1205.8042127433387,
            "px": -21.435760506574926,
            "py": 1249.610631408912,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "EvoRiver: Visual Analysis of Topic Coopetition on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346919",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346919",
                "Firstpage": "1753",
                "Lastpage": "1762",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Cooperation and competition (jointly called coopetition) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., topic leaders) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",
                "AuthorNames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Zhu, J.J.H.;Ronghua Liang",
                "References": "10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162",
                "AuthorKeywords": "Topic coopetition, information diffusion, information propagation, time-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6875992",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5652931;6327271;4658136;6065008;6327273;6876032;6634134;6634164;6634160"
            }
        },
        {
            "name": "MacEachren, A.M.",
            "value": 142,
            "numPapers": 20,
            "cluster": "0",
            "index": 414,
            "weight": 1,
            "x": 520.268407464389,
            "y": 221.63955565918303,
            "px": 523.3143533767164,
            "py": 197.31633469295403,
            "node": {
                "Conference": "InfoVis",
                "Year": "2003",
                "PaperTitle": "Exploring high-D spaces with multiform matrices and small multiples",
                "PaperDOI": "10.1109/INFVIS.2003.1249006",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2003.1249006",
                "Firstpage": "31",
                "Lastpage": "38",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce an approach to visual analysis of multivariate data that integrates several methods from information visualization, exploratory data analysis (EDA), and geovisualization. The approach leverages the component-based architecture implemented in GeoVISTA Studio to construct a flexible, multiview, tightly (but generically) coordinated, EDA toolkit. This toolkit builds upon traditional ideas behind both small multiples and scatterplot matrices in three fundamental ways. First, we develop a general, multiform, bivariate matrix and a complementary multiform, bivariate small multiple plot in which different bivariate representation forms can be used in combination. We demonstrate the flexibility of this approach with matrices and small multiples that depict multivariate data through combinations of: scatterplots, bivariate maps, and space-filling displays. Second, we apply a measure of conditional entropy to (a) identify variables from a high-dimensional data set that are likely to display interesting relationships and (b) generate a default order of these variables in the matrix or small multiple display. Third, we add conditioning, a kind of dynamic query/filtering in which supplementary (undisplayed) variables are used to constrain the view onto variables that are displayed. Conditioning allows the effects of one or more well understood variables to be removed form the analysis, making relationships among remaining variables easier to explore. We illustrate the individual and combined functionality enabled by this approach through application to analysis of cancer diagnosis and mortality data and their associated covariates and risk factors.",
                "AuthorNames": "MacEachren, A.;Xiping, D.;Hardisty, F.;Diansheng Guo;Lengerich, G.",
                "FirstAuthorAffiliation": "Dept. of Geogr., Pennsylvania State Univ., University Park, VA, USA|c|;;;;",
                "AuthorIDs": "37374699000;;37945504200;38197945800;38202682500",
                "Dedupedauthornames": "MacEachren, A.M.;Xiping, D.;Hardisty, F.;Diansheng Guo;Lengerich, G.",
                "References": "10.1109/VISUAL.1991.175815;10.1109/INFVIS.1998.729559",
                "AuthorKeywords": "geovisualization, EDA, scatterplot matrix,bivariate map, space-filling visualization, conditional entropy, small multiples, conditioning, GeoVISTA Studio ",
                "IEEEXPLOREArticleNumberdeprecated": "1249006",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175815;729568"
            }
        },
        {
            "name": "Feinberg, J.",
            "value": 67,
            "numPapers": 2,
            "cluster": "1",
            "index": 415,
            "weight": 2,
            "x": -118.5615317658394,
            "y": 1284.1898235106107,
            "px": -228.6283693099588,
            "py": 1342.7068472185604,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Participatory Visualization with Wordle",
                "PaperDOI": "10.1109/TVCG.2009.171",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.171",
                "Firstpage": "1137",
                "Lastpage": "1144",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.",
                "AuthorNames": "Viegas, F.B.;Wattenberg, M.;Feinberg, J.",
                "FirstAuthorAffiliation": "IBM Res., Hawthorne, CA, USA|c|;;",
                "AuthorIDs": "37681355300;37550759700;38102505300",
                "Dedupedauthornames": "Viegas, F.B.;Wattenberg, M.;Feinberg, J.",
                "References": "10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70577",
                "AuthorKeywords": "Visualization, text, tag cloud, participatory culture, memory, educational visualization, social data analysis",
                "IEEEXPLOREArticleNumberdeprecated": "5290722",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532122;4376131"
            }
        },
        {
            "name": "Gruen, D.",
            "value": 60,
            "numPapers": 8,
            "cluster": "1",
            "index": 416,
            "weight": 2,
            "x": -368.80606172266187,
            "y": 503.3956226413242,
            "px": -497.76949407577456,
            "py": 483.9581804871528,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "A Visual Backchannel for Large-Scale Events",
                "PaperDOI": "10.1109/TVCG.2010.129",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.129",
                "Firstpage": "1129",
                "Lastpage": "1138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.",
                "AuthorNames": "Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "37590950400;37603901200;37276124700;38268267300",
                "Dedupedauthornames": "Dork, M.;Gruen, D.;Williamson, C.;Carpendale, S.",
                "References": "10.1109/VAST.2009.5333443;10.1109/TVCG.2007.70541;10.1109/TVCG.2008.166;10.1109/TVCG.2008.175;10.1109/INFVIS.2005.1532133;10.1109/INFVIS.2003.1249028;10.1109/VAST.2008.4677364;10.1109/VAST.2009.5333437",
                "AuthorKeywords": "Backchannel, information visualization, events, multiple views, microblogging, information retrieval, World Wide Web",
                "IEEEXPLOREArticleNumberdeprecated": "5613451",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5333443;4376134;4658136;4658131;1532133;1249028;4677364;5333437"
            }
        },
        {
            "name": "Williamson, C.",
            "value": 108,
            "numPapers": 14,
            "cluster": "1",
            "index": 417,
            "weight": 3,
            "x": 913.3868708143186,
            "y": 509.33198167025466,
            "px": 913.0926472738004,
            "py": 489.0879362272404,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery",
                "PaperDOI": "10.1109/TVCG.2008.175",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.175",
                "Firstpage": "1205",
                "Lastpage": "1212",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.",
                "AuthorNames": "Dork, M.;Carpendale, S.;Collins, C.;Williamson, C.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of Calgary, Calgary, AB|c|;;;",
                "AuthorIDs": ";37285000100;37669874100;37276124700",
                "Dedupedauthornames": "Dork, M.;Carpendale, S.;Collins, C.;Williamson, C.",
                "References": "10.1109/TVCG.2007.70570;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70577;10.1109/VISUAL.1993.398863;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1996.567610",
                "AuthorKeywords": "Information visualization, World Wide Web, information retrieval, exploratory search, visual information seeking",
                "IEEEXPLOREArticleNumberdeprecated": "4658131",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376138;4376132;4376131;398863;1532122;567610"
            }
        },
        {
            "name": "Bradel, L.",
            "value": 25,
            "numPapers": 11,
            "cluster": "0",
            "index": 418,
            "weight": 1,
            "x": 1431.178805520307,
            "y": 363.6283705121191,
            "px": 1280.7812048210458,
            "py": 340.6923045194594,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Multi-Model Semantic Interaction for Text Analytics",
                "PaperDOI": "10.1109/VAST.2014.7042492",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042492",
                "Firstpage": "163",
                "Lastpage": "172",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection.",
                "AuthorNames": "Bradel, L.;North, C.;House, l.;Leman, S.",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Bradel, L.;North, C.;House, l.;Leman, S.",
                "References": "10.1109/VAST.2011.6102449;10.1109/TVCG.2013.188;10.1109/VAST.2012.6400559;10.1109/VAST.2012.6400486;10.1109/INFVIS.1995.528686;10.1109/VAST.2007.4389006",
                "AuthorKeywords": "Visual analytics, Semantic Interaction, Sensemaking, Text Analytics",
                "IEEEXPLOREArticleNumberdeprecated": "7042492",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102449;6634115;6400559;6400486;528686;4389006"
            }
        },
        {
            "name": "Muhlbacher, T.",
            "value": 55,
            "numPapers": 37,
            "cluster": "0",
            "index": 419,
            "weight": 1,
            "x": 507.17827463379945,
            "y": 1366.1976776528754,
            "px": 493.2947147963379,
            "py": 1233.151040026635,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations",
                "PaperDOI": "10.1109/TVCG.2014.2346578",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346578",
                "Firstpage": "1643",
                "Lastpage": "1652",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.",
                "AuthorNames": "Muhlbacher, T.;Piringer, H.;Gratzl, S.;Sedlmair, M.;Streit, M.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Muhlbacher, T.;Piringer, H.;Gratzl, S.;Sedlmair, M.;Streit, M.",
                "References": "10.1109/VAST.2012.6400486;10.1109/VAST.2007.4388999;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.151;10.1109/TVCG.2014.2346321;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.171;10.1109/TVCG.2013.212;10.1109/TVCG.2013.125;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.110;10.1109/INFVIS.2004.60;10.1109/VAST.2011.6102453;10.1109/TVCG.2012.195;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.229",
                "AuthorKeywords": "Visual analytics infrastructures, integration, interactive algorithms, user involvement, problem subdivision",
                "IEEEXPLOREArticleNumberdeprecated": "6875995",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6400486;4388999;6102449;4376144;5290697;6876043;4677350;4015496;6634167;6634169;1173145;5290719;1382891;6102453;6327292;1249014;6064985"
            }
        },
        {
            "name": "Kai Yan",
            "value": 28,
            "numPapers": 12,
            "cluster": "1",
            "index": 420,
            "weight": 3,
            "x": 309.0025380758267,
            "y": 477.381606209228,
            "px": 145.16044876633788,
            "py": 448.01988890725977,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346920",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346920",
                "Firstpage": "1763",
                "Lastpage": "1772",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.",
                "AuthorNames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "References": "10.1109/TVCG.2011.239;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.291;10.1109/VAST.2006.261431;10.1109/TVCG.2010.129;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346919;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919",
                "AuthorKeywords": "Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail",
                "IEEEXPLOREArticleNumberdeprecated": "6876032",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065008;6634160;6634134;6875938;1532152;6327271;4035748;5613451;6634164;6875992;5613449;5333919"
            }
        },
        {
            "name": "Fangzhao Wu",
            "value": 28,
            "numPapers": 12,
            "cluster": "1",
            "index": 421,
            "weight": 3,
            "x": 334.78098508497317,
            "y": 582.1105226806001,
            "px": 189.1287958467043,
            "py": 582.2292874954671,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media",
                "PaperDOI": "10.1109/TVCG.2014.2346920",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346920",
                "Firstpage": "1763",
                "Lastpage": "1772",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.",
                "AuthorNames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "FirstAuthorAffiliation": "Microsoft Res., Redmond, WA, USA|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu",
                "References": "10.1109/TVCG.2011.239;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.291;10.1109/VAST.2006.261431;10.1109/TVCG.2010.129;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346919;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919",
                "AuthorKeywords": "Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail",
                "IEEEXPLOREArticleNumberdeprecated": "6876032",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6065008;6634160;6634134;6875938;1532152;6327271;4035748;5613451;6634164;6875992;5613449;5333919"
            }
        },
        {
            "name": "Sadransky, B.",
            "value": 4,
            "numPapers": 11,
            "cluster": "4",
            "index": 422,
            "weight": 6,
            "x": 1008.5862721867043,
            "y": 229.83956618751708,
            "px": 1018.4466073229784,
            "py": 450.00857686322973,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Process visualization with levels of detail",
                "PaperDOI": "10.1109/INFVIS.2002.1173149",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173149",
                "Firstpage": "67",
                "Lastpage": "70",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We demonstrate how we apply information visualization techniques to process monitoring. Virtual instruments are enhanced using history encoding instruments are capable of displaying the current value and the value from the near past. Multi-instruments are capable of displaying several data sources simultaneously. Levels of detail for virtual instruments are introduced where the screen area is inversely proportional to the information amount displayed. Furthermore the monitoring system is enhanced by using: 3D anchoring attachment of instruments to positions on a 3D model, collision avoidance a physically based spring model prevents instruments from overlapping, and focus+context rendering - giving the user a possibility to examine particular instruments in detail without loosing the context information.",
                "AuthorNames": "Matkovic, K.;Hauser, H.;Sainitzer, R.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;",
                "AuthorIDs": "38220979200;37274158800;38221553100;37282552200",
                "Dedupedauthornames": "Matkovic, K.;Hauser, H.;Sainitzer, R.;Groller, E.",
                "References": "10.1109/INFVIS.1998.729558;10.1109/INFVIS.2001.963286",
                "AuthorKeywords": "process visualization, information visualization, levels of detail, focus+context visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1173149",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "729558;963286"
            }
        },
        {
            "name": "Ribicic, H.",
            "value": 138,
            "numPapers": 24,
            "cluster": "4",
            "index": 423,
            "weight": 9,
            "x": 841.4709872730045,
            "y": 229.0604819531142,
            "px": 880.9548541375644,
            "py": 358.4483212693184,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "Firstpage": "1458",
                "Lastpage": "1467",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "References": "10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289",
                "AuthorKeywords": "Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics",
                "IEEEXPLOREArticleNumberdeprecated": "5613487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Schindler, B.",
            "value": 134,
            "numPapers": 31,
            "cluster": "4",
            "index": 424,
            "weight": 10,
            "x": 851.9619832962336,
            "y": 396.4227362791265,
            "px": 885.437219728851,
            "py": 537.2223929974424,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "Firstpage": "1458",
                "Lastpage": "1467",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "References": "10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289",
                "AuthorKeywords": "Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics",
                "IEEEXPLOREArticleNumberdeprecated": "5613487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Bloschl, G.",
            "value": 134,
            "numPapers": 19,
            "cluster": "4",
            "index": 425,
            "weight": 6,
            "x": 1035.3902029033638,
            "y": -40.71067887383808,
            "px": 994.9094045833448,
            "py": -45.84296488133176,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "World Lines",
                "PaperDOI": "10.1109/TVCG.2010.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.223",
                "Firstpage": "1458",
                "Lastpage": "1467",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.",
                "AuthorNames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "38111592300;38099765400;38229386600;38102461400;38229402400;37282552200",
                "Dedupedauthornames": "Waser, J.;Fuchs, R.;Ribicic, H.;Schindler, B.;Bloschl, G.;Groller, E.",
                "References": "10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289",
                "AuthorKeywords": "Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics",
                "IEEEXPLOREArticleNumberdeprecated": "5613487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173149;1382904;809871;1532143;5290745;398857;4658193;4376146;745289"
            }
        },
        {
            "name": "Xiting Wang",
            "value": 25,
            "numPapers": 19,
            "cluster": "1",
            "index": 426,
            "weight": 3,
            "x": 329.44276345394013,
            "y": 344.20907975547857,
            "px": 177.01269958443228,
            "py": 264.842523185719,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "TopicPanorama: A Full Picture of Relevant Topics",
                "PaperDOI": "10.1109/VAST.2014.7042494",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042494",
                "Firstpage": "183",
                "Lastpage": "192",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.",
                "AuthorNames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "References": "10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919",
                "AuthorKeywords": "Topic graph, graph matching, graph visualization, user interactions, level-of-detail",
                "IEEEXPLOREArticleNumberdeprecated": "7042494",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102461;6065008;5290695;5613456;6102439;4015433;6327258;6634134;6634160;6327255;5613449;6875938;4376140;6634197;6634167;4376154;6634179;5613451;6875992"
            }
        },
        {
            "name": "Jianfei Chen",
            "value": 25,
            "numPapers": 19,
            "cluster": "1",
            "index": 427,
            "weight": 3,
            "x": 376.9303100961908,
            "y": 330.25000914393286,
            "px": 252.67924707766298,
            "py": 251.81881932655517,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "TopicPanorama: A Full Picture of Relevant Topics",
                "PaperDOI": "10.1109/VAST.2014.7042494",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042494",
                "Firstpage": "183",
                "Lastpage": "192",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.",
                "AuthorNames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "References": "10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919",
                "AuthorKeywords": "Topic graph, graph matching, graph visualization, user interactions, level-of-detail",
                "IEEEXPLOREArticleNumberdeprecated": "7042494",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102461;6065008;5290695;5613456;6102439;4015433;6327258;6634134;6634160;6327255;5613449;6875938;4376140;6634197;6634167;4376154;6634179;5613451;6875992"
            }
        },
        {
            "name": "Jun Zhu",
            "value": 25,
            "numPapers": 19,
            "cluster": "1",
            "index": 428,
            "weight": 3,
            "x": 345.0339605610991,
            "y": 332.43422931240923,
            "px": 199.80018778597858,
            "py": 253.24090499298674,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "TopicPanorama: A Full Picture of Relevant Topics",
                "PaperDOI": "10.1109/VAST.2014.7042494",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042494",
                "Firstpage": "183",
                "Lastpage": "192",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.",
                "AuthorNames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "References": "10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919",
                "AuthorKeywords": "Topic graph, graph matching, graph visualization, user interactions, level-of-detail",
                "IEEEXPLOREArticleNumberdeprecated": "7042494",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102461;6065008;5290695;5613456;6102439;4015433;6327258;6634134;6634160;6327255;5613449;6875938;4376140;6634197;6634167;4376154;6634179;5613451;6875992"
            }
        },
        {
            "name": "Baining Guo",
            "value": 25,
            "numPapers": 19,
            "cluster": "1",
            "index": 429,
            "weight": 3,
            "x": 339.6462228218266,
            "y": 552.948520135308,
            "px": 203.0686593047594,
            "py": 547.3393324445647,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "TopicPanorama: A Full Picture of Relevant Topics",
                "PaperDOI": "10.1109/VAST.2014.7042494",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042494",
                "Firstpage": "183",
                "Lastpage": "192",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.",
                "AuthorNames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Shixia Liu;Xiting Wang;Jianfei Chen;Jun Zhu;Baining Guo",
                "References": "10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919",
                "AuthorKeywords": "Topic graph, graph matching, graph visualization, user interactions, level-of-detail",
                "IEEEXPLOREArticleNumberdeprecated": "7042494",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6102461;6065008;5290695;5613456;6102439;4015433;6327258;6634134;6634160;6327255;5613449;6875938;4376140;6634197;6634167;4376154;6634179;5613451;6875992"
            }
        },
        {
            "name": "Worring, M.",
            "value": 30,
            "numPapers": 24,
            "cluster": "0",
            "index": 430,
            "weight": 1,
            "x": 799.3201088496404,
            "y": -1030.6356601247712,
            "px": 755.1065218133648,
            "py": -891.2107980632132,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "Firstpage": "191",
                "Lastpage": "198",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "References": "10.1109/INFVIS.1999.801855;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249009;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2004.71",
                "AuthorKeywords": "Image retrieval, image layout, semantic image classification,\nmulti-dimensional visualization, visual analytics",
                "IEEEXPLOREArticleNumberdeprecated": "4035765",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Lin, J.",
            "value": 0,
            "numPapers": 14,
            "cluster": "0",
            "index": 431,
            "weight": 1,
            "x": 1334.2318589247416,
            "y": 1103.0487792462807,
            "px": 1214.8808859287203,
            "py": 971.9034803468454,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations",
                "PaperDOI": "10.1109/INFVIS.2000.885091",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885091",
                "Firstpage": "57",
                "Lastpage": "65",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space",
                "AuthorNames": "Stasko, J.;Zhang, E.",
                "FirstAuthorAffiliation": "GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;",
                "AuthorIDs": "37267736900;38020590400",
                "Dedupedauthornames": "Stasko, J.;Zhang, E.",
                "References": "10.1109/INFVIS.1999.801860;10.1109/VISUAL.1992.235217;10.1109/INFVIS.1998.729557;10.1109/VISUAL.1991.175815",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885091",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801860;235217;729567;175815"
            }
        },
        {
            "name": "Barlowe, S.",
            "value": 44,
            "numPapers": 29,
            "cluster": "0",
            "index": 432,
            "weight": 1,
            "x": 866.7340607975158,
            "y": -1072.603294194521,
            "px": 814.3882456251896,
            "py": -929.0998766168326,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "VAET: A Visual Analytics Approach for E-Transactions Time-Series",
                "PaperDOI": "10.1109/TVCG.2014.2346913",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346913",
                "Firstpage": "1743",
                "Lastpage": "1752",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.",
                "AuthorNames": "Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Barlowe, S.;Jing Yang",
                "FirstAuthorAffiliation": "State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Barlowe, S.;Jing Yang",
                "References": "10.1109/TVCG.2009.123;10.1109/VAST.2007.4389009;10.1109/TVCG.2012.212;10.1109/INFVIS.1995.528685;10.1109/VAST.2012.6400494;10.1109/TVCG.2010.162;10.1109/TVCG.2009.180",
                "AuthorKeywords": "Time-Series, Visual Analytics, E-transaction",
                "IEEEXPLOREArticleNumberdeprecated": "6876015",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290717;4389009;6327274;528685;6400494;5613429;5290708"
            }
        },
        {
            "name": "Yu-Hsuan Chan",
            "value": 68,
            "numPapers": 8,
            "cluster": "2",
            "index": 433,
            "weight": 1,
            "x": -794.3269245101966,
            "y": 1848.4744341159478,
            "px": -722.0786936137878,
            "py": 1675.670902221101,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "A framework for uncertainty-aware visual analytics",
                "PaperDOI": "10.1109/VAST.2009.5332611",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332611",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.",
                "AuthorNames": "Correa, C.;Yu-Hsuan Chan;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California at Davis, Davis, CA, USA|c|;;",
                "AuthorIDs": "37282925900;37593323300;37275869400",
                "Dedupedauthornames": "Correa, C.;Yu-Hsuan Chan;Kwan-Liu Ma",
                "References": "10.1109/VAST.2008.4677368;10.1109/VAST.2007.4389000",
                "AuthorKeywords": "Uncertainty, Data Transformations, Principal Component Analysis, Model fitting",
                "IEEEXPLOREArticleNumberdeprecated": "5332611",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4677368;4389000"
            }
        },
        {
            "name": "Dransch, D.",
            "value": 16,
            "numPapers": 16,
            "cluster": "5",
            "index": 434,
            "weight": 1,
            "x": 547.4936709150604,
            "y": -1048.7380651569279,
            "px": 567.4761631843439,
            "py": -867.3848430616684,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles",
                "PaperDOI": "10.1109/TVCG.2014.2346751",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346751",
                "Firstpage": "1893",
                "Lastpage": "1902",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.",
                "AuthorNames": "Kothur, P.;Sips, M.;Dobslaw, H.;Dransch, D.",
                "FirstAuthorAffiliation": "GFZ German Res. Centre for Geosci., Potsdam, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Kothur, P.;Sips, M.;Dobslaw, H.;Dransch, D.",
                "References": "10.1109/TVCG.2012.190;10.1109/TVCG.2012.284;10.1109/TVCG.2008.139",
                "AuthorKeywords": "Ocean modeling, model assessment, geospatial time series, cluster ensembles, visual comparison, visual analytics",
                "IEEEXPLOREArticleNumberdeprecated": "6876007",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327226;6327206;4658178"
            }
        },
        {
            "name": "Tangzhi Ye",
            "value": 14,
            "numPapers": 14,
            "cluster": "5",
            "index": 435,
            "weight": 2,
            "x": 1371.8647410289257,
            "y": 153.0507999186004,
            "px": 1376.3563420372125,
            "py": 164.77554622682908,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Visual Exploration of Sparse Traffic Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2014.2346746",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346746",
                "Firstpage": "1813",
                "Lastpage": "1822",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu",
                "FirstAuthorAffiliation": "Peking Univ., Beijing, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu",
                "References": "10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265",
                "AuthorKeywords": "Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion",
                "IEEEXPLOREArticleNumberdeprecated": "6876014",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6400556;1382887;4677356;1532151;6102458;6065001;6634174;6634194;5332584;6634127;6102454;6102455;5290694;6327262"
            }
        },
        {
            "name": "Min Lu",
            "value": 81,
            "numPapers": 27,
            "cluster": "5",
            "index": 436,
            "weight": 2,
            "x": 1284.2936414597925,
            "y": 54.03826742440809,
            "px": 1293.624165628753,
            "py": 73.05110124559312,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "Firstpage": "2159",
                "Lastpage": "2168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.",
                "References": "10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455",
                "AuthorKeywords": "Traffic visualization, traffic jam propagation",
                "IEEEXPLOREArticleNumberdeprecated": "6634174",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Yuan, J.",
            "value": 14,
            "numPapers": 14,
            "cluster": "5",
            "index": 437,
            "weight": 2,
            "x": 1369.203046956718,
            "y": 113.22047570553917,
            "px": 1375.5685781514032,
            "py": 131.28120801968603,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Visual Exploration of Sparse Traffic Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2014.2346746",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346746",
                "Firstpage": "1813",
                "Lastpage": "1822",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu",
                "FirstAuthorAffiliation": "Peking Univ., Beijing, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu",
                "References": "10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265",
                "AuthorKeywords": "Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion",
                "IEEEXPLOREArticleNumberdeprecated": "6876014",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6400556;1382887;4677356;1532151;6102458;6065001;6634174;6634194;5332584;6634127;6102454;6102455;5290694;6327262"
            }
        },
        {
            "name": "Qianliang Wu",
            "value": 14,
            "numPapers": 14,
            "cluster": "5",
            "index": 438,
            "weight": 2,
            "x": 1400.8938084674357,
            "y": 126.36355648931254,
            "px": 1402.2413361938254,
            "py": 141.77689529226467,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Visual Exploration of Sparse Traffic Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2014.2346746",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346746",
                "Firstpage": "1813",
                "Lastpage": "1822",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu",
                "FirstAuthorAffiliation": "Peking Univ., Beijing, China|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Yuan, J.;Qianliang Wu",
                "References": "10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265",
                "AuthorKeywords": "Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion",
                "IEEEXPLOREArticleNumberdeprecated": "6876014",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6400556;1382887;4677356;1532151;6102458;6065001;6634174;6634194;5332584;6634127;6102454;6102455;5290694;6327262"
            }
        },
        {
            "name": "Alsallakh, B.",
            "value": 45,
            "numPapers": 46,
            "cluster": "0",
            "index": 439,
            "weight": 6,
            "x": -119.11449012821751,
            "y": -368.09073648398726,
            "px": -176.36614516923092,
            "py": -357.1083451716507,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Radial Sets: Interactive Visual Analysis of Large Overlapping Sets",
                "PaperDOI": "10.1109/TVCG.2013.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.184",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.",
                "AuthorNames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "References": "10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157",
                "AuthorKeywords": "Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability",
                "IEEEXPLOREArticleNumberdeprecated": "6634104",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015417;5290706;4658148;6064991;1382886;5613447;6327291;1173157"
            }
        },
        {
            "name": "Aigner, W.",
            "value": 64,
            "numPapers": 29,
            "cluster": "0",
            "index": 440,
            "weight": 5,
            "x": -100.97133644204679,
            "y": -218.1730119988226,
            "px": -163.1647108239442,
            "py": -183.5341388275487,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Radial Sets: Interactive Visual Analysis of Large Overlapping Sets",
                "PaperDOI": "10.1109/TVCG.2013.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.184",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.",
                "AuthorNames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "References": "10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157",
                "AuthorKeywords": "Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability",
                "IEEEXPLOREArticleNumberdeprecated": "6634104",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015417;5290706;4658148;6064991;1382886;5613447;6327291;1173157"
            }
        },
        {
            "name": "Miksch, S.",
            "value": 83,
            "numPapers": 52,
            "cluster": "0",
            "index": 441,
            "weight": 7,
            "x": -4.972464214199196,
            "y": -181.36985942382378,
            "px": -97.65699196787972,
            "py": -303.6341113880665,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Radial Sets: Interactive Visual Analysis of Large Overlapping Sets",
                "PaperDOI": "10.1109/TVCG.2013.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.184",
                "Firstpage": "2496",
                "Lastpage": "2505",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.",
                "AuthorNames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Alsallakh, B.;Aigner, W.;Miksch, S.;Hauser, H.",
                "References": "10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157",
                "AuthorKeywords": "Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability",
                "IEEEXPLOREArticleNumberdeprecated": "6634104",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015417;5290706;4658148;6064991;1382886;5613447;6327291;1173157"
            }
        },
        {
            "name": "Doleisch, H.",
            "value": 216,
            "numPapers": 58,
            "cluster": "2",
            "index": 442,
            "weight": 12,
            "x": 383.33063091352926,
            "y": 288.2400208861207,
            "px": 376.21852123183294,
            "py": 289.9292787025377,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Angular brushing of extended parallel coordinates",
                "PaperDOI": "10.1109/INFVIS.2002.1173157",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173157",
                "Firstpage": "127",
                "Lastpage": "130",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we present angular brushing for parallel coordinates (PC) as a new approach to highlighting rational data-properties, i.e., features which - in a non-separable way - depend on two data dimensions. We also demonstrate smooth brushing as an intuitive tool for specifying nonbinary degree-of-interest functions (for focus+context visualization). We also briefly describe our implementation as well as its application to the visualization of CFD data.",
                "AuthorNames": "Hauser, H.;Ledermann, F.;Doleisch, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;",
                "AuthorIDs": "37274158800;37689207700;37546620400",
                "Dedupedauthornames": "Hauser, H.;Ledermann, F.;Doleisch, H.",
                "References": "10.1109/INFVIS.1996.559216;10.1109/VISUAL.2000.885739;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402",
                "AuthorKeywords": "information visualization, parallel coordinates, brushing, linear correlations, focus+context visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1173157",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559216;885739;346302;485139;146402"
            }
        },
        {
            "name": "Auzinger, T.",
            "value": 11,
            "numPapers": 15,
            "cluster": "2",
            "index": 443,
            "weight": 2,
            "x": -566.5096165252755,
            "y": 232.89448450140594,
            "px": -624.6272170326008,
            "py": 249.88314807904888,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "YMCA - Your Mesh Comparison Application",
                "PaperDOI": "10.1109/VAST.2014.7042491",
                "Link": "http://dx.doi.org/10.1109/VAST.2014.7042491",
                "Firstpage": "153",
                "Lastpage": "162",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.",
                "AuthorNames": "Schmidt, J.;Preiner, R.;Auzinger, T.;Wimmer, T.;Groller, E.;Bruckner S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Schmidt, J.;Preiner, R.;Auzinger, T.;Wimmer, T.;Groller, E.;Bruckner, S.",
                "References": "10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1990.146402;10.1109/TVCG.2013.213;10.1109/VISUAL.2002.1183790",
                "AuthorKeywords": "Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison",
                "IEEEXPLOREArticleNumberdeprecated": "7042491",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173157;146402;6634107;1183790"
            }
        },
        {
            "name": "Hullman, J.",
            "value": 87,
            "numPapers": 19,
            "cluster": "0",
            "index": 444,
            "weight": 1,
            "x": 435.76652598635275,
            "y": -1127.3665426844116,
            "px": 443.8194682889814,
            "py": -975.0631536584831,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Visualization Rhetoric: Framing Effects in Narrative Visualization",
                "PaperDOI": "10.1109/TVCG.2011.255",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.255",
                "Firstpage": "2231",
                "Lastpage": "2240",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that \"tell a story\" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.",
                "AuthorNames": "Hullman, J.;Diakopoulos, N.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "38016234500;37591165700",
                "Dedupedauthornames": "Hullman, J.;Diakopoulos, N.",
                "References": "10.1109/TVCG.2010.179;10.1109/TVCG.2007.70577;10.1109/TVCG.2010.177;10.1109/TVCG.2009.111",
                "AuthorKeywords": "Rhetoric, narrative visualization, framing effects, semiotics, denotation, connotation ",
                "IEEEXPLOREArticleNumberdeprecated": "6064988",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613452;4376131;5613437;5290695"
            }
        },
        {
            "name": "Adar, E.",
            "value": 50,
            "numPapers": 15,
            "cluster": "0",
            "index": 445,
            "weight": 1,
            "x": -31.84874555381796,
            "y": -1660.6597946028076,
            "px": 18.43615395910457,
            "py": -1462.436187877329,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Benefitting InfoVis with Visual Difficulties",
                "PaperDOI": "10.1109/TVCG.2011.175",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.175",
                "Firstpage": "2213",
                "Lastpage": "2222",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative \"chartjunk\" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.",
                "AuthorNames": "Hullman, J.;Adar, E.;Shah, P.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "38016234500;37331417100;38018860000",
                "Dedupedauthornames": "Hullman, J.;Adar, E.;Shah, P.",
                "References": "10.1109/INFVIS.1995.528688;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.177;10.1109/INFVIS.2001.963279;10.1109/TVCG.2009.111",
                "AuthorKeywords": "Desirable difficulites, cognitive efficiency, active processing, engagement, individual differences ",
                "IEEEXPLOREArticleNumberdeprecated": "6064986",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528688;4658146;4376146;5613437;963279;5290695"
            }
        },
        {
            "name": "Amar, R.",
            "value": 161,
            "numPapers": 11,
            "cluster": "0",
            "index": 446,
            "weight": 2,
            "x": 621.9803780764978,
            "y": 1028.733966879447,
            "px": 597.7778522336746,
            "py": 934.0303444512579,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Low-level components of analytic activity in information visualization",
                "PaperDOI": "10.1109/INFVIS.2005.1532136",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532136",
                "Firstpage": "111",
                "Lastpage": "117",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",
                "AuthorNames": "Amar, R.;Eagan, J.;Stasko, J.",
                "FirstAuthorAffiliation": "Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;",
                "AuthorIDs": "37418696100;37550755100;37267736900",
                "Dedupedauthornames": "Amar, R.;Eagan, J.;Stasko, J.",
                "References": "10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.5;10.1109/INFVIS.2001.963289",
                "AuthorKeywords": "Analytic activity, taxonomy, knowledge discovery, design, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1532136",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146375;729560;885092;1382884;963289"
            }
        },
        {
            "name": "Eagan, J.",
            "value": 146,
            "numPapers": 8,
            "cluster": "0",
            "index": 447,
            "weight": 1,
            "x": 1860.1939439805535,
            "y": 1227.5581544903007,
            "px": 1709.1288934080517,
            "py": 1105.1595907379672,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Topological Fisheye Views for Visualizing Large Graphs",
                "PaperDOI": "10.1109/INFVIS.2004.66",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.66",
                "Firstpage": "175",
                "Lastpage": "182",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays",
                "AuthorNames": "Gansner, E.;Koren, Y.;North, S.",
                "FirstAuthorAffiliation": "AT&T Labs., NJ|c|;;",
                "AuthorIDs": "37299368000;37414256700;37372818600",
                "Dedupedauthornames": "Gansner, E.;Koren, Y.;North, S.C.",
                "References": "10.1109/INFVIS.1997.636718;10.1109/INFVIS.2003.1249011",
                "AuthorKeywords": "topological fisheye,large graph visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1382906",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636718;1249011"
            }
        },
        {
            "name": "Grosjean, J.",
            "value": 67,
            "numPapers": 1,
            "cluster": "0",
            "index": 448,
            "weight": 1,
            "x": 638.4430345814292,
            "y": 818.021207031785,
            "px": 647.9857454866125,
            "py": 720.6224302991294,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation",
                "PaperDOI": "10.1109/INFVIS.2002.1173148",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173148",
                "Firstpage": "57",
                "Lastpage": "64",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.",
                "AuthorNames": "Plaisant, C.;Grosjean, J.;Bederson, B.B.",
                "FirstAuthorAffiliation": "Human-Comput. Interaction Lab., Maryland Univ., MD, USA|c|;;",
                "AuthorIDs": "37283026800;37279773300;37279760100",
                "Dedupedauthornames": "Plaisant, C.;Grosjean, J.;Bederson, B.B.",
                "References": "10.1109/VISUAL.1996.567745",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "1173148",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567745"
            }
        },
        {
            "name": "Bederson, B.B.",
            "value": 125,
            "numPapers": 16,
            "cluster": "0",
            "index": 449,
            "weight": 3,
            "x": 931.1133412529839,
            "y": 698.0453045777779,
            "px": 1025.9168184707005,
            "py": 790.0094775973248,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Design Study of LineSets, a Novel Set Visualization Technique",
                "PaperDOI": "10.1109/TVCG.2011.186",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.186",
                "Firstpage": "2259",
                "Lastpage": "2267",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.",
                "AuthorNames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, Mary",
                "FirstAuthorAffiliation": ";;;",
                "AuthorIDs": "38030020400;37590950700;38030407700;37563799500",
                "Dedupedauthornames": "Alper, B.;Riche, N.H.;Ramos, G.;Czerwinski, M.",
                "References": "10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126",
                "AuthorKeywords": "Set visualization, clustering, faceted data visualization, graph visualization \n\n",
                "IEEEXPLOREArticleNumberdeprecated": "6064991",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658148;5613447;5290706;1532126"
            }
        },
        {
            "name": "Donghao Ren",
            "value": 20,
            "numPapers": 33,
            "cluster": "5",
            "index": 450,
            "weight": 2,
            "x": 1274.2120852343216,
            "y": 311.6229734548814,
            "px": 1316.3501634868383,
            "py": 313.9354748203647,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "iVisDesigner: Expressive Interactive Design of Information Visualizations",
                "PaperDOI": "10.1109/TVCG.2014.2346291",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346291",
                "Firstpage": "2092",
                "Lastpage": "2101",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.",
                "AuthorNames": "Donghao Ren;Hollerer, T.;Xiaoru Yuan",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Donghao Ren;Hollerer, T.;Xiaoru Yuan",
                "References": "10.1109/INFVIS.2004.12;10.1109/TVCG.2010.144;10.1109/TVCG.2009.179;10.1109/TVCG.2009.174;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2010.126;10.1109/TVCG.2013.191;10.1109/INFVIS.1997.636792;10.1109/TVCG.2011.201;10.1109/TVCG.2011.261;10.1109/TVCG.2012.275;10.1109/INFVIS.1997.636761",
                "AuthorKeywords": "Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6876042",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382904;5613453;5290705;5290720;1532788;6064996;4376131;1382905;5613455;6634113;636792;6064997;6064975;6327284;636761"
            }
        },
        {
            "name": "Cong Guo",
            "value": 11,
            "numPapers": 29,
            "cluster": "5",
            "index": 451,
            "weight": 2,
            "x": 1235.8947505173185,
            "y": 209.2336880934129,
            "px": 1280.8321998074439,
            "py": 221.664577097646,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Interactive visual clustering of large collections of trajectories",
                "PaperDOI": "10.1109/VAST.2009.5332584",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332584",
                "Firstpage": "3",
                "Lastpage": "10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.",
                "AuthorNames": "Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;;",
                "AuthorIDs": "37283047100;37283047700;37670571400;37669195900;37394413600;37268539100",
                "Dedupedauthornames": "Andrienko, G.;Andrienko, N.;Rinzivillo, S.;Nanni, M.;Pedreschi, D.;Giannotti, F.",
                "References": "10.1109/VAST.2008.4677356;10.1109/VAST.2007.4388999",
                "AuthorKeywords": "Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization",
                "IEEEXPLOREArticleNumberdeprecated": "5332584",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4677356;4388999"
            }
        },
        {
            "name": "Bergeron, R.D.",
            "value": 112,
            "numPapers": 20,
            "cluster": "5",
            "index": 452,
            "weight": 4,
            "x": 1169.4433596838462,
            "y": 328.0920766895054,
            "px": 1162.3213459272451,
            "py": 372.33696938242906,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "Multiresolution multidimensional wavelet brushing",
                "PaperDOI": "10.1109/VISUAL.1996.567800",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567800",
                "Firstpage": "141",
                "Lastpage": "148",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Brushing is a data visualization technique that identifies and highlights data subsets. We introduce a form of brushing in which the brushed data is usually displayed at a different resolution than the non brushed data. The paper presents the rationale behind the multiresolution support of multivariate data visualization and describes the construction of multiresolution brushing using wavelet approximations. The idea is implemented in an enhanced version of XmdvTool. Real scientific data is used for demonstration and practical applications are suggested.",
                "AuthorNames": "Pak Chung Wong;Bergeron, R.D.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;",
                "AuthorIDs": "37280665600;",
                "Dedupedauthornames": "Pak Chung Wong;Bergeron, R.D.",
                "References": "10.1109/VISUAL.1990.146386;10.1109/VISUAL.1993.398864;10.1109/VISUAL.1995.480811;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "567800",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146386;398864;480811;346302;485139;146402"
            }
        },
        {
            "name": "Chiricota, Y.",
            "value": 54,
            "numPapers": 17,
            "cluster": "0",
            "index": 453,
            "weight": 1,
            "x": 916.0193628064582,
            "y": 413.0967948091962,
            "px": 879.4031278917054,
            "py": 366.17609431950007,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration",
                "PaperDOI": "10.1109/TVCG.2010.205",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.205",
                "Firstpage": "1100",
                "Lastpage": "1108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.",
                "AuthorNames": "Viau, C.;McGuffin, M.J.;Chiricota, Y.;Jurisica, I.",
                "FirstAuthorAffiliation": "Ecole de Technol. Super., Montreal, QC, Canada|c|;;;",
                "AuthorIDs": "37590930300;37403234300;37282997400;37353445900",
                "Dedupedauthornames": "Viau, C.;McGuffin, M.J.;Chiricota, Y.;Jurisica, I.",
                "References": "10.1109/TVCG.2009.151;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532141;10.1109/TVCG.2006.187;10.1109/INFVIS.2004.47;10.1109/TVCG.2007.70521;10.1109/INFVIS.2003.1249011;10.1109/TVCG.2008.153",
                "AuthorKeywords": "Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu",
                "IEEEXPLOREArticleNumberdeprecated": "5613448",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290697;1532142;4376168;5290705;5332586;1532141;4015436;1382901;4376140;1249011;4658123"
            }
        },
        {
            "name": "Lins, L.",
            "value": 41,
            "numPapers": 17,
            "cluster": "0",
            "index": 454,
            "weight": 1,
            "x": 1032.3297016686618,
            "y": 1400.3167288625907,
            "px": 894.190029955563,
            "py": 1296.5839962151176,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "Nanocubes for Real-Time Exploration of Spatiotemporal Datasets",
                "PaperDOI": "10.1109/TVCG.2013.179",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.179",
                "Firstpage": "2456",
                "Lastpage": "2465",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.",
                "AuthorNames": "Lins, L.;Klosowski, J.T.;Scheidegger, C.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Lins, L.;Klosowski, J.T.;Scheidegger, C.E.",
                "References": "10.1109/TVCG.2006.161;10.1109/INFVIS.2002.1173141;10.1109/TVCG.2009.191;10.1109/VAST.2008.4677357;10.1109/TVCG.2007.70594;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185",
                "AuthorKeywords": "Data cube, Data structures, Interactive exploration",
                "IEEEXPLOREArticleNumberdeprecated": "6634137",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015421;1173141;5290718;4677357;4376133;1173156;146386;6064996"
            }
        },
        {
            "name": "Cowley, W.",
            "value": 81,
            "numPapers": 13,
            "cluster": "1",
            "index": 455,
            "weight": 2,
            "x": -118.71503387417631,
            "y": 108.03196526840624,
            "px": -84.17263558913447,
            "py": 128.34197455028678,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "Firstpage": "105",
                "Lastpage": "111",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as ABCD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "References": "10.1109/INFVIS.1998.729565;10.1109/INFVIS.1998.729570;10.1109/VISUAL.1998.745302;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1999.801866;10.1109/INFVIS.1997.636791",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885097",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Fujishiro, I.",
            "value": 126,
            "numPapers": 25,
            "cluster": "3",
            "index": 456,
            "weight": 2,
            "x": 346.2363421649791,
            "y": 654.4038739602915,
            "px": 302.85972075038075,
            "py": 626.7384217070227,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Automating transfer function design for comprehensible volume rendering based on 3D field topology analysis",
                "PaperDOI": "10.1109/VISUAL.1999.809932",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809932",
                "Firstpage": "467",
                "Lastpage": "563",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes initial results of a 3D field topology analysis for automating transfer function design aiming at comprehensible volume rendering. The conventional Reeb graph-based approach to describing topological features of 3D surfaces is extended to capture the topological skeleton of a volumetric field. Based on the analysis result, which is represented in the form of a hyper Reeb graph, a procedure is proposed for designing appropriate color/opacity transfer functions. Two analytic volume datasets are used to preliminarily prove the feasibility of the present design methodology.",
                "AuthorNames": "Fujishiro, I.;Azuma, T.;Takeshima, Y.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;",
                "AuthorIDs": "37282596600;37446215100;37282600100",
                "Dedupedauthornames": "Fujishiro, I.;Azuma, T.;Takeshima, Y.",
                "References": "10.1109/VISUAL.1996.568113",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809932",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568112"
            }
        },
        {
            "name": "Takeshima, Y.",
            "value": 100,
            "numPapers": 14,
            "cluster": "2",
            "index": 457,
            "weight": 1,
            "x": 961.329922660241,
            "y": 1506.4301616069142,
            "px": 859.7452170167793,
            "py": 1358.4702683986804,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Automating transfer function design for comprehensible volume rendering based on 3D field topology analysis",
                "PaperDOI": "10.1109/VISUAL.1999.809932",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809932",
                "Firstpage": "467",
                "Lastpage": "563",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes initial results of a 3D field topology analysis for automating transfer function design aiming at comprehensible volume rendering. The conventional Reeb graph-based approach to describing topological features of 3D surfaces is extended to capture the topological skeleton of a volumetric field. Based on the analysis result, which is represented in the form of a hyper Reeb graph, a procedure is proposed for designing appropriate color/opacity transfer functions. Two analytic volume datasets are used to preliminarily prove the feasibility of the present design methodology.",
                "AuthorNames": "Fujishiro, I.;Azuma, T.;Takeshima, Y.",
                "FirstAuthorAffiliation": "Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;",
                "AuthorIDs": "37282596600;37446215100;37282600100",
                "Dedupedauthornames": "Fujishiro, I.;Azuma, T.;Takeshima, Y.",
                "References": "10.1109/VISUAL.1996.568113",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809932",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568112"
            }
        },
        {
            "name": "Barakat, S.S.",
            "value": 8,
            "numPapers": 14,
            "cluster": "3",
            "index": 458,
            "weight": 2,
            "x": 192.4219234016458,
            "y": 506.2147385515653,
            "px": 188.7001144423754,
            "py": 511.42505913096977,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Adaptive Refinement of the Flow Map Using Sparse Samples",
                "PaperDOI": "10.1109/TVCG.2013.128",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.128",
                "Firstpage": "2753",
                "Lastpage": "2762",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.",
                "AuthorNames": "Barakat, S.S.;Tricoche, X.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Purdue Univ., West Lafayette, IN, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Barakat, S.S.;Tricoche, X.",
                "References": "10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2007.70554;10.1109/TVCG.2007.70551",
                "AuthorKeywords": "Lagrangian flow visualization, flow map, edge features, scattered data interpolation, sparse sampling, adaptive refinement, parallel reconstruction",
                "IEEEXPLOREArticleNumberdeprecated": "6634133",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290738;4658156;4376174;4376175"
            }
        },
        {
            "name": "Kraus, M.",
            "value": 192,
            "numPapers": 22,
            "cluster": "2",
            "index": 459,
            "weight": 12,
            "x": 281.7891446884851,
            "y": 252.24180537922584,
            "px": 254.83084906771236,
            "py": 234.26027197066804,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated volume and isosurface rendering based on cell-projection",
                "PaperDOI": "10.1109/VISUAL.2000.885683",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885683",
                "Firstpage": "109",
                "Lastpage": "116",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.",
                "AuthorNames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37357145300;37284293000;37268023800",
                "Dedupedauthornames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "References": "10.1109/VISUAL.1993.398846;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1999.809887;10.1109/VISUAL.1994.346308;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1994.346306;10.1109/VISUAL.1997.663853;10.1109/VISUAL.1999.809878;10.1109/VISUAL.1996.568127;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745713",
                "AuthorKeywords": "Volume Rendering, Isosurfaces, Unstructured\nMeshes, Cell Projection, Graphics Hardware, Texture Mapping, Compositing",
                "IEEEXPLOREArticleNumberdeprecated": "885683",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398846;346320;809887;346308;885688;346306;663853;809878;568127;480806;745300;568121;745713"
            }
        },
        {
            "name": "Bordoloi, U.D.",
            "value": 79,
            "numPapers": 15,
            "cluster": "2",
            "index": 460,
            "weight": 1,
            "x": 301.44243857198313,
            "y": 12.767948970082287,
            "px": 338.0841296786614,
            "py": 24.229420007529356,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "View selection for volume rendering",
                "PaperDOI": "10.1109/VISUAL.2005.1532833",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532833",
                "Firstpage": "487",
                "Lastpage": "494",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint \"goodness\" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests \"interesting\" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the \"interesting\" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.",
                "AuthorNames": "Bordoloi, U.D.;Han-Wei Shen",
                "FirstAuthorAffiliation": "Ohio State Univ., Columbus, OH, USA|c|;",
                "AuthorIDs": "37561558700;37279493500",
                "Dedupedauthornames": "Bordoloi, U.D.;Han-Wei Shen",
                "References": "10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2001.964516",
                "AuthorKeywords": "viewpoint selection, view space partitioning, volume rendering, entropy, visibility",
                "IEEEXPLOREArticleNumberdeprecated": "1532833",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885694;1250386;1532834;964516"
            }
        },
        {
            "name": "Pang, A.",
            "value": 294,
            "numPapers": 93,
            "cluster": "3",
            "index": 461,
            "weight": 28,
            "x": 74.7969405992569,
            "y": 608.9365164025398,
            "px": 112.73080455092267,
            "py": 593.4919979120838,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Topological lines in 3D tensor fields",
                "PaperDOI": "10.1109/VISUAL.2004.105",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.105",
                "Firstpage": "313",
                "Lastpage": "320",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of 3D tensor fields continues to be a major challenge in terms of providing intuitive and uncluttered images that allow the users to better understand their data. The primary focus of this paper is on finding a formulation that lends itself to a stable numerical algorithm for extracting stable and persistent topological features from 2nd order real symmetric 3D tensors. While features in 2D tensors can be identified as either wedge or trisector points, in 3D, the corresponding stable features are lines, not just points. These topological feature lines provide a compact representation of the 3D tensor field and are essential in helping scientists and engineers understand their complex nature. Existing techniques work by finding degenerate points and are not numerically stable, and worse, produce both false positive and false negative feature points. This work seeks to address this problem with a robust algorithm that can extract these features in a numerically stable, accurate, and complete manner.",
                "AuthorNames": "Zheng, X.;Pang, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37274785100;37267352000",
                "Dedupedauthornames": "Zheng, X.;Pang, A.",
                "References": "10.1109/VISUAL.1998.745316;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2003.1250379;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886",
                "AuthorKeywords": "hyperstreamlines, real symmetric tensors, degenerate tensors, tensor topology, topological lines",
                "IEEEXPLOREArticleNumberdeprecated": "1372212",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745316;809894;398849;1250379;1183798;346326;809905;745294;809886"
            }
        },
        {
            "name": "Wei Zeng",
            "value": 26,
            "numPapers": 20,
            "cluster": "2",
            "index": 462,
            "weight": 1,
            "x": 1859.5867223448083,
            "y": 1253.7790499394796,
            "px": 1681.3641543357458,
            "py": 1128.0777681988063,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Context Preserving Maps of Tubular Structures",
                "PaperDOI": "10.1109/TVCG.2011.182",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.182",
                "Firstpage": "1997",
                "Lastpage": "2004",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "When visualizing tubular 3D structures, external representations are often used for guidance and display, and such views in 2D can often contain occlusions. Virtual dissection methods have been proposed where the entire 3D structure can be mapped to the 2D plane, though these will lose context by straightening curved sections. We present a new method of creating maps of 3D tubular structures that yield a succinct view while preserving the overall geometric structure. Given a dominant view plane for the structure, its curve skeleton is first projected to a 2D skeleton. This 2D skeleton is adjusted to account for distortions in length, modified to remove intersections, and optimized to preserve the shape of the original 3D skeleton. Based on this shaped 2D skeleton, a boundary for the map of the object is obtained based on a slicing path through the structure and the radius around the skeleton. The sliced structure is conformally mapped to a rectangle and then deformed via harmonic mapping to match the boundary placement. This flattened map preserves the general geometric context of a 3D object in a 2D display, and rendering of this flattened map can be accomplished using volumetric ray casting. We have evaluated our method on real datasets of human colon models.",
                "AuthorNames": "Marino, J.;Wei Zeng;Xianfeng Gu;Kaufman, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;;",
                "AuthorIDs": "37605959300;38231202300;38183364800;37268052800",
                "Dedupedauthornames": "Marino, J.;Wei Zeng;Xianfeng Gu;Kaufman, A.",
                "References": "10.1109/TVCG.2006.112;10.1109/TVCG.2010.200;10.1109/VISUAL.2001.964540",
                "AuthorKeywords": "Geometry-based technique, volume rendering, biomedical visualization, medical visualization, conformal mapping",
                "IEEEXPLOREArticleNumberdeprecated": "6064963",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015440;5613475;964540"
            }
        },
        {
            "name": "Hong, W.",
            "value": 17,
            "numPapers": 11,
            "cluster": "2",
            "index": 463,
            "weight": 1,
            "x": -1217.9363116415134,
            "y": 1725.8649543924946,
            "px": -1092.1463480785892,
            "py": 1556.9302454837205,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "A Pipeline for Computer Aided Polyp Detection",
                "PaperDOI": "10.1109/TVCG.2006.112",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.112",
                "Firstpage": "861",
                "Lastpage": "868",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy",
                "AuthorNames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stony Brook Univ., NY|c|;;",
                "AuthorIDs": "37277099300;37416126400;37268052800",
                "Dedupedauthornames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "References": "10.1109/VISUAL.2001.964540;10.1109/VISUAL.2004.27;10.1109/VISUAL.1992.235231;10.1109/VISUAL.2003.1250384",
                "AuthorKeywords": "Computer Aided Detection, Virtual Colonoscopy, Texture Analysis, Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "4015440",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964540;1372236;235231;1250384"
            }
        },
        {
            "name": "Obermaier, H.",
            "value": 18,
            "numPapers": 23,
            "cluster": "3",
            "index": 464,
            "weight": 4,
            "x": 203.16560670894532,
            "y": 553.991534464898,
            "px": 223.0377567368653,
            "py": 544.4811153652993,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging",
                "PaperDOI": "10.1109/TVCG.2013.138",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.138",
                "Firstpage": "2703",
                "Lastpage": "2712",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.",
                "AuthorNames": "Gosink, L.;Bensema, K.;Pulsipher, T.;Obermaier, H.;Henry, M.;Childs, H.;Joy, K.I.",
                "FirstAuthorAffiliation": ";;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Gosink, L.;Bensema, K.;Pulsipher, T.;Obermaier, H.;Henry, M.;Childs, H.;Joy, K.I.",
                "References": "10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.208;10.1109/TVCG.2010.181",
                "AuthorKeywords": "Uncertainty visualization, numerical ensembles, statistical visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634123",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183769;1532853;568116;5613476;5613483"
            }
        },
        {
            "name": "Teng-Yok Lee",
            "value": 45,
            "numPapers": 26,
            "cluster": "2",
            "index": 465,
            "weight": 2,
            "x": 486.9568943656611,
            "y": 7.007022034787938,
            "px": 501.89517398945645,
            "py": 5.523679644217155,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform",
                "PaperDOI": "10.1109/TVCG.2013.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.152",
                "Firstpage": "2693",
                "Lastpage": "2702",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.",
                "AuthorNames": "Teng-Yok Lee;Han-Wei Shen",
                "FirstAuthorAffiliation": "Ohio State Univ., Columbus, OH, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Teng-Yok Lee;Han-Wei Shen",
                "References": "10.1109/VISUAL.1999.809910;10.1109/TVCG.2010.131;10.1109/TVCG.2011.246;10.1109/VISUAL.2001.964516;10.1109/TVCG.2011.198;10.1109/TVCG.2009.197",
                "AuthorKeywords": "WaveletSAT, integral histograms, discrete wavelet transform",
                "IEEEXPLOREArticleNumberdeprecated": "6634159",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809910;5613461;6064965;964516;6064942;5290751"
            }
        },
        {
            "name": "Kastner, J.",
            "value": 7,
            "numPapers": 14,
            "cluster": "2",
            "index": 466,
            "weight": 1,
            "x": -848.5086353110047,
            "y": 2160.9051843114444,
            "px": -772.7402943878103,
            "py": 1960.7456771940867,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data",
                "PaperDOI": "10.1109/TVCG.2013.177",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.177",
                "Firstpage": "2906",
                "Lastpage": "2915",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.",
                "AuthorNames": "Reh, A.;Gusenbauer, C.;Kastner, J.;Groller, M.E.;Heinzl, C.",
                "FirstAuthorAffiliation": "Univ. of Appl. Sci. Upper Austria, Wels, Austria|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Reh, A.;Gusenbauer, C.;Kastner, J.;Groller, E.;Heinzl, C.",
                "References": "10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809871;10.1109/TVCG.2009.121;10.1109/TVCG.2012.227;10.1109/TVCG.2011.248;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.190;10.1109/TVCG.2010.214;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1997.663875",
                "AuthorKeywords": "3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects",
                "IEEEXPLOREArticleNumberdeprecated": "6634106",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327240;809871;5290766;6327238;6064952;1532807;5613488;5613489;398859;663875"
            }
        },
        {
            "name": "Entezari, A.",
            "value": 53,
            "numPapers": 45,
            "cluster": "2",
            "index": 467,
            "weight": 8,
            "x": 471.3961540174712,
            "y": 129.20546716669574,
            "px": 307.8366649789222,
            "py": -53.66512136067832,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Uncertainty Quantification in Linear Interpolation for Isosurface Extraction",
                "PaperDOI": "10.1109/TVCG.2013.208",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.208",
                "Firstpage": "2723",
                "Lastpage": "2732",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.",
                "AuthorNames": "Athawale, T.;Entezari, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA|c|;",
                "AuthorIDs": ";",
                "Dedupedauthornames": "Athawale, T.;Entezari, A.",
                "References": "10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70602;10.1109/VISUAL.1991.175782;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.194;10.1109/TVCG.2011.203",
                "AuthorKeywords": "Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes",
                "IEEEXPLOREArticleNumberdeprecated": "6634171",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532853;4376179;175782;4376198;6327235;346331;568116;5290733;6064958"
            }
        },
        {
            "name": "Marschner, S.R.",
            "value": 90,
            "numPapers": 1,
            "cluster": "2",
            "index": 468,
            "weight": 3,
            "x": 599.1055352334087,
            "y": 182.26248626239058,
            "px": 742.9305005431411,
            "py": 320.36625407197835,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "An evaluation of reconstruction filters for volume rendering",
                "PaperDOI": "10.1109/VISUAL.1994.346331",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346331",
                "Firstpage": "100",
                "Lastpage": "107, C10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter",
                "AuthorNames": "Marschner, S.R.;Lobb, R.J.",
                "FirstAuthorAffiliation": "Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;",
                "AuthorIDs": "37333371500;37659292200",
                "Dedupedauthornames": "Marschner, S.R.;Lobb, R.J.",
                "References": "10.1109/VISUAL.1993.398851",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346331",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398851"
            }
        },
        {
            "name": "Lobb, R.J.",
            "value": 90,
            "numPapers": 1,
            "cluster": "2",
            "index": 469,
            "weight": 3,
            "x": 18.493600840295358,
            "y": -1063.3840666763847,
            "px": -7.844332519029625,
            "py": -1319.174665898703,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "An evaluation of reconstruction filters for volume rendering",
                "PaperDOI": "10.1109/VISUAL.1994.346331",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346331",
                "Firstpage": "100",
                "Lastpage": "107, C10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "To render images from a three-dimensional array of sample values, it is necessary to interpolate between the samples. This paper is concerned with interpolation methods that are equivalent to convolving the samples with a reconstruction filter; this covers all commonly used schemes, including trilinear and cubic interpolation. We first outline the formal basis of interpolation in three-dimensional signal processing theory. We then propose numerical metrics that can be used to measure filter characteristics that are relevant to the appearance of images generated using that filter. We apply those metrics to several previously used filters and relate the results to isosurface images of the interpolations. We show that the choice of interpolation scheme can have a dramatic effect on image quality, and we discuss the cost/benefit tradeoff inherent in choosing a filter",
                "AuthorNames": "Marschner, S.R.;Lobb, R.J.",
                "FirstAuthorAffiliation": "Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;",
                "AuthorIDs": "37333371500;37659292200",
                "Dedupedauthornames": "Marschner, S.R.;Lobb, R.J.",
                "References": "10.1109/VISUAL.1993.398851",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346331",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398851"
            }
        },
        {
            "name": "Mistelbauer, G.",
            "value": 9,
            "numPapers": 20,
            "cluster": "2",
            "index": 470,
            "weight": 4,
            "x": 151.03095482305875,
            "y": -3.1810684479098708,
            "px": -3.073878515730241,
            "py": 7.874552013038307,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "Firstpage": "2858",
                "Lastpage": "2867",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "References": "10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "Reformation, volume rendering, surface approximation",
                "IEEEXPLOREArticleNumberdeprecated": "6634141",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Baclija, I.",
            "value": 9,
            "numPapers": 20,
            "cluster": "2",
            "index": 471,
            "weight": 4,
            "x": 144.29268136127646,
            "y": -26.393568116635194,
            "px": 82.91817752562199,
            "py": -20.860420080177047,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "Firstpage": "2858",
                "Lastpage": "2867",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "References": "10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "Reformation, volume rendering, surface approximation",
                "IEEEXPLOREArticleNumberdeprecated": "6634141",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Schernthaner, R.",
            "value": 9,
            "numPapers": 20,
            "cluster": "2",
            "index": 472,
            "weight": 4,
            "x": 257.1141774454854,
            "y": -64.75166598832112,
            "px": 279.666885919719,
            "py": -59.70013293393978,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "Firstpage": "2858",
                "Lastpage": "2867",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "References": "10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "Reformation, volume rendering, surface approximation",
                "IEEEXPLOREArticleNumberdeprecated": "6634141",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Kochl, A.",
            "value": 48,
            "numPapers": 24,
            "cluster": "2",
            "index": 473,
            "weight": 7,
            "x": 281.3754179046238,
            "y": 116.48549366659813,
            "px": 269.1856525021629,
            "py": 113.34188019030535,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "Firstpage": "2858",
                "Lastpage": "2867",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "References": "10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "Reformation, volume rendering, surface approximation",
                "IEEEXPLOREArticleNumberdeprecated": "6634141",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Wimmer, M.",
            "value": 6,
            "numPapers": 11,
            "cluster": "2",
            "index": 474,
            "weight": 2,
            "x": -535.5543661374877,
            "y": 123.10847266553698,
            "px": -588.78275038246,
            "py": 133.11289377955572,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "Vessel Visualization using Curved Surface Reformation",
                "PaperDOI": "10.1109/TVCG.2013.215",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.215",
                "Firstpage": "2858",
                "Lastpage": "2867",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
                "AuthorNames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, M.E.;Bruckner, S.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Auzinger, T.;Mistelbauer, G.;Baclija, I.;Schernthaner, R.;Kochl, A.;Wimmer, M.;Groller, E.;Bruckner, S.",
                "References": "10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "Reformation, volume rendering, surface approximation",
                "IEEEXPLOREArticleNumberdeprecated": "6634141",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290742;1372221;1250353;1250400;4015449;5290734;1183754;6064947;1250351;4015452;964555"
            }
        },
        {
            "name": "Straka, M.",
            "value": 39,
            "numPapers": 4,
            "cluster": "2",
            "index": 475,
            "weight": 1,
            "x": 37.715812927565636,
            "y": -1417.737114687839,
            "px": 39.27842692958258,
            "py": -1259.0135236605527,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "Firstpage": "385",
                "Lastpage": "392",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "References": "10.1109/VISUAL.2001.964538;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "focus & context technique, direct volume rendering, curved planar reformation, vessel visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1372221",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964538;1183754;964555"
            }
        },
        {
            "name": "Cervenansky, M.",
            "value": 39,
            "numPapers": 3,
            "cluster": "2",
            "index": 476,
            "weight": 1,
            "x": -462.045082019691,
            "y": 2410.6310581882617,
            "px": -414.21026305636366,
            "py": 2200.207297211023,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "Firstpage": "385",
                "Lastpage": "392",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "References": "10.1109/VISUAL.2001.964538;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "focus & context technique, direct volume rendering, curved planar reformation, vessel visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1372221",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964538;1183754;964555"
            }
        },
        {
            "name": "La Cruz, A.",
            "value": 39,
            "numPapers": 4,
            "cluster": "2",
            "index": 477,
            "weight": 1,
            "x": 211.1506437339309,
            "y": 2029.3126672842523,
            "px": 197.15119689014386,
            "py": 1847.4536930293143,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "Firstpage": "385",
                "Lastpage": "392",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "References": "10.1109/VISUAL.2001.964538;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "focus & context technique, direct volume rendering, curved planar reformation, vessel visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1372221",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964538;1183754;964555"
            }
        },
        {
            "name": "Sramek, M.",
            "value": 75,
            "numPapers": 18,
            "cluster": "2",
            "index": 478,
            "weight": 7,
            "x": 283.62884864089955,
            "y": 109.64431417639727,
            "px": 272.0495050835014,
            "py": 102.16567538323916,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "The VesselGlyph: focus & context visualization in CT-angiography",
                "PaperDOI": "10.1109/VISUAL.2004.104",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.104",
                "Firstpage": "385",
                "Lastpage": "392",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.",
                "AuthorNames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "FirstAuthorAffiliation": "Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;",
                "AuthorIDs": "37282584800;37282580100;37282579200;37282581900;37268028700;38471588900;37282581000",
                "Dedupedauthornames": "Straka, M.;Cervenansky, M.;La Cruz, A.;Kochl, A.;Sramek, M.;Groller, E.;Fleischmann, D.",
                "References": "10.1109/VISUAL.2001.964538;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964555",
                "AuthorKeywords": "focus & context technique, direct volume rendering, curved planar reformation, vessel visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1372221",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964538;1183754;964555"
            }
        },
        {
            "name": "Feixas, M.",
            "value": 68,
            "numPapers": 17,
            "cluster": "2",
            "index": 479,
            "weight": 3,
            "x": 470.6391001570955,
            "y": 7.12764024263522,
            "px": 500.4692176141707,
            "py": -10.663529067938443,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Importance-Driven Focus of Attention",
                "PaperDOI": "10.1109/TVCG.2006.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.152",
                "Firstpage": "933",
                "Lastpage": "940",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views",
                "AuthorNames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;;",
                "AuthorIDs": "37282726800;37426689600;37396572900;37282552200",
                "Dedupedauthornames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, E.",
                "References": "10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532834;10.1109/INFVIS.2001.963286;10.1109/VISUAL.2005.1532833",
                "AuthorKeywords": "Illustrative visualization, volume visualization, interacting with volumetric datasets, characteristic viewpoint estimation, focus+context techniques",
                "IEEEXPLOREArticleNumberdeprecated": "4015449",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532856;1532834;963286;1532833"
            }
        },
        {
            "name": "Sbert, M.",
            "value": 68,
            "numPapers": 17,
            "cluster": "2",
            "index": 480,
            "weight": 3,
            "x": 122.18431551388677,
            "y": 92.06014762360132,
            "px": 111.37674619489184,
            "py": 91.19157732676078,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Importance-Driven Focus of Attention",
                "PaperDOI": "10.1109/TVCG.2006.152",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.152",
                "Firstpage": "933",
                "Lastpage": "940",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views",
                "AuthorNames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;;",
                "AuthorIDs": "37282726800;37426689600;37396572900;37282552200",
                "Dedupedauthornames": "Viola, I.;Feixas, M.;Sbert, M.;Groller, E.",
                "References": "10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532834;10.1109/INFVIS.2001.963286;10.1109/VISUAL.2005.1532833",
                "AuthorKeywords": "Illustrative visualization, volume visualization, interacting with volumetric datasets, characteristic viewpoint estimation, focus+context techniques",
                "IEEEXPLOREArticleNumberdeprecated": "4015449",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532856;1532834;963286;1532833"
            }
        },
        {
            "name": "Sandner, D.",
            "value": 45,
            "numPapers": 0,
            "cluster": "2",
            "index": 481,
            "weight": 2,
            "x": -481.7272895251992,
            "y": 572.4750453343062,
            "px": -532.3026823902422,
            "py": 611.5136680501166,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Computed tomography angiography: a case study of peripheral vessel investigation",
                "PaperDOI": "10.1109/VISUAL.2001.964555",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964555",
                "Firstpage": "477",
                "Lastpage": "480",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper deals with vessel exploration based on computed tomography angiography. Large image sequences of the lower extremities are investigated in a clinical environment. Two different approaches for peripheral vessel diagnosis dealing with stenosis and calcification detection are introduced. The paper presents an automated vessel-tracking tool for curved planar reformation. An interactive segmentation tool for bone removal is proposed.",
                "AuthorNames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Sandner, D.;Felkel, P.;Groller, E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;",
                "AuthorIDs": "37282727500;37282581000;37267822600;37728392500;37267788200;37284271200",
                "Dedupedauthornames": "Kanitsar, A.;Fleischmann, D.;Wegenkittl, R.;Sandner, D.;Felkel, P.;Groller, E.",
                "References": "",
                "AuthorKeywords": "Computed Tomography Angiography (CTA), semi automatic segmentation, optimal path computation",
                "IEEEXPLOREArticleNumberdeprecated": "964555",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Baudel, T.",
            "value": 27,
            "numPapers": 24,
            "cluster": "0",
            "index": 482,
            "weight": 1,
            "x": 512.4736263956254,
            "y": -1144.2692155235225,
            "px": 509.3862904560271,
            "py": -986.7496890814367,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Decision Exploration Lab: A Visual Analytics Solution for Decision Management",
                "PaperDOI": "10.1109/TVCG.2013.146",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.146",
                "Firstpage": "1972",
                "Lastpage": "1981",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.",
                "AuthorNames": "Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.",
                "FirstAuthorAffiliation": "IBM France Center for Adv. Studies, Univ. of Groningen, Groningen, France|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Broeksema, B.;Baudel, T.;Telea, A.;Crisafulli, P.",
                "References": "10.1109/VISUAL.1991.175815;10.1109/VAST.2011.6102463;10.1109/VAST.2010.5652398;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677363;10.1109/TVCG.2011.185;10.1109/VAST.2011.6102457",
                "AuthorKeywords": "Decision support systems, model validation and analysis, multivariate Statistics, program analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6634184",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175815;6102463;5652398;4677361;4677363;6064996;6102457"
            }
        },
        {
            "name": "Kapler, T.",
            "value": 167,
            "numPapers": 7,
            "cluster": "5",
            "index": 483,
            "weight": 2,
            "x": 1307.1128361999783,
            "y": 468.784835903749,
            "px": 1320.344240380364,
            "py": 470.98097237715814,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "GeoTime Information Visualization",
                "PaperDOI": "10.1109/INFVIS.2004.27",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.27",
                "Firstpage": "25",
                "Lastpage": "32",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks",
                "AuthorNames": "Kapler, T.;Wright, W.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37704437500;37654961400",
                "Dedupedauthornames": "Kapler, T.;Wright, W.",
                "References": "10.1109/INFVIS.2003.1249006",
                "AuthorKeywords": "3-D visualization, spatiotemporal, geospatial, interactive visualization, visual data analysis, link analysis",
                "IEEEXPLOREArticleNumberdeprecated": "1382887",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249006"
            }
        },
        {
            "name": "Wright, W.",
            "value": 179,
            "numPapers": 8,
            "cluster": "5",
            "index": 484,
            "weight": 2,
            "x": 1235.6549459554715,
            "y": 352.5371354543947,
            "px": 1240.5461239643967,
            "py": 348.2965638200453,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "GeoTime Information Visualization",
                "PaperDOI": "10.1109/INFVIS.2004.27",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.27",
                "Firstpage": "25",
                "Lastpage": "32",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks",
                "AuthorNames": "Kapler, T.;Wright, W.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37704437500;37654961400",
                "Dedupedauthornames": "Kapler, T.;Wright, W.",
                "References": "10.1109/INFVIS.2003.1249006",
                "AuthorKeywords": "3-D visualization, spatiotemporal, geospatial, interactive visualization, visual data analysis, link analysis",
                "IEEEXPLOREArticleNumberdeprecated": "1382887",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249006"
            }
        },
        {
            "name": "Andrews, C.",
            "value": 27,
            "numPapers": 20,
            "cluster": "0",
            "index": 485,
            "weight": 3,
            "x": 1024.7887551439208,
            "y": -289.80051950237765,
            "px": 1043.5485564258397,
            "py": -323.4918418699312,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis",
                "PaperDOI": "10.1109/VAST.2010.5652932",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652932",
                "Firstpage": "107",
                "Lastpage": "114",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool's effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis.",
                "AuthorNames": "Haeyong Chung;Seungwon Yang;Massjouni, N.;Andrews, C.;Kanna, R.;North, C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;",
                "AuthorIDs": "37597408500;37598427300;37591135300;37587847300;37591136300;37419565900",
                "Dedupedauthornames": "Haeyong Chung;Seungwon Yang;Massjouni, N.;Andrews, C.;Kanna, R.;North, C.",
                "References": "10.1109/TVCG.2009.148;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333245;10.1109/VAST.2008.4677362;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677366",
                "AuthorKeywords": "Collaborative visualization, text and document data, intelligence analysis",
                "IEEEXPLOREArticleNumberdeprecated": "5652932",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290715;4389006;5333245;4677362;4376131;4677366"
            }
        },
        {
            "name": "Rind, A.",
            "value": 35,
            "numPapers": 16,
            "cluster": "0",
            "index": 486,
            "weight": 1,
            "x": -175.69100358083017,
            "y": -1533.706754148792,
            "px": -110.5149464835496,
            "py": -1347.1709533325309,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analytics for Model Selection in Time Series Analysis",
                "PaperDOI": "10.1109/TVCG.2013.222",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.222",
                "Firstpage": "2237",
                "Lastpage": "2246",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.",
                "AuthorNames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "References": "10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views",
                "IEEEXPLOREArticleNumberdeprecated": "6634112",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634096;6327248;4376146"
            }
        },
        {
            "name": "Lammarsch, T.",
            "value": 35,
            "numPapers": 16,
            "cluster": "0",
            "index": 487,
            "weight": 1,
            "x": 76.86192579255753,
            "y": -1621.1590920652834,
            "px": 116.09147468278293,
            "py": -1425.7690292975776,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Analytics for Model Selection in Time Series Analysis",
                "PaperDOI": "10.1109/TVCG.2013.222",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.222",
                "Firstpage": "2237",
                "Lastpage": "2246",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.",
                "AuthorNames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Bogl, M.;Aigner, W.;Filzmoser, P.;Lammarsch, T.;Miksch, S.;Rind, A.",
                "References": "10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views",
                "IEEEXPLOREArticleNumberdeprecated": "6634112",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634096;6327248;4376146"
            }
        },
        {
            "name": "Legg, P.A.",
            "value": 13,
            "numPapers": 14,
            "cluster": "9",
            "index": 488,
            "weight": 1,
            "x": 1304.7903104936768,
            "y": 535.7587468976341,
            "px": 1423.5964164287047,
            "py": 437.35303443310227,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "Firstpage": "2109",
                "Lastpage": "2118",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Chen, M.",
                "References": "10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208",
                "AuthorKeywords": "Visual knowledge discovery, data clustering, machine learning, multimedia visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Chung, D.H.S.",
            "value": 13,
            "numPapers": 14,
            "cluster": "9",
            "index": 489,
            "weight": 1,
            "x": 1888.0395215878439,
            "y": 829.7041472335444,
            "px": 1946.8756561938233,
            "py": 702.4587621583818,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "Firstpage": "2109",
                "Lastpage": "2118",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Chen, M.",
                "References": "10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208",
                "AuthorKeywords": "Visual knowledge discovery, data clustering, machine learning, multimedia visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Parry, M.L.",
            "value": 13,
            "numPapers": 14,
            "cluster": "9",
            "index": 490,
            "weight": 1,
            "x": 1489.8249332153116,
            "y": 256.6638507340967,
            "px": 1592.659736790082,
            "py": 212.1742040721747,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "Firstpage": "2109",
                "Lastpage": "2118",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Chen, M.",
                "References": "10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208",
                "AuthorKeywords": "Visual knowledge discovery, data clustering, machine learning, multimedia visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Griffiths, I.W.",
            "value": 13,
            "numPapers": 14,
            "cluster": "9",
            "index": 491,
            "weight": 1,
            "x": 1103.8431566907348,
            "y": -165.13652927909646,
            "px": 1254.7499320220413,
            "py": -163.407555408707,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop",
                "PaperDOI": "10.1109/TVCG.2013.207",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.207",
                "Firstpage": "2109",
                "Lastpage": "2118",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.",
                "AuthorNames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Min Chen",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;",
                "AuthorIDs": ";;;;;;",
                "Dedupedauthornames": "Legg, P.A.;Chung, D.H.S.;Parry, M.L.;Bown, R.;Jones, M.W.;Griffiths, I.W.;Chen, M.",
                "References": "10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208",
                "AuthorKeywords": "Visual knowledge discovery, data clustering, machine learning, multimedia visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6634165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015422;1250401;5332628;5613439;4389001;4658160;729568;4015469;6064937"
            }
        },
        {
            "name": "Daniel, G.",
            "value": 42,
            "numPapers": 1,
            "cluster": "9",
            "index": 492,
            "weight": 1,
            "x": 1278.5417125949023,
            "y": 1343.2583542819282,
            "px": 1404.9257058440942,
            "py": 1158.2433838833908,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Video visualization",
                "PaperDOI": "10.1109/VISUAL.2003.1250401",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250401",
                "Firstpage": "409",
                "Lastpage": "416",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for \"summarizing\" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing \"relative\" and \"absolute\" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.",
                "AuthorNames": "Daniel, G.;Chen, M.",
                "FirstAuthorAffiliation": "Univ. of Wales Swansea, UK|c|;",
                "AuthorIDs": "38201565200;37280982800",
                "Dedupedauthornames": "Daniel, G.;Chen, M.",
                "References": "10.1109/VISUAL.2002.1183790",
                "AuthorKeywords": " Video visualization, volume rendering, video surveillance, change detection, image-swept volume",
                "IEEEXPLOREArticleNumberdeprecated": "1250401",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183790"
            }
        },
        {
            "name": "Interrante, V.",
            "value": 202,
            "numPapers": 20,
            "cluster": "2",
            "index": 493,
            "weight": 6,
            "x": 423.3491592597389,
            "y": 131.13244767517835,
            "px": 455.1011310389305,
            "py": 127.37832529648269,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Effectively visualizing multi-valued flow data using color and texture",
                "PaperDOI": "10.1109/VISUAL.2003.1250362",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250362",
                "Firstpage": "115",
                "Lastpage": "121",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we offer several new insights and techniques for effectively using color and texture to simultaneously convey information about multiple 2D scalar and vector distributions, in a way that facilitates allowing each distribution to be understood both individually and in the context of one or more of the other distributions. Specifically, we introduce the concepts of: color weaving for simultaneously representing information about multiple co-located color encoded distributions; and texture stitching for achieving more spatially accurate multi-frequency line integral convolution representations of combined scalar and vector distributions. The target application for our research is the definition, detection and visualization of regions of interest in a turbulent boundary layer flow at moderate Reynolds number. In this work, we examine and analyze streamwise-spanwise planes of three-component velocity vectors with the goal of identifying and characterizing spatially organized packets of hairpin vortices.",
                "AuthorNames": "Urness, T.;Interrante, V.;Marusic, Ivan;Longmire, E.;Ganapathisubramani, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Minnesota Univ., USA|c|;;;;",
                "AuthorIDs": "37282639600;37282637800;37282626600;37282625600;37282627400",
                "Dedupedauthornames": "Urness, T.;Interrante, V.;Marusic, I.;Longmire, E.;Ganapathisubramani, B.",
                "References": "10.1109/VISUAL.1999.809905;10.1109/VISUAL.1997.663897;10.1109/VISUAL.1996.568118;10.1109/VISUAL.2002.1183788;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1998.745292",
                "AuthorKeywords": "flow visualization, line integral convolution, multi-variate data visualization, color, texture",
                "IEEEXPLOREArticleNumberdeprecated": "1250362",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809905;663897;568118;1183788;567784;745294;745292"
            }
        },
        {
            "name": "Junping Zhang",
            "value": 67,
            "numPapers": 13,
            "cluster": "5",
            "index": 494,
            "weight": 2,
            "x": 950.168228007555,
            "y": 277.7350026984931,
            "px": 955.2147952063518,
            "py": 286.12780356205326,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "Visual Traffic Jam Analysis Based on Trajectory Data",
                "PaperDOI": "10.1109/TVCG.2013.228",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.228",
                "Firstpage": "2159",
                "Lastpage": "2168",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",
                "AuthorNames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.",
                "FirstAuthorAffiliation": "Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;van de Wetering, H.",
                "References": "10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455",
                "AuthorKeywords": "Traffic visualization, traffic jam propagation",
                "IEEEXPLOREArticleNumberdeprecated": "6634174",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663866;6102454;5290707;6400556;1382887;4677356;6065021;6400553;6327262;6065019;5332593;4658146;6102455"
            }
        },
        {
            "name": "Dinkla, K.",
            "value": 4,
            "numPapers": 13,
            "cluster": "0",
            "index": 495,
            "weight": 1,
            "x": -916.384751078329,
            "y": 734.9183238695778,
            "px": -760.9237149559278,
            "py": 678.0027104869469,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Compressed Adjacency Matrices: Untangling Gene Regulatory Networks",
                "PaperDOI": "10.1109/TVCG.2012.208",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.208",
                "Firstpage": "2457",
                "Lastpage": "2466",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.",
                "AuthorNames": "Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "38489573400;38185191700;37267249200",
                "Dedupedauthornames": "Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.",
                "References": "10.1109/TVCG.2011.187;10.1109/TVCG.2006.160;10.1109/TVCG.2007.70582;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.147;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70556;10.1109/INFVIS.2004.5;10.1109/TVCG.2006.156;10.1109/TVCG.2010.159;10.1109/INFVIS.2003.1249030",
                "AuthorKeywords": "Network, gene regulation, scale-free, adjacency matrix",
                "IEEEXPLOREArticleNumberdeprecated": "6327251",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064992;4015417;4376154;1382886;1532126;1382907;4015425;4658145;4376153;1382884;4015435;5613445;1249030"
            }
        },
        {
            "name": "Westenberg, M.A.",
            "value": 4,
            "numPapers": 13,
            "cluster": "0",
            "index": 496,
            "weight": 1,
            "x": -1206.445075610989,
            "y": 49.44570005385065,
            "px": -1023.9780275633731,
            "py": 64.16989024359502,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "Compressed Adjacency Matrices: Untangling Gene Regulatory Networks",
                "PaperDOI": "10.1109/TVCG.2012.208",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.208",
                "Firstpage": "2457",
                "Lastpage": "2466",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.",
                "AuthorNames": "Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "38489573400;38185191700;37267249200",
                "Dedupedauthornames": "Dinkla, K.;Westenberg, M.A.;van Wijk, J.J.",
                "References": "10.1109/TVCG.2011.187;10.1109/TVCG.2006.160;10.1109/TVCG.2007.70582;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.147;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70556;10.1109/INFVIS.2004.5;10.1109/TVCG.2006.156;10.1109/TVCG.2010.159;10.1109/INFVIS.2003.1249030",
                "AuthorKeywords": "Network, gene regulation, scale-free, adjacency matrix",
                "IEEEXPLOREArticleNumberdeprecated": "6327251",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064992;4015417;4376154;1382886;1532126;1382907;4015425;4658145;4376153;1382884;4015435;5613445;1249030"
            }
        },
        {
            "name": "Frank, A.",
            "value": 8,
            "numPapers": 13,
            "cluster": "0",
            "index": 497,
            "weight": 1,
            "x": 728.9876865221935,
            "y": 1389.3659017545829,
            "px": 695.8990629268897,
            "py": 1243.0747918875347,
            "node": {
                "Conference": "InfoVis",
                "Year": "2012",
                "PaperTitle": "RelEx: Visualization for Actively Changing Overlay Network Specifications",
                "PaperDOI": "10.1109/TVCG.2012.255",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.255",
                "Firstpage": "2729",
                "Lastpage": "2738",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.",
                "AuthorNames": "Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.",
                "FirstAuthorAffiliation": "Univ. of British Columbia, Vancouver, BC, Canada|c|;;;",
                "AuthorIDs": "37590945600;38490124000;37349490300;37299644000",
                "Dedupedauthornames": "Sedlmair, M.;Frank, A.;Munzner, T.;Butz, A.",
                "References": "10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102443;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.111;10.1109/TVCG.2009.116;10.1109/INFVIS.1999.801869;10.1109/TVCG.2008.141;10.1109/TVCG.2008.117;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/INFVIS.2003.1249030;10.1109/VAST.2006.261426",
                "AuthorKeywords": "Network visualization, change management, traffic routing, traffic optimization, automotive, design study",
                "IEEEXPLOREArticleNumberdeprecated": "6327279",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015417;1382904;6102443;4376154;5290695;5290690;801869;4658145;4658137;1532126;6327248;1249030;4035752"
            }
        },
        {
            "name": "Butz, A.",
            "value": 14,
            "numPapers": 16,
            "cluster": "0",
            "index": 498,
            "weight": 1,
            "x": 1335.5859202615757,
            "y": 774.8822933384405,
            "px": 1229.3476808292226,
            "py": 688.9736332716932,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity",
                "PaperDOI": "10.1109/TVCG.2014.2352953",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2352953",
                "Firstpage": "2201",
                "Lastpage": "2210",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.",
                "AuthorNames": "Stusak, S.;Tabard, A.;Sauka, F.;Khot, R.A.;Butz, A.",
                "FirstAuthorAffiliation": "Univ. of Munich, Munich, Germany|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Stusak, S.;Tabard, A.;Sauka, F.;Khot, R.A.;Butz, A.",
                "References": "10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031;10.1109/TVCG.2013.134",
                "AuthorKeywords": "Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change",
                "IEEEXPLOREArticleNumberdeprecated": "6888482",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376134;1249031;6634126"
            }
        },
        {
            "name": "Crnovrsanin, T.",
            "value": 51,
            "numPapers": 9,
            "cluster": "5",
            "index": 499,
            "weight": 2,
            "x": 1490.1186562834434,
            "y": 87.82104534905866,
            "px": 1502.382040147294,
            "py": 96.59462667120069,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Proximity-based visualization of movement trace data",
                "PaperDOI": "10.1109/VAST.2009.5332593",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332593",
                "Firstpage": "11",
                "Lastpage": "18",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.",
                "AuthorNames": "Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, CA, USA|c|;;;",
                "AuthorIDs": "37597152500;37299311900;37282925900;37275869400",
                "Dedupedauthornames": "Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma",
                "References": "10.1109/INFVIS.2004.27;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70621;10.1109/TVCG.2007.70558",
                "AuthorKeywords": "Spatio-temporal visualization, proximity, linked views, principal component analysis, temporal trajectories, movement patterns",
                "IEEEXPLOREArticleNumberdeprecated": "5332593",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382887;146402;4376136;4376135"
            }
        },
        {
            "name": "Muelder, C.",
            "value": 70,
            "numPapers": 17,
            "cluster": "5",
            "index": 500,
            "weight": 2,
            "x": 1080.2539168572969,
            "y": 117.53698996898981,
            "px": 1091.21242956081,
            "py": 131.4056410432017,
            "node": {
                "Conference": "VAST",
                "Year": "2009",
                "PaperTitle": "Proximity-based visualization of movement trace data",
                "PaperDOI": "10.1109/VAST.2009.5332593",
                "Link": "http://dx.doi.org/10.1109/VAST.2009.5332593",
                "Firstpage": "11",
                "Lastpage": "18",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.",
                "AuthorNames": "Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Univ. of California, Davis, CA, USA|c|;;;",
                "AuthorIDs": "37597152500;37299311900;37282925900;37275869400",
                "Dedupedauthornames": "Crnovrsanin, T.;Muelder, C.;Correa, C.;Kwan-Liu Ma",
                "References": "10.1109/INFVIS.2004.27;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70621;10.1109/TVCG.2007.70558",
                "AuthorKeywords": "Spatio-temporal visualization, proximity, linked views, principal component analysis, temporal trajectories, movement patterns",
                "IEEEXPLOREArticleNumberdeprecated": "5332593",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382887;146402;4376136;4376135"
            }
        },
        {
            "name": "Joia, P.",
            "value": 20,
            "numPapers": 25,
            "cluster": "10",
            "index": 501,
            "weight": 3,
            "x": 1560.940369277039,
            "y": 637.1685774540155,
            "px": 1605.945082937021,
            "py": 482.65179565276526,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Local Affine Multidimensional Projection",
                "PaperDOI": "10.1109/TVCG.2011.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.220",
                "Firstpage": "2563",
                "Lastpage": "2571",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",
                "AuthorNames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;",
                "AuthorIDs": "38017343000;37590969400;38017342500;38017346900;37590974800",
                "Dedupedauthornames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "References": "10.1109/VISUAL.1996.567787;10.1109/TVCG.2009.140;10.1109/TVCG.2007.70580;10.1109/INFVIS.2002.1173159;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173161",
                "AuthorKeywords": "Multidimensional Projection, High Dimensional Data, Visual Data Mining",
                "IEEEXPLOREArticleNumberdeprecated": "6065024",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567787;5290725;4376155;1173159;5613468;5613498;1173161"
            }
        },
        {
            "name": "Paulovich, F.V.",
            "value": 123,
            "numPapers": 34,
            "cluster": "10",
            "index": 502,
            "weight": 3,
            "x": 1372.3818203984563,
            "y": 510.27062841044557,
            "px": 1461.1722713794736,
            "py": 434.91602036541383,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Local Affine Multidimensional Projection",
                "PaperDOI": "10.1109/TVCG.2011.220",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.220",
                "Firstpage": "2563",
                "Lastpage": "2571",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.",
                "AuthorNames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "FirstAuthorAffiliation": "Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;",
                "AuthorIDs": "38017343000;37590969400;38017342500;38017346900;37590974800",
                "Dedupedauthornames": "Joia, P.;Paulovich, F.V.;Coimbra, D.;Cuminato, J.A.;Nonato, L.G.",
                "References": "10.1109/VISUAL.1996.567787;10.1109/TVCG.2009.140;10.1109/TVCG.2007.70580;10.1109/INFVIS.2002.1173159;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173161",
                "AuthorKeywords": "Multidimensional Projection, High Dimensional Data, Visual Data Mining",
                "IEEEXPLOREArticleNumberdeprecated": "6065024",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567787;5290725;4376155;1173159;5613468;5613498;1173161"
            }
        },
        {
            "name": "Chalmers, M.",
            "value": 121,
            "numPapers": 16,
            "cluster": "10",
            "index": 503,
            "weight": 5,
            "x": 1141.6391513701149,
            "y": 1426.8418555149717,
            "px": 1089.7803641296464,
            "py": 1425.4308677254635,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "A linear iteration time layout algorithm for visualising high-dimensional data",
                "PaperDOI": "10.1109/VISUAL.1996.567787",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567787",
                "Firstpage": "127",
                "Lastpage": "131",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A technique is presented for the layout of high dimensional data in a low dimensional space. This technique builds upon the force based methods that have been used previously to make visualisations of various types of data such as bibliographies and sets of software modules. The canonical force based model, related to solutions of the N body problem, has a computational complexity of O(N 2) per iteration. The paper presents a stochastically based algorithm of linear complexity per iteration which produces good layouts, has low overhead, and is easy to implement. Its performance and accuracy are discussed, in particular with regard to the data to which it is applied. Experience with application to bibliographic and time series data, which may have a dimensionality in the tens of thousands, is described.",
                "AuthorNames": "Chalmers, M.",
                "FirstAuthorAffiliation": "Union Bank of Switzerland, Switzerland|c|",
                "AuthorIDs": "37283487400",
                "Dedupedauthornames": "Chalmers, M.",
                "References": "10.1109/INFVIS.1995.528686;10.1109/VISUAL.1995.480814",
                "AuthorKeywords": "layout algorithms, visualization, high-dimensional data, spring models, stochastic algorithms, force-directed placement",
                "IEEEXPLOREArticleNumberdeprecated": "567787",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528686;480814"
            }
        },
        {
            "name": "Kandogan, E.",
            "value": 1,
            "numPapers": 11,
            "cluster": "5",
            "index": 504,
            "weight": 1,
            "x": 262.3009748663006,
            "y": 285.7714581720505,
            "px": 335.9566777147056,
            "py": 286.4734941002973,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations",
                "PaperDOI": "10.1109/VAST.2012.6400487",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400487",
                "Firstpage": "73",
                "Lastpage": "82",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.",
                "AuthorNames": "Kandogan, E.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "Dedupedauthornames": "Kandogan, E.",
                "References": "10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3;10.1109/TVCG.2011.220;10.1109/INFVIS.2004.15;10.1109/INFVIS.1998.729559;10.1109/VAST.2006.261423;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.229",
                "AuthorKeywords": "Just-in-time descriptive analytics, feature identification and characterization, point-based visualizations",
                "IEEEXPLOREArticleNumberdeprecated": "6400487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249015;1532142;1382892;6065024;1382895;729568;4035766;5290704;5652885;5332628;6064985"
            }
        },
        {
            "name": "Bouzari, H.",
            "value": 3,
            "numPapers": 9,
            "cluster": "2",
            "index": 505,
            "weight": 1,
            "x": 203.7770746024837,
            "y": 1690.3712374461209,
            "px": 191.52460261784208,
            "py": 1536.0868614328476,
            "node": {
                "Conference": "VAST",
                "Year": "2012",
                "PaperTitle": "Smart super views---A knowledge-assisted interface for medical visualization",
                "PaperDOI": "10.1109/VAST.2012.6400555",
                "Link": "http://dx.doi.org/10.1109/VAST.2012.6400555",
                "Firstpage": "163",
                "Lastpage": "172",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.",
                "AuthorNames": "Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;",
                "AuthorIDs": ";;;;;;;",
                "Dedupedauthornames": "Mistelbauer, G.;Bouzari, H.;Schernthaner, R.;Baclija, I.;Kochl, A.;Bruckner, S.;Sramek, M.;Groller, E.",
                "References": "10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2007.70576;10.1109/TVCG.2007.70591;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2011.183;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Visualization, Fuzzy Logic, Interaction",
                "IEEEXPLOREArticleNumberdeprecated": "6400555",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250400;4015449;4376185;4376159;1183754;1532856;6064990;1532818;4015460"
            }
        },
        {
            "name": "Kohlmann, P.",
            "value": 90,
            "numPapers": 11,
            "cluster": "2",
            "index": 506,
            "weight": 1,
            "x": 485.32326841434696,
            "y": -31.368999279068813,
            "px": 426.7245690835288,
            "py": 5.350888327660923,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "High-Level User Interfaces for Transfer Function Design with Semantics",
                "PaperDOI": "10.1109/TVCG.2006.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.148",
                "Firstpage": "1021",
                "Lastpage": "1028",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation",
                "AuthorNames": "Salama, C.R.;Keller, M.;Kohlmann, P.",
                "FirstAuthorAffiliation": "Comput. Graphics & Multimedia Syst. Group, Siegen Univ.|c|;;",
                "AuthorIDs": "37840859800;37589324500;37623778100",
                "Dedupedauthornames": "Salama, C.R.;Keller, M.;Kohlmann, P.",
                "References": "10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.1998.745319;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1996.568113;10.1109/VISUAL.1997.663875",
                "AuthorKeywords": "Volume rendering, transfer function design, semantic models",
                "IEEEXPLOREArticleNumberdeprecated": "4015460",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250384;1250413;1183764;745319;964519;1250412;568112;663875"
            }
        },
        {
            "name": "Wilkinson, L.",
            "value": 113,
            "numPapers": 26,
            "cluster": "5",
            "index": 507,
            "weight": 3,
            "x": 360.3350362377521,
            "y": 42.610037959221025,
            "px": 282.52978358614234,
            "py": 96.44740752692208,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Graph-theoretic scagnostics",
                "PaperDOI": "10.1109/INFVIS.2005.1532142",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532142",
                "Firstpage": "157",
                "Lastpage": "164",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.",
                "AuthorNames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "FirstAuthorAffiliation": "SPSS Inc., Chicago, IL, USA|c|;;",
                "AuthorIDs": "37560536200;37548165700;37270222000",
                "Dedupedauthornames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "References": "10.1109/INFVIS.2003.1249006;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.15",
                "AuthorKeywords": "visualization, statistical graphics",
                "IEEEXPLOREArticleNumberdeprecated": "1532142",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249006;1382892;1382895"
            }
        },
        {
            "name": "Grossman, R.",
            "value": 97,
            "numPapers": 3,
            "cluster": "5",
            "index": 508,
            "weight": 3,
            "x": 517.8931304414878,
            "y": 42.2253552886551,
            "px": 472.5734840989706,
            "py": 97.13772805840316,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Graph-theoretic scagnostics",
                "PaperDOI": "10.1109/INFVIS.2005.1532142",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532142",
                "Firstpage": "157",
                "Lastpage": "164",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce Tukey and Tukey scagnostics and develop graph-theoretic methods for implementing their procedure on large datasets.",
                "AuthorNames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "FirstAuthorAffiliation": "SPSS Inc., Chicago, IL, USA|c|;;",
                "AuthorIDs": "37560536200;37548165700;37270222000",
                "Dedupedauthornames": "Wilkinson, L.;Anand, A.;Grossman, R.",
                "References": "10.1109/INFVIS.2003.1249006;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.15",
                "AuthorKeywords": "visualization, statistical graphics",
                "IEEEXPLOREArticleNumberdeprecated": "1532142",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249006;1382892;1382895"
            }
        },
        {
            "name": "Lujin Wang",
            "value": 63,
            "numPapers": 20,
            "cluster": "2",
            "index": 509,
            "weight": 1,
            "x": -1731.3850880026052,
            "y": 153.34337869170034,
            "px": -1543.5082250481632,
            "py": 169.36091823527073,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "The magic volume lens: an interactive focus+context technique for volume rendering",
                "PaperDOI": "10.1109/VISUAL.2005.1532818",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532818",
                "Firstpage": "367",
                "Lastpage": "374",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.",
                "AuthorNames": "Lujin Wang;Ye Zhao;Mueller, K.;Kaufman, A.",
                "FirstAuthorAffiliation": "Center for Visual Comput., Comput. Sci., Stony Brook Univ., NY, USA|c|;;;",
                "AuthorIDs": "37280763200;37277701200;37273119700;37268052800",
                "Dedupedauthornames": "Lujin Wang;Ye Zhao;Mueller, K.;Kaufman, A.",
                "References": "10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559215;10.1109/INFVIS.1996.559214;10.1109/VISUAL.2001.964552;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2004.48;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2000.885697",
                "AuthorKeywords": "Focus+Context Techniques,Lens,Volume Rendering, Hardware-assisted Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1532818",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636786;559215;559214;964552;1250386;1250384;1372190;1250400;885697"
            }
        },
        {
            "name": "Giesen, J.",
            "value": 40,
            "numPapers": 19,
            "cluster": "2",
            "index": 510,
            "weight": 1,
            "x": -856.7771176325791,
            "y": -62.78335756961685,
            "px": -743.6964722786248,
            "py": -20.762187257628284,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Hue-Preserving Color Blending",
                "PaperDOI": "10.1109/TVCG.2009.150",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.150",
                "Firstpage": "1275",
                "Lastpage": "1282",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization.",
                "AuthorNames": "Chuang, J.;Weiskopf, D.;Moller, T.",
                "FirstAuthorAffiliation": "Simon Fraser Univ., Burnaby, BC, Canada|c|;;",
                "AuthorIDs": "38100482200;37268045000;37275858700",
                "Dedupedauthornames": "Chuang, J.;Weiskopf, D.;Moller, T.",
                "References": "10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.118;10.1109/TVCG.2006.183",
                "AuthorKeywords": "Image compositing, perceptual transparency, color blending, volume rendering, illustrative visualization",
                "IEEEXPLOREArticleNumberdeprecated": "5290739",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568118;4658198;4015473"
            }
        },
        {
            "name": "Kaehler, R.",
            "value": 20,
            "numPapers": 12,
            "cluster": "2",
            "index": 511,
            "weight": 1,
            "x": 451.2807234790827,
            "y": 1744.638473293276,
            "px": 400.7425876138677,
            "py": 1578.417938946489,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Hahn, O.",
            "value": 0,
            "numPapers": 9,
            "cluster": "2",
            "index": 512,
            "weight": 1,
            "x": -203.7381759804172,
            "y": -1043.2812678912994,
            "px": -188.41103771404838,
            "py": -917.4317576197335,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Abel, T.",
            "value": 17,
            "numPapers": 10,
            "cluster": "2",
            "index": 513,
            "weight": 1,
            "x": 457.3609091987705,
            "y": -880.7078657934376,
            "px": 401.6562600693141,
            "py": -767.9813812866788,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Weber, G.H.",
            "value": 103,
            "numPapers": 29,
            "cluster": "3",
            "index": 514,
            "weight": 3,
            "x": 277.68399988881083,
            "y": 672.6833091590836,
            "px": 275.3139788794905,
            "py": 665.580015796211,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Topological Landscapes: A Terrain Metaphor for Scientific Data",
                "PaperDOI": "10.1109/TVCG.2007.70601",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70601",
                "Firstpage": "1416",
                "Lastpage": "1423",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called \"topological landscapes,\" which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible.",
                "AuthorNames": "Weber, G.H.;Bremer, P.-T.;Pascucci, V.",
                "FirstAuthorAffiliation": "Lawrence Berkeley Nat. Lab., Berkeley|c|;;",
                "AuthorIDs": "37411444100;;",
                "Dedupedauthornames": "Weber, G.H.;Bremer, P.-T.;Pascucci, V.",
                "References": "10.1109/VISUAL.2004.96;10.1109/VISUAL.1998.745303;10.1109/VISUAL.1992.235215;10.1109/VISUAL.1999.809932;10.1109/INFVIS.2004.57;10.1109/VISUAL.1997.663860;10.1109/VISUAL.1997.663875;10.1109/INFVIS.2002.1173159;10.1109/VISUAL.2002.1183772;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2003.1250376",
                "AuthorKeywords": "Feature Detection, User Interfaces, Visual Analytics, Contour Tree, Terrain, Topology, SOAR",
                "IEEEXPLOREArticleNumberdeprecated": "4376169",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372235;745303;235215;809932;1382888;663860;663875;1173159;1183772;1532839;1250376"
            }
        },
        {
            "name": "Lindholm, S.",
            "value": 8,
            "numPapers": 24,
            "cluster": "2",
            "index": 515,
            "weight": 1,
            "x": 2806.7189006976646,
            "y": 3464.9981687188297,
            "px": 2544.4945688998932,
            "py": 3156.1302966210674,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Spatial Conditioning of Transfer Functions Using Local Material Distributions",
                "PaperDOI": "10.1109/TVCG.2010.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.195",
                "Firstpage": "1301",
                "Lastpage": "1310",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.",
                "AuthorNames": "Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37591265100;37284208400;37284209100;37604521200;37284192000",
                "Dedupedauthornames": "Lindholm, S.;Ljung, P.;Lundstrom, C.;Persson, A.;Ynnerman, A.",
                "References": "10.1109/TVCG.2009.185;10.1109/TVCG.2009.120;10.1109/TVCG.2008.147;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2007.70591;10.1109/VISUAL.2001.964516;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.1999.809932;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Direct Volume Rendering, Transfer Function, Spatial Conditioning, Neighborhood Meta-Data",
                "IEEEXPLOREArticleNumberdeprecated": "5613470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290763;5290764;4658169;1250412;4376159;964516;5290762;4658153;1250413;809932;4015460"
            }
        },
        {
            "name": "von Funck, W.",
            "value": 33,
            "numPapers": 5,
            "cluster": "3",
            "index": 516,
            "weight": 1,
            "x": 3112.8239126180924,
            "y": 1696.7377894731135,
            "px": 2804.6376540521696,
            "py": 1578.5701056419682,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments",
                "PaperDOI": "10.1109/TVCG.2008.163",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.163",
                "Firstpage": "1396",
                "Lastpage": "1403",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.",
                "AuthorNames": "von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.",
                "FirstAuthorAffiliation": "MPI Informatlk, Saarbrucken|c|;;;",
                "AuthorIDs": "37869714300;37282635100;37266875400;37271851300",
                "Dedupedauthornames": "von Funck, W.;Weinkauf, T.;Theisel, H.;Seidel, H.-P.",
                "References": "10.1109/VISUAL.1995.485141;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2001.964506;10.1109/VISUAL.1993.398877",
                "AuthorKeywords": "Unsteady flow visualization, streak surfaces, smoke visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4658155",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "485141;398846;235211;964506;398877"
            }
        },
        {
            "name": "Krishnan, H.",
            "value": 74,
            "numPapers": 12,
            "cluster": "3",
            "index": 517,
            "weight": 3,
            "x": 221.04998859305906,
            "y": 499.1999758044306,
            "px": 217.0677436430876,
            "py": 505.3918264995781,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets",
                "PaperDOI": "10.1109/TVCG.2009.190",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.190",
                "Firstpage": "1267",
                "Lastpage": "1274",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.",
                "AuthorNames": "Krishnan, H.;Garth, C.;Joy, K.I.",
                "FirstAuthorAffiliation": "Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;",
                "AuthorIDs": "37866882400;37282573700;37267811400",
                "Dedupedauthornames": "Krishnan, H.;Garth, C.;Joy, K.I.",
                "References": "10.1109/TVCG.2007.70557;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/TVCG.2008.163;10.1109/VISUAL.2000.885688;10.1109/TVCG.2008.133",
                "AuthorKeywords": "3D vector field visualization, flow visualization, time-varying, time and streak surfaces, surface extraction",
                "IEEEXPLOREArticleNumberdeprecated": "5290738",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376209;235211;398875;964506;4658155;885688;4658156"
            }
        },
        {
            "name": "Hultquist, J.P.M.",
            "value": 120,
            "numPapers": 8,
            "cluster": "3",
            "index": 518,
            "weight": 5,
            "x": 232.39271099194517,
            "y": 458.3181201113129,
            "px": 235.59999106132003,
            "py": 463.9917661535587,
            "node": {
                "Conference": "Vis",
                "Year": "1992",
                "PaperTitle": "Constructing stream surfaces in steady 3D vector fields",
                "PaperDOI": "10.1109/VISUAL.1992.235211",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235211",
                "Firstpage": "171",
                "Lastpage": "178",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Maintenance of a front of particles, an efficient method of generating a set of sample points over a two-dimensional stream surface, is described. The particles are repeatedly advanced a short distance through the flow field. New polygons are appended to the downstream edge of the surface. The spacing of the particles is adjusted to maintain an adequate sampling across the width of the growing surface. Curve and ribbon methods of vector field visualization are reviewed",
                "AuthorNames": "Hultquist, J.P.M.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|",
                "AuthorIDs": "37378417700",
                "Dedupedauthornames": "Hultquist, J.P.M.",
                "References": "10.1109/VISUAL.1990.146359;10.1109/VISUAL.1991.175837;10.1109/VISUAL.1990.146373;10.1109/VISUAL.1992.235202;10.1109/VISUAL.1991.175789",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "235211",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146359;175837;146373;235202;175789"
            }
        },
        {
            "name": "Nelson, B.",
            "value": 14,
            "numPapers": 8,
            "cluster": "3",
            "index": 519,
            "weight": 1,
            "x": 150.16304356183588,
            "y": 820.74951906965,
            "px": 160.41760002985802,
            "py": 847.3346211617875,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields",
                "PaperDOI": "10.1109/TVCG.2011.206",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.206",
                "Firstpage": "1803",
                "Lastpage": "1811",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.",
                "AuthorNames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": "37557887400;37282898700;37275716100",
                "Dedupedauthornames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "References": "10.1109/VISUAL.2005.1532776;10.1109/VISUAL.2004.91;10.1109/TVCG.2006.154",
                "AuthorKeywords": "High-order finite elements, spectral/hp elements, cut-plane extraction, GPU-based root-finding, GPU ray-tracing, cut-surface extraction",
                "IEEEXPLOREArticleNumberdeprecated": "6064943",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532776;1372224;4015486"
            }
        },
        {
            "name": "Haimes, R.",
            "value": 79,
            "numPapers": 11,
            "cluster": "3",
            "index": 520,
            "weight": 2,
            "x": 218.67056200668384,
            "y": 300.8385337178398,
            "px": 216.6424268485098,
            "py": 396.56163968870044,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields",
                "PaperDOI": "10.1109/TVCG.2011.206",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.206",
                "Firstpage": "1803",
                "Lastpage": "1811",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.",
                "AuthorNames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;",
                "AuthorIDs": "37557887400;37282898700;37275716100",
                "Dedupedauthornames": "Nelson, B.;Haimes, R.;Kirby, R.M.",
                "References": "10.1109/VISUAL.2005.1532776;10.1109/VISUAL.2004.91;10.1109/TVCG.2006.154",
                "AuthorKeywords": "High-order finite elements, spectral/hp elements, cut-plane extraction, GPU-based root-finding, GPU ray-tracing, cut-surface extraction",
                "IEEEXPLOREArticleNumberdeprecated": "6064943",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532776;1372224;4015486"
            }
        },
        {
            "name": "Livingston, M.A.",
            "value": 22,
            "numPapers": 28,
            "cluster": "8",
            "index": 521,
            "weight": 3,
            "x": -715.2291206869422,
            "y": 463.6988046055087,
            "px": -451.15850702542633,
            "py": 508.23289720893735,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Evaluation of Multivariate Visualization on a Multivariate Task",
                "PaperDOI": "10.1109/TVCG.2012.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.223",
                "Firstpage": "2114",
                "Lastpage": "2121",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.",
                "AuthorNames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37300434300;37681593700;37330342700",
                "Dedupedauthornames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "References": "10.1109/TVCG.2011.194;10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/TVCG.2007.70623;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362",
                "AuthorKeywords": "Quantitative evaluation, multivariate visualization, visual task design, texture perception",
                "IEEEXPLOREArticleNumberdeprecated": "6327216",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064969;5290732;745292;146387;4376150;146386;175795;745294;1250362"
            }
        },
        {
            "name": "Decker, J.W.",
            "value": 12,
            "numPapers": 19,
            "cluster": "8",
            "index": 522,
            "weight": 3,
            "x": -54.36170831832621,
            "y": 980.0474985632186,
            "px": 122.45017798529456,
            "py": 945.3420454943384,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Evaluation of Multivariate Visualization on a Multivariate Task",
                "PaperDOI": "10.1109/TVCG.2012.223",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.223",
                "Firstpage": "2114",
                "Lastpage": "2121",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.",
                "AuthorNames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37300434300;37681593700;37330342700",
                "Dedupedauthornames": "Livingston, M.A.;Decker, J.W.;Zhuming Ai",
                "References": "10.1109/TVCG.2011.194;10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/TVCG.2007.70623;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362",
                "AuthorKeywords": "Quantitative evaluation, multivariate visualization, visual task design, texture perception",
                "IEEEXPLOREArticleNumberdeprecated": "6327216",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6064969;5290732;745292;146387;4376150;146386;175795;745294;1250362"
            }
        },
        {
            "name": "Healey, C.",
            "value": 123,
            "numPapers": 23,
            "cluster": "8",
            "index": 523,
            "weight": 4,
            "x": 1431.9806334221314,
            "y": 378.714849908853,
            "px": 1837.1623122641302,
            "py": 556.0402128406502,
            "node": {
                "Conference": "SciVis",
                "Year": "2014",
                "PaperTitle": "Multi-Charts for Comparative 3D Ensemble Visualization",
                "PaperDOI": "10.1109/TVCG.2014.2346448",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346448",
                "Firstpage": "2694",
                "Lastpage": "2703",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.",
                "AuthorNames": "Demir, I.;Dick, C.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Garching, Germany|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Demir, I.;Dick, C.;Westermann, R.",
                "References": "10.1109/TVCG.2013.143;10.1109/VISUAL.2000.885739;10.1109/TVCG.2006.159;10.1109/TVCG.2008.139;10.1109/TVCG.2007.70518;10.1109/TVCG.2010.181;10.1109/TVCG.2009.198;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809921",
                "AuthorKeywords": "Ensemble visualization, brushing and linking, statistical analysis",
                "IEEEXPLOREArticleNumberdeprecated": "6875990",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6634129;885739;4015461;4658178;4376198;5613483;5290755;1173157;809921"
            }
        },
        {
            "name": "Snoeyink, J.",
            "value": 94,
            "numPapers": 14,
            "cluster": "3",
            "index": 524,
            "weight": 3,
            "x": 415.15438518953715,
            "y": 582.2877287122509,
            "px": 423.6691979091422,
            "py": 572.805755569762,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Simplifying flexible isosurfaces using local geometric measures",
                "PaperDOI": "10.1109/VISUAL.2004.96",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.96",
                "Firstpage": "497",
                "Lastpage": "504",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.",
                "AuthorNames": "Carr, H.;Snoeyink, J.;van de Panne, Michiel",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;",
                "AuthorIDs": "37282624500;37282623700;37283212000",
                "Dedupedauthornames": "Carr, H.;Snoeyink, J.;van de Panne, M.",
                "References": "10.1109/VISUAL.2001.964499;10.1109/VISUAL.2002.1183774",
                "AuthorKeywords": "Isosurfaces, contourtrees, topological simplification",
                "IEEEXPLOREArticleNumberdeprecated": "1372235",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964499;1183774"
            }
        },
        {
            "name": "van de Panne, M.",
            "value": 70,
            "numPapers": 2,
            "cluster": "3",
            "index": 525,
            "weight": 3,
            "x": 219.8249754606955,
            "y": 710.0528839545923,
            "px": 230.62372258415414,
            "py": 693.0762455677818,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Simplifying flexible isosurfaces using local geometric measures",
                "PaperDOI": "10.1109/VISUAL.2004.96",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.96",
                "Firstpage": "497",
                "Lastpage": "504",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.",
                "AuthorNames": "Carr, H.;Snoeyink, J.;van de Panne, Michiel",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;",
                "AuthorIDs": "37282624500;37282623700;37283212000",
                "Dedupedauthornames": "Carr, H.;Snoeyink, J.;van de Panne, M.",
                "References": "10.1109/VISUAL.2001.964499;10.1109/VISUAL.2002.1183774",
                "AuthorKeywords": "Isosurfaces, contourtrees, topological simplification",
                "IEEEXPLOREArticleNumberdeprecated": "1372235",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964499;1183774"
            }
        },
        {
            "name": "Ahmed, N.",
            "value": 24,
            "numPapers": 20,
            "cluster": "1",
            "index": 526,
            "weight": 3,
            "x": -417.6955127975874,
            "y": 427.5098116816458,
            "px": -563.4015369360665,
            "py": 412.6743577996096,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2011.218",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.218",
                "Firstpage": "1959",
                "Lastpage": "1968",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.",
                "AuthorNames": "Ziyi Zheng;Ahmed, N.;Mueller, K.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "37599599100;38021380500;37273119700",
                "Dedupedauthornames": "Ziyi Zheng;Ahmed, N.;Mueller, K.",
                "References": "10.1109/TVCG.2009.156;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.162;10.1109/TVCG.2008.159;10.1109/TVCG.2010.214;10.1109/TVCG.2009.172;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.124;10.1109/TVCG.2009.185;10.1109/TVCG.2009.189;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2005.1532834",
                "AuthorKeywords": "Direct volume rendering, k-means, entropy, view suggestion, set-cover problem, ant colony optimization",
                "IEEEXPLOREArticleNumberdeprecated": "6064959",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290746;4376185;4658153;4658191;5613489;5290740;1532833;1532818;4015450;5290763;5290762;1250414;1532834"
            }
        },
        {
            "name": "Ziyi Zheng",
            "value": 26,
            "numPapers": 27,
            "cluster": "1",
            "index": 527,
            "weight": 3,
            "x": 57.22114821238737,
            "y": -283.4519573871028,
            "px": -27.584535341680525,
            "py": -376.4108706050694,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2011.218",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.218",
                "Firstpage": "1959",
                "Lastpage": "1968",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.",
                "AuthorNames": "Ziyi Zheng;Ahmed, N.;Mueller, K.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "37599599100;38021380500;37273119700",
                "Dedupedauthornames": "Ziyi Zheng;Ahmed, N.;Mueller, K.",
                "References": "10.1109/TVCG.2009.156;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.162;10.1109/TVCG.2008.159;10.1109/TVCG.2010.214;10.1109/TVCG.2009.172;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.124;10.1109/TVCG.2009.185;10.1109/TVCG.2009.189;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2005.1532834",
                "AuthorKeywords": "Direct volume rendering, k-means, entropy, view suggestion, set-cover problem, ant colony optimization",
                "IEEEXPLOREArticleNumberdeprecated": "6064959",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290746;4376185;4658153;4658191;5613489;5290740;1532833;1532818;4015450;5290763;5290762;1250414;1532834"
            }
        },
        {
            "name": "Clapworthy, G.",
            "value": 4,
            "numPapers": 14,
            "cluster": "2",
            "index": 528,
            "weight": 1,
            "x": -1052.666636967284,
            "y": -1466.907347139351,
            "px": -934.7920374145652,
            "py": -1288.718067407877,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Structure-Aware Lighting Design for Volume Visualization",
                "PaperDOI": "10.1109/TVCG.2012.267",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.267",
                "Firstpage": "2372",
                "Lastpage": "2381",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.",
                "AuthorNames": "Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao",
                "FirstAuthorAffiliation": "State Key Lab. of CAD&amp;CG, Zhejiang Univ., Hangzhou, China|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Yubo Tao;Hai Lin;Feng Dong;Chao Wang;Clapworthy, G.;Hujun Bao",
                "References": "10.1109/TVCG.2006.137;10.1109/TVCG.2011.218;10.1109/VISUAL.2004.62;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2003.1250395;10.1109/VISUAL.2002.1183785",
                "AuthorKeywords": "Automatic lighting design, structural dissimilarity, lighting similarity, lighting stability, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "6327242",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015471;6064959;1372208;1532834;1532833;1250395;1183785"
            }
        },
        {
            "name": "Rutten, M.",
            "value": 7,
            "numPapers": 21,
            "cluster": "3",
            "index": 529,
            "weight": 1,
            "x": 992.9272677541157,
            "y": 433.4999923722345,
            "px": 934.475086316246,
            "py": 432.4786987708503,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Detecting vortical phenomena in vector data by medium-scale correlation",
                "PaperDOI": "10.1109/VISUAL.1999.809917",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809917",
                "Firstpage": "409",
                "Lastpage": "552",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The detection of vortical phenomena in vector data is one of the key issues in many technical applications, in particular in flow visualization. Many existing approaches rely on purely local evaluation of the vector data. In order to overcome the limits of a local approach, we choose to combine a local method with a correlation of a pre-defined generic vortex with the data in a medium-scale region. Two different concepts of generic vortices were tested on various sets of flow velocity vector data. The approach is not limited to the two generic patterns suggested here. The method was found to successfully detect vortices in cases were other methods fail.",
                "AuthorNames": "Pagendarm, H.-G.;Henne, B.;Rutten, M.",
                "FirstAuthorAffiliation": "DLR, Gottingen, Germany|c|;;",
                "AuthorIDs": "37372011800;37442793000;37437412100",
                "Dedupedauthornames": "Pagendarm, H.-G.;Henne, B.;Rutten, M.",
                "References": "10.1109/VISUAL.1993.398849;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1996.568137",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809917",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398849;663910;346327;568137"
            }
        },
        {
            "name": "Guthe, S.",
            "value": 115,
            "numPapers": 15,
            "cluster": "2",
            "index": 530,
            "weight": 4,
            "x": 120.55421529944397,
            "y": 58.69166290945644,
            "px": 110.03040993975738,
            "py": 62.29277608513027,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Real-time decompression and visualization of animated volume data",
                "PaperDOI": "10.1109/VISUAL.2001.964531",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964531",
                "Firstpage": "349",
                "Lastpage": "356",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.",
                "AuthorNames": "Guthe, S.;Strasser, W.",
                "FirstAuthorAffiliation": "WSI/GRIS, Tubingen Univ., Germany|c|;",
                "AuthorIDs": "37728224400;",
                "Dedupedauthornames": "Guthe, S.;Strasser, W.",
                "References": "10.1109/VISUAL.1997.663878",
                "AuthorKeywords": "Time critical Visualization, Compression for Visualization, Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "964531",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663878"
            }
        },
        {
            "name": "Strasser, W.",
            "value": 191,
            "numPapers": 18,
            "cluster": "2",
            "index": 531,
            "weight": 4,
            "x": 181.5026772293136,
            "y": 60.92301357759442,
            "px": 180.80676089583335,
            "py": 67.96690172867162,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Real-time decompression and visualization of animated volume data",
                "PaperDOI": "10.1109/VISUAL.2001.964531",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964531",
                "Firstpage": "349",
                "Lastpage": "356",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.",
                "AuthorNames": "Guthe, S.;Strasser, W.",
                "FirstAuthorAffiliation": "WSI/GRIS, Tubingen Univ., Germany|c|;",
                "AuthorIDs": "37728224400;",
                "Dedupedauthornames": "Guthe, S.;Strasser, W.",
                "References": "10.1109/VISUAL.1997.663878",
                "AuthorKeywords": "Time critical Visualization, Compression for Visualization, Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "964531",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663878"
            }
        },
        {
            "name": "Burger, K.",
            "value": 51,
            "numPapers": 37,
            "cluster": "3",
            "index": 532,
            "weight": 5,
            "x": 242.17076209254196,
            "y": 529.1274492410047,
            "px": 243.1869394455876,
            "py": 524.5399741334847,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Interactive Separating Streak Surfaces",
                "PaperDOI": "10.1109/TVCG.2010.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.169",
                "Firstpage": "1569",
                "Lastpage": "1577",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.",
                "AuthorNames": "Ferstl, F.;Burger, K.;Theisel, H.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization group, Tech. Univ. Munchen, Mnchen, Germany|c|;;;",
                "AuthorIDs": "37606419000;37587634700;37266875400;37444424000",
                "Dedupedauthornames": "Ferstl, F.;Burger, K.;Theisel, H.;Westermann, R.",
                "References": "10.1109/TVCG.2009.190;10.1109/TVCG.2007.70557;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.133;10.1109/VISUAL.2001.964506;10.1109/TVCG.2007.70554;10.1109/VISUAL.1993.398875;10.1109/TVCG.2009.177;10.1109/TVCG.2009.154;10.1109/TVCG.2006.151;10.1109/TVCG.2007.70551;10.1109/TVCG.2008.163;10.1109/VISUAL.2005.1532780",
                "AuthorKeywords": "Unsteady flow visualization, feature extraction, streak surface generation, GPUs",
                "IEEEXPLOREArticleNumberdeprecated": "5613499",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5290738;4376209;235211;4658156;964506;4376174;398875;5290756;5290737;4015480;4376175;4658155;1532780"
            }
        },
        {
            "name": "Ellsworth, D.",
            "value": 84,
            "numPapers": 26,
            "cluster": "2",
            "index": 533,
            "weight": 3,
            "x": 113.78148940175352,
            "y": 145.99299185523842,
            "px": 107.9218737070501,
            "py": 146.63653689014353,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation",
                "PaperDOI": "10.1109/TVCG.2011.252",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.252",
                "Firstpage": "1862",
                "Lastpage": "1871",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C0 continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates \"stitching cells\" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.",
                "AuthorNames": "Moran, P.J.;Ellsworth, D.",
                "FirstAuthorAffiliation": "Ames Res. Center, NASA, Moffett Field, CA, USA|c|;",
                "AuthorIDs": "37264891100;37282594500",
                "Dedupedauthornames": "Moran, P.J.;Ellsworth, D.",
                "References": "10.1109/VISUAL.1991.175782;10.1109/TVCG.2009.149;10.1109/VISUAL.2002.1183820",
                "AuthorKeywords": "Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells",
                "IEEEXPLOREArticleNumberdeprecated": "6064949",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175782;5290780;1183820"
            }
        },
        {
            "name": "Schneider, J.",
            "value": 136,
            "numPapers": 55,
            "cluster": "2",
            "index": 534,
            "weight": 9,
            "x": 274.2367490793552,
            "y": 211.387312931616,
            "px": 256.9288524153073,
            "py": 195.32398729106276,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Investigating swirl and tumble flow with a comparison of visualization techniques",
                "PaperDOI": "10.1109/VISUAL.2004.59",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.59",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We investigate two important, common fluid flow patterns from computational fluid dynamics (CFD) simulations, namely, swirl and tumble motion typical of automotive engines. We study and visualize swirl and tumble flow using three different flow visualization techniques: direct, geometric, and texture-based. When illustrating these methods side-by-side, we describe the relative strengths and weaknesses of each approach within a specific spatial dimension and across multiple spatial dimensions typical of an engineer's analysis. Our study is focused on steady-state flow. Based on this investigation we offer perspectives on where and when these techniques are best applied in order to visualize the behavior of swirl and tumble motion.",
                "AuthorNames": "Laramee, R.S.;Weiskopf, D.;Schneider, J.;Hauser, H.",
                "FirstAuthorAffiliation": "VRV, Vienna, Austria|c|;;;",
                "AuthorIDs": "37267247900;37268045000;37281085800;37274158800",
                "Dedupedauthornames": "Laramee, R.S.;Weiskopf, D.;Schneider, J.;Hauser, H.",
                "References": "10.1109/VISUAL.1999.809918;10.1109/VISUAL.1999.809895;10.1109/VISUAL.2000.885690;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.2003.1250377;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.2003.1250364",
                "AuthorKeywords": "Flow visualization, computational fluid dynamics (CFD), swirl flow, tumble flow, visualization systems, engine simulation, in-cylinder flow",
                "IEEEXPLOREArticleNumberdeprecated": "1372179",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809918;809895;885690;1250363;1250377;1250361;1250364"
            }
        },
        {
            "name": "Kosara, R.",
            "value": 206,
            "numPapers": 31,
            "cluster": "0",
            "index": 535,
            "weight": 6,
            "x": 579.9855240287695,
            "y": 231.74011059246402,
            "px": 604.0944271639378,
            "py": 171.0289763335022,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "The Shaping of Information by Visual Metaphors",
                "PaperDOI": "10.1109/TVCG.2008.171",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.171",
                "Firstpage": "1269",
                "Lastpage": "1276",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.",
                "AuthorNames": "Ziemkiewicz, C.;Kosara, R.",
                "FirstAuthorAffiliation": "UNC, Charlotte, NC|c|;",
                "AuthorIDs": "37548028800;37282563400",
                "Dedupedauthornames": "Ziemkiewicz, C.;Kosara, R.",
                "References": "10.1109/INFVIS.2004.70;10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2004.64;10.1109/INFVIS.2001.963290",
                "AuthorKeywords": "Cognition, visualization theory, metaphors, hierarchies, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "4658138",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382885;1173153;1382905;963290"
            }
        },
        {
            "name": "Laramee, R.S.",
            "value": 105,
            "numPapers": 60,
            "cluster": "3",
            "index": 536,
            "weight": 7,
            "x": 368.2203732435914,
            "y": 437.4023096646016,
            "px": 381.5289654643235,
            "py": 416.60089071328593,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data",
                "PaperDOI": "10.1109/TVCG.2011.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.166",
                "Firstpage": "2572",
                "Lastpage": "2580",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.",
                "AuthorNames": "Zhao Geng;ZhenMin Peng;Laramee, R.S.;Roberts, J.C.;Walker, R.",
                "FirstAuthorAffiliation": "Visual Comput. Group, Swansea Univ., Swansea, UK|c|;;;;",
                "AuthorIDs": "38031256500;38024566900;37267247900;37278794800;37596627100",
                "Dedupedauthornames": "Zhao Geng;ZhenMin Peng;Laramee, R.S.;Roberts, J.C.;Walker, R.",
                "References": "10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/VISUAL.1999.809866;10.1109/INFVIS.1996.559216;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.184;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.170;10.1109/TVCG.2008.131",
                "AuthorKeywords": "Parallel Coordinates, Angular Histogram, Attribute Curves",
                "IEEEXPLOREArticleNumberdeprecated": "6065025",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173157;1382894;4015422;4376143;809866;559216;146402;5613439;1532138;4015444;4658160"
            }
        },
        {
            "name": "Ogievetsky, V.",
            "value": 176,
            "numPapers": 10,
            "cluster": "0",
            "index": 537,
            "weight": 1,
            "x": -202.25724183796916,
            "y": -786.7458699468929,
            "px": -127.06898836714828,
            "py": -665.1101358488049,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "D&#x0B3; Data-Driven Documents",
                "PaperDOI": "10.1109/TVCG.2011.185",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.185",
                "Firstpage": "2301",
                "Lastpage": "2309",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",
                "AuthorNames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;",
                "AuthorIDs": "37591067400;38016292400;37550791300",
                "Dedupedauthornames": "Bostock, M.;Ogievetsky, V.;Heer, J.",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539",
                "AuthorKeywords": "Information visualization, user interfaces, toolkits, 2D graphics",
                "IEEEXPLOREArticleNumberdeprecated": "6064996",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;885098;5613453;5290720;1382904;4015439;1532122;4658136;1382905;4376146"
            }
        },
        {
            "name": "Juhee Bae",
            "value": 21,
            "numPapers": 5,
            "cluster": "0",
            "index": 538,
            "weight": 1,
            "x": -1423.7769261002454,
            "y": 210.71374967107275,
            "px": -1223.3127072019524,
            "py": 207.8522572578913,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "GeneaQuilts: A System for Exploring Large Genealogies",
                "PaperDOI": "10.1109/TVCG.2010.159",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.159",
                "Firstpage": "1073",
                "Lastpage": "1081",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring & Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.",
                "AuthorNames": "Bezerianos, A.;Dragicevic, P.;Fekete, J.;Juhee Bae;Watson, B.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37413699200;37590932700;37407972900;37595934400;37356872100",
                "Dedupedauthornames": "Bezerianos, A.;Dragicevic, P.;Fekete, J.;Juhee Bae;Watson, B.",
                "References": "10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2005.1532124",
                "AuthorKeywords": "Genealogy visualization, interaction",
                "IEEEXPLOREArticleNumberdeprecated": "5613445",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173156;1532124"
            }
        },
        {
            "name": "Watson, B.",
            "value": 21,
            "numPapers": 7,
            "cluster": "0",
            "index": 539,
            "weight": 1,
            "x": -289.4945353019525,
            "y": 19.654214694146834,
            "px": -184.63960629371937,
            "py": 41.04842621005361,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "GeneaQuilts: A System for Exploring Large Genealogies",
                "PaperDOI": "10.1109/TVCG.2010.159",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.159",
                "Firstpage": "1073",
                "Lastpage": "1081",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring & Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.",
                "AuthorNames": "Bezerianos, A.;Dragicevic, P.;Fekete, J.;Juhee Bae;Watson, B.",
                "FirstAuthorAffiliation": ";;;;",
                "AuthorIDs": "37413699200;37590932700;37407972900;37595934400;37356872100",
                "Dedupedauthornames": "Bezerianos, A.;Dragicevic, P.;Fekete, J.;Juhee Bae;Watson, B.",
                "References": "10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2005.1532124",
                "AuthorKeywords": "Genealogy visualization, interaction",
                "IEEEXPLOREArticleNumberdeprecated": "5613445",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173156;1532124"
            }
        },
        {
            "name": "Jimeng Sun",
            "value": 53,
            "numPapers": 29,
            "cluster": "1",
            "index": 540,
            "weight": 2,
            "x": 129.40023639175817,
            "y": 454.48471104508286,
            "px": 106.19124395881275,
            "py": 447.885018236061,
            "node": {
                "Conference": "InfoVis",
                "Year": "2010",
                "PaperTitle": "FacetAtlas: Multifaceted Visualization for Rich Text Corpora",
                "PaperDOI": "10.1109/TVCG.2010.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.154",
                "Firstpage": "1172",
                "Lastpage": "1181",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.",
                "AuthorNames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;",
                "AuthorIDs": "37604309600;37281417100;37598450200;37601397400;37406039100;37272637300",
                "Dedupedauthornames": "Nan Cao;Jimeng Sun;Yu-Ru Lin;Gotz, D.;Shixia Liu;Huamin Qu",
                "References": "10.1109/TVCG.2006.122;10.1109/VAST.2009.5333443;10.1109/INFVIS.2000.885098;10.1109/TVCG.2009.140;10.1109/TVCG.2008.135;10.1109/TVCG.2008.172;10.1109/TVCG.2009.139;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2006.142;10.1109/TVCG.2006.147;10.1109/VISUAL.1998.745302;10.1109/TVCG.2009.165;10.1109/INFVIS.1995.528686;10.1109/TVCG.2006.185",
                "AuthorKeywords": "Multi-facet visualization, Text visualization, Multi-relational Graph, Search UI",
                "IEEEXPLOREArticleNumberdeprecated": "5613456",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015419;5333443;885098;5290725;4658140;4658133;5290723;5290722;1532126;4015432;4015425;745302;5290726;528686;4015423"
            }
        },
        {
            "name": "Yu-Shuen Wang",
            "value": 14,
            "numPapers": 12,
            "cluster": "12",
            "index": 541,
            "weight": 2,
            "x": 1451.341925643882,
            "y": 784.8525031826516,
            "px": 1422.526050640836,
            "py": 778.6099236579464,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Focus+Context Metro Maps",
                "PaperDOI": "10.1109/TVCG.2011.205",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.205",
                "Firstpage": "2528",
                "Lastpage": "2535",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.",
                "AuthorNames": "Yu-Shuen Wang;Ming-Te Chi",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "37407536000;38019484900",
                "Dedupedauthornames": "Yu-Shuen Wang;Ming-Te Chi",
                "References": "10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559214;10.1109/TVCG.2008.132;10.1109/INFVIS.1998.729558;10.1109/VISUAL.2005.1532818",
                "AuthorKeywords": "Focus+context visualization, metro map, octilinear layout, graph labeling, optimization",
                "IEEEXPLOREArticleNumberdeprecated": "6065020",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636786;559214;4658197;729558;1532818"
            }
        },
        {
            "name": "Keahey, T.A.",
            "value": 100,
            "numPapers": 12,
            "cluster": "12",
            "index": 542,
            "weight": 3,
            "x": 1372.9379166571387,
            "y": 702.5382980834244,
            "px": 1362.6321114717937,
            "py": 698.7338776874831,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "The generalized detail in-context problem",
                "PaperDOI": "10.1109/INFVIS.1998.729558",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729558",
                "Firstpage": "44",
                "Lastpage": "51, 152",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes a general formulation of the detail-in-context problem, which is a central issue of fundamental importance to a wide variety of nonlinear magnification systems. A number of tools are described for dealing with this problem effectively. These tools can be applied to any continuous nonlinear magnification system, and are not tied to specific implementation features of the system that produced the original transformation. Of particular interest is the development of seamless multi level views, which allow multiple global views of an information space (each having different information content) to be integrated into a single view without discontinuity",
                "AuthorNames": "Keahey, T.A.",
                "FirstAuthorAffiliation": "Los Alamos Nat. Lab., NM, USA|c|",
                "AuthorIDs": "37349418300",
                "Dedupedauthornames": "Keahey, T.A.",
                "References": "10.1109/INFVIS.1997.636786;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1996.559214",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729558",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636786;636718;559214"
            }
        },
        {
            "name": "Robertson, E.L.",
            "value": 69,
            "numPapers": 1,
            "cluster": "12",
            "index": 543,
            "weight": 3,
            "x": 1357.0301424372958,
            "y": 708.7398364269803,
            "px": 1344.7641811229848,
            "py": 703.7540355784798,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "Nonlinear magnification fields",
                "PaperDOI": "10.1109/INFVIS.1997.636786",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636786",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce nonlinear magnification fields as an abstract representation of nonlinear magnification, providing methods for converting transformation routines to magnification fields and vice-versa. This new representation provides ease of manipulation and power of expression. By removing the restrictions of explicit foci and allowing precise specification of magnification values, we can achieve magnification effects which were not previously possible. Of particular interest are techniques we introduce for expressing complex and subtle magnification effects through magnification brushing, and allowing intrinsic properties of the data being visualized to create data-driven magnifications.",
                "AuthorNames": "Keahey, T.A.;Robertson, E.L.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "",
                "Dedupedauthornames": "Keahey, T.A.;Robertson, E.L.",
                "References": "10.1109/INFVIS.1996.559214",
                "AuthorKeywords": "information visualization, nonlinear magnification, data-driven magnification, fisheye views, magnification brushing, data-mining",
                "IEEEXPLOREArticleNumberdeprecated": "636786",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559214"
            }
        },
        {
            "name": "Minghim, R.",
            "value": 49,
            "numPapers": 14,
            "cluster": "10",
            "index": 544,
            "weight": 1,
            "x": 466.5948275943879,
            "y": -885.5979543700662,
            "px": 457.7901343689037,
            "py": -715.8873574832317,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "An illustrated analysis of sonification for scientific visualisation",
                "PaperDOI": "10.1109/VISUAL.1995.480802",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480802",
                "Firstpage": "110",
                "Lastpage": "117",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents an analysis of progress in the use of sound as a tool in support of visualisation and gives an insight into its development and future needs. Special emphasis is given to the use of sound in scientific and engineering applications. A system developed to support surface data presentation and interaction by using sound is presented and discussed",
                "AuthorNames": "Minghim, R.;Forrest, A.R.",
                "FirstAuthorAffiliation": "Sch. of Inf. Syst., East Anglia Univ., Norwich, UK|c|;",
                "AuthorIDs": "37371567600;37863405200",
                "Dedupedauthornames": "Minghim, R.;Forrest, A.R.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480802",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Schulz, H.",
            "value": 76,
            "numPapers": 35,
            "cluster": "0",
            "index": 545,
            "weight": 1,
            "x": 1118.1407480289597,
            "y": 739.3749672602947,
            "px": 1056.4161004955283,
            "py": 653.2644428272646,
            "node": {
                "Conference": "InfoVis",
                "Year": "2013",
                "PaperTitle": "A Design Space of Visualization Tasks",
                "PaperDOI": "10.1109/TVCG.2013.120",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.120",
                "Firstpage": "2366",
                "Lastpage": "2375",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.",
                "AuthorNames": "Schulz, H.-J.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "FirstAuthorAffiliation": "Univ. of Rostock, Rostock, Germany|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Schulz, H.;Nocke, T.;Heitzler, M.;Schumann, H.",
                "References": "10.1109/INFVIS.1996.559213;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146372;10.1109/TVCG.2012.205;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/INFVIS.1996.559211;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885093;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Task taxonomy, design space, climate impact research, visualization recommendation",
                "IEEEXPLOREArticleNumberdeprecated": "6634156",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "559213;1532136;4376144;146372;6327265;235203;1382903;4677365;559211;1382902;636792;885093;885092;146375"
            }
        },
        {
            "name": "Sips, M.",
            "value": 48,
            "numPapers": 16,
            "cluster": "5",
            "index": 546,
            "weight": 1,
            "x": 931.5248666260727,
            "y": -1204.244860005208,
            "px": 929.1568314032673,
            "py": -1049.540786245781,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Pixnostics: Towards Measuring the Value of Visualization",
                "PaperDOI": "10.1109/VAST.2006.261423",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261423",
                "Firstpage": "199",
                "Lastpage": "206",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach",
                "AuthorNames": "Schneidewind, J.;Sips, M.;Keim, D.A.",
                "FirstAuthorAffiliation": "Konstanz Univ.|c|;;",
                "AuthorIDs": "37669961800;37827860500;37283138700",
                "Dedupedauthornames": "Schneidewind, J.;Sips, M.;Keim, D.A.",
                "References": "10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.2005.1532782;10.1109/VISUAL.2005.1532781;10.1109/INFVIS.2000.885092",
                "AuthorKeywords": "Visual Data Exploration, Visualization technique,\nVisual Analytics",
                "IEEEXPLOREArticleNumberdeprecated": "4035766",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532145;1532142;1532782;1532781;885092"
            }
        },
        {
            "name": "Butkiewicz, T.",
            "value": 15,
            "numPapers": 17,
            "cluster": "0",
            "index": 547,
            "weight": 1,
            "x": 516.5822067284281,
            "y": -513.9208686970345,
            "px": 513.847272621913,
            "py": -421.9001411746194,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Multi-Focused Geospatial Analysis Using Probes",
                "PaperDOI": "10.1109/TVCG.2008.149",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.149",
                "Firstpage": "1165",
                "Lastpage": "1172",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.",
                "AuthorNames": "Butkiewicz, T.;Wenwen Dou;Wartell, Z.;Ribarsky, W.;Chang, R.",
                "FirstAuthorAffiliation": "Charlotte Visualization Center, UNC Charlotte, Charlotte, NC|c|;;;;",
                "AuthorIDs": "37591215700;37606064200;37297344900;37300425000;37592409400",
                "Dedupedauthornames": "Butkiewicz, T.;Wenwen Dou;Wartell, Z.;Ribarsky, W.;Chang, R.",
                "References": "10.1109/INFVIS.2000.885102;10.1109/TVCG.2007.70574",
                "AuthorKeywords": "Multiple-view techniques, geospatial visualization, geospatial analysis, focus + context, probes",
                "IEEEXPLOREArticleNumberdeprecated": "4658126",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885102;4376137"
            }
        },
        {
            "name": "Ghoniem, M.",
            "value": 111,
            "numPapers": 11,
            "cluster": "0",
            "index": 548,
            "weight": 1,
            "x": 1798.2291586563274,
            "y": -233.14548941975266,
            "px": 1653.5658632281381,
            "py": -183.30530040229158,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations",
                "PaperDOI": "10.1109/INFVIS.2004.1",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.1",
                "Firstpage": "17",
                "Lastpage": "24",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we describe a taxonomy of generic graph related tasks and an evaluation aiming at assessing the readability of two representations of graphs: matrix-based representations and node-link diagrams. This evaluation bears on seven generic tasks and leads to important recommendations with regard to the representation of graphs according to their size and density. For instance, we show that when graphs are bigger than twenty vertices, the matrix-based visualization performs better than node-link diagrams on most tasks. Only path finding is consistently in favor of node-link diagrams throughout the evaluation",
                "AuthorNames": "Ghoniem, M.;Fekete, J.;Castagliola, P.",
                "FirstAuthorAffiliation": "Ecole des Mines de Nantes|c|;;",
                "AuthorIDs": "37928384500;37407972900;37939616200",
                "Dedupedauthornames": "Ghoniem, M.;Fekete, J.;Castagliola, P.",
                "References": "10.1109/INFVIS.2003.1249030",
                "AuthorKeywords": "Visualization of graphs, adjacency matrices, node-link representation, readability, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1382886",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249030"
            }
        },
        {
            "name": "Barlow, T.",
            "value": 25,
            "numPapers": 2,
            "cluster": "3",
            "index": 549,
            "weight": 1,
            "x": -968.9122721959637,
            "y": -436.4767636781304,
            "px": -872.0768272201475,
            "py": -336.1020668307085,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "A comparison of 2-D visualizations of hierarchies",
                "PaperDOI": "10.1109/INFVIS.2001.963290",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963290",
                "Firstpage": "131",
                "Lastpage": "138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes two experiments that compare four two-dimensional visualizations of hierarchies: organization chart, icicle plot, treemap, and tree ring. The visualizations are evaluated in the context of decision tree analyses prevalent in data mining applications. The results suggest that either the tree ring or icicle plot is equivalent to the organization chart.",
                "AuthorNames": "Barlow, T.;Neville, P.",
                "FirstAuthorAffiliation": "SAS Institute Inc.|c|;",
                "AuthorIDs": "37733138800;37726433800",
                "Dedupedauthornames": "Barlow, T.;Neville, P.",
                "References": "10.1109/INFVIS.1998.729557;10.1109/VISUAL.1992.235217",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "963290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "729567;235217"
            }
        },
        {
            "name": "Neville, P.",
            "value": 25,
            "numPapers": 2,
            "cluster": "3",
            "index": 550,
            "weight": 1,
            "x": -462.6691237952294,
            "y": -293.5041751783557,
            "px": -411.47645432439714,
            "py": -201.44266067295445,
            "node": {
                "Conference": "InfoVis",
                "Year": "2001",
                "PaperTitle": "A comparison of 2-D visualizations of hierarchies",
                "PaperDOI": "10.1109/INFVIS.2001.963290",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2001.963290",
                "Firstpage": "131",
                "Lastpage": "138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes two experiments that compare four two-dimensional visualizations of hierarchies: organization chart, icicle plot, treemap, and tree ring. The visualizations are evaluated in the context of decision tree analyses prevalent in data mining applications. The results suggest that either the tree ring or icicle plot is equivalent to the organization chart.",
                "AuthorNames": "Barlow, T.;Neville, P.",
                "FirstAuthorAffiliation": "SAS Institute Inc.|c|;",
                "AuthorIDs": "37733138800;37726433800",
                "Dedupedauthornames": "Barlow, T.;Neville, P.",
                "References": "10.1109/INFVIS.1998.729557;10.1109/VISUAL.1992.235217",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "963290",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "729567;235217"
            }
        },
        {
            "name": "Hotz, I.",
            "value": 74,
            "numPapers": 25,
            "cluster": "3",
            "index": 551,
            "weight": 2,
            "x": 321.64856162339294,
            "y": 658.4172194018855,
            "px": 338.2145831435781,
            "py": 642.522315856041,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Moment Invariants for the Analysis of 2D Flow fields",
                "PaperDOI": "10.1109/TVCG.2007.70579",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70579",
                "Firstpage": "1743",
                "Lastpage": "1750",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.",
                "AuthorNames": "Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertram, M.-H.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.",
                "FirstAuthorAffiliation": "Univ. of Kaiserslautern, Kaiserslautern|c|;;;;;;;;",
                "AuthorIDs": "37946182500;37945209200;37945208900;37282721800;37282067000;37282573700;37722986700;37282068700;37282578800",
                "Dedupedauthornames": "Schlemmer, M.;Heringer, M.;Morr, F.;Hotz, I.;Bertam, M.;Garth, C.;Kollmann, W.;Hamann, B.;Hagen, H.",
                "References": "10.1109/VISUAL.2004.68;10.1109/VISUAL.1999.809873;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2003.1250372",
                "AuthorKeywords": "Flow Visualization, Feature Detection, Pattern Extraction, Pattern Recognition, Image Processing",
                "IEEEXPLOREArticleNumberdeprecated": "4376210",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372207;809873;1532858;1250372"
            }
        },
        {
            "name": "Hlawitschka, M.",
            "value": 77,
            "numPapers": 20,
            "cluster": "3",
            "index": 552,
            "weight": 1,
            "x": 337.61818605949406,
            "y": 514.3535232944935,
            "px": 355.64913185740033,
            "py": 481.6180000989828,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2008.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.143",
                "Firstpage": "1475",
                "Lastpage": "1482",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.",
                "AuthorNames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Leipzig Univ., Leipzig|c|;;;;",
                "AuthorIDs": "37869538100;37565763400;37282624500;37403333700;37282574800",
                "Dedupedauthornames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "References": "10.1109/TVCG.2006.164;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2004.107;10.1109/TVCG.2007.70615;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2006.165;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2007.70519;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2005.1532835",
                "AuthorKeywords": "Scalar topology, comparative visualization, contour tree, largest contours, flow visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4658165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015446;964519;1372214;4376165;1532830;4015447;1372235;1250374;4376167;1532848;663875;1532835"
            }
        },
        {
            "name": "Guoning Chen",
            "value": 8,
            "numPapers": 22,
            "cluster": "3",
            "index": 553,
            "weight": 3,
            "x": 512.9232061313892,
            "y": 421.1458028037366,
            "px": 552.2511611121764,
            "py": 384.07611275516786,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "Firstpage": "1979",
                "Lastpage": "1988",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "References": "10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326",
                "AuthorKeywords": "Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent",
                "IEEEXPLOREArticleNumberdeprecated": "6064961",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Zheng, X.",
            "value": 92,
            "numPapers": 31,
            "cluster": "3",
            "index": 554,
            "weight": 13,
            "x": 91.3589205541133,
            "y": 594.0403742915655,
            "px": 142.44926551320194,
            "py": 558.3205578562319,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Topological lines in 3D tensor fields",
                "PaperDOI": "10.1109/VISUAL.2004.105",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.105",
                "Firstpage": "313",
                "Lastpage": "320",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visualization of 3D tensor fields continues to be a major challenge in terms of providing intuitive and uncluttered images that allow the users to better understand their data. The primary focus of this paper is on finding a formulation that lends itself to a stable numerical algorithm for extracting stable and persistent topological features from 2nd order real symmetric 3D tensors. While features in 2D tensors can be identified as either wedge or trisector points, in 3D, the corresponding stable features are lines, not just points. These topological feature lines provide a compact representation of the 3D tensor field and are essential in helping scientists and engineers understand their complex nature. Existing techniques work by finding degenerate points and are not numerically stable, and worse, produce both false positive and false negative feature points. This work seeks to address this problem with a robust algorithm that can extract these features in a numerically stable, accurate, and complete manner.",
                "AuthorNames": "Zheng, X.;Pang, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37274785100;37267352000",
                "Dedupedauthornames": "Zheng, X.;Pang, A.",
                "References": "10.1109/VISUAL.1998.745316;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2003.1250379;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886",
                "AuthorKeywords": "hyperstreamlines, real symmetric tensors, degenerate tensors, tensor topology, topological lines",
                "IEEEXPLOREArticleNumberdeprecated": "1372212",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745316;809894;398849;1250379;1183798;346326;809905;745294;809886"
            }
        },
        {
            "name": "Palke, D.",
            "value": 2,
            "numPapers": 18,
            "cluster": "3",
            "index": 555,
            "weight": 2,
            "x": 1260.533356784054,
            "y": 998.173047574163,
            "px": 1317.3699111327805,
            "py": 995.0465617844729,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "Firstpage": "1979",
                "Lastpage": "1988",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "References": "10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326",
                "AuthorKeywords": "Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent",
                "IEEEXPLOREArticleNumberdeprecated": "6064961",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Zhongzang Lin",
            "value": 2,
            "numPapers": 18,
            "cluster": "3",
            "index": 556,
            "weight": 2,
            "x": 1110.7787897488436,
            "y": 162.15177192172587,
            "px": 1150.31541119563,
            "py": 126.46783188877502,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "Firstpage": "1979",
                "Lastpage": "1988",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "References": "10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326",
                "AuthorKeywords": "Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent",
                "IEEEXPLOREArticleNumberdeprecated": "6064961",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Yeh, H.",
            "value": 2,
            "numPapers": 18,
            "cluster": "3",
            "index": 557,
            "weight": 2,
            "x": 742.978331889919,
            "y": -238.9956594876561,
            "px": 763.5374334370972,
            "py": -296.71919382294345,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "Firstpage": "1979",
                "Lastpage": "1988",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "References": "10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326",
                "AuthorKeywords": "Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent",
                "IEEEXPLOREArticleNumberdeprecated": "6064961",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Vincent, P.",
            "value": 2,
            "numPapers": 18,
            "cluster": "3",
            "index": 558,
            "weight": 2,
            "x": 362.36267501253866,
            "y": 1121.8542321572074,
            "px": 362.68392987520593,
            "py": 1113.77252892008,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Asymmetric Tensor field Visualization for Surfaces",
                "PaperDOI": "10.1109/TVCG.2011.170",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.170",
                "Firstpage": "1979",
                "Lastpage": "1988",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.",
                "AuthorNames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "FirstAuthorAffiliation": "SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37596533600;38016286200;37897252000;37889942300;38024282800;37267247900;37398562200",
                "Dedupedauthornames": "Guoning Chen;Palke, D.;Zhongzang Lin;Yeh, H.;Vincent, P.;Laramee, R.S.;Zhang, E.",
                "References": "10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326",
                "AuthorKeywords": "Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent",
                "IEEEXPLOREArticleNumberdeprecated": "6064961",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250379;5613502;1372212;398849;1532773;1532770;4015499;1532850;4015453;1532841;1250363;745295;1372188;745294;1532832;809905;885690;346326"
            }
        },
        {
            "name": "Zhang, E.",
            "value": 105,
            "numPapers": 33,
            "cluster": "3",
            "index": 559,
            "weight": 2,
            "x": -492.63070693888596,
            "y": -194.48569055742053,
            "px": -545.1029590960273,
            "py": -262.02158735918647,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations",
                "PaperDOI": "10.1109/INFVIS.2000.885091",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885091",
                "Firstpage": "57",
                "Lastpage": "65",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Radial, space-filling visualizations can be useful for depicting information hierarchies, but they suffer from one major problem. As the hierarchy grows in size, many items become small, peripheral slices that are difficult to distinguish. We have developed three visualization/interaction techniques that provide flexible browsing of the display. The techniques allow viewers to examine the small items in detail while providing context within the entire information hierarchy. Additionally, smooth transitions between views help users maintain orientation within the complete information space",
                "AuthorNames": "Stasko, J.;Zhang, E.",
                "FirstAuthorAffiliation": "GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;",
                "AuthorIDs": "37267736900;38020590400",
                "Dedupedauthornames": "Stasko, J.;Zhang, E.",
                "References": "10.1109/INFVIS.1999.801860;10.1109/VISUAL.1992.235217;10.1109/INFVIS.1998.729557;10.1109/VISUAL.1991.175815",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885091",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801860;235217;729567;175815"
            }
        },
        {
            "name": "de Leeuw, W.",
            "value": 205,
            "numPapers": 27,
            "cluster": "3",
            "index": 560,
            "weight": 8,
            "x": 157.28315540212034,
            "y": 442.0927026918261,
            "px": 199.17494120851921,
            "py": 441.93847644405673,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data",
                "PaperDOI": "10.1109/TVCG.2006.195",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.195",
                "Firstpage": "1251",
                "Lastpage": "1258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper we propose an approach in which interactive visualization and analysis are combined with batch tools for the processing of large data collections. Large and heterogeneous data collections are difficult to analyze and pose specific problems to interactive visualization. Application of the traditional interactive processing and visualization approaches as well as batch processing encounter considerable drawbacks for such large and heterogeneous data collections due to the amount and type of data. Computing resources are not sufficient for interactive exploration of the data and automated analysis has the disadvantage that the user has only limited control and feedback on the analysis process. In our approach, an analysis procedure with features and attributes of interest for the analysis is defined interactively. This procedure is used for offline processing of large collections of data sets. The results of the batch process along with \"visual summaries\" are used for further analysis. Visualization is not only used for the presentation of the result, but also as a tool to monitor the validity and quality of the operations performed during the batch process. Operations such as feature extraction and attribute calculation of the collected data sets are validated by visual inspection. This approach is illustrated by an extensive case study, in which a collection of confocal microscopy data sets is analyzed",
                "AuthorNames": "de Leeuw, W.;Verschure, P.J.;van Liere, R.",
                "FirstAuthorAffiliation": "Swammerdam Inst. for Life Sci.|c|;;",
                "AuthorIDs": ";37340174000;",
                "Dedupedauthornames": "de Leeuw, W.;Verschure, P.J.;van Liere, R.",
                "References": "10.1109/VISUAL.1998.745319;10.1109/VISUAL.1990.146378;10.1109/VISUAL.2000.885735;10.1109/VISUAL.2000.885678;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1996.568136",
                "AuthorKeywords": "Biomedical visualization, features in volume data sets, large data set visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015489",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745319;146378;885735;885678;1532788;568136"
            }
        },
        {
            "name": "Muigg, P.",
            "value": 118,
            "numPapers": 44,
            "cluster": "2",
            "index": 561,
            "weight": 9,
            "x": 472.5813393136898,
            "y": 320.95985009140145,
            "px": 451.4183228395746,
            "py": 330.46517118342274,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Hypothesis Generation in Climate Research with Interactive Visual Data Exploration",
                "PaperDOI": "10.1109/TVCG.2008.139",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.139",
                "Firstpage": "1579",
                "Lastpage": "1586",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.",
                "AuthorNames": "Kehrer, J.;Ladstadter, F.;Muigg, P.;Doleisch, H.;Steiner, A.;Hauser, H.",
                "FirstAuthorAffiliation": "Dept. of Inf., Bergen Univ., Bergen|c|;;;;;",
                "AuthorIDs": "37546620000;;37546620600;37546620400;37884365600;37274158800",
                "Dedupedauthornames": "Kehrer, J.;Ladstadter, F.;Muigg, P.;Doleisch, H.;Steiner, A.;Hauser, H.",
                "References": "10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1994.346302;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.170",
                "AuthorKeywords": "Interactive visual hypothesis generation, interactive visual exploration and analysis, visualization for climate research",
                "IEEEXPLOREArticleNumberdeprecated": "4658178",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532138;346302;1532850;4015444"
            }
        },
        {
            "name": "Weiler, M.",
            "value": 70,
            "numPapers": 2,
            "cluster": "2",
            "index": 562,
            "weight": 2,
            "x": 952.6412875657262,
            "y": 921.4308103528573,
            "px": 889.3575509145834,
            "py": 892.5008583237038,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Hardware-based ray casting for tetrahedral meshes",
                "PaperDOI": "10.1109/VISUAL.2003.1250390",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250390",
                "Firstpage": "333",
                "Lastpage": "340",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present the first implementation of a volume ray casting algorithm for tetrahedral meshes running on off-the-shelf programmable graphics hardware. Our implementation avoids the memory transfer bottleneck of the graphics bus since the complete mesh data is stored in the local memory of the graphics adapter and all computations, in particular ray traversal and ray integration, are performed by the graphics processing unit. Analogously to other ray casting algorithms, our algorithm does not require an expensive cell sorting. Provided that the graphics adapter offers enough texture memory, our implementation performs comparable to the fastest published volume rendering algorithms for unstructured meshes. Our approach works with cyclic and/or non-convex meshes and supports early ray termination. Accurate ray integration is guaranteed by applying pre-integrated volume rendering. In order to achieve almost interactive modifications of transfer functions, we propose a new method for computing three-dimensional pre-integration tables.",
                "AuthorNames": "Weiler, Manfred;Kraus, M.;Merz, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Univ. of Stutgart, Germany|c|;;;",
                "AuthorIDs": "37268043100;37284293000;38140167100;37268023800",
                "Dedupedauthornames": "Weiler, M.;Kraus, M.;Merz, M.;Ertl, T.",
                "References": "10.1109/VISUAL.2000.885683",
                "AuthorKeywords": "ray casting, pixel shading, programmable graphics hardware, cell projection, tetrahedral meshes, unstructured meshes, volume visualization, pre-integrated volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1250390",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885683"
            }
        },
        {
            "name": "Bartz, D.",
            "value": 79,
            "numPapers": 27,
            "cluster": "6",
            "index": 563,
            "weight": 2,
            "x": 877.2250618539958,
            "y": 524.8311981567368,
            "px": 904.6459519256642,
            "py": 540.9121929471386,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Illustrative Stream Surfaces",
                "PaperDOI": "10.1109/TVCG.2010.166",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.166",
                "Firstpage": "1329",
                "Lastpage": "1338",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham & Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.",
                "AuthorNames": "Born, S.;Wiebel, A.;Friedrich, J.;Scheuermann, G.;Bartz, D.",
                "FirstAuthorAffiliation": "Univ. Leipzig, Leipzig, Germany|c|;;;;",
                "AuthorIDs": "37590924500;37565763400;37587961900;37282574800;37448237300",
                "Dedupedauthornames": "Born, S.;Wiebel, A.;Friedrich, J.;Scheuermann, G.;Bartz, D.",
                "References": "10.1109/VISUAL.1990.146395;10.1109/TVCG.2009.190;10.1109/TVCG.2007.70565;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.1999.809905;10.1109/TVCG.2008.133;10.1109/TVCG.2009.138;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2005.1532855;10.1109/TVCG.2008.170;10.1109/VISUAL.2004.113;10.1109/VISUAL.2003.1250376",
                "AuthorKeywords": "Flow visualization, Stream surfaces, Illustrative rendering, Silhouettes, GPU technique, 3D vector field data",
                "IEEEXPLOREArticleNumberdeprecated": "5613473",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146395;5290738;4376157;1532857;809905;4658156;5290742;964506;1532858;1532855;4658177;1372196;1250376"
            }
        },
        {
            "name": "Hirsch, C.",
            "value": 23,
            "numPapers": 10,
            "cluster": "2",
            "index": 564,
            "weight": 1,
            "x": 119.6182311071554,
            "y": 806.05649404652,
            "px": 122.55198759215412,
            "py": 725.5156046872085,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations",
                "PaperDOI": "10.1109/TVCG.2011.225",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.225",
                "Firstpage": "1872",
                "Lastpage": "1881",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.",
                "AuthorNames": "Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, M.E.",
                "FirstAuthorAffiliation": "VRVis Vienna, Vienna, Austria|c|;;;;;;",
                "AuthorIDs": "38111592300;38229386600;38099765400;37408064900;38102461400;38229402400;37282552200",
                "Dedupedauthornames": "Waser, J.;Ribicic, H.;Fuchs, R.;Hirsch, C.;Schindler, B.;Bloschl, G.;Groller, E.",
                "References": "10.1109/TVCG.2010.223;10.1109/TVCG.2007.70584;10.1109/INFVIS.2002.1173149;10.1109/TVCG.2010.214;10.1109/INFVIS.2004.12;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2009.195;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2010.190;10.1109/TVCG.2010.223",
                "AuthorKeywords": "Emergency/Disaster Management, Visual Knowledge Discovery, Visualization System and Toolkit Design, Data-Flow, Meta-Flow, Parameter Study, Uncertainty, Visualization of Control",
                "IEEEXPLOREArticleNumberdeprecated": "6064950",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613487;4376187;1173149;5613489;1382904;1532795;5290771;1532143;5613488;5613487"
            }
        },
        {
            "name": "Dyer, R.",
            "value": 22,
            "numPapers": 5,
            "cluster": "2",
            "index": 565,
            "weight": 1,
            "x": 1770.6154123918648,
            "y": 3684.4249148075214,
            "px": 1585.6952359123468,
            "py": 3333.717412698321,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Linear and cubic box splines for the body centered cubic lattice",
                "PaperDOI": "10.1109/VISUAL.2004.65",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.65",
                "Firstpage": "11",
                "Lastpage": "18",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We derive piecewise linear and piecewise cubic box spline reconstruction filters for data sampled on the body centered cubic (BCC) lattice. We analytically derive a time domain representation of these reconstruction filters and using the Fourier slice-projection theorem we derive their frequency responses. The quality of these filters, when used in reconstructing BCC sampled volumetric data, is discussed and is demonstrated with a raycaster. Moreover, to demonstrate the superiority of the BCC sampling, the resulting reconstructions are compared with those produced from similar filters applied to data sampled on the Cartesian lattice.",
                "AuthorNames": "Entezari, A.;Dyer, R.;Moller, T.",
                "FirstAuthorAffiliation": "Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;",
                "AuthorIDs": "37268675600;37282718000;37275858700",
                "Dedupedauthornames": "Entezari, A.;Dyer, R.;Moller, T.",
                "References": "10.1109/VISUAL.1993.398851;10.1109/VISUAL.2001.964498;10.1109/VISUAL.1997.663848;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2001.964499",
                "AuthorKeywords": "Body Centered Cubic Lattice, Reconstruction, Optimal Regular Sampling",
                "IEEEXPLOREArticleNumberdeprecated": "1372174",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398851;964498;663848;346331;964499"
            }
        },
        {
            "name": "Theussl, T.",
            "value": 30,
            "numPapers": 5,
            "cluster": "2",
            "index": 566,
            "weight": 1,
            "x": -311.6155437161456,
            "y": 781.8953778999814,
            "px": -243.0242151614486,
            "py": 745.902546477085,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Optimal regular volume sampling",
                "PaperDOI": "10.1109/VISUAL.2001.964498",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964498",
                "Firstpage": "91",
                "Lastpage": "98",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.",
                "AuthorNames": "Theussl, T.;Mller, T.;Groller, M.E.",
                "FirstAuthorAffiliation": "Inst. of Comput. Graphics & Algorithms, Technische Univ. Wien, Vienna, Austria|c|;;",
                "AuthorIDs": ";37275858700;37282552200",
                "Dedupedauthornames": "Theussl, T.;Mller, T.;Groller, E.",
                "References": "10.1109/VISUAL.1994.346331",
                "AuthorKeywords": "volume data,Cartesiangrid,close packing,hexagonal sampling, body centered cubic",
                "IEEEXPLOREArticleNumberdeprecated": "964498",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346331"
            }
        },
        {
            "name": "Bergner, S.",
            "value": 94,
            "numPapers": 27,
            "cluster": "5",
            "index": 567,
            "weight": 1,
            "x": -12676.74960310091,
            "y": -5803.716404660421,
            "px": -11417.970742973564,
            "py": -5264.96014242725,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "DimStiller: Workflows for dimensional analysis and reduction",
                "PaperDOI": "10.1109/VAST.2010.5652392",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5652392",
                "Firstpage": "3",
                "Lastpage": "10",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.",
                "AuthorNames": "Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;Mller, T.",
                "FirstAuthorAffiliation": "Univ. of British Columbia, Vancouver, BC, Canada|c|;;;;;",
                "AuthorIDs": "37587716200;37349490300;37589529600;37275861300;37418878100;37275858700",
                "Dedupedauthornames": "Ingram, S.;Munzner, T.;Irvine, V.;Tory, M.;Bergner, S.;Mller, T.",
                "References": "10.1109/INFVIS.2003.1249013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2006.178;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.71",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "5652392",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1249013;346302;4015439;1249015;5290704;1382893"
            }
        },
        {
            "name": "Sanderson, A.",
            "value": 12,
            "numPapers": 27,
            "cluster": "3",
            "index": 568,
            "weight": 3,
            "x": 288.286217329882,
            "y": 511.51263005041284,
            "px": 279.0700544455834,
            "py": 508.5884862043689,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Analysis of Recurrent Patterns in Toroidal Magnetic fields",
                "PaperDOI": "10.1109/TVCG.2010.133",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.133",
                "Firstpage": "1431",
                "Lastpage": "1440",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In the development of magnetic confinement fusion which will potentially be a future source for low cost power, physicists must be able to analyze the magnetic field that confines the burning plasma. While the magnetic field can be described as a vector field, traditional techniques for analyzing the field's topology cannot be used because of its Hamiltonian nature. In this paper we describe a technique developed as a collaboration between physicists and computer scientists that determines the topology of a toroidal magnetic field using fieldlines with near minimal lengths. More specifically, we analyze the Poincare map of the sampled fieldlines in a Poincare section including identifying critical points and other topological features of interest to physicists. The technique has been deployed into an interactiveparallel visualization tool which physicists are using to gain new insight into simulations of magnetically confined burning plasmas.",
                "AuthorNames": "Sanderson, A.;Guoning Chen;Tricoche, X.;Pugmire, D.;Kruger, S.;Breslau, J.",
                "FirstAuthorAffiliation": ";;;;;",
                "AuthorIDs": "37283733200;37596533600;37282575100;37394779900;37411319500;37591115800",
                "Dedupedauthornames": "Sanderson, A.;Guoning Chen;Tricoche, X.;Pugmire, D.;Kruger, S.;Breslau, J.",
                "References": "10.1109/VISUAL.2005.1532842;10.1109/VISUAL.2001.964507;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.1997.663858",
                "AuthorKeywords": "Confined magnetic fusion, magnetic field visualization, Poincare map, periodic magnetic fieldlines, recurrent patterns",
                "IEEEXPLOREArticleNumberdeprecated": "5613484",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532842;964507;1250376;663858"
            }
        },
        {
            "name": "Rockwood, A.",
            "value": 46,
            "numPapers": 2,
            "cluster": "3",
            "index": 569,
            "weight": 2,
            "x": 202.81691310911134,
            "y": 670.8099378816758,
            "px": 235.82718406771454,
            "py": 645.6018814705874,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Computing singularities of 3D vector fields with geometric algebra",
                "PaperDOI": "10.1109/VISUAL.2002.1183786",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183786",
                "Firstpage": "283",
                "Lastpage": "289",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.",
                "AuthorNames": "Mann, S.;Rockwood, A.",
                "FirstAuthorAffiliation": "Waterloo Univ., Ont., Canada|c|;",
                "AuthorIDs": "37998748200;37372689000",
                "Dedupedauthornames": "Mann, S.;Rockwood, A.",
                "References": "10.1109/VISUAL.1997.663858;10.1109/VISUAL.1997.663871",
                "AuthorKeywords": "Geometric Algebra, 3D Vector Fields, Singularities",
                "IEEEXPLOREArticleNumberdeprecated": "1183786",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663858;663871"
            }
        },
        {
            "name": "Koehler, C.",
            "value": 6,
            "numPapers": 21,
            "cluster": "3",
            "index": 570,
            "weight": 4,
            "x": 60.479283323487465,
            "y": 544.9855935126551,
            "px": 38.05337885909016,
            "py": 548.0882487368774,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "Firstpage": "2071",
                "Lastpage": "2079",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "References": "10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532831;10.1109/TVCG.2008.163;10.1109/TVCG.2010.169;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2010.212;10.1109/VISUAL.2000.885690;10.1109/TVCG.2010.198;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745296;10.1109/TVCG.2007.70595;10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2006.199;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.166;10.1109/TVCG.2006.201",
                "AuthorKeywords": "Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",
                "IEEEXPLOREArticleNumberdeprecated": "6064971",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Wischgoll, T.",
            "value": 6,
            "numPapers": 21,
            "cluster": "3",
            "index": 571,
            "weight": 4,
            "x": 104.25430340294,
            "y": 548.3951975215582,
            "px": 124.26379931068514,
            "py": 545.865377509872,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "Firstpage": "2071",
                "Lastpage": "2079",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "References": "10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532831;10.1109/TVCG.2008.163;10.1109/TVCG.2010.169;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2010.212;10.1109/VISUAL.2000.885690;10.1109/TVCG.2010.198;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745296;10.1109/TVCG.2007.70595;10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2006.199;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.166;10.1109/TVCG.2006.201",
                "AuthorKeywords": "Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",
                "IEEEXPLOREArticleNumberdeprecated": "6064971",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Haibo Dong",
            "value": 6,
            "numPapers": 21,
            "cluster": "3",
            "index": 572,
            "weight": 4,
            "x": 231.9856959364909,
            "y": 574.4012363935484,
            "px": 254.6112024463288,
            "py": 566.942118884308,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "Firstpage": "2071",
                "Lastpage": "2079",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "References": "10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532831;10.1109/TVCG.2008.163;10.1109/TVCG.2010.169;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2010.212;10.1109/VISUAL.2000.885690;10.1109/TVCG.2010.198;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745296;10.1109/TVCG.2007.70595;10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2006.199;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.166;10.1109/TVCG.2006.201",
                "AuthorKeywords": "Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",
                "IEEEXPLOREArticleNumberdeprecated": "6064971",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Gaston, Z.",
            "value": 6,
            "numPapers": 21,
            "cluster": "3",
            "index": 573,
            "weight": 4,
            "x": 274.01475672534553,
            "y": 535.0352975709114,
            "px": 316.2265463655459,
            "py": 525.2793297318905,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Vortex Visualization in Ultra Low Reynolds Number Insect Flight",
                "PaperDOI": "10.1109/TVCG.2011.260",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.260",
                "Firstpage": "2071",
                "Lastpage": "2079",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.",
                "AuthorNames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "FirstAuthorAffiliation": "Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;",
                "AuthorIDs": "37665393300;37282584400;38026590900;38017003700",
                "Dedupedauthornames": "Koehler, C.;Wischgoll, T.;Haibo Dong;Gaston, Z.",
                "References": "10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532831;10.1109/TVCG.2008.163;10.1109/TVCG.2010.169;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2010.212;10.1109/VISUAL.2000.885690;10.1109/TVCG.2010.198;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745296;10.1109/TVCG.2007.70595;10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2006.199;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.166;10.1109/TVCG.2006.201",
                "AuthorKeywords": "Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",
                "IEEEXPLOREArticleNumberdeprecated": "6064971",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183789;1532830;4376209;1532831;4658155;5613499;1532848;1532850;5613500;885690;5613462;1372196;745296;4376173;5290738;4658156;4015451;1183821;4376212;5613473;4015452"
            }
        },
        {
            "name": "Lazarov, M.",
            "value": 8,
            "numPapers": 10,
            "cluster": "14",
            "index": 574,
            "weight": 2,
            "x": 1175.9516051268308,
            "y": 477.1413619273009,
            "px": 1175.7576219176833,
            "py": 491.7980763868972,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "Firstpage": "1101",
                "Lastpage": "1108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "References": "10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508",
                "AuthorKeywords": "Multi-projector displays, projector-camera systems, geometric and color calibration, distributed algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "4015470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Bhasker, E.",
            "value": 25,
            "numPapers": 11,
            "cluster": "14",
            "index": 575,
            "weight": 7,
            "x": 1103.0801604205528,
            "y": 596.7403101098053,
            "px": 1097.552373759251,
            "py": 605.5785575991864,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "Firstpage": "1101",
                "Lastpage": "1108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "References": "10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508",
                "AuthorKeywords": "Multi-projector displays, projector-camera systems, geometric and color calibration, distributed algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "4015470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Majumder, A.",
            "value": 51,
            "numPapers": 32,
            "cluster": "14",
            "index": 576,
            "weight": 22,
            "x": 1049.804499615796,
            "y": 621.8117511548326,
            "px": 1039.8074225312141,
            "py": 612.0791739680076,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "Firstpage": "1101",
                "Lastpage": "1108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "References": "10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508",
                "AuthorKeywords": "Multi-projector displays, projector-camera systems, geometric and color calibration, distributed algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "4015470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Sinha, P.",
            "value": 13,
            "numPapers": 5,
            "cluster": "14",
            "index": 577,
            "weight": 1,
            "x": 1215.7196491562056,
            "y": 558.7738524714159,
            "px": 1181.6988322339143,
            "py": 575.7268942077699,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2006.121",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.121",
                "Firstpage": "1101",
                "Lastpage": "1108",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays",
                "AuthorNames": "Bhasker, E.S.;Sinha, P.;Majumder, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;",
                "AuthorIDs": "37828782600;37827510800;37408075400",
                "Dedupedauthornames": "Bhasker, E.;Sinha, P.;Majumder, A.",
                "References": "10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508",
                "AuthorKeywords": "Multi-projector displays, projector-camera systems, geometric and color calibration, distributed algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "4015470",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183793;885685;885684;809883;964508"
            }
        },
        {
            "name": "Juang, R.",
            "value": 12,
            "numPapers": 6,
            "cluster": "14",
            "index": 578,
            "weight": 1,
            "x": 862.4254730813354,
            "y": 218.2620269419501,
            "px": 891.7050763579792,
            "py": 270.0117993514599,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Registration Techniques for Using Imperfect and Par tially Calibrated Devices in Planar Multi-Projector Displays",
                "PaperDOI": "10.1109/TVCG.2007.70586",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70586",
                "Firstpage": "1368",
                "Lastpage": "1375",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 times 2500 resolution planar multi-projector display made of 3 times 3 array of nine severely distorted projectors using a low resolution (640 times 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.",
                "AuthorNames": "Bhasker, E.;Juang, R.;Majumder, A.",
                "FirstAuthorAffiliation": "Univ. of California, Irvine|c|;;",
                "AuthorIDs": "37828782600;37927188200;37408075400",
                "Dedupedauthornames": "Bhasker, E.;Juang, R.;Majumder, A.",
                "References": "10.1109/VISUAL.2001.964508;10.1109/TVCG.2006.121;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883",
                "AuthorKeywords": "Geometric calibration, photometric calibration, tiled displays",
                "IEEEXPLOREArticleNumberdeprecated": "4376163",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964508;4015470;885685;1183793;885684;809883"
            }
        },
        {
            "name": "Chen, H.",
            "value": 22,
            "numPapers": 3,
            "cluster": "14",
            "index": 579,
            "weight": 1,
            "x": 931.3056867004622,
            "y": 608.0275662473433,
            "px": 964.959094958528,
            "py": 597.4863116744393,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "Firstpage": "339",
                "Lastpage": "346",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "References": "10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508;10.1109/VISUAL.2000.885685",
                "AuthorKeywords": "large-format tiled projection display, display wall, camera-projector systems, camera-based registration and calibration, automatic alignment, scalability, simulation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1183793",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809883;964508;885685"
            }
        },
        {
            "name": "Sukthankar, R.",
            "value": 22,
            "numPapers": 3,
            "cluster": "14",
            "index": 580,
            "weight": 1,
            "x": 1085.8837217484654,
            "y": 530.5692840731499,
            "px": 1093.80987193522,
            "py": 550.5332190664749,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "Firstpage": "339",
                "Lastpage": "346",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "References": "10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508;10.1109/VISUAL.2000.885685",
                "AuthorKeywords": "large-format tiled projection display, display wall, camera-projector systems, camera-based registration and calibration, automatic alignment, scalability, simulation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1183793",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809883;964508;885685"
            }
        },
        {
            "name": "Wallace, G.",
            "value": 22,
            "numPapers": 3,
            "cluster": "14",
            "index": 581,
            "weight": 1,
            "x": 1189.241858274403,
            "y": 499.9656154245691,
            "px": 1165.1653094450978,
            "py": 528.954067819846,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "Firstpage": "339",
                "Lastpage": "346",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "References": "10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508;10.1109/VISUAL.2000.885685",
                "AuthorKeywords": "large-format tiled projection display, display wall, camera-projector systems, camera-based registration and calibration, automatic alignment, scalability, simulation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1183793",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809883;964508;885685"
            }
        },
        {
            "name": "Li, K.",
            "value": 46,
            "numPapers": 4,
            "cluster": "14",
            "index": 582,
            "weight": 2,
            "x": 930.5461660369281,
            "y": 629.837012448017,
            "px": 948.8124205384528,
            "py": 624.7566508997761,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Scalable alignment of large-format multi-projector displays using camera homography trees",
                "PaperDOI": "10.1109/VISUAL.2002.1183793",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183793",
                "Firstpage": "339",
                "Lastpage": "346",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",
                "AuthorNames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "FirstAuthorAffiliation": "Comput. Sci., Princeton Univ., NJ, USA|c|;;;",
                "AuthorIDs": "37337226600;37282878500;37425426700;37277619300",
                "Dedupedauthornames": "Chen, H.;Sukthankar, R.;Wallace, G.;Li, K.",
                "References": "10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508;10.1109/VISUAL.2000.885685",
                "AuthorKeywords": "large-format tiled projection display, display wall, camera-projector systems, camera-based registration and calibration, automatic alignment, scalability, simulation, evaluation",
                "IEEEXPLOREArticleNumberdeprecated": "1183793",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809883;964508;885685"
            }
        },
        {
            "name": "Nielson, G.M.",
            "value": 211,
            "numPapers": 24,
            "cluster": "3",
            "index": 583,
            "weight": 10,
            "x": 218.1102732423849,
            "y": 509.9609861110908,
            "px": 223.58293197557268,
            "py": 507.0990674374783,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "The asymptotic decider: resolving the ambiguity in marching cubes",
                "PaperDOI": "10.1109/VISUAL.1991.175782",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175782",
                "Firstpage": "83",
                "Lastpage": "91, 413",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A method for computing isovalue or contour surfaces of a trivariate function is discussed. The input data are values of the trivariate function, Fijk, at the cuberille grid points (xi, yj, zk ), and the output of a collection of triangles representing the surface consisting of all points where F(x,y, z) is a constant value. The method is a modification that is intended to correct a problem with a previous method.",
                "AuthorNames": "Nielson, G.M.;Hamann, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;",
                "AuthorIDs": "37283754100;37282068700",
                "Dedupedauthornames": "Nielson, G.M.;Hamann, B.",
                "References": "10.1109/VISUAL.1990.146363",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175782",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146363"
            }
        },
        {
            "name": "Duffy, B.",
            "value": 37,
            "numPapers": 13,
            "cluster": "2",
            "index": 584,
            "weight": 1,
            "x": 239.90376677967404,
            "y": 192.43503234242345,
            "px": 279.29529066662053,
            "py": 197.85031932193283,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Revisiting Histograms and Isosurface Statistics",
                "PaperDOI": "10.1109/TVCG.2008.160",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.160",
                "Firstpage": "1659",
                "Lastpage": "1666",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.",
                "AuthorNames": "Scheidegger, C.E.;Schreiner, J.M.;Duffy, B.;Carr, H.;Silva, C.T.",
                "FirstAuthorAffiliation": "Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake City, UT|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Scheidegger, C.E.;Schreiner, J.;Duffy, B.;Carr, H.;Silva, C.T.",
                "References": "10.1109/TVCG.2006.168;10.1109/TVCG.2008.119;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2001.964515;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2001.964516",
                "AuthorKeywords": "Isosurfaces, Histograms, Coarea Formula",
                "IEEEXPLOREArticleNumberdeprecated": "4658188",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015490;4658159;964519;964515;663875;964516"
            }
        },
        {
            "name": "Machiraju, R.",
            "value": 142,
            "numPapers": 30,
            "cluster": "3",
            "index": 585,
            "weight": 3,
            "x": -203.9493917015814,
            "y": 1882.439466201118,
            "px": -280.70922983846526,
            "py": 1954.981326793382,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Vortex Visualization for Practical Engineering Applications",
                "PaperDOI": "10.1109/TVCG.2006.201",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.201",
                "Firstpage": "957",
                "Lastpage": "964",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability",
                "AuthorNames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Raghu Machiraju",
                "FirstAuthorAffiliation": "Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;",
                "AuthorIDs": ";37826582200;;37269516700",
                "Dedupedauthornames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.",
                "References": "10.1109/VISUAL.1997.663894;10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1999.809896",
                "AuthorKeywords": "Vortex detection, vortex visualization, feature mining",
                "IEEEXPLOREArticleNumberdeprecated": "4015452",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663894;1183789;1532830;745296;745288;809896"
            }
        },
        {
            "name": "Fraedrich, R.",
            "value": 21,
            "numPapers": 20,
            "cluster": "2",
            "index": 586,
            "weight": 2,
            "x": 478.06269423375164,
            "y": -526.5846885220586,
            "px": 423.33022299099514,
            "py": -498.5126073105635,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Efficient High-Quality Volume Rendering of SPH Data",
                "PaperDOI": "10.1109/TVCG.2010.148",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.148",
                "Firstpage": "1533",
                "Lastpage": "1540",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.",
                "AuthorNames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, Mnchen, Germany|c|;;",
                "AuthorIDs": "37590979700;37411079300;37444424000",
                "Dedupedauthornames": "Fraedrich, R.;Auer, S.;Westermann, R.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55",
                "AuthorKeywords": "Particle visualization, volume rendering, ray-casting, GPU resampling",
                "IEEEXPLOREArticleNumberdeprecated": "5613495",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;4658172;235223;1250404;1250384;4376206;5290736;4376164;1372217"
            }
        },
        {
            "name": "Hopf, M.",
            "value": 49,
            "numPapers": 8,
            "cluster": "2",
            "index": 587,
            "weight": 2,
            "x": 361.4231694825244,
            "y": 63.61813199665648,
            "px": 303.4211213057295,
            "py": 143.79027253397575,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Hierarchical splatting of scattered data",
                "PaperDOI": "10.1109/VISUAL.2003.1250404",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250404",
                "Firstpage": "433",
                "Lastpage": "440",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Numerical particle simulations and astronomical observations create huge data sets containing uncorrelated 3D points of varying size. These data sets cannot be visualized interactively by simply rendering millions of colored points for each frame. Therefore, in many visualization applications a scalar density corresponding to the point distribution is resampled on a regular grid for direct volume rendering. However, many fine details are usually lost for voxel resolutions which still allow interactive visualization on standard workstations. Since no surface geometry is associated with our data sets, the recently introduced point-based rendering algorithms cannot be applied as well. In this paper we propose to accelerate the visualization of scattered point data by a hierarchical data structure based on a PCA clustering procedure. By traversing this structure for each frame we can trade-off rendering speed vs. image quality. Our scheme also reduces memory consumption by using quantized relative coordinates and it allows for fast sorting of semi-transparent clusters. We analyze various software and hardware implementations of our renderer and demonstrate that we can now visualize data sets with tens of millions of points interactively with sub-pixel screen space error on current PC graphics hardware employing advanced vertex shader functionality.",
                "AuthorNames": "Hopf, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Univ. of Stuttgart, Germany|c|;",
                "AuthorIDs": "37427327200;37268023800",
                "Dedupedauthornames": "Hopf, M.;Ertl, T.",
                "References": "10.1109/VISUAL.1997.663882;10.1109/VISUAL.2002.1183820;10.1109/VISUAL.1999.809909;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2001.964489;10.1109/VISUAL.2002.1183771",
                "AuthorKeywords": "Volume Rendering, Scattered Data, Splatting, Hierarchical Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1250404",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663882;1183820;809909;964490;964489;1183771"
            }
        },
        {
            "name": "Yagel, R.",
            "value": 191,
            "numPapers": 11,
            "cluster": "2",
            "index": 588,
            "weight": 7,
            "x": 279.5933651853504,
            "y": 93.02481297029183,
            "px": 295.861828997568,
            "py": 80.83370890842123,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "Octree-based decimation of marching cubes surfaces",
                "PaperDOI": "10.1109/VISUAL.1996.568127",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568127",
                "Firstpage": "335",
                "Lastpage": "342",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The marching cubes (MC) algorithm is a method for generating isosurfaces. It also generates an excessively large number of triangles to represent an isosurface; this increases the rendering time. This paper presents a decimation method to reduce the number of triangles generated. Decimation is carried out before creating a large number of triangles. Four major steps comprise the algorithm: surface tracking, merging, crack patching and triangulation. Surface tracking is an enhanced implementation of the MC algorithm. Starting from a seed point, the surface tracker visits only those cells likely to compose part of the desired isosurface. The cells making up the extracted surface are stored in an octree that is further processed. A bottom-up approach is taken in merging the cells containing a relatively flat approximating surface. The finer surface details are maintained. Cells are merged as long as the error due to such an operation is within a user-specified error parameter, or a cell acquires more than one connected surface component in it. A crack patching method is described that forces edges of smaller cells to lie along those of the larger neighboring cells. The overall saving in the number of triangles depends both on the specified error value and the nature of the data. Use of the hierarchical octree data structure also presents the potential of incremental representation of surfaces. We can generate a highly smoothed surface representation which can be progressively refined as the user-specified error value is decreased.",
                "AuthorNames": "Shekhar, R.;Fayyad, E.;Yagel, R.;Cornhill, J.F.",
                "FirstAuthorAffiliation": "Biomed. Eng. Center, Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": "37270717100;37860553000;37342422500;37354614600",
                "Dedupedauthornames": "Shekhar, R.;Fayyad, E.;Yagel, R.;Cornhill, J.F.",
                "References": "10.1109/VISUAL.1994.346308",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "568127",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346308"
            }
        },
        {
            "name": "Bobach, T.",
            "value": 42,
            "numPapers": 5,
            "cluster": "3",
            "index": 589,
            "weight": 1,
            "x": 1640.5022364303734,
            "y": 806.1020928421726,
            "px": 1458.8449967920897,
            "py": 771.340008973076,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "A tetrahedra-based stream surface algorithm",
                "PaperDOI": "10.1109/VISUAL.2001.964506",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964506",
                "Firstpage": "151",
                "Lastpage": "158",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.",
                "AuthorNames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;;;",
                "AuthorIDs": "37282574800;37728450600;37282578800;37728450100;37282068700;37267811400;37722986700",
                "Dedupedauthornames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "References": "10.1109/VISUAL.1993.398875;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1995.485145;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1997.663910",
                "AuthorKeywords": "vector field visualization, flow visualization, tetrahedral grid, unstructured grid, flow surface",
                "IEEEXPLOREArticleNumberdeprecated": "964506",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398875;235211;485145;809896;663910"
            }
        },
        {
            "name": "Mahrous, K.",
            "value": 42,
            "numPapers": 5,
            "cluster": "3",
            "index": 590,
            "weight": 1,
            "x": 1395.6122050559743,
            "y": 202.5004320387529,
            "px": 1235.9960284032954,
            "py": 239.84481222414405,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "A tetrahedra-based stream surface algorithm",
                "PaperDOI": "10.1109/VISUAL.2001.964506",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964506",
                "Firstpage": "151",
                "Lastpage": "158",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.",
                "AuthorNames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;;;",
                "AuthorIDs": "37282574800;37728450600;37282578800;37728450100;37282068700;37267811400;37722986700",
                "Dedupedauthornames": "Scheuermann, G.;Bobach, T.;Hagen, H.;Mahrous, K.;Hamann, B.;Joy, K.I.;Kollmann, W.",
                "References": "10.1109/VISUAL.1993.398875;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1995.485145;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1997.663910",
                "AuthorKeywords": "vector field visualization, flow visualization, tetrahedral grid, unstructured grid, flow surface",
                "IEEEXPLOREArticleNumberdeprecated": "964506",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398875;235211;485145;809896;663910"
            }
        },
        {
            "name": "Chi-Wing Fu",
            "value": 50,
            "numPapers": 47,
            "cluster": "7",
            "index": 591,
            "weight": 2,
            "x": 1444.7411997494569,
            "y": 532.2134724057695,
            "px": 1450.6348360821812,
            "py": 525.4874018587153,
            "node": {
                "Conference": "VAST",
                "Year": "2014",
                "PaperTitle": "Visualizing Mobility of Public Transportation System",
                "PaperDOI": "10.1109/TVCG.2014.2346893",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346893",
                "Firstpage": "1833",
                "Lastpage": "1842",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.",
                "AuthorNames": "Wei Zeng;Chi-Wing Fu;Arisona, S.M.;Erath, A.;Huamin Qu",
                "FirstAuthorAffiliation": "Nanyang Technol. Univ., Singapore, Singapore|c|;;;;",
                "AuthorIDs": ";;;;",
                "Dedupedauthornames": "Wei Zeng;Chi-Wing Fu;Arisona, S.M.;Erath, A.;Huamin Qu",
                "References": "10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.202;10.1109/TVCG.2011.205;10.1109/TVCG.2009.143;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/INFVIS.2005.1532150",
                "AuthorKeywords": "Mobility, public transportation, visual analytics",
                "IEEEXPLOREArticleNumberdeprecated": "6876029",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "963273;6065021;6065020;5290710;6327262;6634174;6634127;6102455;1532150"
            }
        },
        {
            "name": "Law, A.J.",
            "value": 0,
            "numPapers": 5,
            "cluster": "14",
            "index": 592,
            "weight": 1,
            "x": 857.478977149872,
            "y": 623.3999602386682,
            "px": 901.2743179594175,
            "py": 610.7966846804004,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing",
                "PaperDOI": "10.1109/TVCG.2009.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.124",
                "Firstpage": "1317",
                "Lastpage": "1326",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",
                "AuthorNames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;",
                "AuthorIDs": "37391937200;37541336800;37271691400;37408075400",
                "Dedupedauthornames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "References": "10.1109/VISUAL.2001.964508;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/TVCG.2007.70586;10.1109/TVCG.2006.121",
                "AuthorKeywords": "Color Calibration, Multi-Projector Displays, Tiled Displays",
                "IEEEXPLOREArticleNumberdeprecated": "5290744",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964508;1183793;885684;809883;4376163;4015470"
            }
        },
        {
            "name": "Aliaga, D.",
            "value": 28,
            "numPapers": 17,
            "cluster": "14",
            "index": 593,
            "weight": 1,
            "x": 944.7362846389121,
            "y": 759.9716693151756,
            "px": 972.1303543246254,
            "py": 717.0232841894878,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing",
                "PaperDOI": "10.1109/TVCG.2009.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.124",
                "Firstpage": "1317",
                "Lastpage": "1326",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",
                "AuthorNames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;",
                "AuthorIDs": "37391937200;37541336800;37271691400;37408075400",
                "Dedupedauthornames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "References": "10.1109/VISUAL.2001.964508;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/TVCG.2007.70586;10.1109/TVCG.2006.121",
                "AuthorKeywords": "Color Calibration, Multi-Projector Displays, Tiled Displays",
                "IEEEXPLOREArticleNumberdeprecated": "5290744",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964508;1183793;885684;809883;4376163;4015470"
            }
        },
        {
            "name": "Zhu He",
            "value": 18,
            "numPapers": 1,
            "cluster": "14",
            "index": 594,
            "weight": 1,
            "x": 1074.8127708128252,
            "y": 746.0354094644455,
            "px": 1079.042235232943,
            "py": 698.9313463017733,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Achieving color uniformity across multi-projector displays",
                "PaperDOI": "10.1109/VISUAL.2000.885684",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885684",
                "Firstpage": "117",
                "Lastpage": "124",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Large area tiled displays are gaining popularity for use in collaborative immersive virtual environments and scientific visualization. While recent work has addressed the issues of geometric registration, rendering architectures, and human interfaces, there has been relatively little work on photometric calibration in general, and photometric non-uniformity in particular. For example, as a result of differences in the photometric characteristics of projectors, the color and intensity of a large area display varies from place to place. Further, the imagery typically appears brighter at the regions of overlap between adjacent projectors. We analyze and classify the causes of photometric non-uniformity in a tiled display. We then propose a methodology for determining corrections designed to achieve uniformity, that can correct for the photometric variations across a tiled projector display in real time using per channel color look-up-tables (LUT).",
                "AuthorNames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;",
                "AuthorIDs": "38477162600;38024209800;37298881100;37300645000",
                "Dedupedauthornames": "Majumder, A.;Zhu He;Towles, H.;Welch, G.",
                "References": "10.1109/VISUAL.1999.809890",
                "AuthorKeywords": "large area display, tiled displays, projector graphics, color calibration",
                "IEEEXPLOREArticleNumberdeprecated": "885684",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809890"
            }
        },
        {
            "name": "Towles, H.",
            "value": 86,
            "numPapers": 7,
            "cluster": "14",
            "index": 595,
            "weight": 4,
            "x": 1020.8088920589868,
            "y": 613.8893870126852,
            "px": 1029.1789770277535,
            "py": 603.7758762314344,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Welch, G.",
            "value": 66,
            "numPapers": 3,
            "cluster": "14",
            "index": 596,
            "weight": 3,
            "x": 1277.0902310830563,
            "y": 551.7632421176538,
            "px": 1279.9643351825132,
            "py": 549.3220557303163,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Huang, J.",
            "value": 86,
            "numPapers": 53,
            "cluster": "2",
            "index": 597,
            "weight": 11,
            "x": 285.2279185158999,
            "y": 88.26170296236324,
            "px": 288.23322361241355,
            "py": 79.19356591749282,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Visualizing Temporal Patterns in Large Multivariate Data using Textual Pattern Matching",
                "PaperDOI": "10.1109/TVCG.2008.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.184",
                "Firstpage": "1467",
                "Lastpage": "1474",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.",
                "AuthorNames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "FirstAuthorAffiliation": "Univ. of Tennessee at Knoxville, Knoxville, TN|c|;;;;",
                "AuthorIDs": "37828700000;37281262900;37410066100;37672397100;37545504600",
                "Dedupedauthornames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "References": "10.1109/VISUAL.2003.1250402;10.1109/TVCG.2007.70600;10.1109/TVCG.2006.175;10.1109/VISUAL.2004.95;10.1109/TVCG.2007.70519;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2005.1532792",
                "AuthorKeywords": "Multivariate visualization, Time-varying, Uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "4658164",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250402;4376164;4015494;1372194;4376167;964519;1532792"
            }
        },
        {
            "name": "Ahrens, E.T.",
            "value": 83,
            "numPapers": 1,
            "cluster": "3",
            "index": 598,
            "weight": 2,
            "x": 436.6015481756174,
            "y": -433.57934316483835,
            "px": 451.7431393378023,
            "py": -528.1114950040624,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "Firstpage": "127",
                "Lastpage": "134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "References": "10.1109/VISUAL.1992.235201",
                "AuthorKeywords": "multi-valued visualization, tensor field visualization,oil painting",
                "IEEEXPLOREArticleNumberdeprecated": "745294",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235201"
            }
        },
        {
            "name": "Kremers, D.",
            "value": 83,
            "numPapers": 1,
            "cluster": "3",
            "index": 599,
            "weight": 2,
            "x": -737.2679558522058,
            "y": -243.22873453008492,
            "px": -825.1539391884721,
            "py": -333.04510578761983,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "Firstpage": "127",
                "Lastpage": "134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "References": "10.1109/VISUAL.1992.235201",
                "AuthorKeywords": "multi-valued visualization, tensor field visualization,oil painting",
                "IEEEXPLOREArticleNumberdeprecated": "745294",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235201"
            }
        },
        {
            "name": "Avalos, M.J.",
            "value": 83,
            "numPapers": 1,
            "cluster": "3",
            "index": 600,
            "weight": 2,
            "x": 201.61466954867547,
            "y": 1789.5533260627149,
            "px": 197.8354493455768,
            "py": 1880.4910058965677,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "Firstpage": "127",
                "Lastpage": "134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "References": "10.1109/VISUAL.1992.235201",
                "AuthorKeywords": "multi-valued visualization, tensor field visualization,oil painting",
                "IEEEXPLOREArticleNumberdeprecated": "745294",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235201"
            }
        },
        {
            "name": "Jacobs, R.E.",
            "value": 83,
            "numPapers": 1,
            "cluster": "3",
            "index": 601,
            "weight": 2,
            "x": -660.7657600323308,
            "y": 1436.825487502,
            "px": -744.6192547938589,
            "py": 1495.9817913689865,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "Firstpage": "127",
                "Lastpage": "134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "References": "10.1109/VISUAL.1992.235201",
                "AuthorKeywords": "multi-valued visualization, tensor field visualization,oil painting",
                "IEEEXPLOREArticleNumberdeprecated": "745294",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235201"
            }
        },
        {
            "name": "Readhead, C.",
            "value": 83,
            "numPapers": 1,
            "cluster": "3",
            "index": 602,
            "weight": 2,
            "x": -407.77544576132783,
            "y": 708.6079362994777,
            "px": -445.41807052770577,
            "py": 692.9136268194081,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Visualizing diffusion tensor images of the mouse spinal cord",
                "PaperDOI": "10.1109/VISUAL.1998.745294",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745294",
                "Firstpage": "127",
                "Lastpage": "134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",
                "AuthorNames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "FirstAuthorAffiliation": "California Inst. of Technol., Pasadena, CA, USA|c|;;;;;",
                "AuthorIDs": "37275712600;37359190700;37371978600;37371978400;37368212100;37371977900",
                "Dedupedauthornames": "Laidlaw, D.H.;Ahrens, E.T.;Kremers, D.;Avalos, M.J.;Jacobs, R.E.;Readhead, C.",
                "References": "10.1109/VISUAL.1992.235201",
                "AuthorKeywords": "multi-valued visualization, tensor field visualization,oil painting",
                "IEEEXPLOREArticleNumberdeprecated": "745294",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235201"
            }
        },
        {
            "name": "Delmarcelle, T.",
            "value": 100,
            "numPapers": 5,
            "cluster": "3",
            "index": 603,
            "weight": 4,
            "x": -63.629336825521946,
            "y": 522.0398472562722,
            "px": -197.0986162012545,
            "py": 503.7160545735281,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "The topology of symmetric, second-order tensor fields",
                "PaperDOI": "10.1109/VISUAL.1994.346326",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346326",
                "Firstpage": "140",
                "Lastpage": "147, C15",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We study the topology of symmetric, second-order tensor fields. The goal is to represent their complex structure by a simple set of carefully chosen points and lines analogous to vector field topology. We extract topological skeletons of the eigenvector fields, and we track their evolution over time. We study tensor topological transitions and correlate tensor and vector data. The basic constituents of tensor topology are the degenerate points, or points where eigenvalues are equal to each other. Degenerate points play a similar role as critical points in vector fields. We identify two kinds of elementary degenerate points, which we call wedges and trisectors. They can combine to form more familiar singularities-such as saddles, nodes, centers, or foci. However, these are generally unstable structures in tensor fields. Finally, we show a topological rule that puts a constraint on the topology of tensor fields defined across surfaces, extending to tensor fields the Poincare-Hopf theorem for vector fields",
                "AuthorNames": "Delmarcelle, T.;Hesselink, Lambertus",
                "FirstAuthorAffiliation": "Dept. of Appl. Phys., Stanford Univ., CA, USA|c|;",
                "AuthorIDs": "37378372200;37274095200",
                "Dedupedauthornames": "Delmarcelle, T.;Hesselink, L.",
                "References": "10.1109/VISUAL.1991.175773",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346326",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175773"
            }
        },
        {
            "name": "Gerber, S.",
            "value": 32,
            "numPapers": 6,
            "cluster": "3",
            "index": 604,
            "weight": 1,
            "x": 325.9337057786007,
            "y": 630.9690051589624,
            "px": 315.1960661773074,
            "py": 642.4479116091347,
            "node": {
                "Conference": "Vis",
                "Year": "2010",
                "PaperTitle": "Visual Exploration of High Dimensional Scalar Functions",
                "PaperDOI": "10.1109/TVCG.2010.213",
                "Link": "http://dx.doi.org/10.1109/TVCG.2010.213",
                "Firstpage": "1271",
                "Lastpage": "1280",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.",
                "AuthorNames": "Gerber, S.;Bremer, P.;Pascucci, V.;Whitaker, R.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;",
                "AuthorIDs": "37390992900;38266672800;37284312600;37267322600",
                "Dedupedauthornames": "Gerber, S.;Bremer, P.-T.;Pascucci, V.;Whitaker, R.T.",
                "References": "10.1109/VISUAL.2004.96;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2007.70552;10.1109/TVCG.2007.70601;10.1109/VISUAL.2005.1532839",
                "AuthorKeywords": "Morse theory, High-dimensional visualization, Morse-Smale complex",
                "IEEEXPLOREArticleNumberdeprecated": "5613467",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372235;4376171;4015464;4376172;4376169;1532839"
            }
        },
        {
            "name": "Johansson, S.",
            "value": 68,
            "numPapers": 9,
            "cluster": "5",
            "index": 605,
            "weight": 2,
            "x": 1092.247665256316,
            "y": 302.6324506282237,
            "px": 1134.287667176017,
            "py": 308.53266843641376,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics",
                "PaperDOI": "10.1109/TVCG.2009.153",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.153",
                "Firstpage": "993",
                "Lastpage": "1000",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.",
                "AuthorNames": "Johansson, S.;Johansson, J.",
                "FirstAuthorAffiliation": "Norrkoping Visualization & Interaction Studio (NVIS), Linkoping Univ., Linkoping, Sweden|c|;",
                "AuthorIDs": "37924876400;37273045500",
                "Dedupedauthornames": "Johansson, S.;Johansson, J.",
                "References": "10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.161;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2008.138;10.1109/INFVIS.2004.15",
                "AuthorKeywords": "dimensionality reduction, interactivity, quality metrics, variable ordering",
                "IEEEXPLOREArticleNumberdeprecated": "5290704",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532142;1249015;729568;4015421;1382891;1382892;1382893;4658134;1382895"
            }
        },
        {
            "name": "Johnson, B.",
            "value": 190,
            "numPapers": 4,
            "cluster": "0",
            "index": 606,
            "weight": 2,
            "x": 666.5056048261795,
            "y": -1183.980145590784,
            "px": 634.8381618123494,
            "py": -1076.4424207992447,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "Tree-maps: a space-filling approach to the visualization of hierarchical information structures",
                "PaperDOI": "10.1109/VISUAL.1991.175815",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175815",
                "Firstpage": "284",
                "Lastpage": "291",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A method for visualizing hierarchically structured information is described. The tree-map visualization technique makes 100% use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. Tree-maps can depict both the structure and content of the hierarchy. However, the approach is best suited to hierarchies in which the content of the leaf nodes and the structure of the hierarchy are of primary importance, and the content information associated with internal nodes is largely derived from their children",
                "AuthorNames": "Johnson, B.;Shneiderman, B.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;",
                "AuthorIDs": "37381975300;37283016400",
                "Dedupedauthornames": "Johnson, B.;Shneiderman, B.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175815",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Post, F.H.",
            "value": 211,
            "numPapers": 31,
            "cluster": "3",
            "index": 607,
            "weight": 1,
            "x": 1146.9228005341934,
            "y": 893.242723501084,
            "px": 1017.4900798594342,
            "py": 846.3873223200617,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Smooth Graphs for Visual Exploration of Higher-Order State Transitions",
                "PaperDOI": "10.1109/TVCG.2009.181",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.181",
                "Firstpage": "969",
                "Lastpage": "976",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.",
                "AuthorNames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.;Laramee, R.S.;Post, F.H.",
                "FirstAuthorAffiliation": "Visualization Group, Delft Univ. of Technol., Delft, Netherlands|c|;;;;;",
                "AuthorIDs": "37550793100;37373834100;38110391600;37335785800;37267247900;37295045800",
                "Dedupedauthornames": "Blaas, J.;Botha, C.P.;Grundy, E.;Jones, M.W.;Laramee, R.S.;Post, F.H.",
                "References": "10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.155;10.1109/TVCG.2008.135;10.1109/TVCG.2006.192;10.1109/INFVIS.2001.963281;10.1109/INFVIS.2001.963281;10.1109/TVCG.2006.147",
                "AuthorKeywords": "State transitions, Graph drawing, Time series, Biological data",
                "IEEEXPLOREArticleNumberdeprecated": "5290701",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "528685;4658147;4658140;4015418;963281;963281;4015425"
            }
        },
        {
            "name": "Mansmann, F.",
            "value": 51,
            "numPapers": 14,
            "cluster": "5",
            "index": 608,
            "weight": 1,
            "x": -661.6903550026615,
            "y": 227.91161297246012,
            "px": -499.5434966602472,
            "py": 235.0509161966389,
            "node": {
                "Conference": "InfoVis",
                "Year": "2009",
                "PaperTitle": "Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps",
                "PaperDOI": "10.1109/TVCG.2009.182",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.182",
                "Firstpage": "913",
                "Lastpage": "920",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.",
                "AuthorNames": "Bak, P.;Mansmann, F.;Janetzko, H.;Keim, D.A.",
                "FirstAuthorAffiliation": "Univ. of Konstanz, Konstanz, Germany|c|;;;",
                "AuthorIDs": "37392085400;37392086200;37594026300;37283138700",
                "Dedupedauthornames": "Bak, P.;Mansmann, F.;Janetzko, H.;Keim, D.A.",
                "References": "10.1109/INFVIS.2004.27;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2006.198;10.1109/TVCG.2007.70621;10.1109/TVCG.2007.70535;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.202",
                "AuthorKeywords": "spatiotemporal visualization, visual analytics, animal behavior, dense pixel displays",
                "IEEEXPLOREArticleNumberdeprecated": "5290694",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382887;485140;1532144;4015426;4376136;4376143;801851;4015427"
            }
        },
        {
            "name": "Panse, C.",
            "value": 27,
            "numPapers": 8,
            "cluster": "5",
            "index": 609,
            "weight": 1,
            "x": 1892.402078638509,
            "y": 763.8764708150915,
            "px": 1784.5822537080496,
            "py": 706.8284120273313,
            "node": {
                "Conference": "InfoVis",
                "Year": "2002",
                "PaperTitle": "Efficient cartogram generation: a comparison",
                "PaperDOI": "10.1109/INFVIS.2002.1173144",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2002.1173144",
                "Firstpage": "33",
                "Lastpage": "36",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Cartograms are a well-known technique for showing geography-related statistical information, such as population demographics and epidemiological data. The basic idea is to distort a map by resizing its regions according to a statistical parameter, but in a way that keeps the map recognizable. We deal with the problem of making continuous cartograms that strictly retain the topology of the input mesh. We compare two algorithms to solve the continuous cartogram problem. The first one uses an iterative relocation of the vertices based on scanlines. The second one is based on the Gridfit technique, which uses pixel-based distortion based on a quadtree-like data structure.",
                "AuthorNames": "Keim, D.A.;North, S.C.;Panse, C.;Schneidewind, J.",
                "FirstAuthorAffiliation": "AT&T Shannon Lab., Florham Park, NJ, USA|c|;;;",
                "AuthorIDs": "37283138700;37372818600;37282557300;37669961800",
                "Dedupedauthornames": "Keim, D.A.;North, S.C.;Panse, C.;Schneidewind, J.",
                "References": "10.1109/VISUAL.1998.745301;10.1109/VISUAL.1998.745303",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "1173144",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745301;745303"
            }
        },
        {
            "name": "Sajadi, B.",
            "value": 8,
            "numPapers": 11,
            "cluster": "14",
            "index": 610,
            "weight": 4,
            "x": 1034.9722771366153,
            "y": 688.4331611000987,
            "px": 1033.507069080972,
            "py": 688.0623073543836,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing",
                "PaperDOI": "10.1109/TVCG.2009.124",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.124",
                "Firstpage": "1317",
                "Lastpage": "1326",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",
                "AuthorNames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "FirstAuthorAffiliation": "Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;",
                "AuthorIDs": "37391937200;37541336800;37271691400;37408075400",
                "Dedupedauthornames": "Sajadi, B.;Lazarov, M.;Gopi, M.;Majumder, A.",
                "References": "10.1109/VISUAL.2001.964508;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/TVCG.2007.70586;10.1109/TVCG.2006.121",
                "AuthorKeywords": "Color Calibration, Multi-Projector Displays, Tiled Displays",
                "IEEEXPLOREArticleNumberdeprecated": "5290744",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964508;1183793;885684;809883;4376163;4015470"
            }
        },
        {
            "name": "Ruigang Yang",
            "value": 58,
            "numPapers": 4,
            "cluster": "14",
            "index": 611,
            "weight": 3,
            "x": 1142.5622620826164,
            "y": 456.10697858905877,
            "px": 1157.513098838608,
            "py": 447.20564647595995,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Brown, M.S.",
            "value": 58,
            "numPapers": 15,
            "cluster": "14",
            "index": 612,
            "weight": 6,
            "x": 1176.2035827187583,
            "y": 657.4059573230351,
            "px": 1183.5590429718418,
            "py": 649.5044814250257,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Hensley, J.",
            "value": 20,
            "numPapers": 4,
            "cluster": "14",
            "index": 613,
            "weight": 1,
            "x": 1474.5429556776105,
            "y": 895.6931285112391,
            "px": 1418.494513456981,
            "py": 840.8646144331497,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "PixelFlex: a reconfigurable multi-projector display system",
                "PaperDOI": "10.1109/VISUAL.2001.964508",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964508",
                "Firstpage": "167",
                "Lastpage": "554",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.",
                "AuthorNames": "Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;",
                "AuthorIDs": "37277874700;37601397400;37274010000;38278187600;37277811200",
                "Dedupedauthornames": "Ruigang Yang;Gotz, D.;Hensley, J.;Towles, H.;Brown, M.S.",
                "References": "10.1109/VISUAL.2000.885685;10.1109/VISUAL.1999.809890;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2000.885712",
                "AuthorKeywords": "large-format projection display, camera-based registration and calibration",
                "IEEEXPLOREArticleNumberdeprecated": "964508",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885685;809890;809883;885712"
            }
        },
        {
            "name": "Raskar, R.",
            "value": 38,
            "numPapers": 0,
            "cluster": "14",
            "index": 614,
            "weight": 1,
            "x": 1567.6120032765402,
            "y": 961.1400737309111,
            "px": 1499.8063489280805,
            "py": 902.8173550077285,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Wei-Chao Chen",
            "value": 38,
            "numPapers": 0,
            "cluster": "14",
            "index": 615,
            "weight": 1,
            "x": 1113.658072274116,
            "y": 500.0456120464413,
            "px": 1108.0855173953255,
            "py": 530.9338214456586,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Scales, B.",
            "value": 38,
            "numPapers": 0,
            "cluster": "14",
            "index": 616,
            "weight": 1,
            "x": 1433.4592864098204,
            "y": 1066.2452325664594,
            "px": 1388.5790454029702,
            "py": 990.8564545164832,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Fuchs, H.",
            "value": 127,
            "numPapers": 7,
            "cluster": "14",
            "index": 617,
            "weight": 2,
            "x": 1253.926618302781,
            "y": 604.7091682782761,
            "px": 1232.7099109002907,
            "py": 589.6516389492639,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Multi-projector displays using camera-based registration",
                "PaperDOI": "10.1109/VISUAL.1999.809883",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809883",
                "Firstpage": "161",
                "Lastpage": "522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Conventional projector-based display systems are typically designed around precise and regular configurations of projectors and display surfaces. While this results in rendering simplicity and speed, it also means painstaking construction and ongoing maintenance. In previously published work, we introduced a vision of projector-based displays constructed from a collection of casually-arranged projectors and display surfaces. In this paper, we present flexible yet practical methods for realizing this vision, enabling low-cost mega-pixel display systems with large physical dimensions, higher resolution, or both. The techniques afford new opportunities to build personal 3D visualization systems in offices, conference rooms, theaters, or even your living room. As a demonstration of the simplicity and effectiveness of the methods that we continue to perfect, we show in the included video that a 10-year old child can construct and calibrate a two-camera, two-projector, head-tracked display system, all in about 15 minutes.",
                "AuthorNames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;",
                "AuthorIDs": "37271940800;37277811200;37277874700;37440192900;37300645000;38278187300;;37285537200",
                "Dedupedauthornames": "Raskar, R.;Brown, M.S.;Ruigang Yang;Wei-Chao Chen;Welch, G.;Towles, H.;Scales, B.;Fuchs, H.",
                "References": "",
                "AuthorKeywords": "display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration",
                "IEEEXPLOREArticleNumberdeprecated": "809883",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Chu, A.",
            "value": 0,
            "numPapers": 7,
            "cluster": "7",
            "index": 618,
            "weight": 1,
            "x": 1467.203671769422,
            "y": 475.18473777791746,
            "px": 1448.2937203509034,
            "py": 461.96603997640517,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Spiders: a new user interface for rotation and visualization of n-dimensional point sets",
                "PaperDOI": "10.1109/VISUAL.1994.346318",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346318",
                "Firstpage": "205",
                "Lastpage": "211, C22",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a new method for creating n-dimensional rotation matrices from manipulating the projections of n-dimensional data coordinate axes onto a viewing plane. A user interface for n-dimensional rotation is implemented. The interface is shown to have no rotational hysteresis",
                "AuthorNames": "Duffin, K.L.;Barrett, W.A.",
                "FirstAuthorAffiliation": "Brigham Young Univ., Provo, UT, USA|c|;",
                "AuthorIDs": "37663438100;37339053800",
                "Dedupedauthornames": "Duffin, K.L.;Barrett, W.A.",
                "References": "10.1109/VISUAL.1991.175794",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346318",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175794"
            }
        },
        {
            "name": "Heng, P.A.",
            "value": 34,
            "numPapers": 4,
            "cluster": "7",
            "index": 619,
            "weight": 2,
            "x": 1436.1255668691606,
            "y": 524.1664011010195,
            "px": 1412.440430069649,
            "py": 511.5303753295917,
            "node": {
                "Conference": "Vis",
                "Year": "1992",
                "PaperTitle": "Four-dimensional views of 3D scalar fields",
                "PaperDOI": "10.1109/VISUAL.1992.235222",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235222",
                "Firstpage": "84",
                "Lastpage": "91",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Scalar functions of three variables, w=f(x , y, z), are common in many types of scientific and medical applications. Such 3D scalar fields can be understood as elevation maps in four dimensions, with three independent variables (x, y, z) and a fourth, dependent, variable w that corresponds to the elevations. It is shown how techniques developed originally for the display of 3-manifolds in 4D Euclidean space can be adapted to visualize 3D scalar fields in a variety of ways",
                "AuthorNames": "Hanson, A.J.;Heng, P.A.",
                "FirstAuthorAffiliation": "CERN, Geneva, Switzerland|c|;",
                "AuthorIDs": "37333439100;37388382500",
                "Dedupedauthornames": "Hanson, A.J.;Heng, P.A.",
                "References": "10.1109/VISUAL.1990.146363;10.1109/VISUAL.1991.175821;10.1109/VISUAL.1990.146391",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "235222",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146363;175821;146391"
            }
        },
        {
            "name": "Pheng-Ann Heng",
            "value": 3,
            "numPapers": 11,
            "cluster": "7",
            "index": 620,
            "weight": 1,
            "x": 1454.3416433711268,
            "y": 540.713946554832,
            "px": 1435.0035015806618,
            "py": 526.1008336683561,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Spiders: a new user interface for rotation and visualization of n-dimensional point sets",
                "PaperDOI": "10.1109/VISUAL.1994.346318",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346318",
                "Firstpage": "205",
                "Lastpage": "211, C22",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a new method for creating n-dimensional rotation matrices from manipulating the projections of n-dimensional data coordinate axes onto a viewing plane. A user interface for n-dimensional rotation is implemented. The interface is shown to have no rotational hysteresis",
                "AuthorNames": "Duffin, K.L.;Barrett, W.A.",
                "FirstAuthorAffiliation": "Brigham Young Univ., Provo, UT, USA|c|;",
                "AuthorIDs": "37663438100;37339053800",
                "Dedupedauthornames": "Duffin, K.L.;Barrett, W.A.",
                "References": "10.1109/VISUAL.1991.175794",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346318",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175794"
            }
        },
        {
            "name": "Cross, R.A.",
            "value": 37,
            "numPapers": 6,
            "cluster": "7",
            "index": 621,
            "weight": 3,
            "x": 1478.527153827681,
            "y": 532.3601675110481,
            "px": 1460.7825126186763,
            "py": 515.5234502172483,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Virtual reality performance for virtual geometry",
                "PaperDOI": "10.1109/VISUAL.1994.346324",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346324",
                "Firstpage": "156",
                "Lastpage": "163, C17",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe the theoretical and practical visualization issues solved in the implementation of an interactive real-time four-dimensional geometry interface for the CAVE, an immersive virtual reality environment. While our specific task is to produce a virtual geometry experience by approximating physically correct rendering of manifolds embedded in four dimensions, the general principles exploited by our approach reflect requirements common to many immersive virtual reality applications, especially those involving volume rendering. Among the issues we address are the classification of rendering tasks, the specialized hardware support required to attain interactivity, specific techniques required to render 4D objects, and interactive methods appropriate for our 4D virtual world application",
                "AuthorNames": "Cross, R.A.;Hanson, A.J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37664370800;37333439100",
                "Dedupedauthornames": "Cross, R.A.;Hanson, A.J.",
                "References": "10.1109/VISUAL.1994.346330;10.1109/VISUAL.1993.398869;10.1109/VISUAL.1991.175821;10.1109/VISUAL.1992.235222",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346324",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346330;398869;175821;235222"
            }
        },
        {
            "name": "Varetto, U.",
            "value": 0,
            "numPapers": 14,
            "cluster": "2",
            "index": 622,
            "weight": 1,
            "x": 651.0149507348125,
            "y": -25.32406722542195,
            "px": 551.08721797515,
            "py": 15.891107673651929,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Visual Verification and Analysis of Cluster Detection for Molecular Dynamics",
                "PaperDOI": "10.1109/TVCG.2007.70614",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70614",
                "Firstpage": "1624",
                "Lastpage": "1631",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.",
                "AuthorNames": "Grottel, S.;Reina, G.;Vrabec, J.;Ertl, T.",
                "FirstAuthorAffiliation": "Univ. Stuttgart, Stuttgart|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Grottel, S.;Reina, G.;Vrabec, J.;Ertl, T.",
                "References": "10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2002.1183811;10.1109/TVCG.2006.115;10.1109/VISUAL.2004.103;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250404",
                "AuthorKeywords": "Cluster detection analysis, molecular dynamics visualization, time-dependent scattered data, glyph visualization, out-of-core techniques, evolution graph vie",
                "IEEEXPLOREArticleNumberdeprecated": "4376195",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250404;1183811;4015487;1372203;4015464;1250404"
            }
        },
        {
            "name": "Yi-Jen Chiang",
            "value": 81,
            "numPapers": 17,
            "cluster": "2",
            "index": 623,
            "weight": 10,
            "x": 251.66478378868104,
            "y": 110.39673463851591,
            "px": 232.7044221552488,
            "py": 104.16330045596375,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Out-of-core isosurface extraction of time-varying fields over irregular grids",
                "PaperDOI": "10.1109/VISUAL.2003.1250375",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250375",
                "Firstpage": "217",
                "Lastpage": "224",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper, we propose a novel out-of-core isosurface extraction technique for large time-varying fields over irregular grids. We employ our meta-cell technique to explore the spatial coherence of the data, and our time tree algorithm to consider the temporal coherence as well. Our one-time preprocessing phase first partitions the dataset into meta-cells that cluster spatially neighboring cells together and are stored in disk. We then build a time tree to index the meta-cells for fast isosurface extraction. The time tree takes advantage of the temporal coherence among the scalar values at different time steps, and uses BBIO trees as secondary structures, which are stored in disk and support I/O-optimal interval searches. The time tree algorithm employs a novel meta-interval collapsing scheme and the buffer technique, to take care of the temporal coherence in an I/O-efficient way. We further make the time tree cache-oblivious, so that searching on it automatically performs optimal number of block transfers between any two consecutive levels of memory hierarchy (such as between cache and main memory and between main memory and disk) simultaneously. At run-time, we perform optimal cache-oblivious searches in the time tree, together with I/O-optimal searches in the BBIO trees, to read the active meta-cells from disk and generate the queried isosurface efficiently. The experiments demonstrate the effectiveness of our new technique. In particular, compared with the query-optimal main-memory algorithm by Cignoni et al. (1997) (extended for time-varying fields) when there is not enough main memory, our technique can speed up the isosurface queries from more than 18 hours to less than 4 minutes.",
                "AuthorNames": "Yi-Jen Chiang",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Polytech. Univ., Brooklyn, NY, USA|c|",
                "AuthorIDs": "37288235400",
                "Dedupedauthornames": "Yi-Jen Chiang",
                "References": "10.1109/VISUAL.1995.480806;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1996.568121;10.1109/VISUAL.2003.1250373;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1998.745298",
                "AuthorKeywords": "isosurface extraction, out-of-core techniques, time-varying fields, irregular grids",
                "IEEEXPLOREArticleNumberdeprecated": "1250375",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480806;745299;663895;568121;1250373;663888;745298"
            }
        },
        {
            "name": "Livnat, Y.",
            "value": 218,
            "numPapers": 28,
            "cluster": "2",
            "index": 624,
            "weight": 18,
            "x": 221.8846081227044,
            "y": 75.98074304132606,
            "px": 220.55440016755477,
            "py": 67.0048191202791,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Visual correlation for situational awareness",
                "PaperDOI": "10.1109/INFVIS.2005.1532134",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532134",
                "Firstpage": "95",
                "Lastpage": "102",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel visual correlation paradigm for situational awareness (SA) and suggest its usage in a diverse set of applications that require a high level of SA. Our approach is based on a concise and scalable representation, which leads to a flexible visualization tool that is both clear and intuitive to use. Situational awareness is the continuous extraction of environmental information, its integration with previous knowledge to form a coherent mental picture, and the use of that picture in anticipating future events. In this paper we build on our previous work on visualization for network intrusion detection and show how that approach can be generalized to encompass a much broader class of SA systems. We first propose a generalization that is based on what we term, the w3 premise, namely that each event must have at least the what, when and where attributes. We also present a second generalization, which increases flexibility and facilitates complex visual correlations. Finally, we demonstrate the generality of our approaches by applying our visualization paradigm in a collection of diverse SA areas.",
                "AuthorNames": "Livnat, Y.;Agutter, J.;Shaun Moon;Foresti, S.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah Univ., USA|c|;;;",
                "AuthorIDs": "37282553200;37442679500;37553253600;37354354100",
                "Dedupedauthornames": "Livnat, Y.;Agutter, J.;Shaun Moon;Foresti, S.",
                "References": "10.1109/VISUAL.2003.1250415",
                "AuthorKeywords": "situation awareness, network intrusion, visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1532134",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250415"
            }
        },
        {
            "name": "Hermann, S.",
            "value": 25,
            "numPapers": 9,
            "cluster": "2",
            "index": 625,
            "weight": 1,
            "x": -1516.991782019726,
            "y": 25.47166064116626,
            "px": -1329.5422637843553,
            "py": 53.6957950180383,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "Firstpage": "1515",
                "Lastpage": "1522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/VISUAL.1992.235203;10.1109/TVCG.2007.70576;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964538;10.1109/TVCG.2007.70560;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250396",
                "AuthorKeywords": "Vessel visualization, plaque growth, multipath CPR, vessel flattening",
                "IEEEXPLOREArticleNumberdeprecated": "5290768",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "Reich, R.",
            "value": 25,
            "numPapers": 9,
            "cluster": "2",
            "index": 626,
            "weight": 1,
            "x": -917.5863956447123,
            "y": 1441.8924423247706,
            "px": -792.5320720954419,
            "py": 1318.5074597684775,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "Firstpage": "1515",
                "Lastpage": "1522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/VISUAL.1992.235203;10.1109/TVCG.2007.70576;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964538;10.1109/TVCG.2007.70560;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250396",
                "AuthorKeywords": "Vessel visualization, plaque growth, multipath CPR, vessel flattening",
                "IEEEXPLOREArticleNumberdeprecated": "5290768",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "Schafers, M.",
            "value": 25,
            "numPapers": 9,
            "cluster": "2",
            "index": 627,
            "weight": 1,
            "x": -979.9786616680879,
            "y": 144.09537990311813,
            "px": -839.0077542751968,
            "py": 158.30621530943813,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans",
                "PaperDOI": "10.1109/TVCG.2009.169",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.169",
                "Firstpage": "1515",
                "Lastpage": "1522",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",
                "AuthorNames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;",
                "AuthorIDs": "37295281400;38113668500;38099511600;38101001700;37267218300",
                "Dedupedauthornames": "Ropinski, T.;Hermann, S.;Reich, R.;Schafers, M.;Hinrichs, K.",
                "References": "10.1109/VISUAL.2003.1250353;10.1109/VISUAL.1992.235203;10.1109/TVCG.2007.70576;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964538;10.1109/TVCG.2007.70560;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250396",
                "AuthorKeywords": "Vessel visualization, plaque growth, multipath CPR, vessel flattening",
                "IEEEXPLOREArticleNumberdeprecated": "5290768",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250353;235203;4376185;1372221;1250384;964538;4376204;1183754;1250396"
            }
        },
        {
            "name": "Hinrichs, K.",
            "value": 57,
            "numPapers": 27,
            "cluster": "2",
            "index": 628,
            "weight": 2,
            "x": -798.4120446543903,
            "y": 221.85730876476055,
            "px": -896.7371995855856,
            "py": 239.5668744280018,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2008.136",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.136",
                "Firstpage": "1499",
                "Lastpage": "1506",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.",
                "AuthorNames": "Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.",
                "FirstAuthorAffiliation": "Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster|c|;;;;",
                "AuthorIDs": "37869986400;37273031400;;37295281400;37267218300",
                "Dedupedauthornames": "Meyer-Spradow, J.;Stegger, L.;Doring, C.;Ropinski, T.;Hinrichs, K.",
                "References": "10.1109/VISUAL.2003.1250425;10.1109/TVCG.2006.134;10.1109/TVCG.2007.70550;10.1109/VISUAL.1998.745294",
                "AuthorKeywords": "Multivariate visualization, glyph techniques, SPECT, myocardial perfusion imaging",
                "IEEEXPLOREArticleNumberdeprecated": "4658168",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250425;4015499;4376196;745294"
            }
        },
        {
            "name": "Ming-Yuen Chan",
            "value": 19,
            "numPapers": 31,
            "cluster": "2",
            "index": 629,
            "weight": 2,
            "x": -506.56552366398097,
            "y": 1567.0341493710573,
            "px": -604.0267436424683,
            "py": 1716.6442676338838,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Perception-Based Transparency Optimization for Direct Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2009.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.172",
                "Firstpage": "1283",
                "Lastpage": "1290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.",
                "AuthorNames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;",
                "AuthorIDs": "37401176900;37407308300;37306814700;37279188600;37272637300",
                "Dedupedauthornames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "References": "10.1109/VISUAL.1998.745319;10.1109/VISUAL.2000.885694;10.1109/TVCG.2008.118;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70591;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/TVCG.2006.183;10.1109/TVCG.2008.159;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Direct volume rendering, image enhancement, layer perception",
                "IEEEXPLOREArticleNumberdeprecated": "5290740",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745319;885694;4658198;1250414;4376159;1372208;4658153;4015473;4658191;4015460"
            }
        },
        {
            "name": "Wai-Ho Mak",
            "value": 19,
            "numPapers": 26,
            "cluster": "2",
            "index": 630,
            "weight": 2,
            "x": -1111.2137138766316,
            "y": 197.55237609075553,
            "px": -1269.2683049791008,
            "py": 199.16752507259145,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Perception-Based Transparency Optimization for Direct Volume Rendering",
                "PaperDOI": "10.1109/TVCG.2009.172",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.172",
                "Firstpage": "1283",
                "Lastpage": "1290",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.",
                "AuthorNames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;",
                "AuthorIDs": "37401176900;37407308300;37306814700;37279188600;37272637300",
                "Dedupedauthornames": "Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu",
                "References": "10.1109/VISUAL.1998.745319;10.1109/VISUAL.2000.885694;10.1109/TVCG.2008.118;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70591;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/TVCG.2006.183;10.1109/TVCG.2008.159;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Direct volume rendering, image enhancement, layer perception",
                "IEEEXPLOREArticleNumberdeprecated": "5290740",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745319;885694;4658198;1250414;4376159;1372208;4658153;4015473;4658191;4015460"
            }
        },
        {
            "name": "Georgii, J.",
            "value": 30,
            "numPapers": 20,
            "cluster": "2",
            "index": 631,
            "weight": 2,
            "x": 192.04671742824527,
            "y": 44.73102915712456,
            "px": 206.3353885901237,
            "py": 38.33791042735195,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Stress Tensor field Visualization for Implant Planning in Orthopedics",
                "PaperDOI": "10.1109/TVCG.2009.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.184",
                "Firstpage": "1399",
                "Lastpage": "1406",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.",
                "AuthorNames": "Dick, C.;Georgii, J.;Burgkart, R.;Westermann, R.",
                "FirstAuthorAffiliation": "Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;;",
                "AuthorIDs": "38013954900;37828702100;37281609100;37444424000",
                "Dedupedauthornames": "Dick, C.;Georgii, J.;Burgkart, R.;Westermann, R.",
                "References": "10.1109/VISUAL.2005.1532780;10.1109/TVCG.2006.124;10.1109/VISUAL.2003.1250379;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/TVCG.2007.70532;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2005.1532771;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2002.1183799;10.1109/TVCG.2006.151;10.1109/VISUAL.1998.745316",
                "AuthorKeywords": "Stress Tensor fields, Biomedical Visualization, Comparative Visualization, Implant Planning, GPU Techniques",
                "IEEEXPLOREArticleNumberdeprecated": "5290754",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532780;4015450;1250379;1372188;745294;4376178;1183797;346326;1532771;1183798;346326;1183799;4015480;745316"
            }
        },
        {
            "name": "Lum, E.B.",
            "value": 95,
            "numPapers": 16,
            "cluster": "2",
            "index": 632,
            "weight": 2,
            "x": 137.16729457552535,
            "y": -875.5920372126662,
            "px": 82.00492917114556,
            "py": -967.937037112774,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Texture Hardware Assisted Rendering of Time-Varying Volume Data",
                "PaperDOI": "10.1109/VISUAL.2001.964520",
                "Link": "http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964520",
                "Firstpage": "263",
                "Lastpage": "270",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.",
                "AuthorNames": "Lum, E.B.;Ma, K.-L.;Clyne, J.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "Dedupedauthornames": "Lum, E.B.;Kwan-Liu Ma;Clyne, J.",
                "References": "10.1109/VISUAL.1999.809910;10.1109/VISUAL.1994.346321;10.1109/VISUAL.1995.480809;10.1109/VISUAL.1994.346341;10.1109/VISUAL.1999.809879",
                "AuthorKeywords": "Compression, high performance computing, out-of-core processing, PC, scientific visualization, texture hardware, time-varying data, transform encoding, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "964541_06",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": "809910;346321;480809;346341;809879"
            }
        },
        {
            "name": "Miller, M.",
            "value": 122,
            "numPapers": 10,
            "cluster": "2",
            "index": 633,
            "weight": 1,
            "x": 1036.1958469372878,
            "y": 826.7388874426013,
            "px": 921.6716914499483,
            "py": 747.0356268310904,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "ROAMing terrain: Real-time Optimally Adapting Meshes",
                "PaperDOI": "10.1109/VISUAL.1997.663860",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663860",
                "Firstpage": "81",
                "Lastpage": "88",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Terrain visualization is a difficult problem for applications requiring accurate images of large datasets at high frame rates, such as flight simulation and ground-based aircraft testing using synthetic sensor simulation. On current graphics hardware, the problem is to maintain dynamic, view-dependent triangle meshes and texture maps that produce good images at the required frame rate. We present an algorithm for constructing triangle meshes that optimizes flexible view-dependent error metrics, produces guaranteed error bounds, achieves specified triangle counts directly and uses frame-to-frame coherence to operate at high frame rates for thousands of triangles per frame. Our method, dubbed Real-time Optimally Adapting Meshes (ROAM), uses two priority queues to drive split and merge operations that maintain continuous triangulations built from pre-processed bintree triangles. We introduce two additional performance optimizations: incremental triangle stripping and priority-computation deferral lists. ROAM's execution time is proportional to the number of triangle changes per frame, which is typically a few percent of the output mesh size; hence ROAM's performance is insensitive to the resolution and extent of the input terrain. Dynamic terrain and simple vertex morphing are supported.",
                "AuthorNames": "Duchaineau, M.;Wolinsky, M.;Sigeti, D.E.;Miller, M.C.;Aldrich, C.;Mineev-Weinstein, M.B.",
                "FirstAuthorAffiliation": "Los Alamos Nat. Lab., NM, USA|c|;;;;;",
                "AuthorIDs": "37267813100;37443252200;37443253500;;37608683600;37612202100",
                "Dedupedauthornames": "Duchaineau, M.;Wolinsky, M.;Sigeti, D.E.;Miller, M.;Aldrich, C.;Mineev-Weinstein, M.B.",
                "References": "10.1109/VISUAL.1996.567600;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1996.568125;10.1109/VISUAL.1995.480813;10.1109/VISUAL.1995.480805",
                "AuthorKeywords": "triangle bintree, view-dependent mesh, frame-to-frame coherence, greedy algorithms",
                "IEEEXPLOREArticleNumberdeprecated": "663860",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567600;568126;568125;480813;480805"
            }
        },
        {
            "name": "Shirley, P.",
            "value": 87,
            "numPapers": 14,
            "cluster": "2",
            "index": 634,
            "weight": 2,
            "x": -751.5371063881253,
            "y": 676.9478999799747,
            "px": -862.6223559463454,
            "py": 711.0934611273495,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Interactive rendering of large unstructured grids using dynamic level-of-detail",
                "PaperDOI": "10.1109/VISUAL.2005.1532796",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532796",
                "Firstpage": "199",
                "Lastpage": "206",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe a new dynamic level-of-detail (LOD) technique that allows real-time rendering of large tetrahedral meshes. Unlike approaches that require hierarchies of tetrahedra, our approach uses a subset of the faces that compose the mesh. No connectivity is used for these faces so our technique eliminates the need for topological information and hierarchical data structures. By operating on a simple set of triangular faces, our algorithm allows a robust and straightforward graphics hardware (GPU) implementation. Because the subset of faces processed can be constrained to arbitrary size, interactive rendering is possible for a wide range of data sets and hardware configurations.",
                "AuthorNames": "Callahan, S.P.;Comba, J.L.D.;Shirley, P.;Silva, C.T.",
                "FirstAuthorAffiliation": "Sci. Comput. & Imaging Inst., Utah State Univ., Logan, UT, USA|c|;;;",
                "AuthorIDs": "37426872800;37267034700;37266808400;37275249200",
                "Dedupedauthornames": "Callahan, S.P.;Comba, J.L.D.;Shirley, P.;Silva, C.T.",
                "References": "10.1109/VISUAL.2004.102;10.1109/VISUAL.1999.809908;10.1109/VISUAL.1998.745283;10.1109/VISUAL.2004.85;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2002.1183778;10.1109/VISUAL.1998.745329;10.1109/VISUAL.2002.1183767;10.1109/VISUAL.2000.885711",
                "AuthorKeywords": " interactive volume rendering, multiresolution meshes, level-of-detail, tetrahedral meshes",
                "IEEEXPLOREArticleNumberdeprecated": "1532796",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372227;809908;745283;1372176;1250390;1183778;745329;1183767;885711"
            }
        },
        {
            "name": "Green, T.M.",
            "value": 55,
            "numPapers": 7,
            "cluster": "0",
            "index": 635,
            "weight": 1,
            "x": 1406.519222990475,
            "y": -293.2282525771348,
            "px": 1298.479804221096,
            "py": -230.97511333548528,
            "node": {
                "Conference": "VAST",
                "Year": "2010",
                "PaperTitle": "Towards the Personal Equation of Interaction: The impact of personality factors on visual analytics interface interaction",
                "PaperDOI": "10.1109/VAST.2010.5653587",
                "Link": "http://dx.doi.org/10.1109/VAST.2010.5653587",
                "Firstpage": "203",
                "Lastpage": "210",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "These current studies explored the impact of individual differences in personality factors on interface interaction and learning performance behaviors in both an interactive visualization and a menu-driven web table in two studies. Participants were administered 3 psychometric measures designed to assess Locus of Control, Extraversion, and Neuroticism. Participants were then asked to complete multiple procedural learning tasks in each interface. Results demonstrated that all three measures predicted completion times. Additionally, results analyses demonstrated personality factors also predicted the number of insights participants reported while completing the tasks in each interface. We discuss how these findings advance our ongoing research in the Personal Equation of Interaction.",
                "AuthorNames": "Green, T.M.;Fisher, B.",
                "FirstAuthorAffiliation": "Sch. of Interactive Arts + Technol., Simon Fraser Univ., Surrey, BC, Canada|c|;",
                "AuthorIDs": "37403562900;37267458000",
                "Dedupedauthornames": "Green, T.M.;Fisher, B.",
                "References": "",
                "AuthorKeywords": "visual analytics, cognition and perception theory, embodied cognition, visualization taxonomies and models \n",
                "IEEEXPLOREArticleNumberdeprecated": "5653587",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Jianping Fan",
            "value": 28,
            "numPapers": 13,
            "cluster": "5",
            "index": 636,
            "weight": 2,
            "x": 1332.522091323698,
            "y": -754.9031623967892,
            "px": 1252.5076970321359,
            "py": -633.3779844456996,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "Firstpage": "191",
                "Lastpage": "198",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "References": "10.1109/INFVIS.1999.801855;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249009;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2004.71",
                "AuthorKeywords": "Image retrieval, image layout, semantic image classification,\nmulti-dimensional visualization, visual analytics",
                "IEEEXPLOREArticleNumberdeprecated": "4035765",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Hangzai Luo",
            "value": 28,
            "numPapers": 13,
            "cluster": "5",
            "index": 637,
            "weight": 2,
            "x": 1629.3414974184052,
            "y": -275.8356851754625,
            "px": 1519.6528867269367,
            "py": -191.37848027090897,
            "node": {
                "Conference": "VAST",
                "Year": "2006",
                "PaperTitle": "Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis",
                "PaperDOI": "10.1109/VAST.2006.261425",
                "Link": "http://dx.doi.org/10.1109/VAST.2006.261425",
                "Firstpage": "191",
                "Lastpage": "198",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks",
                "AuthorNames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;",
                "AuthorIDs": "37292632600;37271216800;37300421500;37404899900;37275772500;37300425000;37268441700",
                "Dedupedauthornames": "Jing Yang;Jianping Fan;Hubball, D.;Yuli Gao;Hangzai Luo;Ribarsky, W.;Ward, M.O.",
                "References": "10.1109/INFVIS.1999.801855;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249009;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2004.71",
                "AuthorKeywords": "Image retrieval, image layout, semantic image classification,\nmulti-dimensional visualization, visual analytics",
                "IEEEXPLOREArticleNumberdeprecated": "4035765",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801855;528686;1249009;485140;1382893"
            }
        },
        {
            "name": "Wise, J.A.",
            "value": 183,
            "numPapers": 1,
            "cluster": "5",
            "index": 638,
            "weight": 4,
            "x": 1173.1627234458203,
            "y": 255.360560296775,
            "px": 1172.4030641818633,
            "py": 282.5068909971503,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Pennock, K.",
            "value": 183,
            "numPapers": 1,
            "cluster": "5",
            "index": 639,
            "weight": 4,
            "x": 1108.756218265111,
            "y": -99.00308559551523,
            "px": 1114.660750827292,
            "py": -189.17318004382471,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Lantrip, D.",
            "value": 183,
            "numPapers": 1,
            "cluster": "5",
            "index": 640,
            "weight": 4,
            "x": 1133.877285834063,
            "y": -14.668977546987287,
            "px": 1139.622834874276,
            "py": -63.55037308607174,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Pottier, M.",
            "value": 183,
            "numPapers": 1,
            "cluster": "5",
            "index": 641,
            "weight": 4,
            "x": 1219.929437373161,
            "y": -80.8005208809835,
            "px": 1263.6263590243343,
            "py": -167.43014042153763,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Schur, A.",
            "value": 183,
            "numPapers": 1,
            "cluster": "5",
            "index": 642,
            "weight": 4,
            "x": 1036.8934492201602,
            "y": -122.45748520439288,
            "px": 1016.0021445968848,
            "py": -211.54132037974168,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Crow, V.",
            "value": 208,
            "numPapers": 5,
            "cluster": "5",
            "index": 643,
            "weight": 4,
            "x": 1045.7714062372613,
            "y": 415.6381374537465,
            "px": 1008.7411021239664,
            "py": 469.6904736551446,
            "node": {
                "Conference": "InfoVis",
                "Year": "1995",
                "PaperTitle": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
                "PaperDOI": "10.1109/INFVIS.1995.528686",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1995.528686",
                "Firstpage": "51",
                "Lastpage": "58",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
                "AuthorNames": "Wise, J.A.;Thomas, J.J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;",
                "AuthorIDs": "37358036500;37273308900;37352135600;37352136200;37352134600;37352142300;37352143800",
                "Dedupedauthornames": "Wise, J.A.;Thomas, J.;Pennock, K.;Lantrip, D.;Pottier, M.;Schur, A.;Crow, V.",
                "References": "10.1109/VISUAL.1993.398863",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "528686",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398863"
            }
        },
        {
            "name": "Gross, M.",
            "value": 156,
            "numPapers": 36,
            "cluster": "3",
            "index": 644,
            "weight": 4,
            "x": 296.2581603131367,
            "y": 577.6813678437949,
            "px": 311.111868420886,
            "py": 564.9364135082039,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Efficient simplification of point-sampled surfaces",
                "PaperDOI": "10.1109/VISUAL.2002.1183771",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183771",
                "Firstpage": "163",
                "Lastpage": "170",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.",
                "AuthorNames": "Pauly, M.;Gross, Markus;Kobbelt, L.P.",
                "FirstAuthorAffiliation": "Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;",
                "AuthorIDs": "37283033000;37275694700;37266790600",
                "Dedupedauthornames": "Pauly, M.;Gross, M.;Kobbelt, L.P.",
                "References": "10.1109/VISUAL.2001.964503;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2001.964502;10.1109/VISUAL.2001.964489;10.1109/VISUAL.2000.885722",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "1183771",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964541_08;809896;964502;964489;885722"
            }
        },
        {
            "name": "Staadt, O.",
            "value": 65,
            "numPapers": 4,
            "cluster": "3",
            "index": 645,
            "weight": 2,
            "x": 365.86839097502184,
            "y": 811.9290287070239,
            "px": 358.85858794039257,
            "py": 797.1129356737156,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Progressive tetrahedralizations",
                "PaperDOI": "10.1109/VISUAL.1998.745329",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745329",
                "Firstpage": "397",
                "Lastpage": "402",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The paper describes some fundamental issues for robust implementations of progressively refined tetrahedralizations generated through sequences of edge collapses. We address the definition of appropriate cost functions and explain on various tests which are necessary to preserve the consistency of the mesh when collapsing edges. Although considered a special case of progressive simplicial complexes (J. Popovic and H. Hoppe, 1997), the results of our method are of high practical importance and can be used in many different applications, such as finite element meshing, scattered data interpolation, or rendering of unstructured volume data.",
                "AuthorNames": "Staadt, O.G.;Gross, M.H.",
                "FirstAuthorAffiliation": "Comput. Graphics Res. Group, Fed.. Inst. of Technol., Zurich, Switzerland|c|;",
                "AuthorIDs": "37355334600;37275694700",
                "Dedupedauthornames": "Staadt, O.;Gross, M.",
                "References": "10.1109/VISUAL.1997.663907;10.1109/VISUAL.1997.663901;10.1109/VISUAL.1997.663883",
                "AuthorKeywords": "mesh simplification, multiresolution, level-of-detail, unstructured meshes, mesh generation",
                "IEEEXPLOREArticleNumberdeprecated": "745329",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663907;663901;663883"
            }
        },
        {
            "name": "Cignoni, P.",
            "value": 103,
            "numPapers": 26,
            "cluster": "3",
            "index": 646,
            "weight": 1,
            "x": 720.5586609162367,
            "y": 529.9486049502265,
            "px": 680.9890772569189,
            "py": 509.89647952943267,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization",
                "PaperDOI": "10.1109/TVCG.2006.115",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.115",
                "Firstpage": "1237",
                "Lastpage": "1244",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 106 atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time.",
                "AuthorNames": "Tarini, M.;Cignoni, P.;Montani, C.",
                "FirstAuthorAffiliation": "Universita dell''Insubria, Varese|c|;;",
                "AuthorIDs": "37591264000;37265783400;37265786500",
                "Dedupedauthornames": "Tarini, M.;Cignoni, P.;Montani, C.",
                "References": "10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250394",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "4015487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885694;1250394"
            }
        },
        {
            "name": "Costanza, D.",
            "value": 34,
            "numPapers": 4,
            "cluster": "3",
            "index": 647,
            "weight": 1,
            "x": 663.9747412007349,
            "y": 340.29682252397316,
            "px": 633.2916488616421,
            "py": 352.6088816867394,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Simplification of tetrahedral meshes with accurate error evaluation",
                "PaperDOI": "10.1109/VISUAL.2000.885680",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885680",
                "Firstpage": "85",
                "Lastpage": "92",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.",
                "AuthorNames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "FirstAuthorAffiliation": "Ist. Sci. e Tecnol. dell''Inf., CNR, Pisa, Italy|c|;;;;",
                "AuthorIDs": "37265783400;38015245400;37265786500;37333160000;37270887900",
                "Dedupedauthornames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "References": "10.1109/VISUAL.1998.745315;10.1109/VISUAL.1997.663907;10.1109/VISUAL.1998.745329;10.1109/VISUAL.1998.745312",
                "AuthorKeywords": "Simplicial Complexes, Mesh Simplification,\nVolume Visualization, Unstructured Grids",
                "IEEEXPLOREArticleNumberdeprecated": "885680",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745315;663907;745329;745312"
            }
        },
        {
            "name": "Montani, C.",
            "value": 97,
            "numPapers": 8,
            "cluster": "3",
            "index": 648,
            "weight": 1,
            "x": 422.08081976969913,
            "y": 359.8108950124162,
            "px": 428.1424447211085,
            "py": 381.5516711077918,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization",
                "PaperDOI": "10.1109/TVCG.2006.115",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.115",
                "Firstpage": "1237",
                "Lastpage": "1244",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 106 atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time.",
                "AuthorNames": "Tarini, M.;Cignoni, P.;Montani, C.",
                "FirstAuthorAffiliation": "Universita dell''Insubria, Varese|c|;;",
                "AuthorIDs": "37591264000;37265783400;37265786500",
                "Dedupedauthornames": "Tarini, M.;Cignoni, P.;Montani, C.",
                "References": "10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250394",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "4015487",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885694;1250394"
            }
        },
        {
            "name": "Rocchini, C.",
            "value": 45,
            "numPapers": 5,
            "cluster": "3",
            "index": 649,
            "weight": 1,
            "x": 574.7975384686342,
            "y": 604.9148347113976,
            "px": 543.5512192316747,
            "py": 570.7712216910772,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Simplification of tetrahedral meshes with accurate error evaluation",
                "PaperDOI": "10.1109/VISUAL.2000.885680",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885680",
                "Firstpage": "85",
                "Lastpage": "92",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.",
                "AuthorNames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "FirstAuthorAffiliation": "Ist. Sci. e Tecnol. dell''Inf., CNR, Pisa, Italy|c|;;;;",
                "AuthorIDs": "37265783400;38015245400;37265786500;37333160000;37270887900",
                "Dedupedauthornames": "Cignoni, P.;Costanza, D.;Montani, C.;Rocchini, C.;Scopigno, R.",
                "References": "10.1109/VISUAL.1998.745315;10.1109/VISUAL.1997.663907;10.1109/VISUAL.1998.745329;10.1109/VISUAL.1998.745312",
                "AuthorKeywords": "Simplicial Complexes, Mesh Simplification,\nVolume Visualization, Unstructured Grids",
                "IEEEXPLOREArticleNumberdeprecated": "885680",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745315;663907;745329;745312"
            }
        },
        {
            "name": "Scopigno, R.",
            "value": 89,
            "numPapers": 25,
            "cluster": "3",
            "index": 650,
            "weight": 1,
            "x": 678.9171625719259,
            "y": 439.5337064216786,
            "px": 642.6010808785413,
            "py": 438.3062205251119,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Optimal global conformal surface parameterization",
                "PaperDOI": "10.1109/VISUAL.2004.75",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.75",
                "Firstpage": "267",
                "Lastpage": "274",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "All orientable metric surfaces are Riemann surfaces and admit global conformal parameterizations. Riemann surface structure is a fundamental structure and governs many natural physical phenomena, such as heat diffusion and electro-magnetic fields on the surface. A good parameterization is crucial for simulation and visualization. This paper provides an explicit method for finding optimal global conformal parameterizations of arbitrary surfaces. It relies on certain holomorphic differential forms and conformal mappings from differential geometry and Riemann surface theories. Algorithms are developed to modify topology, locate zero points, and determine cohomology types of differential forms. The implementation is based on a finite dimensional optimization method. The optimal parameterization is intrinsic to the geometry, preserves angular structure, and can play an important role in various applications including texture mapping, remeshing, morphing and simulation. The method is demonstrated by visualizing the Riemann surface structure of real surfaces represented as triangle meshes.",
                "AuthorNames": "Miao Jin;Yalin Wang;Shing-Tung Yau;Gu, X.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;",
                "AuthorIDs": "37279448300;37281424800;37272109300;37276603700",
                "Dedupedauthornames": "Miao Jin;Yalin Wang;Shing-Tung Yau;Gu, X.",
                "References": "",
                "AuthorKeywords": "Computational geometry and object modeling, Curve / surface / solid and object representations, Surface parameterization",
                "IEEEXPLOREArticleNumberdeprecated": "1372206",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Gerstner, T.",
            "value": 46,
            "numPapers": 9,
            "cluster": "3",
            "index": 651,
            "weight": 2,
            "x": 352.4757718760249,
            "y": 642.2300469518221,
            "px": 368.9072349846863,
            "py": 623.6819613299408,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Topology preserving and controlled topology simplifying multiresolution isosurface extraction",
                "PaperDOI": "10.1109/VISUAL.2000.885703",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885703",
                "Firstpage": "259",
                "Lastpage": "266",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Multiresolution methods are becoming increasingly important tools for the interactive visualization of very large data sets. Multiresolution isosurface visualization allows the user to explore volume data using simplified and coarse representations of the isosurface for overview images, and finer resolution in areas of high interest or when zooming into the data. Ideally, a coarse isosurface should have the same topological structure as the original. The topological genus of the isosurface is one important property which is often neglected in multiresolution algorithms. This results in uncontrolled topological changes which can occur whenever the level-of-detail is changed. The scope of this paper is to propose an efficient technique which allows preservation of topology as well as controlled topology simplification in multiresolution isosurface extraction.",
                "AuthorNames": "Gerstner, T.;Pajarola, R.",
                "FirstAuthorAffiliation": "Dept. of Appl. Math., Bonn Univ., Germany|c|;",
                "AuthorIDs": "38015261400;37282193800",
                "Dedupedauthornames": "Gerstner, T.;Pajarola, R.",
                "References": "10.1109/VISUAL.1996.568127;10.1109/VISUAL.1997.663907;10.1109/VISUAL.1997.663909;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1994.346334;10.1109/VISUAL.1997.663869",
                "AuthorKeywords": "tetrahedral grid refinement, implicit surface approximation, level-of-detail, topological genus, critical points",
                "IEEEXPLOREArticleNumberdeprecated": "885703",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568127;663907;663909;745300;346334;663869"
            }
        },
        {
            "name": "Pajarola, R.",
            "value": 108,
            "numPapers": 36,
            "cluster": "3",
            "index": 652,
            "weight": 3,
            "x": 294.939302686705,
            "y": 671.7504742639401,
            "px": 310.96567511275475,
            "py": 649.1207778335013,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Extinction-Based Shading and Illumination in GPU Volume Ray-Casting",
                "PaperDOI": "10.1109/TVCG.2011.198",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.198",
                "Firstpage": "1795",
                "Lastpage": "1802",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Direct volume rendering has become a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and color bleeding effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering is based on a very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i.e. soft directional shadows, ambient occlusion and color bleeding. We will show how this can be achieved and how it can be implemented on the GPU.",
                "AuthorNames": "Schlegel, P.;Makhinya, M.;Pajarola, R.",
                "FirstAuthorAffiliation": "Dept. of Inf., Univ. of Zurich, Zurich, Switzerland|c|;;",
                "AuthorIDs": "38026738000;37695663200;37282193800",
                "Dedupedauthornames": "Schlegel, P.;Makhinya, M.;Pajarola, R.",
                "References": "10.1109/TVCG.2007.70555;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2003.1250384",
                "AuthorKeywords": "Volume Rendering, Shadows, Ambient Occlusion, GPU Ray-Casting, Exponential Extinction",
                "IEEEXPLOREArticleNumberdeprecated": "6064942",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376160;1183764;1250384"
            }
        },
        {
            "name": "Chandak, A.",
            "value": 0,
            "numPapers": 5,
            "cluster": "3",
            "index": 653,
            "weight": 5,
            "x": 174.27934830385058,
            "y": 638.7753946827978,
            "px": 170.57932820802088,
            "py": 630.8191657153566,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Listener-based Analysis of Surface Importance for Acoustic Metrics",
                "PaperDOI": "10.1109/TVCG.2007.70575",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70575",
                "Firstpage": "1680",
                "Lastpage": "1687",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D50) and clarity (C50) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C50) values at listener positions throughout the room.",
                "AuthorNames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "FirstAuthorAffiliation": "IRTG Kaiserslautern, Kaiserslautern|c|;;;;",
                "AuthorIDs": "37838754300;37282727900;;37282573700;37282578800",
                "Dedupedauthornames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "References": "10.1109/TVCG.2006.125;10.1109/VISUAL.2005.1532790",
                "AuthorKeywords": "Sound analytics, Applications of Visualization, Room Acoustics, Phonon Tracing, Acoustic Metric",
                "IEEEXPLOREArticleNumberdeprecated": "4376202",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015479;1532790"
            }
        },
        {
            "name": "Deines, E.",
            "value": 67,
            "numPapers": 14,
            "cluster": "3",
            "index": 654,
            "weight": 5,
            "x": 327.3488186208444,
            "y": 644.4754928053829,
            "px": 351.19292263869494,
            "py": 627.3027627221396,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Visualization of intricate flow structures for vortex breakdown analysis",
                "PaperDOI": "10.1109/VISUAL.2004.113",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.113",
                "Firstpage": "187",
                "Lastpage": "194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Vortex breakdowns and flow recirculation are essential phenomena in aeronautics where they appear as a limiting factor in the design of modern aircrafts. Because of the inherent intricacy of these features, standard flow visualization techniques typically yield cluttered depictions. The paper addresses the challenges raised by the visual exploration and validation of two CFD simulations involving vortex breakdown. To permit accurate and insightful visualization we propose a new approach that unfolds the geometry of the breakdown region by letting a plane travel through the structure along a curve. We track the continuous evolution of the associated projected vector field using the theoretical framework of parametric topology. To improve the understanding of the spatial relationship between the resulting curves and lines we use direct volume rendering and multidimensional transfer functions for the display of flow-derived scalar quantities. This enriches the visualization and provides an intuitive context for the extracted topological information. Our results offer clear, synthetic depictions that permit new insight into the structural properties of vortex breakdowns.",
                "AuthorNames": "Tricoche, X.;Garth, C.;Kindlmann, G.;Deines, E.;Scheuermann, G.;Ruetten, M.;Hansen, C.",
                "FirstAuthorAffiliation": "Utah Univ., Salt Lake City, UT, USA|c|;;;;;;",
                "AuthorIDs": "37282575100;37282573700;37282742400;37282727900;37282574800;37282728900;37266777200",
                "Dedupedauthornames": "Tricoche, X.;Garth, C.;Kindlmann, G.;Deines, E.;Scheuermann, G.;Ruetten, M.;Hansen, C.",
                "References": "10.1109/VISUAL.2001.964519;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2001.964489;10.1109/VISUAL.1993.398875;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1994.346314",
                "AuthorKeywords": "flow visualization, vortex analysis, parametric topology, cutting planes, volume rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1372196",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964519;745296;175773;663910;809896;1250414;1250376;964489;398875;175789;346314"
            }
        },
        {
            "name": "Lauterbach, C.",
            "value": 0,
            "numPapers": 5,
            "cluster": "3",
            "index": 655,
            "weight": 5,
            "x": 521.89307649396,
            "y": 570.1677973954841,
            "px": 532.0713893578107,
            "py": 557.9480180724142,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Listener-based Analysis of Surface Importance for Acoustic Metrics",
                "PaperDOI": "10.1109/TVCG.2007.70575",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70575",
                "Firstpage": "1680",
                "Lastpage": "1687",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D50) and clarity (C50) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C50) values at listener positions throughout the room.",
                "AuthorNames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "FirstAuthorAffiliation": "IRTG Kaiserslautern, Kaiserslautern|c|;;;;",
                "AuthorIDs": "37838754300;37282727900;;37282573700;37282578800",
                "Dedupedauthornames": "Michel, F.;Deines, E.;Hering-Bertram, M.;Garth, C.;Hagen, H.",
                "References": "10.1109/TVCG.2006.125;10.1109/VISUAL.2005.1532790",
                "AuthorKeywords": "Sound analytics, Applications of Visualization, Room Acoustics, Phonon Tracing, Acoustic Metric",
                "IEEEXPLOREArticleNumberdeprecated": "4376202",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015479;1532790"
            }
        },
        {
            "name": "Manocha, D.",
            "value": 43,
            "numPapers": 27,
            "cluster": "3",
            "index": 656,
            "weight": 7,
            "x": 336.90129016716037,
            "y": 520.8771911856111,
            "px": 332.9677935721208,
            "py": 522.6264718753932,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Feature-sensitive subdivision and isosurface reconstruction",
                "PaperDOI": "10.1109/VISUAL.2003.1250360",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250360",
                "Firstpage": "99",
                "Lastpage": "106",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present improved subdivision and isosurface reconstruction algorithms for polygonizing implicit surfaces and performing accurate geometric operations. Our improved reconstruction algorithm uses directed distance fields (Kobbelt et al., 2001) to detect multiple intersections along an edge, separates them into components and reconstructs an isosurface locally within each components using the dual contouring algorithm (Ju et al., 2002). It can reconstruct thin features without creating handles and results in improved surface extraction from volumetric data. Our subdivision algorithm takes into account sharp features that arise from intersecting surfaces or Boolean operations and generates an adaptive grid such that each voxel has at most one sharp feature. The subdivision algorithm is combined with our improved reconstruction algorithm to compute accurate polygonization of Boolean combinations or offsets of complex primitives that faithfully reconstruct the sharp features. We have applied these algorithms to polygonize complex CAD models designed using thousands of Boolean operations on curved primitives.",
                "AuthorNames": "Varadhan, G.;Shankar Krishnan;Kim, Y.J.;Manocha, D.",
                "FirstAuthorAffiliation": "North Carolina Univ., Chapel Hill, NC, USA|c|;;;",
                "AuthorIDs": "37267825100;37275776600;38185529300;37267825600",
                "Dedupedauthornames": "Varadhan, G.;Shankar Krishnan;Kim, Y.J.;Manocha, D.",
                "References": "10.1109/VISUAL.2001.964518;10.1109/VISUAL.1996.568127",
                "AuthorKeywords": "Implicit modeling, Boolean operations, Marching Cubes, Distance fields, Subdivision",
                "IEEEXPLOREArticleNumberdeprecated": "1250360",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964518;568127"
            }
        },
        {
            "name": "Bertram, M.",
            "value": 35,
            "numPapers": 9,
            "cluster": "3",
            "index": 657,
            "weight": 3,
            "x": 767.0866917496251,
            "y": 437.36989630726646,
            "px": 803.1820884024386,
            "py": 412.4343062960719,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Comparative Visualization for Wave-based and Geometric Acoustics",
                "PaperDOI": "10.1109/TVCG.2006.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.125",
                "Firstpage": "1173",
                "Lastpage": "1180",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects",
                "AuthorNames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "FirstAuthorAffiliation": "IRTG, Kaiserslautern|c|;;;;;;",
                "AuthorIDs": "37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100",
                "Dedupedauthornames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "References": "10.1109/VISUAL.2005.1532790",
                "AuthorKeywords": "Acoustic simulation, comparative visualization, ray tracing, finite element method, phonon map",
                "IEEEXPLOREArticleNumberdeprecated": "4015479",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532790"
            }
        },
        {
            "name": "Mohring, J.",
            "value": 33,
            "numPapers": 1,
            "cluster": "3",
            "index": 658,
            "weight": 3,
            "x": 437.1075128549062,
            "y": 508.57569877544057,
            "px": 442.0971501621493,
            "py": 490.02185990222665,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Comparative Visualization for Wave-based and Geometric Acoustics",
                "PaperDOI": "10.1109/TVCG.2006.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.125",
                "Firstpage": "1173",
                "Lastpage": "1180",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects",
                "AuthorNames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "FirstAuthorAffiliation": "IRTG, Kaiserslautern|c|;;;;;;",
                "AuthorIDs": "37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100",
                "Dedupedauthornames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "References": "10.1109/VISUAL.2005.1532790",
                "AuthorKeywords": "Acoustic simulation, comparative visualization, ray tracing, finite element method, phonon map",
                "IEEEXPLOREArticleNumberdeprecated": "4015479",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532790"
            }
        },
        {
            "name": "Jegorovs, J.",
            "value": 33,
            "numPapers": 1,
            "cluster": "3",
            "index": 659,
            "weight": 3,
            "x": 56.45750582648247,
            "y": 586.199671912592,
            "px": 83.09498074224112,
            "py": 567.4377802861479,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Comparative Visualization for Wave-based and Geometric Acoustics",
                "PaperDOI": "10.1109/TVCG.2006.125",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.125",
                "Firstpage": "1173",
                "Lastpage": "1180",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects",
                "AuthorNames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "FirstAuthorAffiliation": "IRTG, Kaiserslautern|c|;;;;;;",
                "AuthorIDs": "37282727900;37282067000;37543023400;37550794800;37838754300;37282578800;37283754100",
                "Dedupedauthornames": "Deines, E.;Bertram, M.;Mohring, J.;Jegorovs, J.;Michel, F.;Hagen, H.;Nielson, G.M.",
                "References": "10.1109/VISUAL.2005.1532790",
                "AuthorKeywords": "Acoustic simulation, comparative visualization, ray tracing, finite element method, phonon map",
                "IEEEXPLOREArticleNumberdeprecated": "4015479",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532790"
            }
        },
        {
            "name": "Joshi, A.",
            "value": 49,
            "numPapers": 19,
            "cluster": "2",
            "index": 660,
            "weight": 2,
            "x": 74.26958209428875,
            "y": 170.66980231899208,
            "px": 55.9980292959032,
            "py": 172.83335567083367,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Texture-based feature tracking for effective time-varying data visualization",
                "PaperDOI": "10.1109/TVCG.2007.70599",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70599",
                "Firstpage": "1472",
                "Lastpage": "1479",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.",
                "AuthorNames": "Caban, J.J.;Joshi, A.;Rheingans, P.",
                "FirstAuthorAffiliation": "Univ. of Maryland Baltimore County, Baltimore|c|;;",
                "AuthorIDs": ";37278517400;37282292000",
                "Dedupedauthornames": "Caban, J.J.;Joshi, A.;Rheingans, P.",
                "References": "10.1109/VISUAL.2003.1250374;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1996.567807",
                "AuthorKeywords": "Feature tracking, texture-based analysis, flow visualization, time-varying data, visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4376176",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250374;885694;745288;567807"
            }
        },
        {
            "name": "Schneider, D.",
            "value": 65,
            "numPapers": 18,
            "cluster": "3",
            "index": 661,
            "weight": 1,
            "x": 369.5927416332794,
            "y": 605.6798185855492,
            "px": 384.3473586737921,
            "py": 556.5258863363582,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization",
                "PaperDOI": "10.1109/TVCG.2008.143",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.143",
                "Firstpage": "1475",
                "Lastpage": "1482",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.",
                "AuthorNames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "FirstAuthorAffiliation": "Leipzig Univ., Leipzig|c|;;;;",
                "AuthorIDs": "37869538100;37565763400;37282624500;37403333700;37282574800",
                "Dedupedauthornames": "Schneider, D.;Wiebel, A.;Carr, H.;Hlawitschka, M.;Scheuermann, G.",
                "References": "10.1109/TVCG.2006.164;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2004.107;10.1109/TVCG.2007.70615;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2006.165;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2007.70519;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2005.1532835",
                "AuthorKeywords": "Scalar topology, comparative visualization, contour tree, largest contours, flow visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4658165",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4015446;964519;1372214;4376165;1532830;4015447;1372235;1250374;4376167;1532848;663875;1532835"
            }
        },
        {
            "name": "Globus, A.",
            "value": 121,
            "numPapers": 2,
            "cluster": "3",
            "index": 662,
            "weight": 3,
            "x": 133.1932711910131,
            "y": 582.1228317372617,
            "px": 167.99665086807593,
            "py": 570.7217308755335,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "A tool for visualizing the topology of three-dimensional vector fields",
                "PaperDOI": "10.1109/VISUAL.1991.175773",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175773",
                "Firstpage": "33",
                "Lastpage": "40, 408",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 33 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.",
                "AuthorNames": "Globus, A.;Levit, C.;Lasinski, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37377256900;37671515100;37671524000",
                "Dedupedauthornames": "Globus, A.;Levit, C.;Lasinski, T.",
                "References": "10.1109/VISUAL.1990.146360;10.1109/VISUAL.1990.146359",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175773",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146360;146359"
            }
        },
        {
            "name": "Levit, C.",
            "value": 144,
            "numPapers": 2,
            "cluster": "3",
            "index": 663,
            "weight": 3,
            "x": 90.4807627180226,
            "y": 640.1723038842578,
            "px": 127.75474471834924,
            "py": 617.3542140582241,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "A tool for visualizing the topology of three-dimensional vector fields",
                "PaperDOI": "10.1109/VISUAL.1991.175773",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175773",
                "Firstpage": "33",
                "Lastpage": "40, 408",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 33 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.",
                "AuthorNames": "Globus, A.;Levit, C.;Lasinski, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37377256900;37671515100;37671524000",
                "Dedupedauthornames": "Globus, A.;Levit, C.;Lasinski, T.",
                "References": "10.1109/VISUAL.1990.146360;10.1109/VISUAL.1990.146359",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175773",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146360;146359"
            }
        },
        {
            "name": "Lasinski, T.",
            "value": 84,
            "numPapers": 2,
            "cluster": "3",
            "index": 664,
            "weight": 2,
            "x": 255.43050314974872,
            "y": 609.2599652731623,
            "px": 287.34925769817465,
            "py": 588.3338212755056,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "A tool for visualizing the topology of three-dimensional vector fields",
                "PaperDOI": "10.1109/VISUAL.1991.175773",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175773",
                "Firstpage": "33",
                "Lastpage": "40, 408",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A description is given of a software system, TOPO, that numerically analyzes and graphically displays topological aspects of a three-dimensional vector field, v, to produce a single, relatively simple picture that characterizes v. The topology of v considered consists of its critical points (where v=0), their invariant manifolds, and the integral curves connecting these invariant manifolds. The field in the neighborhood of each critical point is approximated by the Taylor expansion. The coefficients of the first nonzero term of the Taylor expansion around a critical point are the 33 matrix ?v. Critical points are classified by examining ?v's eigenvalues. The eigenvectors of ?v span the invariant manifolds of the linearized field around a critical point. Curves integrated from initial points on the eigenvectors a small distance from a critical point connect with other critical points (or the boundary) to complete the topology. One class of critical surfaces that is important in computational fluid dynamics is analyzed.",
                "AuthorNames": "Globus, A.;Levit, C.;Lasinski, T.",
                "FirstAuthorAffiliation": ";;",
                "AuthorIDs": "37377256900;37671515100;37671524000",
                "Dedupedauthornames": "Globus, A.;Levit, C.;Lasinski, T.",
                "References": "10.1109/VISUAL.1990.146360;10.1109/VISUAL.1990.146359",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175773",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146360;146359"
            }
        },
        {
            "name": "Ka-Kei Chung",
            "value": 11,
            "numPapers": 22,
            "cluster": "2",
            "index": 665,
            "weight": 1,
            "x": -64.0997994532113,
            "y": -780.4676628916482,
            "px": -42.460041535825724,
            "py": -668.5237796178862,
            "node": {
                "Conference": "Vis",
                "Year": "2009",
                "PaperTitle": "Interactive Visual Optimization and Analysis for RfiD Benchmarking",
                "PaperDOI": "10.1109/TVCG.2009.156",
                "Link": "http://dx.doi.org/10.1109/TVCG.2009.156",
                "Firstpage": "1335",
                "Lastpage": "1342",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.",
                "AuthorNames": "Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Cheung, S.C.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;",
                "AuthorIDs": "37407308300;37406959900;37272637300;37403856700;37275216500",
                "Dedupedauthornames": "Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Cheung, S.C.",
                "References": "10.1109/TVCG.2008.131;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2004.2",
                "AuthorKeywords": "RfiD Visualization, Visual analytics, Visual Optimization",
                "IEEEXPLOREArticleNumberdeprecated": "5290746",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658160;146402;4376143;1532141;567800;1382890"
            }
        },
        {
            "name": "Termeer, M.",
            "value": 38,
            "numPapers": 6,
            "cluster": "2",
            "index": 666,
            "weight": 1,
            "x": 95.93782575818118,
            "y": 1635.0745310000082,
            "px": 95.13448369949813,
            "py": 1485.7732164143292,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "Firstpage": "1632",
                "Lastpage": "1639",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "References": "10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2006.152;10.1109/VISUAL.2004.104",
                "AuthorKeywords": "Cardiac MRI, late enhancement, viability, bull's eye plot",
                "IEEEXPLOREArticleNumberdeprecated": "4376196",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Bescos, J.O.",
            "value": 43,
            "numPapers": 10,
            "cluster": "2",
            "index": 667,
            "weight": 1,
            "x": 495.7358720667608,
            "y": 1703.9900141182682,
            "px": 453.14807665513933,
            "py": 1549.404072707049,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "Firstpage": "1632",
                "Lastpage": "1639",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "References": "10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2006.152;10.1109/VISUAL.2004.104",
                "AuthorKeywords": "Cardiac MRI, late enhancement, viability, bull's eye plot",
                "IEEEXPLOREArticleNumberdeprecated": "4376196",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Gerritsen, F.",
            "value": 45,
            "numPapers": 10,
            "cluster": "2",
            "index": 668,
            "weight": 1,
            "x": 3.605965819598257,
            "y": 359.1796274603096,
            "px": 25.51440836500044,
            "py": 320.9142376858512,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "CoViCAD: Comprehensive Visualization of Coronary Artery Disease",
                "PaperDOI": "10.1109/TVCG.2007.70550",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70550",
                "Firstpage": "1632",
                "Lastpage": "1639",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",
                "AuthorNames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, M.E.",
                "FirstAuthorAffiliation": "Vienna Univ. of Technol., Vienna|c|;;;;;",
                "AuthorIDs": "37869997400;;37374875300;37282551500;37374887400;",
                "Dedupedauthornames": "Termeer, M.;Bescos, J.O.;Breeuwer, M.;Vilanova, A.;Gerritsen, F.;Groller, E.",
                "References": "10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2006.152;10.1109/VISUAL.2004.104",
                "AuthorKeywords": "Cardiac MRI, late enhancement, viability, bull's eye plot",
                "IEEEXPLOREArticleNumberdeprecated": "4376196",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250386;1183754;4015449;1372221"
            }
        },
        {
            "name": "Hongwei Li",
            "value": 25,
            "numPapers": 25,
            "cluster": "7",
            "index": 669,
            "weight": 2,
            "x": 1494.3978573754907,
            "y": 537.9073468009208,
            "px": 1480.6196351549588,
            "py": 525.6069217878287,
            "node": {
                "Conference": "Vis",
                "Year": "2007",
                "PaperTitle": "Visualizing Large-Scale Uncertainty in Astrophysical Data",
                "PaperDOI": "10.1109/TVCG.2007.70530",
                "Link": "http://dx.doi.org/10.1109/TVCG.2007.70530",
                "Firstpage": "1640",
                "Lastpage": "1647",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.",
                "AuthorNames": "Hongwei Li;Chi-Wing Fu;Yinggang Li;Hanson, A.J.",
                "FirstAuthorAffiliation": "Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;;",
                "AuthorIDs": "37881121400;;37835045200;",
                "Dedupedauthornames": "Hongwei Li;Chi-Wing Fu;Yinggang Li;Hanson, A.J.",
                "References": "10.1109/VISUAL.2000.885679;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2006.155;10.1109/TVCG.2006.176;10.1109/VISUAL.2004.25;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/VISUAL.2002.1183824;10.1109/VISUAL.1996.568105;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.2005.1532803;10.1109/VISUAL.2004.18",
                "AuthorKeywords": "Uncertainty visualization, large spatial scale, interstellar data, astronomy",
                "IEEEXPLOREArticleNumberdeprecated": "4376197",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885679;1183769;1250404;1532807;4015476;4015458;1372187;1532853;568116;1183824;568105;1173145;1532803;1372183"
            }
        },
        {
            "name": "Thompson, D.",
            "value": 72,
            "numPapers": 23,
            "cluster": "3",
            "index": 670,
            "weight": 2,
            "x": 62.053751953322205,
            "y": 1266.3028224451464,
            "px": 17.417187944447534,
            "py": 1254.1453485670766,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Vortex Visualization for Practical Engineering Applications",
                "PaperDOI": "10.1109/TVCG.2006.201",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.201",
                "Firstpage": "957",
                "Lastpage": "964",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability",
                "AuthorNames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Raghu Machiraju",
                "FirstAuthorAffiliation": "Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;",
                "AuthorIDs": ";37826582200;;37269516700",
                "Dedupedauthornames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.",
                "References": "10.1109/VISUAL.1997.663894;10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1999.809896",
                "AuthorKeywords": "Vortex detection, vortex visualization, feature mining",
                "IEEEXPLOREArticleNumberdeprecated": "4015452",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663894;1183789;1532830;745296;745288;809896"
            }
        },
        {
            "name": "Glatter, M.",
            "value": 16,
            "numPapers": 15,
            "cluster": "2",
            "index": 671,
            "weight": 1,
            "x": 286.89227040108057,
            "y": -300.61078323670864,
            "px": 250.20958696886632,
            "py": -227.46202557304034,
            "node": {
                "Conference": "Vis",
                "Year": "2008",
                "PaperTitle": "Visualizing Temporal Patterns in Large Multivariate Data using Textual Pattern Matching",
                "PaperDOI": "10.1109/TVCG.2008.184",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.184",
                "Firstpage": "1467",
                "Lastpage": "1474",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.",
                "AuthorNames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "FirstAuthorAffiliation": "Univ. of Tennessee at Knoxville, Knoxville, TN|c|;;;;",
                "AuthorIDs": "37828700000;37281262900;37410066100;37672397100;37545504600",
                "Dedupedauthornames": "Glatter, M.;Huang, J.;Ahern, S.;Daniel, J.;Aidong Lu",
                "References": "10.1109/VISUAL.2003.1250402;10.1109/TVCG.2007.70600;10.1109/TVCG.2006.175;10.1109/VISUAL.2004.95;10.1109/TVCG.2007.70519;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2005.1532792",
                "AuthorKeywords": "Multivariate visualization, Time-varying, Uncertainty",
                "IEEEXPLOREArticleNumberdeprecated": "4658164",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250402;4376164;4015494;1372194;4376167;964519;1532792"
            }
        },
        {
            "name": "Wehrend, S.",
            "value": 54,
            "numPapers": 0,
            "cluster": "0",
            "index": 672,
            "weight": 1,
            "x": 524.4969921698837,
            "y": -1123.0408448789633,
            "px": 508.07713025502835,
            "py": -973.0498616609865,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "A problem-oriented classification of visualization techniques",
                "PaperDOI": "10.1109/VISUAL.1990.146375",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146375",
                "Firstpage": "139",
                "Lastpage": "143, 469",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods",
                "AuthorNames": "Wehrend, S.;Lewis, C.",
                "FirstAuthorAffiliation": "Colorado Univ., Boulder, CO, USA|c|;",
                "AuthorIDs": "38222492800;37380191400",
                "Dedupedauthornames": "Wehrend, S.;Lewis, C.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146375",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Lewis, C.",
            "value": 54,
            "numPapers": 0,
            "cluster": "0",
            "index": 673,
            "weight": 1,
            "x": 843.1447741895568,
            "y": -1175.9157635561794,
            "px": 793.6937978976175,
            "py": -1022.6600823610016,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "A problem-oriented classification of visualization techniques",
                "PaperDOI": "10.1109/VISUAL.1990.146375",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146375",
                "Firstpage": "139",
                "Lastpage": "143, 469",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods",
                "AuthorNames": "Wehrend, S.;Lewis, C.",
                "FirstAuthorAffiliation": "Colorado Univ., Boulder, CO, USA|c|;",
                "AuthorIDs": "38222492800;37380191400",
                "Dedupedauthornames": "Wehrend, S.;Lewis, C.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146375",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "North, S.C.",
            "value": 105,
            "numPapers": 19,
            "cluster": "5",
            "index": 674,
            "weight": 1,
            "x": 788.3685495235499,
            "y": -1246.0425626420101,
            "px": 801.4859910397552,
            "py": -1087.2708315190366,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Topological Fisheye Views for Visualizing Large Graphs",
                "PaperDOI": "10.1109/INFVIS.2004.66",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.66",
                "Firstpage": "175",
                "Lastpage": "182",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Graph drawing is a basic visualization tool. For graphs of up to hundreds of nodes and edges, there are many effective techniques available. At greater scale, data density and occlusion problems often negate its effectiveness. Conventional pan-and-zoom, and multiscale and geometric fisheye views are not fully satisfactory solutions to this problem. As an alternative, we describe a topological zooming method. It is based on the precomputation of a hierarchy of coarsened graphs, which are combined on the fly into renderings with the level of detail dependent on the distance from one or more foci. We also discuss a related distortion method that allows our technique to achieve constant information density displays",
                "AuthorNames": "Gansner, E.;Koren, Y.;North, S.",
                "FirstAuthorAffiliation": "AT&T Labs., NJ|c|;;",
                "AuthorIDs": "37299368000;37414256700;37372818600",
                "Dedupedauthornames": "Gansner, E.;Koren, Y.;North, S.C.",
                "References": "10.1109/INFVIS.1997.636718;10.1109/INFVIS.2003.1249011",
                "AuthorKeywords": "topological fisheye,large graph visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1382906",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636718;1249011"
            }
        },
        {
            "name": "Tsigas, P.",
            "value": 46,
            "numPapers": 16,
            "cluster": "5",
            "index": 675,
            "weight": 1,
            "x": 1268.6365754742028,
            "y": 247.0475275182395,
            "px": 1299.7461523748277,
            "py": 267.5605652282772,
            "node": {
                "Conference": "VAST",
                "Year": "2007",
                "PaperTitle": "DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data",
                "PaperDOI": "10.1109/VAST.2007.4389013",
                "Link": "http://dx.doi.org/10.1109/VAST.2007.4389013",
                "Firstpage": "187",
                "Lastpage": "194",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.",
                "AuthorNames": "Elmqvist, N.;Stasko, J.;Tsigas, P.",
                "FirstAuthorAffiliation": "Univ. Paris-Sud, Paris|c|;;",
                "AuthorIDs": "37295438200;37267736900;37295439000",
                "Dedupedauthornames": "Elmqvist, N.;Stasko, J.;Tsigas, P.",
                "References": "10.1109/INFVIS.2000.885086;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2003.1249026;10.1109/VAST.2006.261439;10.1109/INFVIS.2005.1532139;10.1109/VAST.2006.261424;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1997.636793;10.1109/VAST.2006.261422;10.1109/VAST.2006.261430;10.1109/INFVIS.2003.1249016;10.1109/VISUAL.1999.809866;10.1109/VISUAL.1990.146375",
                "AuthorKeywords": "Multivariate data, visual analytics, parallel coordinates, dynamic queries, iterative analysis, starplot, small multiples",
                "IEEEXPLOREArticleNumberdeprecated": "4389013",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885086;146386;175815;1249026;4035757;1532139;4035764;4035743;1532136;636793;4035763;4035747;1249016;809866;146375"
            }
        },
        {
            "name": "Hao, M.C.",
            "value": 64,
            "numPapers": 20,
            "cluster": "5",
            "index": 676,
            "weight": 1,
            "x": -74.94923547723374,
            "y": 919.3461812452218,
            "px": 30.975404940483152,
            "py": 847.866174829971,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Importance-driven visualization layouts for large time series data",
                "PaperDOI": "10.1109/INFVIS.2005.1532148",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532148",
                "Firstpage": "203",
                "Lastpage": "210",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm.",
                "AuthorNames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Schreck, T.",
                "FirstAuthorAffiliation": "Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;",
                "AuthorIDs": "37274264300;37275646700;37283138700;37282557600",
                "Dedupedauthornames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Schreck, T.",
                "References": "10.1109/INFVIS.1999.801867;10.1109/INFVIS.1999.801851;10.1109/VISUAL.1995.485140;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Information Visualization, Time Series, Space-Filling Layout Generation",
                "IEEEXPLOREArticleNumberdeprecated": "1532148",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801867;801851;485140;801860;885086"
            }
        },
        {
            "name": "Dayal, U.",
            "value": 105,
            "numPapers": 20,
            "cluster": "5",
            "index": 677,
            "weight": 1,
            "x": 1331.8252554202784,
            "y": 1808.0492903783725,
            "px": 1290.9585770345934,
            "py": 1652.8427768129363,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "Importance-driven visualization layouts for large time series data",
                "PaperDOI": "10.1109/INFVIS.2005.1532148",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532148",
                "Firstpage": "203",
                "Lastpage": "210",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Time series are an important type of data with applications in virtually every aspect of the real world. Often a large number of time series have to be monitored and analyzed in parallel. Sets of time series may show intrinsic hierarchical relationships and varying degrees of importance among the individual time series. Effective techniques for visually analyzing large sets of time series should encode the relative importance and hierarchical ordering of the time series data by size and position, and should also provide a high degree of regularity in order to support comparability by the analyst. In this paper, we present a framework for visualizing large sets of time series. Based on the notion of inter time series importance relationships, we define a set of objective functions that space-filling layout schemes for time series data should obey. We develop an efficient algorithm addressing the identified problems by generating layouts that reflect hierarchy and importance based relationships in a regular layout with favorable aspect ratios. We apply our technique to a number of real world data sets including sales and stock data, and we compare our technique with an aspect ratio aware variant of the well known TreeMap algorithm. The examples show the advantages and practical usefulness of our layout algorithm.",
                "AuthorNames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Schreck, T.",
                "FirstAuthorAffiliation": "Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;",
                "AuthorIDs": "37274264300;37275646700;37283138700;37282557600",
                "Dedupedauthornames": "Hao, M.C.;Dayal, U.;Keim, D.A.;Schreck, T.",
                "References": "10.1109/INFVIS.1999.801867;10.1109/INFVIS.1999.801851;10.1109/VISUAL.1995.485140;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2000.885086",
                "AuthorKeywords": "Information Visualization, Time Series, Space-Filling Layout Generation",
                "IEEEXPLOREArticleNumberdeprecated": "1532148",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "801867;801851;485140;801860;885086"
            }
        },
        {
            "name": "Peitgen, H.-O.",
            "value": 74,
            "numPapers": 8,
            "cluster": "2",
            "index": 678,
            "weight": 1,
            "x": 604.7614651904164,
            "y": 621.6530157166383,
            "px": 542.142484105028,
            "py": 562.7934173123415,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Visualization and interaction techniques for the exploration of vascular structures",
                "PaperDOI": "10.1109/VISUAL.2001.964538",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964538",
                "Firstpage": "395",
                "Lastpage": "402",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.",
                "AuthorNames": "Hahn, H.K.;Preim, B.;Selle, D.;Peitgen, H.-O.",
                "FirstAuthorAffiliation": "MeVis-Center for Med. Diagnostic Syst., Bremen, Germany|c|;;;",
                "AuthorIDs": "37729702200;37424645300;37728223900;37442956900",
                "Dedupedauthornames": "Hahn, H.K.;Preim, B.;Selle, D.;Peitgen, H.-O.",
                "References": "10.1109/VISUAL.1997.663917",
                "AuthorKeywords": "vessel visualization, medical visualization, computer-assisted surgery",
                "IEEEXPLOREArticleNumberdeprecated": "964538",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663917"
            }
        },
        {
            "name": "Martin, A.R.",
            "value": 117,
            "numPapers": 3,
            "cluster": "5",
            "index": 679,
            "weight": 2,
            "x": 1092.024153419741,
            "y": 421.88637104794384,
            "px": 1130.0624862771142,
            "py": 422.32636175693585,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "High Dimensional Brushing for Interactive Exploration of Multivariate Data",
                "PaperDOI": "10.1109/VISUAL.1995.485139",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.485139",
                "Firstpage": "271",
                "Lastpage": "",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Brushing is an operation found in many data visualization systems. It is a mechanism for interactively selecting subsets of the data so that they may be highlighted, deleted, or masked. Traditionally, brushes have been defined in screen space via methods such as painting and rubberband rectangles. In this paper we describe the design of N-dimensional brushes which are defined in data space rather than screen space, and show how they have been integrated into XmdvTool, a visualization package for displaying multivariate data. Depending on the data display technique in use, brushes may be specified and manipulated via direct or indirect methods, and the specification may be demand-driven or data-driven. Various brush operations such as highlighting, linking, masking, moving average, and quantitative display have been developed to apply to the selected data. In addition, we have explored several new brush concepts, such as non-discrete brush boundaries, simultaneous display of multiple brushes, and creating composite brushes via logical operators. Preliminary experimental evaluation with test subjects supports the usefulness of N-dimensional brushes in data exploration tasks.",
                "AuthorNames": "Martin, A.R.;Ward, M.O.",
                "FirstAuthorAffiliation": ";",
                "AuthorIDs": "38149689900;37268441700",
                "Dedupedauthornames": "Martin, A.R.;Ward, M.O.",
                "References": "10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "485139",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146386;146402;346302"
            }
        },
        {
            "name": "House, D.",
            "value": 54,
            "numPapers": 10,
            "cluster": "5",
            "index": 680,
            "weight": 1,
            "x": 1920.8902730884017,
            "y": 747.3853250329147,
            "px": 1807.3935996937487,
            "py": 693.2512060912763,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Texturing of Layered Surfaces for Optimal Viewing",
                "PaperDOI": "10.1109/TVCG.2006.183",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.183",
                "Firstpage": "1125",
                "Lastpage": "1132",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a \"human in the loop\" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines",
                "AuthorNames": "Bair, A.S.;House, D.H.;Ware, C.",
                "FirstAuthorAffiliation": "Texas A&M Univ., College Station, TX|c|;;",
                "AuthorIDs": "37565577300;37284216700;37265850800",
                "Dedupedauthornames": "Bair, A.;House, D.;Ware, C.",
                "References": "10.1109/VISUAL.2005.1532782;10.1109/INFVIS.2003.1249022",
                "AuthorKeywords": "perception, optimal visualization, layered surfaces, human-in-the-loop, genetic algorithm, data mining, linear discriminant analysis, parallel coordinates, decision trees",
                "IEEEXPLOREArticleNumberdeprecated": "4015473",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1532782;1249022"
            }
        },
        {
            "name": "Feng Qiu",
            "value": 22,
            "numPapers": 12,
            "cluster": "2",
            "index": 681,
            "weight": 1,
            "x": -1908.5655565711515,
            "y": 1913.386669716709,
            "px": -1722.361649361383,
            "py": 1732.0785300913067,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "A Pipeline for Computer Aided Polyp Detection",
                "PaperDOI": "10.1109/TVCG.2006.112",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.112",
                "Firstpage": "861",
                "Lastpage": "868",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy",
                "AuthorNames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Stony Brook Univ., NY|c|;;",
                "AuthorIDs": "37277099300;37416126400;37268052800",
                "Dedupedauthornames": "Hong, W.;Feng Qiu;Kaufman, A.",
                "References": "10.1109/VISUAL.2001.964540;10.1109/VISUAL.2004.27;10.1109/VISUAL.1992.235231;10.1109/VISUAL.2003.1250384",
                "AuthorKeywords": "Computer Aided Detection, Virtual Colonoscopy, Texture Analysis, Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "4015440",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964540;1372236;235231;1250384"
            }
        },
        {
            "name": "Avila, R.",
            "value": 100,
            "numPapers": 14,
            "cluster": "2",
            "index": 682,
            "weight": 7,
            "x": 176.32818430346327,
            "y": 170.8286278752659,
            "px": 80.43576125885025,
            "py": 206.65933220556678,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "A haptic interaction method for volume visualization",
                "PaperDOI": "10.1109/VISUAL.1996.568108",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568108",
                "Firstpage": "197",
                "Lastpage": "204",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume visualization techniques typically provide support for visual exploration of data, however additional information can be conveyed by allowing a user to see as well as feel virtual objects. We present a haptic interaction method that is suitable for both volume visualization and modeling applications. Point contact forces are computed directly from the volume data and are consistent with the isosurface and volume rendering methods, providing a strong correspondence between visual and haptic feedback. Virtual tools are simulated by applying three-dimensional filters to some properties of the data within the extent of the tool, and interactive visual feedback rates are obtained by using an accelerated ray casting method. This haptic interaction method was implemented using a PHANToM haptic interface.",
                "AuthorNames": "Avila, R.S.;Sobierajski, L.M.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;",
                "AuthorIDs": "37323905300;37378488600",
                "Dedupedauthornames": "Avila, R.;Sobierajski, L.",
                "References": "10.1109/VISUAL.1995.480792",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "568108",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480792"
            }
        },
        {
            "name": "Sobierajski, L.",
            "value": 102,
            "numPapers": 16,
            "cluster": "2",
            "index": 683,
            "weight": 7,
            "x": 330.73503456366336,
            "y": 48.72039243195151,
            "px": 206.97576800246887,
            "py": 114.68027750108243,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "A haptic interaction method for volume visualization",
                "PaperDOI": "10.1109/VISUAL.1996.568108",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568108",
                "Firstpage": "197",
                "Lastpage": "204",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volume visualization techniques typically provide support for visual exploration of data, however additional information can be conveyed by allowing a user to see as well as feel virtual objects. We present a haptic interaction method that is suitable for both volume visualization and modeling applications. Point contact forces are computed directly from the volume data and are consistent with the isosurface and volume rendering methods, providing a strong correspondence between visual and haptic feedback. Virtual tools are simulated by applying three-dimensional filters to some properties of the data within the extent of the tool, and interactive visual feedback rates are obtained by using an accelerated ray casting method. This haptic interaction method was implemented using a PHANToM haptic interface.",
                "AuthorNames": "Avila, R.S.;Sobierajski, L.M.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;",
                "AuthorIDs": "37323905300;37378488600",
                "Dedupedauthornames": "Avila, R.;Sobierajski, L.",
                "References": "10.1109/VISUAL.1995.480792",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "568108",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480792"
            }
        },
        {
            "name": "Jankun-Kelly, T.J.",
            "value": 94,
            "numPapers": 33,
            "cluster": "2",
            "index": 684,
            "weight": 1,
            "x": 2528.6227212283598,
            "y": 750.03692406665,
            "px": 2278.2273720554676,
            "py": 687.2206175298292,
            "node": {
                "Conference": "InfoVis",
                "Year": "2003",
                "PaperTitle": "MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes",
                "PaperDOI": "10.1109/INFVIS.2003.1249009",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2003.1249009",
                "Firstpage": "59",
                "Lastpage": "66",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Graph and tree visualization techniques enable interactive exploration of complex relations while communicating topology. However, most existing techniques have not been designed for situations where visual information such as images is also present at each node and must be displayed. This paper presents MoireGraphs to address this need. MoireGraphs combine a new focus+context radial graph layout with a suite of interaction techniques (focus strength changing, radial rotation, level highlighting, secondary foci, animated transitions and node information) to assist in the exploration of graphs with visual nodes. The method is scalable to hundreds of displayed visual nodes.",
                "AuthorNames": "Jankun-Kelly, T.J.;Kwan-Liu Ma",
                "FirstAuthorAffiliation": "Mississippi State Univ., Starkville, MS, USA|c|;",
                "AuthorIDs": "38198374100;37275869400",
                "Dedupedauthornames": "Jankun-Kelly, T.J.;Kwan-Liu Ma",
                "References": "10.1109/INFVIS.2000.885091;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1996.559214;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173151",
                "AuthorKeywords": "information visualization, focus+context, radial graph layout, graph drawing",
                "IEEEXPLOREArticleNumberdeprecated": "1249009",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885091;636718;559214;963279;1173151"
            }
        },
        {
            "name": "Wei Qiao",
            "value": 51,
            "numPapers": 21,
            "cluster": "2",
            "index": 685,
            "weight": 2,
            "x": 294.20558704514406,
            "y": 354.1083608870927,
            "px": 272.2807548901239,
            "py": 334.52055303725086,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Projecting tetrahedra without rendering artifacts",
                "PaperDOI": "10.1109/VISUAL.2004.85",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.85",
                "Firstpage": "27",
                "Lastpage": "34",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Hardware-accelerated direct volume rendering of unstructured volumetric meshes is often based on tetrahedral cell projection, in particular, the projected tetrahedra (PT) algorithm and its variants. Unfortunately, even implementations of the most advanced variants of the PT algorithm are very prone to rendering artifacts. In this work, we identify linear interpolation in screen coordinates as a cause for significant rendering artifacts and implement the correct perspective interpolation for the PT algorithm with programmable graphics hardware. We also demonstrate how to use features of modern graphics hardware to improve the accuracy of the coloring of individual tetrahedra and the compositing of the resulting colors, in particular, by employing a logarithmic scale for the preintegrated color lookup table, using textures with high color resolution, rendering to floating-point color buffers, and alpha dithering. Combined with a correct visibility ordering, these techniques result in the first implementation of the PT algorithm without objectionable rendering artifacts. Apart from the important improvement in rendering quality, our approach also provides a test bed for different implementations of the PT algorithm that allows us to study the particular rendering artifacts introduced by these variants.",
                "AuthorNames": "Kraus, M.;Wei Qiao;Ebert, D.S.",
                "FirstAuthorAffiliation": "Purdue Univ., West Lafayette, IN, USA|c|;;",
                "AuthorIDs": "38367958800;37282552800;38472155300",
                "Dedupedauthornames": "Kraus, M.;Wei Qiao;Ebert, D.S.",
                "References": "10.1109/VISUAL.2000.885683;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2001.964514;10.1109/VISUAL.2003.1250384",
                "AuthorKeywords": "volume visualization, volume rendering, cell projection, projected tetrahedra, perspective interpolation, dithering, programmable graphics hardware",
                "IEEEXPLOREArticleNumberdeprecated": "1372176",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885683;1250390;964514;1250384"
            }
        },
        {
            "name": "Erlebacher, G.",
            "value": 74,
            "numPapers": 19,
            "cluster": "2",
            "index": 686,
            "weight": 5,
            "x": 186.4457722145364,
            "y": 193.38500461960388,
            "px": 165.1165395819884,
            "py": 183.18137272148869,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated texture advection for unsteady flow visualization",
                "PaperDOI": "10.1109/VISUAL.2000.885689",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885689",
                "Firstpage": "155",
                "Lastpage": "162",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.",
                "AuthorNames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;",
                "AuthorIDs": "37267249300;37324424400;37324426600",
                "Dedupedauthornames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "References": "10.1109/VISUAL.1995.480817;10.1109/VISUAL.1998.745324",
                "AuthorKeywords": "unsteady, vector field, pathlines, streakline, advection, texture, hardware, OpenGL",
                "IEEEXPLOREArticleNumberdeprecated": "885689",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480817;745324"
            }
        },
        {
            "name": "Zhang, H.",
            "value": 0,
            "numPapers": 14,
            "cluster": "2",
            "index": 687,
            "weight": 1,
            "x": -1665.7417467723312,
            "y": 184.34259457084158,
            "px": -1491.6593464520854,
            "py": 189.40422913673328,
            "node": {
                "Conference": "SciVis",
                "Year": "2013",
                "PaperTitle": "An Exploration Framework to Identify and Track Movement of Cloud Systems",
                "PaperDOI": "10.1109/TVCG.2013.131",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.131",
                "Firstpage": "2896",
                "Lastpage": "2905",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.",
                "AuthorNames": "Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA|c|;;",
                "AuthorIDs": ";;",
                "Dedupedauthornames": "Doraiswamy, H.;Natarajan, V.;Nanjundiah, R.S.",
                "References": "10.1109/TVCG.2007.70519;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250383",
                "AuthorKeywords": "Cloud clusters, tracking, computational topology, split tree, weather and climate simulations",
                "IEEEXPLOREArticleNumberdeprecated": "6634109",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4376167;4015464;1250383"
            }
        },
        {
            "name": "Parker, S.",
            "value": 67,
            "numPapers": 5,
            "cluster": "2",
            "index": 688,
            "weight": 1,
            "x": -587.5839872057329,
            "y": 1268.894925344782,
            "px": -516.6244703963965,
            "py": 1137.0729412167204,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "Firstpage": "233",
                "Lastpage": "238",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "References": "10.1109/VISUAL.1997.663888;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1998.745300",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "745713",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "Sloan, P.-P.",
            "value": 67,
            "numPapers": 5,
            "cluster": "2",
            "index": 689,
            "weight": 1,
            "x": 295.88614413395106,
            "y": 1509.091293553816,
            "px": 275.5875153179888,
            "py": 1350.3732463910924,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "Firstpage": "233",
                "Lastpage": "238",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "References": "10.1109/VISUAL.1997.663888;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1998.745300",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "745713",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "Shi, Q.",
            "value": 0,
            "numPapers": 11,
            "cluster": "2",
            "index": 690,
            "weight": 3,
            "x": 447.376604880942,
            "y": -25.56352636518885,
            "px": 455.54895018442664,
            "py": -30.442077652466907,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Interactive ray tracing for isosurface rendering",
                "PaperDOI": "10.1109/VISUAL.1998.745713",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745713",
                "Firstpage": "233",
                "Lastpage": "238",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",
                "AuthorNames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;",
                "AuthorIDs": "37361048100;37266808400;37282553200;37266777200;37373213900",
                "Dedupedauthornames": "Parker, S.;Shirley, P.;Livnat, Y.;Hansen, C.;Sloan, P.-P.",
                "References": "10.1109/VISUAL.1997.663888;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1998.745300",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "745713",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663888;346331;346320;485154;745300"
            }
        },
        {
            "name": "JaJa, J.",
            "value": 12,
            "numPapers": 25,
            "cluster": "2",
            "index": 691,
            "weight": 3,
            "x": 77.4944355516653,
            "y": 107.12643052440646,
            "px": 41.08533269917994,
            "py": 107.83260052444551,
            "node": {
                "Conference": "Vis",
                "Year": "2012",
                "PaperTitle": "Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms",
                "PaperDOI": "10.1109/TVCG.2012.231",
                "Link": "http://dx.doi.org/10.1109/TVCG.2012.231",
                "Firstpage": "2355",
                "Lastpage": "2363",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.",
                "AuthorNames": "Cheuk Yiu Ip;Varshney, A.;JaJa, J.",
                "FirstAuthorAffiliation": "Inst. for Adv. Comput. Studies, Univ. of Maryland, College Park, MD, USA|c|;;",
                "AuthorIDs": "37586231900;37282560200;37276261200",
                "Dedupedauthornames": "Cheuk Yiu Ip;Varshney, A.;JaJa, J.",
                "References": "10.1109/TVCG.2010.132;10.1109/TVCG.2009.185;10.1109/VISUAL.1999.809932;10.1109/VISUAL.2005.1532795;10.1109/VISUAL.2003.1250370;10.1109/TVCG.2010.208;10.1109/TVCG.2008.162;10.1109/TVCG.2011.248;10.1109/TVCG.2011.173;10.1109/TVCG.2006.174;10.1109/TVCG.2011.231;10.1109/TVCG.2007.70590;10.1109/TVCG.2009.197;10.1109/TVCG.2006.148",
                "AuthorKeywords": "Volume exploration, volume classification, normalized cut, Information-guided exploration",
                "IEEEXPLOREArticleNumberdeprecated": "6327240",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "5613460;5290763;809932;1532795;1250370;5613476;4658153;6064952;6064956;4015448;6064936;4376207;5290751;4015460"
            }
        },
        {
            "name": "Yoon, S.-E.",
            "value": 17,
            "numPapers": 17,
            "cluster": "3",
            "index": 692,
            "weight": 2,
            "x": 109.66426426299272,
            "y": 710.8844363515819,
            "px": 133.03375005797466,
            "py": 693.6354807869926,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Mesh Layouts for Block-Based Caches",
                "PaperDOI": "10.1109/TVCG.2006.162",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.162",
                "Firstpage": "1213",
                "Lastpage": "1220",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy",
                "AuthorNames": "Yoon, S.-E.;Lindstrom, P.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Berkeley, CA|c|;",
                "AuthorIDs": ";37269320000",
                "Dedupedauthornames": "Yoon, S.-E.;Lindstrom, P.",
                "References": "10.1109/VISUAL.2004.86;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1996.568125;10.1109/VISUAL.2005.1532800;10.1109/VISUAL.2002.1183794",
                "AuthorKeywords": "Mesh and graph layouts, cache-aware and cache-oblivious layouts, metrics for cache coherence, data locality",
                "IEEEXPLOREArticleNumberdeprecated": "4015484",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1372189;1250408;964533;568125;1532800;1183794"
            }
        },
        {
            "name": "Gao, J.",
            "value": 35,
            "numPapers": 34,
            "cluster": "2",
            "index": 693,
            "weight": 7,
            "x": 301.9940179680934,
            "y": 21.522149170514567,
            "px": 292.78101649362037,
            "py": 21.73526113078987,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Distributed data management for large volume visualization",
                "PaperDOI": "10.1109/VISUAL.2005.1532794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532794",
                "Firstpage": "183",
                "Lastpage": "189",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an \"enhanced time-space partitioning\" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.",
                "AuthorNames": "Gao, J.;Huang, J.;Johnson, C.R.;Atchley, S.",
                "FirstAuthorAffiliation": "Oak Ridge Nat. Lab., TN, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Gao, J.;Huang, J.;Johnson, C.R.;Atchley, S.",
                "References": "10.1109/VISUAL.2002.1183758;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2004.110;10.1109/VISUAL.2004.112;10.1109/VISUAL.1999.809879",
                "AuthorKeywords": "large data visualization, distributed storage, logistical networking, visibility culling, volume rendering, multiresolution rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1532794",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183758;1183757;809910;745300;1372191;1372192;809879"
            }
        },
        {
            "name": "Shareef, N.",
            "value": 29,
            "numPapers": 3,
            "cluster": "2",
            "index": 694,
            "weight": 1,
            "x": 145.6442271428449,
            "y": 1055.5314507242074,
            "px": 121.49432801057262,
            "py": 938.4473042289505,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "FastSplats: optimized splatting on rectilinear grids",
                "PaperDOI": "10.1109/VISUAL.2000.885698",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885698",
                "Firstpage": "219",
                "Lastpage": "226",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Splatting is widely applied in many areas, including volume, point-based and image-based rendering. Improvements to splatting, such as eliminating popping and color bleeding, occasion-based acceleration, post-rendering classification and shading, have all been recently accomplished. These improvements share a common need for efficient frame-buffer accesses. We present an optimized software splatting package, using a newly designed primitive, called FastSplat, to scan-convert footprints. Our approach does not use texture mapping hardware, but supports the whole pipeline in memory. In such an integrated pipeline, we are then able to study the optimization strategies and address image quality issues. While this research is meant for a study of the inherent trade-off of splatting, our renderer, purely in software, achieves 3- to 5-fold speedups over a top-end texture hardware implementation (for opaque data sets). We further propose a method of efficient occlusion culling using a summed area table of opacity. 3D solid texturing and bump mapping capabilities are demonstrated to show the flexibility of such an integrated rendering pipeline. A detailed numerical error analysis, in addition to the performance and storage issues, is also presented. Our approach requires low storage and uses simple operations. Thus, it is easily implementable in hardware.",
                "AuthorNames": "Huang, Jian;Mueller, K.;Shareef, N.;Crawfis, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;",
                "AuthorIDs": "37367805100;37273119700;37355552900;37284273900",
                "Dedupedauthornames": "Huang, J.;Mueller, K.;Shareef, N.;Crawfis, R.",
                "References": "10.1109/VISUAL.1999.809909;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1999.809872",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885698",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809909;398877;809872"
            }
        },
        {
            "name": "Jiang, M.",
            "value": 51,
            "numPapers": 10,
            "cluster": "3",
            "index": 695,
            "weight": 2,
            "x": 562.3156006540542,
            "y": 1108.321862849061,
            "px": 540.018071647917,
            "py": 1077.290743745926,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Vortex Visualization for Practical Engineering Applications",
                "PaperDOI": "10.1109/TVCG.2006.201",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.201",
                "Firstpage": "957",
                "Lastpage": "964",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability",
                "AuthorNames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Raghu Machiraju",
                "FirstAuthorAffiliation": "Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;",
                "AuthorIDs": ";37826582200;;37269516700",
                "Dedupedauthornames": "Jankun-Kelly, M.;Jiang, M.;Thompson, D.;Machiraju, R.",
                "References": "10.1109/VISUAL.1997.663894;10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1999.809896",
                "AuthorKeywords": "Vortex detection, vortex visualization, feature mining",
                "IEEEXPLOREArticleNumberdeprecated": "4015452",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "663894;1183789;1532830;745296;745288;809896"
            }
        },
        {
            "name": "Fanea, E.",
            "value": 19,
            "numPapers": 13,
            "cluster": "5",
            "index": 696,
            "weight": 2,
            "x": 1193.9850841551988,
            "y": 304.3080954144923,
            "px": 1233.104512570901,
            "py": 309.2179923841927,
            "node": {
                "Conference": "InfoVis",
                "Year": "2005",
                "PaperTitle": "An interactive 3D integration of parallel coordinates and star glyphs",
                "PaperDOI": "10.1109/INFVIS.2005.1532141",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2005.1532141",
                "Firstpage": "149",
                "Lastpage": "156",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Parallel coordinates are a powerful method for visualizing multidimensional data but, when applied to large data sets, they become cluttered and difficult to read. Star glyphs, on the other hand, can be used to display either the attributes of a data item or the values across all items for a single attribute. Star glyphs may readily provide a quick impression; however, since the full data set require multiple glyphs, overall readings are more difficult. We present parallel glyphs, an interactive integration of the visual representations of parallel coordinates and star glyphs that utilizes the advantages of both representations to offset the disadvantages they have separately. We discuss the role of uniform and stepped colour scales in the visual comparison of non-adjacent items and star glyphs. Parallel glyphs provide capabilities for focus-in-context exploration using two types of lenses and interactions specific to the 3D space.",
                "AuthorNames": "Fanea, E.;Carpendale, S.;Isenberg, T.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;",
                "AuthorIDs": "37550785900;37285000100;37297057400",
                "Dedupedauthornames": "Fanea, E.;Carpendale, S.;Isenberg, T.",
                "References": "10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249024;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2004.71;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2004.15;10.1109/INFVIS.2004.68;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2002.1173151;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1990.146402",
                "AuthorKeywords": "Parallel Glyphs, parallel coordinates, star glyphs, multi-dimensional data sets, 3D visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1532141",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "485139;1249024;1249008;1173157;1382893;1249015;1382895;1382894;809866;1173151;346302;663866;146402"
            }
        },
        {
            "name": "Telea, A.",
            "value": 152,
            "numPapers": 48,
            "cluster": "3",
            "index": 697,
            "weight": 1,
            "x": 60.37359400494023,
            "y": 958.5175782016285,
            "px": 57.66432925198258,
            "py": 893.0549785852897,
            "node": {
                "Conference": "InfoVis",
                "Year": "2011",
                "PaperTitle": "Skeleton-Based Edge Bundling for Graph Visualization",
                "PaperDOI": "10.1109/TVCG.2011.233",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.233",
                "Firstpage": "2364",
                "Lastpage": "2373",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.",
                "AuthorNames": "Ersoy, O.;Hurter, C.;Paulovich, F.V.;Cantareiro, G.;Telea, A.",
                "FirstAuthorAffiliation": "Univ. of Groningen, Groningen, Netherlands|c|;;;;",
                "AuthorIDs": "37672044200;38017336200;37590969400;;37268047100",
                "Dedupedauthornames": "Ersoy, O.;Hurter, C.;Paulovich, F.V.;Cantareiro, G.;Telea, A.",
                "References": "10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70535;10.1109/TVCG.2006.120;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2003.1249030",
                "AuthorKeywords": "Graph layouts, edge bundles, image-based information visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6065003",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "4658140;4015425;4376143;4015416;1532150;1249030"
            }
        },
        {
            "name": "Weinstein, D.",
            "value": 127,
            "numPapers": 12,
            "cluster": "3",
            "index": 698,
            "weight": 2,
            "x": -806.3490122542078,
            "y": 842.6155539753339,
            "px": -877.8115756434448,
            "py": 837.989747178251,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Hue-balls and lit-tensors for direct volume rendering of diffusion tensor fields",
                "PaperDOI": "10.1109/VISUAL.1999.809886",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809886",
                "Firstpage": "183",
                "Lastpage": "524",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "With the development of magnetic resonance imaging techniques for acquiring diffusion tensor data from biological tissue, visualization of tensor data has become a new research focus. The diffusion tensor describes the directional dependence of water molecules' diffusion and can be represented by a three-by-three symmetric matrix. Visualization of second-order tensor fields is difficult because the data values have many degrees of freedom. Existing visualization techniques are best at portraying the tensor's properties over a two-dimensional field, or over a small subset of locations within a three-dimensional field. A means of visualizing the global structure in measured diffusion tensor data is needed. We propose the use of direct volume rendering, with novel approaches for the tensors' coloring, lighting, and opacity assignment. Hue-balls use a two-dimensional colormap on the unit sphere to illustrate the tensor's action as a linear operator. Lit-tensors provide a lighting model for tensors which includes as special cases both lit-lines (from streamline vector visualization) and standard Phong surface lighting. Together with an opacity assignment based on a novel two-dimensional barycentric space of anisotropy, these methods are shown to produce informative renderings of measured diffusion tensor data from the human brain.",
                "AuthorNames": "Kindlmann, G.;Weinstein, D.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;",
                "AuthorIDs": "37282742400;37337510400",
                "Dedupedauthornames": "Kindlmann, G.;Weinstein, D.",
                "References": "10.1109/VISUAL.1990.146373;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1998.745294",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809886",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146373;235193;567777;745294"
            }
        },
        {
            "name": "Bemis, K.",
            "value": 17,
            "numPapers": 9,
            "cluster": "2",
            "index": 699,
            "weight": 2,
            "x": -323.2730836923666,
            "y": 195.86431889350627,
            "px": -281.33061117971243,
            "py": 190.19380323652481,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Generating realistic images from hydrothermal plume data",
                "PaperDOI": "10.1109/VISUAL.2004.34",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.34",
                "Firstpage": "91",
                "Lastpage": "98",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Most data used in the study of seafloor hydrothermal plumes consists of sonar (acoustic) scans and sensor readings. Visual data captures only a portion of the sonar data range due to the prohibitive cost and physical infeasibility of taking sufficient lighting and video equipment to such extreme depths. However, visual images are available from research dives and from the recent IMAX movie, volcanoes of the deep sea. In this application paper, we apply existing lighting models with forward scattering and light attenuation to the 3D sonar data in order to mimic the visual images available. These generated images are compared to existing visual images. This can help the geoscientists understand the relationship between these different data modalities and elucidate some of the mechanisms used to capture the data.",
                "AuthorNames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "FirstAuthorAffiliation": "Rutgers Univ., NJ, USA|c|;;;;",
                "AuthorIDs": "37282733800;37282733100;37274132700;37410745700;37282733200",
                "Dedupedauthornames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "References": "10.1109/VISUAL.2000.885737;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1998.745347",
                "AuthorKeywords": "Applications of volume graphics and volume visualization, Earth / Space / and Environmental Sciences Visualization, PC-based volume graphics, Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1372184",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885737;1250383;745347"
            }
        },
        {
            "name": "Rona, P.",
            "value": 17,
            "numPapers": 9,
            "cluster": "2",
            "index": 700,
            "weight": 2,
            "x": 625.9245991519283,
            "y": -24.506643274395287,
            "px": 674.760536254884,
            "py": -26.29896917449336,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Generating realistic images from hydrothermal plume data",
                "PaperDOI": "10.1109/VISUAL.2004.34",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.34",
                "Firstpage": "91",
                "Lastpage": "98",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Most data used in the study of seafloor hydrothermal plumes consists of sonar (acoustic) scans and sensor readings. Visual data captures only a portion of the sonar data range due to the prohibitive cost and physical infeasibility of taking sufficient lighting and video equipment to such extreme depths. However, visual images are available from research dives and from the recent IMAX movie, volcanoes of the deep sea. In this application paper, we apply existing lighting models with forward scattering and light attenuation to the 3D sonar data in order to mimic the visual images available. These generated images are compared to existing visual images. This can help the geoscientists understand the relationship between these different data modalities and elucidate some of the mechanisms used to capture the data.",
                "AuthorNames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "FirstAuthorAffiliation": "Rutgers Univ., NJ, USA|c|;;;;",
                "AuthorIDs": "37282733800;37282733100;37274132700;37410745700;37282733200",
                "Dedupedauthornames": "Santilli, K.;Bemis, K.;Silver, D.;Dastur, J.;Rona, P.",
                "References": "10.1109/VISUAL.2000.885737;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1998.745347",
                "AuthorKeywords": "Applications of volume graphics and volume visualization, Earth / Space / and Environmental Sciences Visualization, PC-based volume graphics, Volume Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1372184",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885737;1250383;745347"
            }
        },
        {
            "name": "Stegmaier, S.",
            "value": 49,
            "numPapers": 21,
            "cluster": "2",
            "index": 701,
            "weight": 1,
            "x": -145.62343092310434,
            "y": -395.68909348034396,
            "px": -130.53489529533277,
            "py": -323.31007809169125,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Opening the can of worms: an exploration tool for vortical flows",
                "PaperDOI": "10.1109/VISUAL.2005.1532830",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532830",
                "Firstpage": "463",
                "Lastpage": "470",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the 2 method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.",
                "AuthorNames": "Stegmaier, S.;Rist, U.;Ertl, T.",
                "FirstAuthorAffiliation": "Inst. for Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37267809900;37397347800;37268023800",
                "Dedupedauthornames": "Stegmaier, S.;Rist, U.;Ertl, T.",
                "References": "10.1109/VISUAL.1990.146359;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1994.346327;10.1109/VISUAL.2004.3;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1998.745296",
                "AuthorKeywords": "Flow Features, Vortex Detection, Interactive Manipulation, 3D Vector Field Visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1532830",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146359;745297;346327;1372197;745288;745296"
            }
        },
        {
            "name": "Brannon, R.",
            "value": 4,
            "numPapers": 18,
            "cluster": "3",
            "index": 702,
            "weight": 2,
            "x": 65.48696314650704,
            "y": 540.3129477341629,
            "px": 150.02018475127838,
            "py": 532.2750673845563,
            "node": {
                "Conference": "Vis",
                "Year": "2005",
                "PaperTitle": "Exploring 2D tensor fields using stress nets",
                "PaperDOI": "10.1109/VISUAL.2005.1532771",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2005.1532771",
                "Firstpage": "11",
                "Lastpage": "18",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this article we describe stress nets, a technique for exploring 2D tensor fields. Our method allows a user to examine simultaneously the tensors' eigenvectors (both major and minor) as well as scalar-valued tensor invariants. By avoiding noise-advection techniques, we are able to display both principal directions of the tensor field as well as the derived scalars without cluttering the display. We present a CPU-only implementation of stress nets as well as a hybrid CPU/GPU approach and discuss the relative strengths and weaknesses of each. Stress nets have been used as part of an investigation into crack propagation. They were used to display the directions of maximum shear in a slab of material under tension as well as the magnitude of the shear forces acting on each point. Our methods allowed users to find new features in the data that were not visible on standard plots of tensor invariants. These features disagree with commonly accepted analytical crack propagation solutions and have sparked renewed investigation. Though developed for a materials mechanics problem, our method applies equally well to any 2D tensor field having unique characteristic directions.",
                "AuthorNames": "Wilson, A.;Brannon, R.",
                "FirstAuthorAffiliation": "Sandia Nat. Labs., Albuquerque, NM, USA|c|;",
                "AuthorIDs": "37554778300;37282577100",
                "Dedupedauthornames": "Wilson, A.;Brannon, R.",
                "References": "10.1109/VISUAL.1998.745316;10.1109/VISUAL.1992.235193;10.1109/VISUAL.2002.1183799;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1999.809894;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1993.398849",
                "AuthorKeywords": "tensor field, stress tensor, streamlines,controlled density streamlines, crack propagation",
                "IEEEXPLOREArticleNumberdeprecated": "1532771",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745316;235193;1183799;346326;809894;885690;398849"
            }
        },
        {
            "name": "Hastreiter, P.",
            "value": 76,
            "numPapers": 36,
            "cluster": "3",
            "index": 703,
            "weight": 1,
            "x": 2843.0667976479026,
            "y": 2311.114416333219,
            "px": 2583.6206147828866,
            "py": 2125.304793536221,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Interactive exploration of volume line integral convolution based on 3D-texture mapping",
                "PaperDOI": "10.1109/VISUAL.1999.809892",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809892",
                "Firstpage": "233",
                "Lastpage": "528",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Line integral convolution (LIC) is an effective technique for visualizing vector fields. The application of LIC to 3D flow fields has yet been limited by difficulties to efficiently display and animate the resulting 3D-images. Texture-based volume rendering allows interactive visualization and manipulation of 3D-LIC textures. In order to ensure the comprehensive and convenient exploration of flow fields, we suggest interactive functionality including transfer functions and different clipping mechanisms. Thereby, we efficiently substitute the calculation of LIC based on sparse noise textures and show the convenient visual access of interior structures. Further on, we introduce two approaches for animating static 3D-flow fields without the computational expense and the immense memory requirements for pre-computed 3D-textures and without loss of interactivity. This is achieved by using a single 3D-LIC texture and a set of time surfaces as clipping geometries. In our first approach we use the clipping geometry to pre-compute a special 3D-LIC texture that can be animated by time-dependent color tables. Our second approach uses time volumes to actually clip the 3D-LIC volume interactively during rasterization. Additionally, several examples demonstrate the value of our strategy in practice.",
                "AuthorNames": "Rezk-Salama, C.;Hastreiter, P.;Teitzel, C.;Ertl, T.",
                "FirstAuthorAffiliation": "Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;;;",
                "AuthorIDs": "37442697900;37373297800;37427416100;37268023800",
                "Dedupedauthornames": "Rezk-Salama, C.;Hastreiter, P.;Teitzel, C.;Ertl, T.",
                "References": "10.1109/VISUAL.1993.398877;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1994.346314;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1997.663898;10.1109/VISUAL.1997.663897;10.1109/VISUAL.1997.663899",
                "AuthorKeywords": "Flow Visualization, Animated LIC, Direct Volume Rendering, 3D-Textures Mapping, Interactive Volume Exploration",
                "IEEEXPLOREArticleNumberdeprecated": "809892",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398877;398846;485141;346313;346314;146391;663898;663897;663899"
            }
        },
        {
            "name": "Hui Ma",
            "value": 10,
            "numPapers": 5,
            "cluster": "7",
            "index": 704,
            "weight": 2,
            "x": 1472.1540706841724,
            "y": 511.6311180073732,
            "px": 1453.86616399478,
            "py": 498.3218035878213,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "Space walking",
                "PaperDOI": "10.1109/VISUAL.1995.480804",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480804",
                "Firstpage": "126",
                "Lastpage": "133, 445",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Proposes an interactive method for exploring topological spaces based on the natural local geometry of the space. Examples of spaces appropriate for this visualization approach occur in abundance in mathematical visualization, surface and volume visualization problems, and scientific applications such as general relativity. Our approach is based on using a controller to choose a direction in which to walk a manifold along a local geodesic path. The method automatically generates orientation changes that produce a maximal viewable region with each step of the walk. The proposed interaction framework has many natural properties to help the user develop a useful cognitive map of a space and is well-suited to haptic interfaces that may be incorporated into desktop virtual reality systems",
                "AuthorNames": "Hanson, A.J.;Hui Ma",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37333439100;37654495700",
                "Dedupedauthornames": "Hanson, A.J.;Hui Ma",
                "References": "10.1109/VISUAL.1994.346324;10.1109/VISUAL.1992.235222",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480804",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346324;235222"
            }
        },
        {
            "name": "Jobard, B.",
            "value": 79,
            "numPapers": 10,
            "cluster": "2",
            "index": 705,
            "weight": 3,
            "x": 106.53750523924371,
            "y": 169.4238573228462,
            "px": 126.74431030249978,
            "py": 163.4860707361275,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Image space based visualization of unsteady flow on surfaces",
                "PaperDOI": "10.1109/VISUAL.2003.1250364",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250364",
                "Firstpage": "131",
                "Lastpage": "138",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a technique for direct visualization of unsteady flow on surfaces from computational fluid dynamics. The method generates dense representations of time-dependent vector fields with high spatio-temporal correlation using both Lagrangian-Eulerian advection and image based flow visualization as its foundation. While the 3D vector fields are associated with arbitrary triangular surface meshes, the generation and advection of texture properties is confined to image space. Frame rates of up to 20 frames per second are realized by exploiting graphics card hardware. We apply this algorithm to unsteady flow on boundary surfaces of, large, complex meshes from computational fluid dynamics composed of more than 250,000 polygons, dynamic meshes with time-dependent geometry and topology, as well as medical data.",
                "AuthorNames": "Laramee, R.S.;Jobard, B.;Hauser, H.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Graz, Austria|c|;;",
                "AuthorIDs": "37267247900;37267249300;37274158800",
                "Dedupedauthornames": "Laramee, R.S.;Jobard, B.;Hauser, H.",
                "References": "10.1109/VISUAL.2001.964493;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1995.480817",
                "AuthorKeywords": "Unsteady flow visualization, computational fluid dynamics (CFD), surface representation, texture mapping",
                "IEEEXPLOREArticleNumberdeprecated": "1250364",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "964541_04;346313;480817"
            }
        },
        {
            "name": "Hussaini, M.Y.",
            "value": 46,
            "numPapers": 6,
            "cluster": "2",
            "index": 706,
            "weight": 1,
            "x": -86.72891263875846,
            "y": 164.53057531206315,
            "px": -64.54574147815761,
            "py": 164.4002575795607,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated texture advection for unsteady flow visualization",
                "PaperDOI": "10.1109/VISUAL.2000.885689",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885689",
                "Firstpage": "155",
                "Lastpage": "162",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a novel hardware-accelerated texture advection algorithm to visualize the motion of two-dimensional unsteady flows. Making use of several proposed extensions to the OpenGL-1.2 specification, we demonstrate animations of over 65,000 particles at 2 frames/sec on an SGI Octane with EMXI graphics. High image quality is achieved by careful attention to edge effects, noise frequency, and image enhancement. We provide a detailed description of the hardware implementation, including temporal and spatial coherence techniques, dye advection techniques, and feature extraction.",
                "AuthorNames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "FirstAuthorAffiliation": "Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;",
                "AuthorIDs": "37267249300;37324424400;37324426600",
                "Dedupedauthornames": "Jobard, B.;Erlebacher, G.;Hussaini, M.Y.",
                "References": "10.1109/VISUAL.1995.480817;10.1109/VISUAL.1998.745324",
                "AuthorKeywords": "unsteady, vector field, pathlines, streakline, advection, texture, hardware, OpenGL",
                "IEEEXPLOREArticleNumberdeprecated": "885689",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480817;745324"
            }
        },
        {
            "name": "Rottger, S.",
            "value": 80,
            "numPapers": 17,
            "cluster": "2",
            "index": 707,
            "weight": 1,
            "x": 198.11173648748462,
            "y": 58.563151695020885,
            "px": 213.32767872521853,
            "py": 57.68667915832855,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Hardware-accelerated volume and isosurface rendering based on cell-projection",
                "PaperDOI": "10.1109/VISUAL.2000.885683",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885683",
                "Firstpage": "109",
                "Lastpage": "116",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present two beneficial rendering extensions to the projected tetrahedra (PT) algorithm proposed by Shirley and Tuchman (1990). These extensions are compatible with any cell sorting technique, for example the BSP-XMPVO sorting algorithm for unstructured meshes. Using 3D texture mapping our first extension solves the longstanding problem of hardware-accelerated but accurate rendering of tetrahedral volume cells with arbitrary transfer functions. By employing 2D texture mapping our second extension realizes the hardware-accelerated rendering of multiple shaded isosurfaces within the PT algorithm without reconstructing the isosurfaces. Additionally, two methods are presented to combine projected tetrahedral volumes with isosurfaces. The time complexity of all our algorithms is linear in the number of tetrahedra and does neither depend on the number of isosurfaces nor on the employed transfer functions.",
                "AuthorNames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "FirstAuthorAffiliation": "Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;",
                "AuthorIDs": "37357145300;37284293000;37268023800",
                "Dedupedauthornames": "Rottger, S.;Kraus, M.;Ertl, T.",
                "References": "10.1109/VISUAL.1993.398846;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1999.809887;10.1109/VISUAL.1994.346308;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1994.346306;10.1109/VISUAL.1997.663853;10.1109/VISUAL.1999.809878;10.1109/VISUAL.1996.568127;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745713",
                "AuthorKeywords": "Volume Rendering, Isosurfaces, Unstructured\nMeshes, Cell Projection, Graphics Hardware, Texture Mapping, Compositing",
                "IEEEXPLOREArticleNumberdeprecated": "885683",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398846;346320;809887;346308;885688;346306;663853;809878;568127;480806;745300;568121;745713"
            }
        },
        {
            "name": "Kao, D.",
            "value": 117,
            "numPapers": 25,
            "cluster": "3",
            "index": 708,
            "weight": 1,
            "x": -24.2131779441821,
            "y": 570.3236112098331,
            "px": 28.39795500060886,
            "py": 527.5939320899311,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study",
                "PaperDOI": "10.1109/VISUAL.2001.964550",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964550",
                "Firstpage": "457",
                "Lastpage": "460",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these \"distribution data sets\" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.",
                "AuthorNames": "Kao, D.;Dungan, J.L.;Pang, A.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;;",
                "AuthorIDs": "37339406400;37295769200;37267352000",
                "Dedupedauthornames": "Kao, D.;Dungan, J.L.;Pang, A.",
                "References": "",
                "AuthorKeywords": "uncertainty, probability density function, geostatistics, conditional simulation, data assimilation",
                "IEEEXPLOREArticleNumberdeprecated": "964550",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Ye Zhao",
            "value": 49,
            "numPapers": 44,
            "cluster": "2",
            "index": 709,
            "weight": 2,
            "x": -331.3876650841061,
            "y": 1764.2744558502325,
            "px": -302.9614072585474,
            "py": 1611.826954895814,
            "node": {
                "Conference": "InfoVis",
                "Year": "2014",
                "PaperTitle": "TenniVis: Visualization for Tennis Match Analysis",
                "PaperDOI": "10.1109/TVCG.2014.2346445",
                "Link": "http://dx.doi.org/10.1109/TVCG.2014.2346445",
                "Firstpage": "2339",
                "Lastpage": "2348",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.",
                "AuthorNames": "Polk, T.;Jing Yang;Yueqi Hu;Ye Zhao",
                "FirstAuthorAffiliation": "Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;",
                "AuthorIDs": ";;;",
                "Dedupedauthornames": "Polk, T.;Jing Yang;Yueqi Hu;Ye Zhao",
                "References": "10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/VISUAL.2001.964496;10.1109/INFVIS.1996.559229;10.1109/INFVIS.2002.1173148",
                "AuthorKeywords": "Visual knowledge discovery, sports analytics, tennis visualization",
                "IEEEXPLOREArticleNumberdeprecated": "6876044",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "6327288;6634087;964541_07;559229;1173148"
            }
        },
        {
            "name": "Wei, X.",
            "value": 33,
            "numPapers": 6,
            "cluster": "2",
            "index": 710,
            "weight": 2,
            "x": -170.54575737655006,
            "y": 1434.012297153232,
            "px": -123.81699677796074,
            "py": 1245.1828322923816,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Case study: visualization of particle track data",
                "PaperDOI": "10.1109/VISUAL.2001.964552",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964552",
                "Firstpage": "465",
                "Lastpage": "468",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The Relativistic Heavy Ion Collider (RHIC) experiment at the Brookhaven National Lab is designed to study how the universe came into being. It is believed that after the Big Bang, the universe expanded and cooled, consisting of a soup of quarks, gluons, electrons and neutrinos. As the temperature lowered, electrons combined with protons and formed neutral atoms. Later, clouds of atoms contracted into stars. In this paper, we describe how techniques of volume rendering and information visualization are used to visualize the large particle track data set generated from this high energy physics experiment. The system, called TrackVis, is based on our earlier work of VolVis - Volume Visualization software. Example images of real particle collision data are shown, which are helpful to physicists in investigating the behavior of strongly interacting matter at high energy density.",
                "AuthorNames": "Wei, X.;Kaufman, A.E.;Hallman, T.J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "37279025800;37268052800;37376928400",
                "Dedupedauthornames": "Wei, X.;Kaufman, A.;Hallman, T.J.",
                "References": "10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559214;10.1109/VISUAL.1994.346340",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "964552",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636786;559214;346340"
            }
        },
        {
            "name": "Berchtold, S.",
            "value": 105,
            "numPapers": 3,
            "cluster": "5",
            "index": 711,
            "weight": 2,
            "x": 1059.7592478601841,
            "y": 229.64889833727327,
            "px": 1100.0950875278422,
            "py": 247.22735123961618,
            "node": {
                "Conference": "InfoVis",
                "Year": "1998",
                "PaperTitle": "Similarity clustering of dimensions for an enhanced visualization of multidimensional data",
                "PaperDOI": "10.1109/INFVIS.1998.729559",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1998.729559",
                "Firstpage": "52",
                "Lastpage": "60, 153",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results",
                "AuthorNames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "FirstAuthorAffiliation": "Munich Univ., Germany|c|;;",
                "AuthorIDs": "37371609900;37374589200;37283138700",
                "Dedupedauthornames": "Ankerst, M.;Berchtold, S.;Keim, D.A.",
                "References": "10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "729568",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146402;346302;485140"
            }
        },
        {
            "name": "Ying-Huey Fua",
            "value": 129,
            "numPapers": 16,
            "cluster": "5",
            "index": 712,
            "weight": 3,
            "x": 913.0861115870532,
            "y": 316.6754106015245,
            "px": 939.6543908549166,
            "py": 330.47487399511454,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Hierarchical parallel coordinates for exploration of large datasets",
                "PaperDOI": "10.1109/VISUAL.1999.809866",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809866",
                "Firstpage": "43",
                "Lastpage": "508",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Our ability to accumulate large, complex (multivariate) data sets has far exceeded our ability to effectively process them in searching for patterns, anomalies and other interesting features. Conventional multivariate visualization techniques generally do not scale well with respect to the size of the data set. The focus of this paper is on the interactive visualization of large multivariate data sets based on a number of novel extensions to the parallel coordinates display technique. We develop a multi-resolution view of the data via hierarchical clustering, and use a variation of parallel coordinates to convey aggregation information for the resulting clusters. Users can then navigate the resulting structure until the desired focus region and level of detail is reached, using our suite of navigational and filtering tools. We describe the design and implementation of our hierarchical parallel coordinates system which is based on extending the XmdvTool system. Lastly, we show examples of the tools and techniques applied to large (hundreds of thousands of records) multivariate data sets.",
                "AuthorNames": "Ying-Huey Fua;Ward, M.O.;Rundensteiner, E.A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;",
                "AuthorIDs": "37445066400;37268441700;37279217900",
                "Dedupedauthornames": "Ying-Huey Fua;Ward, M.O.;Rundensteiner, E.A.",
                "References": "10.1109/VISUAL.1994.346302;10.1109/INFVIS.1999.801858;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1998.729556;10.1109/VISUAL.1995.485139",
                "AuthorKeywords": "Large-scale multivariate data visualization, hierarchical data exploration, parallel coordinates",
                "IEEEXPLOREArticleNumberdeprecated": "809866",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346302;801858;567800;485140;146386;146402;729557;485139"
            }
        },
        {
            "name": "Williams, M.",
            "value": 39,
            "numPapers": 8,
            "cluster": "10",
            "index": 713,
            "weight": 1,
            "x": 1575.0538135003032,
            "y": -213.40094254869388,
            "px": 1401.927207584202,
            "py": -377.64037450069486,
            "node": {
                "Conference": "InfoVis",
                "Year": "2004",
                "PaperTitle": "Steerable, Progressive Multidimensional Scaling",
                "PaperDOI": "10.1109/INFVIS.2004.60",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2004.60",
                "Firstpage": "57",
                "Lastpage": "64",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Current implementations of multidimensional scaling (MDS), an approach that attempts to best represent data point similarity in a low-dimensional representation, are not suited for many of today's large-scale datasets. We propose an extension to the spring model approach that allows the user to interactively explore datasets that are far beyond the scale of previous implementations of MDS. We present MDSteer, a steerable MDS computation engine and visualization tool that progressively computes an MDS layout and handles datasets of over one million points. Our technique employs hierarchical data structures and progressive layouts to allow the user to steer the computation of the algorithm to the interesting areas of the dataset. The algorithm iteratively alternates between a layout stage in which a subselection of points are added to the set of active points affected by the MDS iteration, and a binning stage which increases the depth of the bin hierarchy and organizes the currently unplaced points into separate spatial regions. This binning strategy allows the user to select onscreen regions of the layout to focus the MDS computation into the areas of the dataset that are assigned to the selected bins. We show both real and common synthetic benchmark datasets with dimensionalities ranging from 3 to 300 and cardinalities of over one million points",
                "AuthorNames": "Williams, M.;Munzner, T.",
                "FirstAuthorAffiliation": "British Columbia Univ., Vancouver, BC|c|;",
                "AuthorIDs": "37926388300;37349490300",
                "Dedupedauthornames": "Williams, M.;Munzner, T.",
                "References": "10.1109/INFVIS.2002.1173150;10.1109/INFVIS.2003.1249013;10.1109/INFVIS.2001.963275;10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2002.1173161;10.1109/VISUAL.1996.567787;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249012",
                "AuthorKeywords": "dimensionality reduction, multidimensional scaling",
                "IEEEXPLOREArticleNumberdeprecated": "1382891",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1173150;1249013;963275;1173159;1173161;567787;528686;1249012"
            }
        },
        {
            "name": "Preusser, T.",
            "value": 17,
            "numPapers": 17,
            "cluster": "3",
            "index": 714,
            "weight": 1,
            "x": -55.107780665691585,
            "y": -1052.5655129521754,
            "px": -50.58303757353987,
            "py": -888.0666667389067,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Anisotropic nonlinear diffusion in flow visualization",
                "PaperDOI": "10.1109/VISUAL.1999.809904",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809904",
                "Firstpage": "325",
                "Lastpage": "539",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.",
                "AuthorNames": "Preusser, T.;Rumpf, M.",
                "FirstAuthorAffiliation": "Inst. fur Angewandte Math., Bonn Univ., Germany|c|;",
                "AuthorIDs": "37282573000;37268036500",
                "Dedupedauthornames": "Preusser, T.;Rumpf, M.",
                "References": "10.1109/VISUAL.1993.398875;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346312;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1997.663898",
                "AuthorKeywords": "flow visualization, multiscale, nonlinear diffusion, segmentation",
                "IEEEXPLOREArticleNumberdeprecated": "809904",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398875;480817;346312;663912;567784;663898"
            }
        },
        {
            "name": "Rumpf, M.",
            "value": 27,
            "numPapers": 26,
            "cluster": "3",
            "index": 715,
            "weight": 1,
            "x": 68.33119707524304,
            "y": 979.7702720035221,
            "px": 64.54162503124886,
            "py": 909.246383714122,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "A continuous clustering method for vector fields",
                "PaperDOI": "10.1109/VISUAL.2000.885715",
                "Link": "http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885715",
                "Firstpage": "351",
                "Lastpage": "358",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new method for the simplification of flow fields is presented. It is based on continuous clustering. A well-known physical clustering model, the Cahn Hillard model which describes phase separation, is modified to reflect the properties of the data to be visualized. Clusters are defined implicitly as connected components of the positivity set of a density function. An evolution equation for this function is obtained as a suitable gradient flow of an underlying anisotropic energy functional. Here, time serves as the scale parameter. The evolution is characterized by a successive coarsening of patternsthe actual clustering  and meanwhile the underlying simulation data specifies preferable pattern boundaries. Here we discuss the applicability of this new type of approach mainly for flow fields, where the cluster energy penalizes cross streamline boundaries, but the method also carries provisions in other fields as well. The clusters are visualized via iconic representations. A skeletonization algorithm is used to find suitable positions for the icons.",
                "AuthorNames": "Garcke, H.;Preuer, T.;Rumpf, M.;Telea, A.;Weikard, U.;van Wijk, J.J.",
                "FirstAuthorAffiliation": "Technical University Eindhoven, Eindhoven, NL",
                "AuthorIDs": "",
                "Dedupedauthornames": "Garcke, H.;Preuer, T.;Rumpf, M.;Telea, A.;Weikard, U.;van Wijk, J.J.",
                "References": "10.1109/VISUAL.1999.809865;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1999.809863;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1999.809892;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1999.809904",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885715",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": "809865;480817;346313;809863;485141;809892;567777;809904"
            }
        },
        {
            "name": "Liu Ren",
            "value": 6,
            "numPapers": 9,
            "cluster": "2",
            "index": 716,
            "weight": 2,
            "x": 267.3050109297367,
            "y": 49.1385349149692,
            "px": 301.6938978056825,
            "py": 67.0096908942579,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "Hardware-accelerated adaptive EWA volume splatting",
                "PaperDOI": "10.1109/VISUAL.2004.38",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.38",
                "Firstpage": "67",
                "Lastpage": "74",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a hardware-accelerated adaptive EWA (elliptical weighted average) volume splatting algorithm. EWA splatting combines a Gaussian reconstruction kernel with a low-pass image filter for high image quality without aliasing artifacts or excessive blurring. We introduce a novel adaptive filtering scheme to reduce the computational cost of EWA splatting. We show how this algorithm can be efficiently implemented on modern graphics processing units (GPUs). Our implementation includes interactive classification and fast lighting. To accelerate the rendering we store splat geometry and 3D volume data locally in GPU memory. We present results for several rectilinear volume datasets that demonstrate the high image quality and interactive rendering speed of our method.",
                "AuthorNames": "Wei Chen;Liu Ren;Zwicker, M.;Pfister, H.",
                "FirstAuthorAffiliation": "Zhejiang Univ., Hangzhou, China|c|;;;",
                "AuthorIDs": "37279188600;37266117500;37282240200;37275698100",
                "Dedupedauthornames": "Wei Chen;Liu Ren;Zwicker, M.;Pfister, H.",
                "References": "10.1109/VISUAL.1993.398877;10.1109/VISUAL.1997.663882;10.1109/VISUAL.2003.1250403;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1996.567608;10.1109/VISUAL.1999.809909;10.1109/VISUAL.1995.480797;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2000.885698",
                "AuthorKeywords": "Direct volume rendering, volume splatting, EWA filter, hardware acceleration",
                "IEEEXPLOREArticleNumberdeprecated": "1372181",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398877;663882;1250403;745309;567608;809909;480797;964490;885698"
            }
        },
        {
            "name": "Zwicker, M.",
            "value": 39,
            "numPapers": 14,
            "cluster": "2",
            "index": 717,
            "weight": 4,
            "x": 224.2721838717398,
            "y": 27.613299620515615,
            "px": 245.31877058925534,
            "py": 46.05346076830166,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "EWA volume splatting",
                "PaperDOI": "10.1109/VISUAL.2001.964490",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2001.964490",
                "Firstpage": "29",
                "Lastpage": "36",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.",
                "AuthorNames": "Zwicker, M.;Pfister, H.;van Baar, J.;Gross, Markus",
                "FirstAuthorAffiliation": "Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;",
                "AuthorIDs": "37282240200;37275698100;37324479700;37275694700",
                "Dedupedauthornames": "Zwicker, M.;Pfister, H.;van Baar, J.;Gross, M.",
                "References": "10.1109/VISUAL.1995.480796;10.1109/VISUAL.1997.663882;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1996.567608;10.1109/VISUAL.1999.809909",
                "AuthorKeywords": "Volume Rendering, Splatting, Antialiasing",
                "IEEEXPLOREArticleNumberdeprecated": "964490",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "480796;663882;745309;567608;809909"
            }
        },
        {
            "name": "Itoh, T.",
            "value": 26,
            "numPapers": 3,
            "cluster": "2",
            "index": 718,
            "weight": 2,
            "x": -132.23851869165802,
            "y": -1058.840233293074,
            "px": -194.34782937493839,
            "py": -1151.912986243899,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Isosurface generation by using extrema graphs",
                "PaperDOI": "10.1109/VISUAL.1994.346334",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346334",
                "Firstpage": "77",
                "Lastpage": "83, C7",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A high-performance algorithm for generating isosurfaces is presented. In this algorithm, extrema points in a scalar field are first extracted. A graph is then generated in which the extrema points are taken as nodes. Each arc of the graph has a list of IDs of the cells that are intersected by the arc. A boundary cell list ordered according to cells' values is also generated. The graph and the list generated in this pre-process are used as a guide in searching for seed cells. Isosurfaces are generated from seed cells that are found in arcs of the graph. In this process, isosurfaces appear to propagate themselves. The algorithm visits only cells that are intersected by an isosurface and cells whose IDs an included in cell lists. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described show the efficiency of the algorithm",
                "AuthorNames": "Itoh, T.;Koyamada, K.",
                "FirstAuthorAffiliation": "Res. Lab., IBM Japan Ltd., Tokyo, Japan|c|;",
                "AuthorIDs": "37655930100;37284304900",
                "Dedupedauthornames": "Itoh, T.;Koyamada, K.",
                "References": "10.1109/VISUAL.1992.235213;10.1109/VISUAL.1991.175780",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346334",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235213;175780"
            }
        },
        {
            "name": "Koyamada, K.",
            "value": 28,
            "numPapers": 4,
            "cluster": "2",
            "index": 719,
            "weight": 2,
            "x": 644.1711150966619,
            "y": 775.9148181324126,
            "px": 643.6472523241083,
            "py": 813.4711204413001,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Isosurface generation by using extrema graphs",
                "PaperDOI": "10.1109/VISUAL.1994.346334",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346334",
                "Firstpage": "77",
                "Lastpage": "83, C7",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A high-performance algorithm for generating isosurfaces is presented. In this algorithm, extrema points in a scalar field are first extracted. A graph is then generated in which the extrema points are taken as nodes. Each arc of the graph has a list of IDs of the cells that are intersected by the arc. A boundary cell list ordered according to cells' values is also generated. The graph and the list generated in this pre-process are used as a guide in searching for seed cells. Isosurfaces are generated from seed cells that are found in arcs of the graph. In this process, isosurfaces appear to propagate themselves. The algorithm visits only cells that are intersected by an isosurface and cells whose IDs an included in cell lists. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described show the efficiency of the algorithm",
                "AuthorNames": "Itoh, T.;Koyamada, K.",
                "FirstAuthorAffiliation": "Res. Lab., IBM Japan Ltd., Tokyo, Japan|c|;",
                "AuthorIDs": "37655930100;37284304900",
                "Dedupedauthornames": "Itoh, T.;Koyamada, K.",
                "References": "10.1109/VISUAL.1992.235213;10.1109/VISUAL.1991.175780",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346334",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235213;175780"
            }
        },
        {
            "name": "Moran, P.J.",
            "value": 47,
            "numPapers": 31,
            "cluster": "8",
            "index": 720,
            "weight": 3,
            "x": 1717.6789345131858,
            "y": 719.4364497951934,
            "px": 1627.7898281300932,
            "py": 693.2742487869742,
            "node": {
                "Conference": "Vis",
                "Year": "2011",
                "PaperTitle": "Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation",
                "PaperDOI": "10.1109/TVCG.2011.252",
                "Link": "http://dx.doi.org/10.1109/TVCG.2011.252",
                "Firstpage": "1862",
                "Lastpage": "1871",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C0 continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates \"stitching cells\" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.",
                "AuthorNames": "Moran, P.J.;Ellsworth, D.",
                "FirstAuthorAffiliation": "Ames Res. Center, NASA, Moffett Field, CA, USA|c|;",
                "AuthorIDs": "37264891100;37282594500",
                "Dedupedauthornames": "Moran, P.J.;Ellsworth, D.",
                "References": "10.1109/VISUAL.1991.175782;10.1109/TVCG.2009.149;10.1109/VISUAL.2002.1183820",
                "AuthorKeywords": "Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells",
                "IEEEXPLOREArticleNumberdeprecated": "6064949",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175782;5290780;1183820"
            }
        },
        {
            "name": "Abram, G.",
            "value": 114,
            "numPapers": 17,
            "cluster": "8",
            "index": 721,
            "weight": 3,
            "x": -42.65470821342615,
            "y": 725.7476616794588,
            "px": -199.96077192372172,
            "py": 883.0670721009116,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "An extended data-flow architecture for data analysis and visualization",
                "PaperDOI": "10.1109/VISUAL.1995.480821",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480821",
                "Firstpage": "263",
                "Lastpage": "270, 461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure data-flow. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer",
                "AuthorNames": "Abram, G.;Treinish, L.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;",
                "AuthorIDs": "37378534500;37372175500",
                "Dedupedauthornames": "Abram, G.;Treinish, L.A.",
                "References": "10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480821",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346305;398860;175818;235219"
            }
        },
        {
            "name": "Wan, M.",
            "value": 95,
            "numPapers": 16,
            "cluster": "2",
            "index": 722,
            "weight": 5,
            "x": 873.9024258331265,
            "y": 172.88029308584396,
            "px": 621.774653209495,
            "py": 221.95013541782762,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "Image based rendering with stable frame rates",
                "PaperDOI": "10.1109/VISUAL.2000.885702",
                "Link": "http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885702",
                "Firstpage": "251",
                "Lastpage": "258",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents an efficient keyframeless image-based rendering technique. An intermediate image is used to exploit the coherences among neighboring frames. The pixels in the intermediate image are first rendered by a ray-casting method and then warped to the intermediate image at the current viewpoint and view direction. We use an offset buffer to record the precise positions of these pixels in the intermediate image. Every frame is generated in three steps: warping the intermediate image onto the frame, filling in holes, and selectively rendering a group of old pixels. By dynamically adjusting the number of those old pixels in the last step, the workload at every frame can be balanced. The pixels generated by the last two steps make contributions to the new intermediate image. Unlike occasional keyframes in conventional image-based rendering which need to be totally rerendered, intermediate images only need to be partially updated at every frame. In this way, we guarantee more stable frame rates and more uniform image qualities. The intermediate image can be warped efficiently by a modified incremental 3D warp algorithm. As a specific application, we demonstrate our technique with a voxel-based terrain rendering system.\"",
                "AuthorNames": "Qu, H.;Wan, M;Qin, J.;Kaufman, A.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;",
                "AuthorIDs": "",
                "Dedupedauthornames": "Qu, H.;Wan, M.;Qin, J.;Kaufman, A.",
                "References": "10.1109/VISUAL.1992.235190;10.1109/VISUAL.1998.745305;10.1109/VISUAL.1999.809900",
                "AuthorKeywords": "Image-based rendering, ray casting, voxel-based modeling,\nterrain rendering",
                "IEEEXPLOREArticleNumberdeprecated": "885702",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": "235190;745305;809900"
            }
        },
        {
            "name": "Zhengrong Liang",
            "value": 33,
            "numPapers": 4,
            "cluster": "2",
            "index": 723,
            "weight": 2,
            "x": 1971.6474289589466,
            "y": 215.02544864006106,
            "px": 2030.1735320103278,
            "py": 179.7132928895479,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Volume rendering based interactive navigation within the human colon",
                "PaperDOI": "10.1109/VISUAL.1999.809914",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809914",
                "Firstpage": "397",
                "Lastpage": "549",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an interactive navigation system for virtual colonoscopy, which is based solely on high performance volume rendering. Previous colonic navigation systems have employed either a surface rendering or a Z-buffer-assisted volume rendering method that depends on the surface rendering results. Our method is a fast direct volume rendering technique that exploits distance information stored in the potential field of the camera control model, and is parallelized on a multiprocessor. Experiments have been conducted on both a simulated pipe and patients' data sets acquired with a CT scanner.",
                "AuthorNames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;",
                "AuthorIDs": "37362958300;37446853000;37268052800;37273115400;37354296000",
                "Dedupedauthornames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "References": "10.1109/VISUAL.1999.809911;10.1109/VISUAL.1997.663915;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1993.398852",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809914",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809911;663915;745713;398852"
            }
        },
        {
            "name": "Wax, M.",
            "value": 33,
            "numPapers": 4,
            "cluster": "2",
            "index": 724,
            "weight": 2,
            "x": 3095.046531232809,
            "y": -156.04498949904405,
            "px": 3237.275543419636,
            "py": -216.08019637102234,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "Volume rendering based interactive navigation within the human colon",
                "PaperDOI": "10.1109/VISUAL.1999.809914",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809914",
                "Firstpage": "397",
                "Lastpage": "549",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an interactive navigation system for virtual colonoscopy, which is based solely on high performance volume rendering. Previous colonic navigation systems have employed either a surface rendering or a Z-buffer-assisted volume rendering method that depends on the surface rendering results. Our method is a fast direct volume rendering technique that exploits distance information stored in the potential field of the camera control model, and is parallelized on a multiprocessor. Experiments have been conducted on both a simulated pipe and patients' data sets acquired with a CT scanner.",
                "AuthorNames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;",
                "AuthorIDs": "37362958300;37446853000;37268052800;37273115400;37354296000",
                "Dedupedauthornames": "Wan, M.;Tang, Q.;Kaufman, A.;Zhengrong Liang;Wax, M.",
                "References": "10.1109/VISUAL.1999.809911;10.1109/VISUAL.1997.663915;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1993.398852",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "809914",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809911;663915;745713;398852"
            }
        },
        {
            "name": "El-Sana, J.",
            "value": 41,
            "numPapers": 19,
            "cluster": "3",
            "index": 725,
            "weight": 7,
            "x": 196.0003950212131,
            "y": 583.1321402075278,
            "px": 201.5347940163777,
            "py": 562.7331790674991,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Optimized view-dependent rendering for large polygonal datasets",
                "PaperDOI": "10.1109/VISUAL.2002.1183760",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183760",
                "Firstpage": "77",
                "Lastpage": "84",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.",
                "AuthorNames": "El-Sana, J.;Bachmat, E.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel|c|;",
                "AuthorIDs": "37393584400;37698248900",
                "Dedupedauthornames": "El-Sana, J.;Bachmat, E.",
                "References": "10.1109/VISUAL.1999.809877;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2000.885724;10.1109/VISUAL.1998.745283;10.1109/VISUAL.1995.480805",
                "AuthorKeywords": "Surface Simplification, Level of Detail, Multiresolution Hierarchies, View-Dependent Rendering",
                "IEEEXPLOREArticleNumberdeprecated": "1183760",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809877;663860;885724;745283;480805"
            }
        },
        {
            "name": "Salomon, B.",
            "value": 15,
            "numPapers": 11,
            "cluster": "3",
            "index": 726,
            "weight": 1,
            "x": 47.2212231801703,
            "y": 619.1944985234483,
            "px": 107.34869937059612,
            "py": 617.3332670945105,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Interactive view-dependent rendering with conservative occlusion culling in complex environments",
                "PaperDOI": "10.1109/VISUAL.2003.1250368",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250368",
                "Firstpage": "163",
                "Lastpage": "170",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.",
                "AuthorNames": "Yoon, S.-E.;Salomon, B.;Manocha, D.",
                "FirstAuthorAffiliation": "North Carolina Univ., Chapel Hill, NC, USA|c|;;",
                "AuthorIDs": "37279394100;37271825900;37267825600",
                "Dedupedauthornames": "Yoon, S.-E.;Salomon, B.;Manocha, D.",
                "References": "10.1109/VISUAL.2002.1183760;10.1109/VISUAL.2001.964534;10.1109/VISUAL.2002.1183796",
                "AuthorKeywords": "Interactive Display, View-Dependent Rendering, Occlusion Culling, Level of Detail, Multiresolution Hierarchies",
                "IEEEXPLOREArticleNumberdeprecated": "1250368",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183760;964534;1183796"
            }
        },
        {
            "name": "Zhang, C.",
            "value": 6,
            "numPapers": 18,
            "cluster": "2",
            "index": 727,
            "weight": 2,
            "x": 234.02757902871346,
            "y": 62.19001934666619,
            "px": 278.08719754623024,
            "py": 80.96464098766685,
            "node": {
                "Conference": "Vis",
                "Year": "2002",
                "PaperTitle": "Volumetric shadows using splatting",
                "PaperDOI": "10.1109/VISUAL.2002.1183761",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2002.1183761",
                "Firstpage": "85",
                "Lastpage": "92",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "This paper describes an efficient algorithm to model the light attenuation due to a participating media with low albedo. The light attenuation is modeled using splatting volume renderer for both the viewer and the light source. During the rendering, a 2D shadow buffer attenuates the light for each pixel. When the contribution of a footprint is added to the image buffer, as seen from the eye, we add the contribution to the shadow buffer, as seen from the light source. We have generated shadows for point lights and parallel lights using this algorithm. The shadow algorithm has been extended to deal with multiple light sources and projective textured lights.",
                "AuthorNames": "Zhang, C.;Crawfis, R.",
                "FirstAuthorAffiliation": "Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;",
                "AuthorIDs": "37274216600;37284273900",
                "Dedupedauthornames": "Zhang, C.;Crawfis, R.",
                "References": "10.1109/VISUAL.1998.745309;10.1109/VISUAL.1999.809909;10.1109/VISUAL.2000.885698;10.1109/VISUAL.2002.1183764",
                "AuthorKeywords": "visualization, volume rendering, shadows, illumination",
                "IEEEXPLOREArticleNumberdeprecated": "1183761",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745309;809909;885698;1183764"
            }
        },
        {
            "name": "Mroz, L.",
            "value": 43,
            "numPapers": 19,
            "cluster": "2",
            "index": 728,
            "weight": 2,
            "x": -716.5259404531877,
            "y": 1045.7733438713065,
            "px": -830.5026174323427,
            "py": 1120.7046355184452,
            "node": {
                "Conference": "Vis",
                "Year": "2004",
                "PaperTitle": "STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery",
                "PaperDOI": "10.1109/VISUAL.2004.98",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2004.98",
                "Firstpage": "513",
                "Lastpage": "520",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Endonasal transsphenoidal pituitary surgery is a minimally invasive endoscopic procedure, applied to remove various kinds of pituitary tumors. To reduce the risk associated with this treatment, the surgeon must be skilled and well-prepared. Virtual endoscopy can be beneficial as a tool for training, preoperative planning and intraoperative support. This work introduces STEPS, a virtual endoscopy system designed to aid surgeons in getting acquainted with the endoscopic view, the handling of instruments, the transsphenoidal approach and challenges associated with the procedure. STEPS also assists experienced surgeons in planning a real endoscopic intervention by getting familiar with the individual patient anatomy, identifying landmarks, planning the approach and deciding upon the ideal target position of the actual surgical activity. Besides interactive visualization using two different first-hit ray casting techniques, the application provides navigation and perception aids and the possibility to simulate the procedure, including haptic feedback and simulation of surgical instruments.",
                "AuthorNames": "Neubauer, A.;Mroz, L.;Wolfsberger, S.;Wegenkittl, R.;Forster, M.-T.;Buhler, K.",
                "FirstAuthorAffiliation": "VRVis Res. Center, Vienna, Austria|c|;;;;;",
                "AuthorIDs": "37270727300;37282641800;37282642600;37267822600;37282643000;37267821300",
                "Dedupedauthornames": "Neubauer, A.;Mroz, L.;Wolfsberger, S.;Wegenkittl, R.;Forster, M.-T.;Buhler, K.",
                "References": "10.1109/VISUAL.2000.885732;10.1109/VISUAL.2000.885702;10.1109/VISUAL.2000.885673",
                "AuthorKeywords": "virtual endoscopy, ray casting, iso-surfacing, pituitary surgery",
                "IEEEXPLOREArticleNumberdeprecated": "1372237",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "885732;885702;885673"
            }
        },
        {
            "name": "Kenwright, D.",
            "value": 84,
            "numPapers": 12,
            "cluster": "3",
            "index": 729,
            "weight": 2,
            "x": 374.8725434362677,
            "y": 549.2207443065494,
            "px": 408.2458871562833,
            "py": 509.7009655142681,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "Vortex identification-applications in aerodynamics: a case study",
                "PaperDOI": "10.1109/VISUAL.1997.663910",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663910",
                "Firstpage": "413",
                "Lastpage": "416",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An eigenvector method for vortex identification has been applied to recent numerical and experimental studies in external flow aerodynamics. It is shown to be an effective way to extract and visualize features such as vortex cores, spiral vortex breakdowns, vortex bursting, and vortex diffusion. Several problems are reported and illustrated. These include: disjointed line segments, detecting non-vortical flow features, and vortex core displacement. Future research and applications are discussed, such as using vortex cores to guide automatic grid refinement.",
                "AuthorNames": "Kenwright, D.;Haimes, R.",
                "FirstAuthorAffiliation": "NASA Ames Res. Center, Moffett Field, CA, USA|c|;",
                "AuthorIDs": "37355295400;37282898700",
                "Dedupedauthornames": "Kenwright, D.;Haimes, R.",
                "References": "10.1109/VISUAL.1996.568137;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1991.175773",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "663910",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "568137;346327;175773"
            }
        },
        {
            "name": "Kohl, J.A.",
            "value": 9,
            "numPapers": 19,
            "cluster": "2",
            "index": 730,
            "weight": 3,
            "x": 149.18546666984093,
            "y": 40.39349757944504,
            "px": 169.95537914161454,
            "py": 42.883366455672714,
            "node": {
                "Conference": "Vis",
                "Year": "2003",
                "PaperTitle": "Visibility culling using plenoptic opacity functions for large volume visualization",
                "PaperDOI": "10.1109/VISUAL.2003.1250391",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2003.1250391",
                "Firstpage": "341",
                "Lastpage": "348",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Visibility culling has the potential to accelerate large data visualization in significant ways. Unfortunately, existing algorithms do not scale well when parallelized, and require full re-computation whenever the opacity transfer function is modified. To address these issues, we have designed a Plenoptic Opacity Function (POF) scheme to encode the view-dependent opacity of a volume block. POFs are computed off-line during a pre-processing stage, only once for each block. We show that using POFs is (i) an efficient, conservative and effective way to encode the opacity variations of a volume block for a range of views, (ii) flexible for re-use by a family of opacity transfer functions without the need for additional off-line processing, and (iii) highly scalable for use in massively parallel implementations. Our results confirm the efficacy of POFs for visibility culling in large-scale parallel volume rendering; we can interactively render the Visible Woman dataset using software ray-casting on 32 processors, with interactive modification of the opacity transfer function on-the-fly.",
                "AuthorNames": "Gao, J.;Huang, J.;Han-Wei Shen;Kohl, J.A.",
                "FirstAuthorAffiliation": "Ohio State Univ., USA|c|;;;",
                "AuthorIDs": "37279695300;37281262900;37279493500;37430506600",
                "Dedupedauthornames": "Gao, J.;Huang, J.;Han-Wei Shen;Kohl, J.A.",
                "References": "10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2002.1183784;10.1109/VISUAL.1998.745713;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2001.964515;10.1109/VISUAL.2000.885698",
                "AuthorKeywords": "visibility culling, volume rendering, plenoptic opacity function, large data visualization",
                "IEEEXPLOREArticleNumberdeprecated": "1250391",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1183757;1183784;745713;964519;745300;964515;885698"
            }
        },
        {
            "name": "Banks, D.C.",
            "value": 138,
            "numPapers": 22,
            "cluster": "3",
            "index": 731,
            "weight": 1,
            "x": 1015.0086602387265,
            "y": 1641.8538567322764,
            "px": 894.3479774720993,
            "py": 1494.7616062752027,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "Multi-frequency noise for LIC",
                "PaperDOI": "10.1109/VISUAL.1996.567784",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.567784",
                "Firstpage": "121",
                "Lastpage": "126",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present a way to visualize a flow field using Line Integral Convolution (LIC) with a multi frequency noise texture. A broad range of feature sizes can enhance a user's perception of the magnitudes and direction of the flow. In addition, the multiple scales of feature size help a user clarify the motion of the flow in an animation.",
                "AuthorNames": "Ming-Hoe Kiu;Banks, D.C.",
                "FirstAuthorAffiliation": "Dept. of Electr. Eng., Mississippi State Univ., MS, USA|c|;",
                "AuthorIDs": "37612321600;37356983700",
                "Dedupedauthornames": "Ming-Hoe Kiu;Banks, D.C.",
                "References": "10.1109/VISUAL.1994.346313",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "567784",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346313"
            }
        },
        {
            "name": "Singer, B.A.",
            "value": 50,
            "numPapers": 1,
            "cluster": "3",
            "index": 732,
            "weight": 1,
            "x": 1443.9277473201537,
            "y": 419.6815610001773,
            "px": 1270.8393183107255,
            "py": 408.2040477736179,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Vortex tubes in turbulent flows: identification, representation, reconstruction",
                "PaperDOI": "10.1109/VISUAL.1994.346327",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346327",
                "Firstpage": "132",
                "Lastpage": "139, C14",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A new algorithm for identifying vortices in complex flows is presented. The scheme uses both the vorticity and pressure fields. A skeleton line along the center of a vortex is produced by a two-step predictor-corrector scheme. The technique uses the vector field to move in the direction of the skeleton line and the scalar field to correct the location in the plane perpendicular to the skeleton line. With an economical description of the vortex tube's cross-section, the skeleton compresses the representation of the flow by a factor of 4000 or more. We show how the reconstructed geometry of vortex tubes can be enhanced to help visualize helical motion",
                "AuthorNames": "Banks, D.C.;Singer, B.A.",
                "FirstAuthorAffiliation": "Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;",
                "AuthorIDs": "37356983700;37651784800",
                "Dedupedauthornames": "Banks, D.C.;Singer, B.A.",
                "References": "10.1109/VISUAL.1991.175773",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346327",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175773"
            }
        },
        {
            "name": "Gallagher, R.S.",
            "value": 27,
            "numPapers": 1,
            "cluster": "2",
            "index": 733,
            "weight": 1,
            "x": 113.88748389612324,
            "y": 56.03547388930369,
            "px": 183.8955352221165,
            "py": 53.451530459691426,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "Span filtering: an optimization scheme for volume visualization of large finite element models",
                "PaperDOI": "10.1109/VISUAL.1991.175780",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175780",
                "Firstpage": "68",
                "Lastpage": "75, 411",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Techniques for displaying 3D isovalues of scalar fields such as stress within a solid finite-element model generally involve examining each element for values of interest. An inexpensive, straightforward method is discussed for reducing the number of elements searched for such isovalues. It takes advantage of one traversal of the element data to yield a compact classification of the model by result values and ranges, with no sorting required. This data structure can then relate any scalar isovalue to a set of element groups which are closely inclusive of the isovalue. This method is intended for applications requiring repeated access to the analysis data, such as animation and interactive rendering of isosurfaces and scalar fields. While applicable to general volume visualization problems, it is particularly well suited to optimizing real-valued continuum field results such as those found in finite-element data",
                "AuthorNames": "Gallagher, R.S.",
                "FirstAuthorAffiliation": "Swanson Analysis Systems Inc., Houston, PA, USA|c|",
                "AuthorIDs": "38179868800",
                "Dedupedauthornames": "Gallagher, R.S.",
                "References": "10.1109/VISUAL.1990.146390",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175780",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146390"
            }
        },
        {
            "name": "Garland, M.",
            "value": 88,
            "numPapers": 35,
            "cluster": "3",
            "index": 734,
            "weight": 1,
            "x": 284.8868622516818,
            "y": 880.0070933360412,
            "px": 270.62589670198133,
            "py": 813.6280841068772,
            "node": {
                "Conference": "Vis",
                "Year": "2006",
                "PaperTitle": "Interactive Point-Based Rendering of Higher-Order Tetrahedral Data",
                "PaperDOI": "10.1109/TVCG.2006.154",
                "Link": "http://dx.doi.org/10.1109/TVCG.2006.154",
                "Firstpage": "1229",
                "Lastpage": "1236",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates",
                "AuthorNames": "Zhou, Y.;Garland, M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Illinois Univ., Urbana, IL|c|;",
                "AuthorIDs": "37273640900;37272036400",
                "Dedupedauthornames": "Zhou, Y.;Garland, M.",
                "References": "10.1109/VISUAL.2003.1250406;10.1109/VISUAL.2005.1532796;10.1109/VISUAL.2005.1532776;10.1109/VISUAL.2005.1532809;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2002.1183771;10.1109/VISUAL.2004.91;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.1999.809868;10.1109/VISUAL.2004.38;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2002.1183778;10.1109/VISUAL.2005.1532808;10.1109/VISUAL.2003.1250389;10.1109/VISUAL.1995.480790;10.1109/VISUAL.2004.81;10.1109/VISUAL.2005.1532801",
                "AuthorKeywords": "Interactive large higher-order tetrahedral volume visualization, point-based visualization",
                "IEEEXPLOREArticleNumberdeprecated": "4015486",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1250406;1532796;1532776;1532809;1250404;1183757;1183771;1372224;1250390;809867;1372181;1250384;885683;1183778;1532808;1250389;480790;1372226;1532801"
            }
        },
        {
            "name": "Shaffer, E.",
            "value": 34,
            "numPapers": 7,
            "cluster": "3",
            "index": 735,
            "weight": 1,
            "x": 237.400277930406,
            "y": 647.2549627232463,
            "px": 227.0819727786753,
            "py": 648.3428445659027,
            "node": {
                "Conference": "Vis",
                "Year": "2001",
                "PaperTitle": "Efficient Adaptive Simplification of Massive Meshes",
                "PaperDOI": "10.1109/VISUAL.2001.964503",
                "Link": "http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964503",
                "Firstpage": "127",
                "Lastpage": "134",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The growing availability of massive polygonal models, and the inability of most existing visualization tools to work with such data, has created a pressing need for memory efficient methods capable of simplifying very large meshes. In this paper, we present a method for performing adaptive simplification of polygonal meshes that are too large to fit in-core.Our algorithm performs two passes over an input mesh. In the first pass, the model is quantized using a uniform grid, and surface information is accumulated in the form of quadrics and dual quadrics. This sampling is then used to construct a BSP-Tree in which the partitioning planes are determined by the dual quadrics. In the final pass, the original vertices are clustered using the BSP-Tree, yielding an adaptive approximation of the original mesh. The BSP-Tree describes a natural simplification hierarchy, making it possible to generate a progressive transmission and construct level-of-detail representations. In this way, the algorithm provides some of the features associated with more expensive edge contraction methods while maintaining greater computational efficiency. In addition to performing adaptive simplification, our algorithm exhibits output-sensitive memory requirements and allows fine control over the size of the simplified mesh.",
                "AuthorNames": "Shaffer, E.;Garland, M.",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "Dedupedauthornames": "Shaffer, E.;Garland, M.",
                "References": "10.1109/VISUAL.2001.964502;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1998.745314",
                "AuthorKeywords": "surface simplification, massive meshes, quadric error metric, recursive partitioning, out-of-core simplification",
                "IEEEXPLOREArticleNumberdeprecated": "964541_08",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": "964502;745282;745314"
            }
        },
        {
            "name": "Rogowitz, B.",
            "value": 130,
            "numPapers": 8,
            "cluster": "8",
            "index": 736,
            "weight": 1,
            "x": 1228.4457418392424,
            "y": -219.98831643010664,
            "px": 1239.89459606494,
            "py": -23.665718179253684,
            "node": {
                "Conference": "InfoVis",
                "Year": "2008",
                "PaperTitle": "Perceptual Organization in User-Generated Graph Layouts",
                "PaperDOI": "10.1109/TVCG.2008.155",
                "Link": "http://dx.doi.org/10.1109/TVCG.2008.155",
                "Firstpage": "1333",
                "Lastpage": "1339",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.",
                "AuthorNames": "van Ham, F.;Rogowitz, B.",
                "FirstAuthorAffiliation": "IBM Res., Cambridge|c|;",
                "AuthorIDs": "37882135400;37332114400",
                "Dedupedauthornames": "van Ham, F.;Rogowitz, B.",
                "References": "10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70577",
                "AuthorKeywords": "Network layout visualization, perceptual organization, graph layout, user studies",
                "IEEEXPLOREArticleNumberdeprecated": "4658147",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "1382886;4376131"
            }
        },
        {
            "name": "Treinish, L.A.",
            "value": 170,
            "numPapers": 26,
            "cluster": "8",
            "index": 737,
            "weight": 7,
            "x": 874.3563383799122,
            "y": -121.70963962887129,
            "px": 802.0371438881077,
            "py": -124.21179147894325,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "An extended data-flow architecture for data analysis and visualization",
                "PaperDOI": "10.1109/VISUAL.1995.480821",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480821",
                "Firstpage": "263",
                "Lastpage": "270, 461",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Modular visualization environments utilizing a data-flow execution model have become quite popular in recent years, especially those that incorporate visual programming tools. However, simplistic implementations of such an execution model are quite limited when applied to problems of realistic complexity, which negate the intuitive advantage of data-flow systems. This situation can be resolved by extending the execution model to incorporate a more complete and efficient programming infrastructure while still preserving the virtues of pure data-flow. This approach has been used for the implementation of a general-purpose software package, IBM Visualization Data Explorer",
                "AuthorNames": "Abram, G.;Treinish, L.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;",
                "AuthorIDs": "37378534500;37372175500",
                "Dedupedauthornames": "Abram, G.;Treinish, L.A.",
                "References": "10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480821",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346305;398860;175818;235219"
            }
        },
        {
            "name": "Angel, E.",
            "value": 30,
            "numPapers": 5,
            "cluster": "2",
            "index": 738,
            "weight": 1,
            "x": 287.17502071848793,
            "y": 683.0152900082343,
            "px": 271.9721368960828,
            "py": 710.2247173053679,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "Isosurface extraction using particle systems",
                "PaperDOI": "10.1109/VISUAL.1997.663930",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663930",
                "Firstpage": "495",
                "Lastpage": "498",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.",
                "AuthorNames": "Crossno, P.;Angel, E.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., New Mexico Univ., Albuquerque, NM, USA|c|;",
                "AuthorIDs": "37282576500;37284249400",
                "Dedupedauthornames": "Crossno, P.;Angel, E.",
                "References": "10.1109/VISUAL.1993.398880",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "663930",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398880"
            }
        },
        {
            "name": "Gatti, R.",
            "value": 25,
            "numPapers": 1,
            "cluster": "3",
            "index": 739,
            "weight": 1,
            "x": 361.5018055661883,
            "y": 677.2295469574415,
            "px": 326.7427860300758,
            "py": 649.1712959638511,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "Fast multiresolution surface meshing",
                "PaperDOI": "10.1109/VISUAL.1995.480805",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480805",
                "Firstpage": "135",
                "Lastpage": "142, 446",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Presents a new method for adaptive surface meshing and triangulation which controls the local level-of-detail of the surface approximation by local spectral estimates. These estimates are determined by a wavelet representation of the surface data. The basic idea is to decompose the initial data set by means of an orthogonal or semi-orthogonal tensor product wavelet transform (WT) and to analyze the resulting coefficients. In surface regions where the partial energy of the resulting coefficients is low, the polygonal approximation of the surface can be performed with larger triangles without losing too much fine-grain detail. However, since the localization of the WT is bound by the Heisenberg principle, the meshing method has to be controlled by the detail signals rather than directly by the coefficients. The dyadic scaling of the WT stimulated us to build a hierarchical meshing algorithm which transforms the initially regular data grid into a quadtree representation by rejection of unimportant mesh vertices. The optimum triangulation of the resulting quadtree cells is carried out by selection from a look-up table. The tree grows recursively, as controlled by the detail signals, which are computed from a modified inverse WT. In order to control the local level-of-detail, we introduce a new class of wavelet space filters acting as magnifying glasses on the data",
                "AuthorNames": "Gross, M.H.;Gatti, R.;Staadt, O.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;",
                "AuthorIDs": "37275694700;37355330500;37355334600",
                "Dedupedauthornames": "Gross, M.;Gatti, R.;Staadt, O.",
                "References": "10.1109/VISUAL.1994.346333",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480805",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "346333"
            }
        },
        {
            "name": "Jurrus, E.",
            "value": 47,
            "numPapers": 11,
            "cluster": "5",
            "index": 740,
            "weight": 1,
            "x": 1626.3464328402881,
            "y": -104.32506454446607,
            "px": 1488.4733668067945,
            "py": -13.443306856092144,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "Visualizing sequential patterns for text mining",
                "PaperDOI": "10.1109/INFVIS.2000.885097",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885097",
                "Firstpage": "105",
                "Lastpage": "111",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A sequential pattern in data mining is a finite series of elements such as ABCD where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment",
                "AuthorNames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "FirstAuthorAffiliation": "Pacific Northwest Lab., Richland, WA, USA|c|;;;;",
                "AuthorIDs": "37280665600;37672002300;37372586800;37725413900;37273308900",
                "Dedupedauthornames": "Pak Chung Wong;Cowley, W.;Foote, H.;Jurrus, E.;Thomas, J.",
                "References": "10.1109/INFVIS.1998.729565;10.1109/INFVIS.1998.729570;10.1109/VISUAL.1998.745302;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1999.801866;10.1109/INFVIS.1997.636791",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "885097",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "729553;729555;745302;528686;801866;636791"
            }
        },
        {
            "name": "Beddow, J.",
            "value": 27,
            "numPapers": 0,
            "cluster": "5",
            "index": 741,
            "weight": 1,
            "x": 1286.7948263851172,
            "y": 753.9937055354194,
            "px": 1242.7642599309481,
            "py": 689.096693131825,
            "node": {
                "Conference": "Vis",
                "Year": "1990",
                "PaperTitle": "Shape coding of multidimensional data on a microcomputer display",
                "PaperDOI": "10.1109/VISUAL.1990.146387",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1990.146387",
                "Firstpage": "238",
                "Lastpage": "246, 478",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The author presents a simple and flexible method of sharp coding for higher dimensional data sets that allows the database operator or the scientist quick access to promising patterns within and among records or samples. The example used is a 13-parameter set of solar wind, magnetosphere, and ground observation data collected hourly for 21 days in 1976. The software system is a prototype developed to demonstrate the glyph approach to depicting higher-dimensional data sets. The experiment was to depict all parameters simultaneously, to see if any global or local patterns emerged. This experiment proves that much more complex data can be presented for visual pattern extraction than standard methods allow",
                "AuthorNames": "Beddow, J.",
                "FirstAuthorAffiliation": "Microsimulations Res., Minneapolis, MN|c|",
                "AuthorIDs": "",
                "Dedupedauthornames": "Beddow, J.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "146387",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Taosong He",
            "value": 84,
            "numPapers": 11,
            "cluster": "2",
            "index": 742,
            "weight": 5,
            "x": -165.25491485963107,
            "y": 311.6659623119718,
            "px": -68.53042635654747,
            "py": 202.13329571692557,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "Integrated volume compression and visualization",
                "PaperDOI": "10.1109/VISUAL.1997.663900",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663900",
                "Firstpage": "329",
                "Lastpage": "336",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Volumetric data sets require enormous storage capacity even at moderate resolution levels. The excessive storage demands not only stress the capacity of the underlying storage and communications systems, but also seriously limit the speed of volume rendering due to data movement and manipulation. A novel volumetric data visualization scheme is proposed and implemented in this work that renders 2D images directly from compressed 3D data sets. The novelty of this algorithm is that rendering is performed on the compressed representation of the volumetric data without pre-decompression. As a result, the overheads associated with both data movement and rendering processing are significantly reduced. The proposed algorithm generalizes previously proposed whole-volume frequency-domain rendering schemes by first dividing the 3D data set into subcubes, transforming each subcube to a frequency-domain representation, and applying the Fourier projection theorem to produce the projected 2D images according to given viewing angles. Compared to the whole-volume approach, the subcube-based scheme not only achieves higher compression efficiency by exploiting local coherency, but also improves the quality of resultant rendering images because it approximates the occlusion effect on a subcube by subcube basis.",
                "AuthorNames": "Tzi-cker Chiueh;Chuan-Kai Yang;Taosong He;Pfister, H.;Kaufman, A.",
                "FirstAuthorAffiliation": "Center for Visual Comput., State Univ. of New York, Stony Brook, NY, USA|c|;;;;",
                "AuthorIDs": "37273336700;37615351500;37350343500;37275698100;37268052800",
                "Dedupedauthornames": "Tzi-cker Chiueh;Chuan-Kai Yang;Taosong He;Pfister, H.;Kaufman, A.",
                "References": "10.1109/VISUAL.1993.398845",
                "AuthorKeywords": "Volume Compression, Fourier Projection Theorem, Discrete Hartley Transform, Image Compositing",
                "IEEEXPLOREArticleNumberdeprecated": "663900",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398845"
            }
        },
        {
            "name": "Lichan Hong",
            "value": 80,
            "numPapers": 19,
            "cluster": "2",
            "index": 743,
            "weight": 2,
            "x": -831.915936239781,
            "y": 872.2503156648376,
            "px": -942.0344664429223,
            "py": 912.8676347386836,
            "node": {
                "Conference": "Vis",
                "Year": "1998",
                "PaperTitle": "Accelerated ray-casting for curvilinear volumes",
                "PaperDOI": "10.1109/VISUAL.1998.745310",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1998.745310",
                "Firstpage": "247",
                "Lastpage": "253",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We present an efficient and robust ray-casting algorithm for directly rendering a curvilinear volume of arbitrarily-shaped cells. We designed the algorithm to alleviate the consumption of CPU power and memory space. By incorporating the essence of the projection paradigm into the ray-casting process, we have successfully accelerated the ray traversal through the grid and data interpolations at sample points. Our algorithm also overcomes the conventional limitation requiring the cells to be convex. Application of this algorithm to several commonly-used curvilinear data sets has produced a favorable performance when compared with recently reported algorithms.",
                "AuthorNames": "Lichan Hong;Kaufman, A.",
                "FirstAuthorAffiliation": "Lucent Technol., AT&T Bell Labs., Naperville, IL, USA|c|;",
                "AuthorIDs": "37347459100;37268052800",
                "Dedupedauthornames": "Lichan Hong;Kaufman, A.",
                "References": "10.1109/VISUAL.1993.398853;10.1109/VISUAL.1992.235228;10.1109/VISUAL.1996.567606",
                "AuthorKeywords": "volume visualization, volume rendering, irregular grid, curvilinear grid, ray-casting, parallel rendering, dynamic simulation",
                "IEEEXPLOREArticleNumberdeprecated": "745310",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398853;235228;567606"
            }
        },
        {
            "name": "Wang, S.",
            "value": 73,
            "numPapers": 7,
            "cluster": "2",
            "index": 744,
            "weight": 3,
            "x": -146.45394788109562,
            "y": 383.5196277759762,
            "px": -238.47121533297303,
            "py": 433.86378333927894,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "VolVis: a diversified volume visualization system",
                "PaperDOI": "10.1109/VISUAL.1994.346340",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346340",
                "Firstpage": "31",
                "Lastpage": "38, C3",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "VolVis is a diversified, easy to use, extensible, high performance, and portable volume visualization system for scientists and engineers as well as for visualization developers and researchers. VolVis accepts as input 3D scalar volumetric data as well as 3D volume-sampled and classical geometric models. Interaction with the data is controlled by a variety of 3D input devices in an input device-independent environment. VolVis output includes navigation preview, static images, and animation sequences. A variety of volume rendering algorithms are supported ranging from fast rough approximations, to compression-domain rendering, to accurate volumetric ray tracing and radiosity, and irregular grid rendering",
                "AuthorNames": "Avila, R.;Taosong He;Lichan Hong;Kaufman, A.;Pfister, H.;Silva, C.;Sobierajski, L.;Wang, S.",
                "FirstAuthorAffiliation": "Howard Hughes Med. Inst., State Univ. of New York, Stony Brook, NY, USA|c|;;;;;;;",
                "AuthorIDs": "37323905300;37350343500;37652123600;37268052800;37275698100;38183059100;37378488600;37351033000",
                "Dedupedauthornames": "Avila, R.;Taosong He;Lichan Hong;Kaufman, A.;Pfister, H.;Silva, C.T.;Sobierajski, L.;Wang, S.",
                "References": "10.1109/VISUAL.1992.235231;10.1109/VISUAL.1993.398862;10.1109/VISUAL.1993.398854;10.1109/VISUAL.1990.146391",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346340",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235231;398862;398854;146391"
            }
        },
        {
            "name": "Wilhelms, J.",
            "value": 32,
            "numPapers": 6,
            "cluster": "2",
            "index": 745,
            "weight": 1,
            "x": 716.2619352128734,
            "y": 1622.7173805194855,
            "px": 637.7680637311365,
            "py": 1467.9157522564974,
            "node": {
                "Conference": "Vis",
                "Year": "1993",
                "PaperTitle": "Rapid exploration of curvilinear grids using direct volume rendering (Extended Abstract)",
                "PaperDOI": "10.1109/VISUAL.1993.398853",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398853",
                "Firstpage": "70",
                "Lastpage": "77",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Fast techniques for direct volume rendering over curvilinear grids (common to computational fluid dynamics and finite element analysis) are developed. Three new projection methods that use polygon-rendering hardware for speed are presented and compared with each other and with previous methods for tetrahedral grids and rectilinear grids. A simplified algorithm for visibility ordering, based on a combination of breadth-first and depth-first searches, is described. A new multi-pass blending method is described that reduces visual artifacts that are introduced by linear interpolation in hardware where exponential interpolation is needed. Visualization tools that permit rapid data banding and cycling through transfer functions, as well as region restriction, are described",
                "AuthorNames": "Van Gelder, A.;Wilhelms, J.",
                "FirstAuthorAffiliation": "Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37352962400;37828154400",
                "Dedupedauthornames": "Van Gelder, A.;Wilhelms, J.",
                "References": "10.1109/VISUAL.1992.235204;10.1109/VISUAL.1992.235228",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "398853",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235204;235228"
            }
        },
        {
            "name": "Van Gelder, A.",
            "value": 32,
            "numPapers": 6,
            "cluster": "2",
            "index": 746,
            "weight": 1,
            "x": -146.05286935851728,
            "y": 136.64094354356195,
            "px": -109.61602028570424,
            "py": 134.53732946226614,
            "node": {
                "Conference": "Vis",
                "Year": "1993",
                "PaperTitle": "Rapid exploration of curvilinear grids using direct volume rendering (Extended Abstract)",
                "PaperDOI": "10.1109/VISUAL.1993.398853",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398853",
                "Firstpage": "70",
                "Lastpage": "77",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Fast techniques for direct volume rendering over curvilinear grids (common to computational fluid dynamics and finite element analysis) are developed. Three new projection methods that use polygon-rendering hardware for speed are presented and compared with each other and with previous methods for tetrahedral grids and rectilinear grids. A simplified algorithm for visibility ordering, based on a combination of breadth-first and depth-first searches, is described. A new multi-pass blending method is described that reduces visual artifacts that are introduced by linear interpolation in hardware where exponential interpolation is needed. Visualization tools that permit rapid data banding and cycling through transfer functions, as well as region restriction, are described",
                "AuthorNames": "Van Gelder, A.;Wilhelms, J.",
                "FirstAuthorAffiliation": "Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;",
                "AuthorIDs": "37352962400;37828154400",
                "Dedupedauthornames": "Van Gelder, A.;Wilhelms, J.",
                "References": "10.1109/VISUAL.1992.235204;10.1109/VISUAL.1992.235228",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "398853",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235204;235228"
            }
        },
        {
            "name": "Dong, F.",
            "value": 0,
            "numPapers": 7,
            "cluster": "2",
            "index": 747,
            "weight": 1,
            "x": -1583.3977461120348,
            "y": -617.3019786980486,
            "px": -1411.7391068114557,
            "py": -523.7742222644132,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "An anti-aliasing technique for splatting",
                "PaperDOI": "10.1109/VISUAL.1997.663882",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663882",
                "Firstpage": "197",
                "Lastpage": "204",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Splatting is a popular direct volume rendering algorithm. However, the algorithm does not correctly render cases where the volume sampling rate is higher than the image sampling rate (e.g. more than one voxel maps into a pixel). This situation arises with orthographic projections of high-resolution volumes, as well as with perspective projections of volumes of any resolution. The result is potentially severe spatial and temporal aliasing artifacts. Some volume ray-casting algorithms avoid these artifacts by employing reconstruction kernels which vary in width as the rays diverge. Unlike ray-casting algorithms, existing splatting algorithms do not have an equivalent mechanism for avoiding these artifacts. The authors propose such a mechanism, which delivers high-quality splatted images and has the potential for a very efficient hardware implementation.",
                "AuthorNames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "FirstAuthorAffiliation": "Adv. Comput. Center for the Arts & Design, Ohio State Univ., Columbus, OH, USA|c|;;;;;",
                "AuthorIDs": "37295140400;37273119700;38341221100;;37284273900;38335291800",
                "Dedupedauthornames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "References": "10.1109/VISUAL.1996.567608;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1995.480792;10.1109/VISUAL.1993.398852",
                "AuthorKeywords": "volume rendering, splatting, direct volume rendering, resampling, reconstruction, anti-aliasing, perspective projection",
                "IEEEXPLOREArticleNumberdeprecated": "663882",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567608;398877;346331;480792;398852"
            }
        },
        {
            "name": "Krokos, M.",
            "value": 0,
            "numPapers": 7,
            "cluster": "2",
            "index": 748,
            "weight": 1,
            "x": 353.89900597203524,
            "y": 647.9364633049853,
            "px": 326.20999132766593,
            "py": 596.2351857186951,
            "node": {
                "Conference": "Vis",
                "Year": "1997",
                "PaperTitle": "An anti-aliasing technique for splatting",
                "PaperDOI": "10.1109/VISUAL.1997.663882",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1997.663882",
                "Firstpage": "197",
                "Lastpage": "204",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Splatting is a popular direct volume rendering algorithm. However, the algorithm does not correctly render cases where the volume sampling rate is higher than the image sampling rate (e.g. more than one voxel maps into a pixel). This situation arises with orthographic projections of high-resolution volumes, as well as with perspective projections of volumes of any resolution. The result is potentially severe spatial and temporal aliasing artifacts. Some volume ray-casting algorithms avoid these artifacts by employing reconstruction kernels which vary in width as the rays diverge. Unlike ray-casting algorithms, existing splatting algorithms do not have an equivalent mechanism for avoiding these artifacts. The authors propose such a mechanism, which delivers high-quality splatted images and has the potential for a very efficient hardware implementation.",
                "AuthorNames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "FirstAuthorAffiliation": "Adv. Comput. Center for the Arts & Design, Ohio State Univ., Columbus, OH, USA|c|;;;;;",
                "AuthorIDs": "37295140400;37273119700;38341221100;;37284273900;38335291800",
                "Dedupedauthornames": "Swan, J.E.;Mueller, K.;Moller, T.;Shareel, N.;Crawfis, R.;Yagel, R.",
                "References": "10.1109/VISUAL.1996.567608;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1995.480792;10.1109/VISUAL.1993.398852",
                "AuthorKeywords": "volume rendering, splatting, direct volume rendering, resampling, reconstruction, anti-aliasing, perspective projection",
                "IEEEXPLOREArticleNumberdeprecated": "663882",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567608;398877;346331;480792;398852"
            }
        },
        {
            "name": "Chi, E.H.",
            "value": 89,
            "numPapers": 15,
            "cluster": "13",
            "index": 749,
            "weight": 2,
            "x": 1115.927636746269,
            "y": 970.2958825907488,
            "px": 1047.7648494243665,
            "py": 939.9471606936829,
            "node": {
                "Conference": "InfoVis",
                "Year": "2000",
                "PaperTitle": "A taxonomy of visualization techniques using the data state reference model",
                "PaperDOI": "10.1109/INFVIS.2000.885092",
                "Link": "http://dx.doi.org/10.1109/INFVIS.2000.885092",
                "Firstpage": "69",
                "Lastpage": "75",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In previous work, researchers have attempted to construct taxonomies of information visualization techniques by examining the data domains that are compatible with these techniques. This is useful because implementers can quickly identify various techniques that can be applied to their domain of interest. However, these taxonomies do not help the implementers understand how to apply and implement these techniques. The author extends and proposes a new way to taxonomize information visualization techniques by using the Data State Model (E.H. Chi and J.T. Reidl, 1998). In fact, as the taxonomic analysis in the paper will show, many of the techniques share similar operating steps that can easily be reused. The paper shows that the Data State Model not only helps researchers understand the space of design, but also helps implementers understand how information visualization techniques can be applied more broadly",
                "AuthorNames": "Chi, Ed H.",
                "FirstAuthorAffiliation": "Xerox Palo Alto Res. Center, CA, USA|c|",
                "AuthorIDs": "37448030800",
                "Dedupedauthornames": "Chi, E.H.",
                "References": "10.1109/INFVIS.1997.636761;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1998.729560",
                "AuthorKeywords": "Information Visualization, Data State Model,Reference Model, Taxonomy, Techniques, Operators",
                "IEEEXPLOREArticleNumberdeprecated": "885092",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "636761;636792;729560"
            }
        },
        {
            "name": "Riedl, J.",
            "value": 98,
            "numPapers": 17,
            "cluster": "13",
            "index": 750,
            "weight": 7,
            "x": 1088.786818235307,
            "y": 873.9949607075841,
            "px": 1066.4759783560276,
            "py": 865.8812432909128,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "A spreadsheet approach to information visualization",
                "PaperDOI": "10.1109/INFVIS.1997.636761",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636761",
                "Firstpage": "17",
                "Lastpage": "24",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.",
                "AuthorNames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "",
                "Dedupedauthornames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "References": "10.1109/VISUAL.1996.567796;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1995.528690;10.1109/VISUAL.1995.480794;10.1109/VISUAL.1993.398859",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "636761",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567796;567746_1;528690;480794;398859"
            }
        },
        {
            "name": "Becker, B.",
            "value": 69,
            "numPapers": 23,
            "cluster": "5",
            "index": 751,
            "weight": 4,
            "x": 1056.2382836364807,
            "y": 313.41811779373336,
            "px": 1013.4064186260716,
            "py": 354.4605952055967,
            "node": {
                "Conference": "Vis",
                "Year": "1993",
                "PaperTitle": "Flow volumes for interactive vector field visualization",
                "PaperDOI": "10.1109/VISUAL.1993.398846",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1993.398846",
                "Firstpage": "19",
                "Lastpage": "24",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Flow volumes are the volumetric equivalent of stream lines. They provide more information about the vector field being visualized than do stream lines or ribbons. Presented is an efficient method for producing flow volumes, composed of transparently rendered tetrahedra, for use in an interactive system. The problems of rendering, subdivision, sorting, composing artifacts, and user interaction are dealt with. Efficiency comes from rendering only the volume of the smoke, and using hardware texturing and compositing",
                "AuthorNames": "Max, N.;Becker, B.;Crawfis, R.",
                "FirstAuthorAffiliation": "Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;;",
                "AuthorIDs": "37267387800;37363099200;37284273900",
                "Dedupedauthornames": "Max, N.;Becker, B.;Crawfis, R.",
                "References": "10.1109/VISUAL.1992.235210;10.1109/VISUAL.1992.235211",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "398846",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235210;235211"
            }
        },
        {
            "name": "Lodha, S.K.",
            "value": 87,
            "numPapers": 19,
            "cluster": "3",
            "index": 752,
            "weight": 2,
            "x": 297.3969880383825,
            "y": 518.6044772307973,
            "px": 336.7729672755534,
            "py": 502.16307120125026,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "UFLOW: visualizing uncertainty in fluid flow",
                "PaperDOI": "10.1109/VISUAL.1996.568116",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568116",
                "Firstpage": "249",
                "Lastpage": "254",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.",
                "AuthorNames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;;",
                "AuthorIDs": "37298532100;37267352000;38242145300;37351416000",
                "Dedupedauthornames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "References": "10.1109/VISUAL.1992.235199;10.1109/VISUAL.1996.568105;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1994.346315",
                "AuthorKeywords": "flow visualization, uncertainty glyphs, streamlines, rakes, flow envelopes, animation",
                "IEEEXPLOREArticleNumberdeprecated": "568116",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235199;568105;485141;346315"
            }
        },
        {
            "name": "Wernert, E.A.",
            "value": 17,
            "numPapers": 4,
            "cluster": "7",
            "index": 753,
            "weight": 1,
            "x": 1469.6709010115478,
            "y": 497.2482699536891,
            "px": 1435.1979509316304,
            "py": 483.300380052357,
            "node": {
                "Conference": "Vis",
                "Year": "1999",
                "PaperTitle": "A framework for assisted exploration with collaboration",
                "PaperDOI": "10.1109/VISUAL.1999.809893",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1999.809893",
                "Firstpage": "241",
                "Lastpage": "529",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "We approach the problem of exploring a virtual space by exploiting positional and camera-model constraints on navigation to provide extra assistance that focuses the user's explorational wanderings on the task objectives. Our specific design incorporates not only task-based constraints on the viewer's location, gaze, and viewing parameters, but also a personal \"glide\" that serves two important functions: keeping the user oriented in the navigation space, and \"pointing\" to interesting subject areas as they are approached. The guide's cues may be ignored by continuing in motion, but if the user stops, the gaze shifts automatically toward whatever the guide was interested in. This design has the serendipitous feature that it automatically incorporates a nested collaborative paradigm simply by allowing any given viewer to be seen as the \"guide\" of one or more viewers following behind; the leading automated guide (we tend to select a guide dog for this avatar) can remind the leading live human guide of interesting sites to point out, while each real human collaborator down the chain has some choices about whether to follow the local leader's hints. We have chosen VRML as our initial development medium primarily because of its portability, and we have implemented a variety of natural modes for leading and collaborating, including ways for collaborators to attach to and detach from a particular leader.",
                "AuthorNames": "Wernert, E.A.;Hanson, A.J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;",
                "AuthorIDs": "37371964800;37333439100",
                "Dedupedauthornames": "Wernert, E.A.;Hanson, A.J.",
                "References": "10.1109/VISUAL.1998.745326;10.1109/VISUAL.1997.663876",
                "AuthorKeywords": "wayfinding, locomotion, navigation, exploration, collaboration, virtual reality, VRML",
                "IEEEXPLOREArticleNumberdeprecated": "809893",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "745326;663876"
            }
        },
        {
            "name": "Sheehan, R.E.",
            "value": 74,
            "numPapers": 10,
            "cluster": "3",
            "index": 754,
            "weight": 1,
            "x": 92.05885786881932,
            "y": 1109.0550859400166,
            "px": 109.93933701523298,
            "py": 1001.5376109287722,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "UFLOW: visualizing uncertainty in fluid flow",
                "PaperDOI": "10.1109/VISUAL.1996.568116",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1996.568116",
                "Firstpage": "249",
                "Lastpage": "254",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Uncertainty or errors are introduced in fluid flow data as the data is acquired, transformed and rendered. Although researchers are aware of these uncertainties, little has been done to incorporate them in the existing visualization systems for fluid flow. In the absence of integrated presentation of data and its associated uncertainty, the analysis of the visualization is incomplete at best and may lead to inaccurate or incorrect conclusions. The article presents UFLOW-a system for visualizing uncertainty in fluid flow. Although there are several sources of uncertainties in fluid flow data, in this work, we focus on uncertainty arising from the use of different numerical algorithms for computing particle traces in a fluid flow. The techniques that we have employed to visualize uncertainty in fluid flow include uncertainty glyphs, flow envelopes, animations, priority sequences, twirling batons of trace viewpoints, and rakes. These techniques are effective in making the users aware of the effects of different integration methods and their sensitivity, especially near critical points in the flow field.",
                "AuthorNames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;;",
                "AuthorIDs": "37298532100;37267352000;38242145300;37351416000",
                "Dedupedauthornames": "Lodha, S.K.;Pang, A.;Sheehan, R.E.;Wittenbrink, C.M.",
                "References": "10.1109/VISUAL.1992.235199;10.1109/VISUAL.1996.568105;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1994.346315",
                "AuthorKeywords": "flow visualization, uncertainty glyphs, streamlines, rakes, flow envelopes, animation",
                "IEEEXPLOREArticleNumberdeprecated": "568116",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235199;568105;485141;346315"
            }
        },
        {
            "name": "Ed Huai-Hsin Chi",
            "value": 74,
            "numPapers": 13,
            "cluster": "13",
            "index": 755,
            "weight": 2,
            "x": 687.0039166819765,
            "y": 831.013874790156,
            "px": 683.6792515050628,
            "py": 805.3885165063425,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "A spreadsheet approach to information visualization",
                "PaperDOI": "10.1109/INFVIS.1997.636761",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636761",
                "Firstpage": "17",
                "Lastpage": "24",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.",
                "AuthorNames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "",
                "Dedupedauthornames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "References": "10.1109/VISUAL.1996.567796;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1995.528690;10.1109/VISUAL.1995.480794;10.1109/VISUAL.1993.398859",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "636761",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567796;567746_1;528690;480794;398859"
            }
        },
        {
            "name": "Barry, P.",
            "value": 49,
            "numPapers": 9,
            "cluster": "13",
            "index": 756,
            "weight": 2,
            "x": 905.2681096724011,
            "y": 932.7407989369818,
            "px": 911.3757394016011,
            "py": 906.254525254606,
            "node": {
                "Conference": "InfoVis",
                "Year": "1997",
                "PaperTitle": "A spreadsheet approach to information visualization",
                "PaperDOI": "10.1109/INFVIS.1997.636761",
                "Link": "http://dx.doi.org/10.1109/INFVIS.1997.636761",
                "Firstpage": "17",
                "Lastpage": "24",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "In information visualization, as the volume and complexity of the data increases, researchers require more powerful visualization tools that enable them to more effectively explore multidimensional datasets. We discuss the general utility of a novel visualization spreadsheet framework. Just as a numerical spreadsheet enables exploration of numbers, a visualization spreadsheet enables exploration of visual forms of information. We show that the spreadsheet approach facilitates certain information visualization tasks that are more difficult using other approaches. Unlike traditional spreadsheets, which store only simple data elements and formulas in each cell, a visualization spreadsheet cell can hold an entire complex data set, selection criteria, viewing specifications, and other information needed for a full-fledged information visualization. Similarly, inter-cell operations are far more complex, stretching beyond simple arithmetic and string operations to encompass a range of domain-specific operators. We have built two prototype systems that illustrate some of these research issues. The underlying approach in our work allows domain experts to define new data types and data operations, and enables visualization experts to incorporate new visualizations, viewing parameters, and view operations.",
                "AuthorNames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;",
                "AuthorIDs": "",
                "Dedupedauthornames": "Ed Huai-Hsin Chi;Barry, P.;Riedl, J.;Konstan, J.",
                "References": "10.1109/VISUAL.1996.567796;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1995.528690;10.1109/VISUAL.1995.480794;10.1109/VISUAL.1993.398859",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "636761",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "567796;567746_1;528690;480794;398859"
            }
        },
        {
            "name": "Shoop, E.",
            "value": 24,
            "numPapers": 4,
            "cluster": "13",
            "index": 757,
            "weight": 1,
            "x": 1017.5385668743628,
            "y": 883.9804622754414,
            "px": 971.2987478520294,
            "py": 853.5927541912963,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "Visualization of biological sequence similarity search results",
                "PaperDOI": "10.1109/VISUAL.1995.480794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480794",
                "Firstpage": "44",
                "Lastpage": "51, 437",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Biological sequence similarity analysis presents visualization challenges, primarily because of the massive amounts of discrete, multi dimensional data. Genomic data generated by molecular biologists is analyzed by algorithms that search for similarity to known sequences in large genomic databases. The output from these algorithms can be several thousand pages of text, and is difficult to analyze because of its length and complexity. We developed and implemented a novel graphical representation for sequence similarity search results, which visually reveals features that are difficult to find in textual reports. The method opens new possibilities in the interpretation of this discrete, multidimensional data by enabling interactive investigation of the graphical representation",
                "AuthorNames": "Chi, E.H.-H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;;;",
                "AuthorIDs": "38256270000;38285364900;37660278300;37564789400;37660264900;38475865200",
                "Dedupedauthornames": "Chi, E.H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "References": "10.1109/VISUAL.1993.398883",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480794",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398883"
            }
        },
        {
            "name": "Carlis, J.V.",
            "value": 24,
            "numPapers": 12,
            "cluster": "13",
            "index": 758,
            "weight": 1,
            "x": 813.5837248236331,
            "y": 806.5650094915045,
            "px": 802.7842642404062,
            "py": 805.9722393329469,
            "node": {
                "Conference": "VAST",
                "Year": "2013",
                "PaperTitle": "MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation",
                "PaperDOI": "10.1109/TVCG.2013.178",
                "Link": "http://dx.doi.org/10.1109/TVCG.2013.178",
                "Firstpage": "2257",
                "Lastpage": "2266",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "J",
                "Abstract": "We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.",
                "AuthorNames": "Bernard, J.;Wilhelm, N.;Kruger, B.;May, T.;Schreck, T.;Kohlhammer, J.",
                "FirstAuthorAffiliation": "Fraunhofer Inst. for Comput. Graphics Res. Darmstadt, Darmstadt, Germany|c|;;;;;",
                "AuthorIDs": ";;;;;",
                "Dedupedauthornames": "Bernard, J.;Wilhelm, N.;Kruger, B.;May, T.;Schreck, T.;Kohlhammer, J.",
                "References": "10.1109/VISUAL.1999.809865;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.120;10.1109/TVCG.2011.181;10.1109/TVCG.2011.188",
                "AuthorKeywords": "Visual analytics, exploratory search, multivariate time series, motion capture data, data aggregation, cluster glyph",
                "IEEEXPLOREArticleNumberdeprecated": "6634102",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "809865;4677350;4015416;6065019;6065026"
            }
        },
        {
            "name": "Retzel, E.",
            "value": 24,
            "numPapers": 4,
            "cluster": "13",
            "index": 759,
            "weight": 1,
            "x": 882.0386408219142,
            "y": 285.7079527026985,
            "px": 843.0669353801408,
            "py": 358.849940127849,
            "node": {
                "Conference": "Vis",
                "Year": "1995",
                "PaperTitle": "Visualization of biological sequence similarity search results",
                "PaperDOI": "10.1109/VISUAL.1995.480794",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1995.480794",
                "Firstpage": "44",
                "Lastpage": "51, 437",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Biological sequence similarity analysis presents visualization challenges, primarily because of the massive amounts of discrete, multi dimensional data. Genomic data generated by molecular biologists is analyzed by algorithms that search for similarity to known sequences in large genomic databases. The output from these algorithms can be several thousand pages of text, and is difficult to analyze because of its length and complexity. We developed and implemented a novel graphical representation for sequence similarity search results, which visually reveals features that are difficult to find in textual reports. The method opens new possibilities in the interpretation of this discrete, multidimensional data by enabling interactive investigation of the graphical representation",
                "AuthorNames": "Chi, E.H.-H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "FirstAuthorAffiliation": "Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;;;",
                "AuthorIDs": "38256270000;38285364900;37660278300;37564789400;37660264900;38475865200",
                "Dedupedauthornames": "Chi, E.H.;Barry, P.;Shoop, E.;Carlis, J.V.;Retzel, E.;Riedl, J.",
                "References": "10.1109/VISUAL.1993.398883",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "480794",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398883"
            }
        },
        {
            "name": "Volpe, C.R.",
            "value": 62,
            "numPapers": 7,
            "cluster": "14",
            "index": 760,
            "weight": 2,
            "x": 1024.6320872104734,
            "y": 710.1892245527237,
            "px": 1010.2307535202835,
            "py": 700.1105312153863,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "The stream polygon: A technique for 3D vector field visualization",
                "PaperDOI": "10.1109/VISUAL.1991.175789",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175789",
                "Firstpage": "126",
                "Lastpage": "132, 417",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "A method is presented for the visualization of 3D vector fields. The stream polygon, which is a regular, n-sided polygon, oriented normal to the local vector, can present local deformations due to rigid body rotation and both normal and shear strain. The effect of translation and scalar functions can be represented by sweeping the stream polygon along the streamline, and by appropriately varying the radius and shading the surface of the resulting streamtube. A mathematical foundation for the stream is developed, and examples with application to velocity field visualization are provided.",
                "AuthorNames": "Schroeder, W.J.;Volpe, C.R.;Lorensen, W.E.",
                "FirstAuthorAffiliation": "General Electric Corp. Res. & Dev., Schenectady, NY, USA|c|;;",
                "AuthorIDs": "37282730100;37378427600;37378427200",
                "Dedupedauthornames": "Schroeder, W.J.;Volpe, C.R.;Lorensen, W.F.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175789",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Lorensen, W.F.",
            "value": 143,
            "numPapers": 10,
            "cluster": "14",
            "index": 761,
            "weight": 3,
            "x": 907.3595113142482,
            "y": 554.1086971232,
            "px": 897.1042630455107,
            "py": 539.4607429782801,
            "node": {
                "Conference": "Vis",
                "Year": "1996",
                "PaperTitle": "The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization",
                "PaperDOI": "10.1109/VISUAL.1996.567752",
                "Link": "http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567752",
                "Firstpage": "93",
                "Lastpage": "100",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The Visualization Toolkit (vtk) is afreely available C++ class library for 30 graphics and visualization. In this paper we describe core characteristics of the toolkit. This includes a description of object-oriented models for graphics and visualization; methods for synchronizing system execution: a summary of data representation schemes; the role of C+ +; issues in portability across PC and Unix systems; and how we automatically wrap the C+ + class library with interpreted languages such as Java and Tel. We also demonstrate the capabilities of the system for scalar, vector, tensor, and other visualization techniques.",
                "AuthorNames": "Schroedel, W. J.;Martin, K. M.;Lorensen, W. E.  ",
                "FirstAuthorAffiliation": "",
                "AuthorIDs": "",
                "Dedupedauthornames": "Schroedel, W. J.;Martin, K.;Lorensen, W.F.",
                "References": "10.1109/VISUAL.1993.398878;10.1109/VISUAL.1994.346303;10.1109/VISUAL.1992.235205;10.1109/VISUAL.1995.480821",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "567746_1",
                "IEEEXploreNumberGuesseddeprecated": "x",
                "Referencesdeprecated": "398878;346303;235205;480821"
            }
        },
        {
            "name": "Hai Tao",
            "value": 29,
            "numPapers": 1,
            "cluster": "2",
            "index": 762,
            "weight": 1,
            "x": 681.0918448612902,
            "y": -0.07299609896064219,
            "px": 818.7360311488424,
            "py": -197.6093496217013,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Progressive transmission of scientific data using biorthogonal wavelet transform",
                "PaperDOI": "10.1109/VISUAL.1994.346332",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346332",
                "Firstpage": "93",
                "Lastpage": "99, C9",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "An important issue in scientific visualization systems is the management of data sets. Most data sets in scientific visualization, whether created by measurement or simulation, are usually voluminous. The goal of data management is to reduce the storage space and the access time of these data sets to speed up the visualization process. A new progressive transmission scheme using spline biorthogonal wavelet bases is proposed in this paper. By exploiting the properties of this set of wavelet bases, a fast algorithm involving only additions and subtractions is developed. Due to the multiresolutional nature of the wavelet transform, this scheme is compatible with hierarchical-structured rendering algorithms. The formula for reconstructing the functional values in a continuous volume space is given in a simple polynomial form. Lossless compression is possible, even when using floating-point numbers. This algorithm has been applied to data from a global ocean model. The lossless compression ratio is about 1.5:1. With a compression ratio of 50:1, the reconstructed data is still of good quality. Several other wavelet bases are compared with the spline biorthogonal wavelet bases. Finally the reconstructed data is visualized using various algorithms and the results are demonstrated",
                "AuthorNames": "Hai Tao;Moorhead, R.J.",
                "FirstAuthorAffiliation": "NSF Eng. Res. Center for Comput. Field Simulation, Mississippi Univ., MS, USA|c|;",
                "AuthorIDs": "37652845200;37282559500",
                "Dedupedauthornames": "Hai Tao;Moorhead, R.J.",
                "References": "10.1109/VISUAL.1993.398845",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346332",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "398845"
            }
        },
        {
            "name": "Schroeder, W.J.",
            "value": 168,
            "numPapers": 23,
            "cluster": "14",
            "index": 763,
            "weight": 1,
            "x": 817.4879472477633,
            "y": 800.5251405964975,
            "px": 829.3540989294504,
            "py": 754.6132903209703,
            "node": {
                "Conference": "Vis",
                "Year": "1994",
                "PaperTitle": "Implicit modeling of swept surfaces and volumes",
                "PaperDOI": "10.1109/VISUAL.1994.346339",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1994.346339",
                "Firstpage": "40",
                "Lastpage": "45, C4",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Swept surfaces and volumes are generated by moving a geometric model through space. Swept surfaces and volumes are important in many computer-aided design applications including geometric modeling, numerical cutter path generation, and spatial path planning. In this paper we describe a numerical algorithm to generate swept surfaces and volumes using implicit modeling techniques. The algorithm is applicable to any geometric representation for which a distance function can be computed. The algorithm also treats degenerate trajectories such as self-intersection and surface singularity. We show applications of this algorithm to maintainability design and robot path planning",
                "AuthorNames": "Schroeder, W.J.;Lorensen, W.F.;Linthicum, S.",
                "FirstAuthorAffiliation": "Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;",
                "AuthorIDs": "37282730100;37378427200;37659236800",
                "Dedupedauthornames": "Schroeder, W.J.;Lorensen, W.F.;Linthicum, S.",
                "References": "",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "346339",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": ""
            }
        },
        {
            "name": "Lucas, B.",
            "value": 99,
            "numPapers": 6,
            "cluster": "8",
            "index": 764,
            "weight": 2,
            "x": 1433.325855148735,
            "y": 455.30816911752413,
            "px": 1570.2520739827792,
            "py": 612.0163174361974,
            "node": {
                "Conference": "Vis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "Firstpage": "107",
                "Lastpage": "114",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "References": "10.1109/VISUAL.1990.146397;10.1109/VISUAL.1992.235204;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1991.175833",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "235219",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Collins, N.",
            "value": 86,
            "numPapers": 4,
            "cluster": "8",
            "index": 765,
            "weight": 1,
            "x": 1383.1482002730866,
            "y": 1271.0630449148168,
            "px": 1366.4394913047254,
            "py": 1377.473148581156,
            "node": {
                "Conference": "Vis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "Firstpage": "107",
                "Lastpage": "114",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "References": "10.1109/VISUAL.1990.146397;10.1109/VISUAL.1992.235204;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1991.175833",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "235219",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Epstein, D.A.",
            "value": 50,
            "numPapers": 4,
            "cluster": "8",
            "index": 766,
            "weight": 1,
            "x": 1437.9753794595254,
            "y": 1271.9523871028061,
            "px": 1409.030203816227,
            "py": 1379.5174853101407,
            "node": {
                "Conference": "Vis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "Firstpage": "107",
                "Lastpage": "114",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "References": "10.1109/VISUAL.1990.146397;10.1109/VISUAL.1992.235204;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1991.175833",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "235219",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Gresh, D.L.",
            "value": 99,
            "numPapers": 13,
            "cluster": "8",
            "index": 767,
            "weight": 1,
            "x": 1842.7157354827762,
            "y": 1235.8533620003457,
            "px": 1764.042824003127,
            "py": 1350.4456345719432,
            "node": {
                "Conference": "Vis",
                "Year": "2000",
                "PaperTitle": "WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data",
                "PaperDOI": "10.1109/VISUAL.2000.885739",
                "Link": "http://dx.doi.org/10.1109/VISUAL.2000.885739",
                "Firstpage": "489",
                "Lastpage": "492",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "WEAVE (Workbench Environment for Analysis and Visual Exploration) is an environment for creating interactive visualization applications. WEAVE differs from previous systems in that it provides transparent linking between custom 3D visualizations and multidimensional statistical representations, and provides interactive color brushing between all visualizations. The authors demonstrate how WEAVE can be used to rapidly prototype a biomedical application, weaving together simulation data, measurement data, and 3D anatomical data concerning the propagation of excitation in the heart. These linked statistical and custom three-dimensional visualizations of the heart can allow scientists to more effectively study the correspondence of structure and behavior.",
                "AuthorNames": "Gresh, D.L.;Rogowitz, B.E.;Winslow, R.L.;Scollan, D.F.;Yung, C.K.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;",
                "AuthorIDs": "37378534100;37332114400;37330343000;37443860200;38021754100",
                "Dedupedauthornames": "Gresh, D.L.;Rogowtiz, B.;Winslow, R.L.;Scollan, D.F.;Yung, C.K.",
                "References": "10.1109/VISUAL.1992.235219;10.1109/VISUAL.1999.809894;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1991.175794;10.1109/INFVIS.1996.559210",
                "AuthorKeywords": "visualization, medical, heart, data synthesis",
                "IEEEXPLOREArticleNumberdeprecated": "885739",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "235219;809894;528688;175794;559210"
            }
        },
        {
            "name": "McAuliffe, K.P.",
            "value": 50,
            "numPapers": 4,
            "cluster": "8",
            "index": 768,
            "weight": 1,
            "x": 1838.9140212991906,
            "y": 1226.6401550701066,
            "px": 1760.8415996837855,
            "py": 1340.7318153855863,
            "node": {
                "Conference": "Vis",
                "Year": "1992",
                "PaperTitle": "An architecture for a scientific visualization system",
                "PaperDOI": "10.1109/VISUAL.1992.235219",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1992.235219",
                "Firstpage": "107",
                "Lastpage": "114",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "The architecture of the Data Explorer, a scientific visualization system, is described. Data Explorer supports the visualization of a wide variety of data by means of a flexible set of visualization modules. A single powerful data model common to all modules allows a wide range of data types to be imported and passed between modules. There is integral support for parallelism, affecting the data model and the execution model. The visualization modules are highly interoperable, due in part to the common data model, and exemplified by the renderer. An execution model facilitates parallelization of modules and incorporates optimizations such as caching. The two-process client-server system structure consists of a user interface that communicates with an executive via a dataflow language",
                "AuthorNames": "Lucas, B.;Abram, G.D.;Collins, N.S.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "FirstAuthorAffiliation": "IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;",
                "AuthorIDs": "37388593200;37378534500;37386981900;38183190800;37378534100;37378530900",
                "Dedupedauthornames": "Lucas, B.;Abram, G.;Collins, N.;Epstein, D.A.;Gresh, D.L.;McAuliffe, K.P.",
                "References": "10.1109/VISUAL.1990.146397;10.1109/VISUAL.1992.235204;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1991.175833",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "235219",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "146397;235204;175818;175833"
            }
        },
        {
            "name": "Elvins, T.T.",
            "value": 14,
            "numPapers": 8,
            "cluster": "14",
            "index": 769,
            "weight": 1,
            "x": 1097.6873793759944,
            "y": 506.04656081275357,
            "px": 1088.6657916005581,
            "py": 485.5314630537284,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "Image handling in a multi-vendor environment",
                "PaperDOI": "10.1109/VISUAL.1991.175814",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175814",
                "Firstpage": "276",
                "Lastpage": "283",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Software developed to deal with differing image file formats, mismatched byte order and word sizes, and confusing hardcopy device interfaces is described. The SDSC Image Tool suite provides a simple, extensible, and portable mechanism for the support of a variety of common image formats so that tool-writers can concentrate on the task in hand, rather than on the quirks of a particular image file format. Users of such tools are able to work with images generated from a variety of sources, without being restricted to an arbitrary standard format. The SDSC Visualization Printing suite creates a unified view of hardcopy devices",
                "AuthorNames": "Nadeau, David R.;Elvins, T.T.;Bailey, M.J.",
                "FirstAuthorAffiliation": "San Diego Supercomput. Center, CA, USA|c|;;",
                "AuthorIDs": "37374054100;37389499500;37280473500",
                "Dedupedauthornames": "Nadeau, D.R.;Elvins, T.T.;Bailey, M.",
                "References": "10.1109/VISUAL.1991.175807",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175814",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175807"
            }
        },
        {
            "name": "Nadeau, D.R.",
            "value": 14,
            "numPapers": 6,
            "cluster": "14",
            "index": 770,
            "weight": 1,
            "x": 1108.463645261786,
            "y": 523.6141553276577,
            "px": 1094.7163604834116,
            "py": 510.12185704095117,
            "node": {
                "Conference": "Vis",
                "Year": "1991",
                "PaperTitle": "Image handling in a multi-vendor environment",
                "PaperDOI": "10.1109/VISUAL.1991.175814",
                "Link": "http://dx.doi.org/10.1109/VISUAL.1991.175814",
                "Firstpage": "276",
                "Lastpage": "283",
                "PanelKeynoteCaptstoneDemoPoster": "",
                "PapertypeCconferencepaperJjournalpaperMmiscellaneouscapstonekeynoteVASTchallengepanelposter": "C",
                "Abstract": "Software developed to deal with differing image file formats, mismatched byte order and word sizes, and confusing hardcopy device interfaces is described. The SDSC Image Tool suite provides a simple, extensible, and portable mechanism for the support of a variety of common image formats so that tool-writers can concentrate on the task in hand, rather than on the quirks of a particular image file format. Users of such tools are able to work with images generated from a variety of sources, without being restricted to an arbitrary standard format. The SDSC Visualization Printing suite creates a unified view of hardcopy devices",
                "AuthorNames": "Nadeau, David R.;Elvins, T.T.;Bailey, M.J.",
                "FirstAuthorAffiliation": "San Diego Supercomput. Center, CA, USA|c|;;",
                "AuthorIDs": "37374054100;37389499500;37280473500",
                "Dedupedauthornames": "Nadeau, D.R.;Elvins, T.T.;Bailey, M.",
                "References": "10.1109/VISUAL.1991.175807",
                "AuthorKeywords": "",
                "IEEEXPLOREArticleNumberdeprecated": "175814",
                "IEEEXploreNumberGuesseddeprecated": "",
                "Referencesdeprecated": "175807"
            }
        }
    ]
}